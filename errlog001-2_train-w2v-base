INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=hydra_train
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.distributed.utils:distributed init (rank 2): tcp://localhost:36778
[W socket.cpp:601] [c10d] The client socket has failed to connect to [localhost]:36778 (errno: 99 - Cannot assign requested address).
INFO:fairseq.distributed.utils:distributed init (rank 0): tcp://localhost:36778
INFO:fairseq.distributed.utils:distributed init (rank 3): tcp://localhost:36778
INFO:fairseq.distributed.utils:distributed init (rank 1): tcp://localhost:36778
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 3
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 2
INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0
INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:fairseq.distributed.utils:initialized host 19e0b2a19b1c as rank 0
INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:fairseq.distributed.utils:initialized host 19e0b2a19b1c as rank 1
INFO:fairseq.distributed.utils:initialized host 19e0b2a19b1c as rank 3
INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
INFO:fairseq.distributed.utils:initialized host 19e0b2a19b1c as rank 2
[2023-09-08 18:22:25,979][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:36778', 'distributed_port': 36778, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 1400000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1400000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 400000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 25000, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': True, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 0.1, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': {'_name': 'audio_pretraining', 'data': '/home/Workspace/fairseq/data', 'labels': None, 'multi_corpus_keys': None, 'multi_corpus_sampling_weights': None, 'binarized_dataset': False, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_sample_size': 250000, 'min_sample_size': 32000, 'num_batch_buckets': 0, 'tpu': False, 'text_compression_level': none, 'rebuild_batches': True, 'precompute_mask_config': None, 'post_save_script': None, 'subsample': 1.0, 'seed': 1}, 'criterion': {'_name': 'wav2vec', 'infonce': True, 'loss_weights': [0.1, 10.0], 'log_keys': ['prob_perplexity', 'code_perplexity', 'temp']}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 32000, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 400000.0, 'lr': [0.0005]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2023-09-08 18:22:27,545][fairseq_cli.train][INFO] - Wav2Vec2Model(
  (feature_extractor): ConvFeatureExtractionModel(
    (conv_layers): ModuleList(
      (0): Sequential(
        (0): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): Fp32GroupNorm(512, 512, eps=1e-05, affine=True)
        (3): GELU(approximate='none')
      )
      (1-4): 4 x Sequential(
        (0): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU(approximate='none')
      )
      (5-6): 2 x Sequential(
        (0): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)
        (1): Dropout(p=0.0, inplace=False)
        (2): GELU(approximate='none')
      )
    )
  )
  (post_extract_proj): Linear(in_features=512, out_features=768, bias=True)
  (dropout_input): Dropout(p=0.1, inplace=False)
  (dropout_features): Dropout(p=0.1, inplace=False)
  (quantizer): GumbelVectorQuantizer(
    (weight_proj): Linear(in_features=512, out_features=640, bias=True)
  )
  (project_q): Linear(in_features=256, out_features=256, bias=True)
  (encoder): TransformerEncoder(
    (pos_conv): Sequential(
      (0): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)
      (1): SamePad()
      (2): GELU(approximate='none')
    )
    (layers): ModuleList(
      (0-11): 12 x TransformerSentenceEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=768, out_features=768, bias=True)
          (v_proj): Linear(in_features=768, out_features=768, bias=True)
          (q_proj): Linear(in_features=768, out_features=768, bias=True)
          (out_proj): Linear(in_features=768, out_features=768, bias=True)
        )
        (dropout1): Dropout(p=0.1, inplace=False)
        (dropout2): Dropout(p=0.0, inplace=False)
        (dropout3): Dropout(p=0.1, inplace=False)
        (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
  )
  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (final_proj): Linear(in_features=768, out_features=256, bias=True)
)
[2023-09-08 18:22:27,548][fairseq_cli.train][INFO] - task: AudioPretrainingTask
[2023-09-08 18:22:27,548][fairseq_cli.train][INFO] - model: Wav2Vec2Model
[2023-09-08 18:22:27,548][fairseq_cli.train][INFO] - criterion: Wav2vecCriterion
[2023-09-08 18:22:27,549][fairseq_cli.train][INFO] - num. shared model params: 95,044,608 (num. trained: 95,044,608)
[2023-09-08 18:22:27,550][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-09-08 18:22:27,559][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 5474, skipped 93 samples
[2023-09-08 18:22:27,592][torch.distributed.distributed_c10d][INFO] - Added key: store_based_barrier_key:2 to store for rank: 0
[2023-09-08 18:22:27,623][torch.distributed.distributed_c10d][INFO] - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
[2023-09-08 18:22:27,624][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.1.0.bias
[2023-09-08 18:22:27,624][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.2.0.bias
[2023-09-08 18:22:27,624][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.3.0.bias
[2023-09-08 18:22:27,624][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.4.0.bias
[2023-09-08 18:22:27,624][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.5.0.bias
[2023-09-08 18:22:27,624][fairseq.trainer][INFO] - detected shared parameter: feature_extractor.conv_layers.0.0.bias <- feature_extractor.conv_layers.6.0.bias
[2023-09-08 18:22:27,718][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2023-09-08 18:22:27,718][fairseq.utils][INFO] - rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-09-08 18:22:27,718][fairseq.utils][INFO] - rank   1: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-09-08 18:22:27,718][fairseq.utils][INFO] - rank   2: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-09-08 18:22:27,718][fairseq.utils][INFO] - rank   3: capabilities =  8.9  ; total memory = 23.648 GB ; name = NVIDIA GeForce RTX 4090                 
[2023-09-08 18:22:27,718][fairseq.utils][INFO] - ***********************CUDA enviroments for all 4 workers***********************
[2023-09-08 18:22:27,718][fairseq_cli.train][INFO] - training on 4 devices (GPUs/TPUs)
[2023-09-08 18:22:27,719][fairseq_cli.train][INFO] - max tokens per device = 1400000 and max sentences per device = None
[2023-09-08 18:22:27,719][fairseq.trainer][INFO] - Preparing to load checkpoint checkpoints/checkpoint_last.pt
[2023-09-08 18:22:27,719][fairseq.trainer][INFO] - No existing checkpoint found checkpoints/checkpoint_last.pt
[2023-09-08 18:22:27,720][fairseq.trainer][INFO] - loading train data for epoch 1
[2023-09-08 18:22:27,989][fairseq.data.audio.raw_audio_dataset][INFO] - loaded 280531, skipped 710 samples
[2023-09-08 18:22:28,062][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-09-08 18:22:28,062][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-09-08 18:22:28,063][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = True
[2023-09-08 18:22:28,063][fairseq.tasks.fairseq_task][INFO] - batches will be rebuilt for each epoch
[2023-09-08 18:22:28,063][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
[2023-09-08 18:22:28,364][fairseq_cli.train][INFO] - begin dry-run validation on "valid" subset
[2023-09-08 18:22:28,365][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-09-08 18:22:28,366][fairseq.tasks.fairseq_task][INFO] - reuse_dataloader = True
[2023-09-08 18:22:28,366][fairseq.tasks.fairseq_task][INFO] - rebuild_batches = True
[2023-09-08 18:22:28,366][fairseq.tasks.fairseq_task][INFO] - batches will be rebuilt for each epoch
[2023-09-08 18:22:28,366][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 1
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
[2023-09-08 18:23:11,168][fairseq.data.iterators][INFO] - grouped total_num_itrs = 11116
[2023-09-08 18:23:11,172][fairseq.trainer][INFO] - begin training epoch 1
[2023-09-08 18:23:11,172][fairseq_cli.train][INFO] - Start iterating over samples
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
INFO:fairseq.tasks.text_to_speech:Please install tensorboardX: pip install tensorboardX
[2023-09-08 18:24:30,453][train_inner][INFO] - {"epoch": 1, "update": 0.018, "loss": "9.429", "ntokens": "7094.2", "nsentences": "25.26", "prob_perplexity": "377.385", "code_perplexity": "358.5", "temp": "1.999", "loss_0": "6.683", "loss_1": "0.059", "loss_2": "2.687", "accuracy": "0.01182", "wps": "22605.7", "ups": "3.19", "wpb": "7094.2", "bsz": "25.3", "num_updates": "200", "lr": "3.125e-06", "gnorm": "1.49", "loss_scale": "128", "train_wall": "64", "gb_free": "18", "wall": "123"}
[2023-09-08 18:25:31,628][train_inner][INFO] - {"epoch": 1, "update": 0.036, "loss": "7.014", "ntokens": "7021.21", "nsentences": "25.85", "prob_perplexity": "522.315", "code_perplexity": "501.693", "temp": "1.997", "loss_0": "6.661", "loss_1": "0.026", "loss_2": "0.326", "accuracy": "0.01196", "wps": "22954.6", "ups": "3.27", "wpb": "7021.2", "bsz": "25.9", "num_updates": "400", "lr": "6.25e-06", "gnorm": "0.17", "loss_scale": "128", "train_wall": "61", "gb_free": "17.9", "wall": "184"}
[2023-09-08 18:26:32,651][train_inner][INFO] - {"epoch": 1, "update": 0.054, "loss": "6.732", "ntokens": "7044.21", "nsentences": "25.48", "prob_perplexity": "573.148", "code_perplexity": "552.777", "temp": "1.995", "loss_0": "6.659", "loss_1": "0.015", "loss_2": "0.058", "accuracy": "0.01193", "wps": "23087.4", "ups": "3.28", "wpb": "7044.2", "bsz": "25.5", "num_updates": "600", "lr": "9.375e-06", "gnorm": "0.055", "loss_scale": "128", "train_wall": "61", "gb_free": "15.9", "wall": "245"}
[2023-09-08 18:27:34,896][train_inner][INFO] - {"epoch": 1, "update": 0.072, "loss": "6.692", "ntokens": "7047.94", "nsentences": "25.235", "prob_perplexity": "584.994", "code_perplexity": "564.062", "temp": "1.993", "loss_0": "6.659", "loss_1": "0.012", "loss_2": "0.021", "accuracy": "0.01195", "wps": "22646.2", "ups": "3.21", "wpb": "7047.9", "bsz": "25.2", "num_updates": "800", "lr": "1.25e-05", "gnorm": "0.041", "loss_scale": "128", "train_wall": "62", "gb_free": "17.2", "wall": "307"}
[2023-09-08 18:28:37,508][train_inner][INFO] - {"epoch": 1, "update": 0.09, "loss": "6.683", "ntokens": "7038.48", "nsentences": "25.84", "prob_perplexity": "587.232", "code_perplexity": "566.064", "temp": "1.991", "loss_0": "6.659", "loss_1": "0.012", "loss_2": "0.012", "accuracy": "0.0118", "wps": "22482.8", "ups": "3.19", "wpb": "7038.5", "bsz": "25.8", "num_updates": "1000", "lr": "1.5625e-05", "gnorm": "0.035", "loss_scale": "128", "train_wall": "62", "gb_free": "16", "wall": "370"}
[2023-09-08 18:29:40,048][train_inner][INFO] - {"epoch": 1, "update": 0.108, "loss": "6.679", "ntokens": "7038.74", "nsentences": "25.28", "prob_perplexity": "587.616", "code_perplexity": "564.439", "temp": "1.989", "loss_0": "6.658", "loss_1": "0.012", "loss_2": "0.009", "accuracy": "0.01192", "wps": "22510.1", "ups": "3.2", "wpb": "7038.7", "bsz": "25.3", "num_updates": "1200", "lr": "1.875e-05", "gnorm": "0.032", "loss_scale": "128", "train_wall": "62", "gb_free": "15.5", "wall": "432"}
[2023-09-08 18:30:41,530][train_inner][INFO] - {"epoch": 1, "update": 0.126, "loss": "6.677", "ntokens": "6998.23", "nsentences": "25.025", "prob_perplexity": "588.004", "code_perplexity": "563.979", "temp": "1.987", "loss_0": "6.658", "loss_1": "0.012", "loss_2": "0.007", "accuracy": "0.0119", "wps": "22765.3", "ups": "3.25", "wpb": "6998.2", "bsz": "25", "num_updates": "1400", "lr": "2.1875e-05", "gnorm": "0.03", "loss_scale": "128", "train_wall": "61", "gb_free": "17.2", "wall": "494"}
[2023-09-08 18:31:44,878][train_inner][INFO] - {"epoch": 1, "update": 0.144, "loss": "6.675", "ntokens": "7126.84", "nsentences": "25.3", "prob_perplexity": "588.947", "code_perplexity": "566.821", "temp": "1.985", "loss_0": "6.658", "loss_1": "0.011", "loss_2": "0.006", "accuracy": "0.012", "wps": "22500.8", "ups": "3.16", "wpb": "7126.8", "bsz": "25.3", "num_updates": "1600", "lr": "2.5e-05", "gnorm": "0.031", "loss_scale": "128", "train_wall": "63", "gb_free": "17.4", "wall": "557"}
[2023-09-08 18:32:46,814][train_inner][INFO] - {"epoch": 1, "update": 0.162, "loss": "6.461", "ntokens": "7067.05", "nsentences": "25.205", "prob_perplexity": "405.563", "code_perplexity": "390.44", "temp": "1.983", "loss_0": "6.4", "loss_1": "0.053", "loss_2": "0.008", "accuracy": "0.02518", "wps": "22820.9", "ups": "3.23", "wpb": "7067", "bsz": "25.2", "num_updates": "1800", "lr": "2.8125e-05", "gnorm": "0.61", "loss_scale": "128", "train_wall": "61", "gb_free": "19.4", "wall": "619"}
[2023-09-08 18:33:48,731][train_inner][INFO] - {"epoch": 1, "update": 0.18, "loss": "6.162", "ntokens": "7063.7", "nsentences": "24.905", "prob_perplexity": "228.685", "code_perplexity": "222.94", "temp": "1.981", "loss_0": "6.057", "loss_1": "0.093", "loss_2": "0.013", "accuracy": "0.04643", "wps": "22816.7", "ups": "3.23", "wpb": "7063.7", "bsz": "24.9", "num_updates": "2000", "lr": "3.125e-05", "gnorm": "1.105", "loss_scale": "128", "train_wall": "61", "gb_free": "18.1", "wall": "681"}
[2023-09-08 18:34:20,496][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-09-08 18:34:52,285][train_inner][INFO] - {"epoch": 1, "update": 0.198, "loss": "5.968", "ntokens": "7130.88", "nsentences": "24.74", "prob_perplexity": "120.855", "code_perplexity": "118.389", "temp": "1.979", "loss_0": "5.836", "loss_1": "0.117", "loss_2": "0.015", "accuracy": "0.0782", "wps": "22440.8", "ups": "3.15", "wpb": "7130.9", "bsz": "24.7", "num_updates": "2200", "lr": "3.4375e-05", "gnorm": "1.212", "loss_scale": "64", "train_wall": "63", "gb_free": "15.7", "wall": "745"}
[2023-09-08 18:35:54,287][train_inner][INFO] - {"epoch": 1, "update": 0.216, "loss": "5.771", "ntokens": "7063.86", "nsentences": "24.92", "prob_perplexity": "69.884", "code_perplexity": "68.934", "temp": "1.977", "loss_0": "5.626", "loss_1": "0.129", "loss_2": "0.017", "accuracy": "0.12749", "wps": "22786.1", "ups": "3.23", "wpb": "7063.9", "bsz": "24.9", "num_updates": "2400", "lr": "3.75e-05", "gnorm": "1.314", "loss_scale": "64", "train_wall": "61", "gb_free": "15.7", "wall": "807"}
[2023-09-08 18:36:41,627][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-09-08 18:36:57,370][train_inner][INFO] - {"epoch": 1, "update": 0.234, "loss": "5.594", "ntokens": "7091.03", "nsentences": "25.16", "prob_perplexity": "52.49", "code_perplexity": "52.037", "temp": "1.975", "loss_0": "5.443", "loss_1": "0.132", "loss_2": "0.018", "accuracy": "0.16351", "wps": "22481.7", "ups": "3.17", "wpb": "7091", "bsz": "25.2", "num_updates": "2600", "lr": "4.0625e-05", "gnorm": "1.35", "loss_scale": "32", "train_wall": "63", "gb_free": "15.9", "wall": "870"}
[2023-09-08 18:38:00,468][train_inner][INFO] - {"epoch": 1, "update": 0.252, "loss": "5.496", "ntokens": "7073.98", "nsentences": "25.135", "prob_perplexity": "46.307", "code_perplexity": "46.04", "temp": "1.973", "loss_0": "5.344", "loss_1": "0.134", "loss_2": "0.018", "accuracy": "0.18022", "wps": "22422.5", "ups": "3.17", "wpb": "7074", "bsz": "25.1", "num_updates": "2800", "lr": "4.375e-05", "gnorm": "1.372", "loss_scale": "32", "train_wall": "63", "gb_free": "15.7", "wall": "933"}
[2023-09-08 18:39:03,949][train_inner][INFO] - {"epoch": 1, "update": 0.27, "loss": "5.419", "ntokens": "7065.75", "nsentences": "25.625", "prob_perplexity": "46.371", "code_perplexity": "46.156", "temp": "1.971", "loss_0": "5.268", "loss_1": "0.134", "loss_2": "0.017", "accuracy": "0.18797", "wps": "22261.2", "ups": "3.15", "wpb": "7065.8", "bsz": "25.6", "num_updates": "3000", "lr": "4.6875e-05", "gnorm": "1.323", "loss_scale": "32", "train_wall": "63", "gb_free": "17.6", "wall": "996"}
[2023-09-08 18:40:06,272][train_inner][INFO] - {"epoch": 1, "update": 0.288, "loss": "5.336", "ntokens": "7043.02", "nsentences": "25.58", "prob_perplexity": "46.943", "code_perplexity": "46.764", "temp": "1.969", "loss_0": "5.185", "loss_1": "0.134", "loss_2": "0.017", "accuracy": "0.19583", "wps": "22601.9", "ups": "3.21", "wpb": "7043", "bsz": "25.6", "num_updates": "3200", "lr": "5e-05", "gnorm": "1.293", "loss_scale": "32", "train_wall": "62", "gb_free": "16.2", "wall": "1059"}
[2023-09-08 18:41:11,212][train_inner][INFO] - {"epoch": 1, "update": 0.306, "loss": "5.277", "ntokens": "7101.1", "nsentences": "24.775", "prob_perplexity": "47.13", "code_perplexity": "46.971", "temp": "1.967", "loss_0": "5.127", "loss_1": "0.134", "loss_2": "0.017", "accuracy": "0.20132", "wps": "21869.8", "ups": "3.08", "wpb": "7101.1", "bsz": "24.8", "num_updates": "3400", "lr": "5.3125e-05", "gnorm": "1.254", "loss_scale": "32", "train_wall": "64", "gb_free": "17.9", "wall": "1123"}
[2023-09-08 18:42:14,185][train_inner][INFO] - {"epoch": 1, "update": 0.324, "loss": "5.207", "ntokens": "7060.45", "nsentences": "25.76", "prob_perplexity": "47.85", "code_perplexity": "47.714", "temp": "1.965", "loss_0": "5.056", "loss_1": "0.133", "loss_2": "0.017", "accuracy": "0.20885", "wps": "22424", "ups": "3.18", "wpb": "7060.5", "bsz": "25.8", "num_updates": "3600", "lr": "5.625e-05", "gnorm": "1.199", "loss_scale": "32", "train_wall": "62", "gb_free": "17.2", "wall": "1186"}
[2023-09-08 18:43:16,613][train_inner][INFO] - {"epoch": 1, "update": 0.342, "loss": "5.165", "ntokens": "7018.91", "nsentences": "25.405", "prob_perplexity": "48.232", "code_perplexity": "48.101", "temp": "1.963", "loss_0": "5.014", "loss_1": "0.133", "loss_2": "0.018", "accuracy": "0.2128", "wps": "22486.5", "ups": "3.2", "wpb": "7018.9", "bsz": "25.4", "num_updates": "3800", "lr": "5.9375e-05", "gnorm": "1.168", "loss_scale": "32", "train_wall": "62", "gb_free": "19", "wall": "1249"}
[2023-09-08 18:44:19,278][train_inner][INFO] - {"epoch": 1, "update": 0.36, "loss": "5.128", "ntokens": "7097.6", "nsentences": "25.195", "prob_perplexity": "48.518", "code_perplexity": "48.39", "temp": "1.961", "loss_0": "4.977", "loss_1": "0.133", "loss_2": "0.018", "accuracy": "0.21693", "wps": "22652.7", "ups": "3.19", "wpb": "7097.6", "bsz": "25.2", "num_updates": "4000", "lr": "6.25e-05", "gnorm": "1.091", "loss_scale": "32", "train_wall": "62", "gb_free": "17.3", "wall": "1312"}
[2023-09-08 18:45:23,951][train_inner][INFO] - {"epoch": 1, "update": 0.378, "loss": "5.084", "ntokens": "7085.37", "nsentences": "24.255", "prob_perplexity": "49.401", "code_perplexity": "49.284", "temp": "1.959", "loss_0": "4.933", "loss_1": "0.133", "loss_2": "0.018", "accuracy": "0.22204", "wps": "21911.7", "ups": "3.09", "wpb": "7085.4", "bsz": "24.3", "num_updates": "4200", "lr": "6.5625e-05", "gnorm": "1.075", "loss_scale": "32", "train_wall": "64", "gb_free": "16", "wall": "1376"}
[2023-09-08 18:46:26,861][train_inner][INFO] - {"epoch": 1, "update": 0.396, "loss": "5.054", "ntokens": "7109.94", "nsentences": "25.695", "prob_perplexity": "50.049", "code_perplexity": "49.941", "temp": "1.957", "loss_0": "4.902", "loss_1": "0.133", "loss_2": "0.018", "accuracy": "0.22576", "wps": "22603.8", "ups": "3.18", "wpb": "7109.9", "bsz": "25.7", "num_updates": "4400", "lr": "6.875e-05", "gnorm": "1.051", "loss_scale": "32", "train_wall": "62", "gb_free": "17.1", "wall": "1439"}
[2023-09-08 18:47:29,805][train_inner][INFO] - {"epoch": 1, "update": 0.414, "loss": "5.015", "ntokens": "7075.65", "nsentences": "25.015", "prob_perplexity": "50.939", "code_perplexity": "50.843", "temp": "1.956", "loss_0": "4.864", "loss_1": "0.133", "loss_2": "0.018", "accuracy": "0.22821", "wps": "22482.4", "ups": "3.18", "wpb": "7075.7", "bsz": "25", "num_updates": "4600", "lr": "7.1875e-05", "gnorm": "1.005", "loss_scale": "32", "train_wall": "62", "gb_free": "15.6", "wall": "1502"}
[2023-09-08 18:48:01,212][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2023-09-08 18:48:32,839][train_inner][INFO] - {"epoch": 1, "update": 0.432, "loss": "4.913", "ntokens": "7085.99", "nsentences": "25.285", "prob_perplexity": "51.805", "code_perplexity": "51.718", "temp": "1.954", "loss_0": "4.761", "loss_1": "0.133", "loss_2": "0.019", "accuracy": "0.24497", "wps": "22483.3", "ups": "3.17", "wpb": "7086", "bsz": "25.3", "num_updates": "4800", "lr": "7.5e-05", "gnorm": "1.027", "loss_scale": "16", "train_wall": "63", "gb_free": "16", "wall": "1565"}
[2023-09-08 18:49:35,902][train_inner][INFO] - {"epoch": 1, "update": 0.45, "loss": "4.896", "ntokens": "7138.11", "nsentences": "24.325", "prob_perplexity": "53.05", "code_perplexity": "52.96", "temp": "1.952", "loss_0": "4.745", "loss_1": "0.132", "loss_2": "0.019", "accuracy": "0.24443", "wps": "22638.5", "ups": "3.17", "wpb": "7138.1", "bsz": "24.3", "num_updates": "5000", "lr": "7.8125e-05", "gnorm": "0.992", "loss_scale": "16", "train_wall": "63", "gb_free": "17.9", "wall": "1628"}
[2023-09-08 18:50:38,640][train_inner][INFO] - {"epoch": 1, "update": 0.468, "loss": "4.858", "ntokens": "7073.62", "nsentences": "25.055", "prob_perplexity": "53.486", "code_perplexity": "53.403", "temp": "1.95", "loss_0": "4.706", "loss_1": "0.132", "loss_2": "0.019", "accuracy": "0.24827", "wps": "22549.9", "ups": "3.19", "wpb": "7073.6", "bsz": "25.1", "num_updates": "5200", "lr": "8.125e-05", "gnorm": "0.963", "loss_scale": "16", "train_wall": "62", "gb_free": "16.2", "wall": "1691"}
[2023-09-08 18:51:39,972][train_inner][INFO] - {"epoch": 1, "update": 0.486, "loss": "4.81", "ntokens": "7070.76", "nsentences": "26", "prob_perplexity": "53.863", "code_perplexity": "53.792", "temp": "1.948", "loss_0": "4.659", "loss_1": "0.132", "loss_2": "0.019", "accuracy": "0.2554", "wps": "23057.9", "ups": "3.26", "wpb": "7070.8", "bsz": "26", "num_updates": "5400", "lr": "8.4375e-05", "gnorm": "0.95", "loss_scale": "16", "train_wall": "61", "gb_free": "17.9", "wall": "1752"}
[2023-09-08 18:52:42,840][train_inner][INFO] - {"epoch": 1, "update": 0.504, "loss": "4.802", "ntokens": "7064.06", "nsentences": "25.425", "prob_perplexity": "54.327", "code_perplexity": "54.257", "temp": "1.946", "loss_0": "4.65", "loss_1": "0.132", "loss_2": "0.02", "accuracy": "0.25477", "wps": "22472.7", "ups": "3.18", "wpb": "7064.1", "bsz": "25.4", "num_updates": "5600", "lr": "8.75e-05", "gnorm": "0.912", "loss_scale": "16", "train_wall": "62", "gb_free": "17.4", "wall": "1815"}
[2023-09-08 18:53:44,969][train_inner][INFO] - {"epoch": 1, "update": 0.522, "loss": "4.785", "ntokens": "7102.47", "nsentences": "25", "prob_perplexity": "55.261", "code_perplexity": "55.192", "temp": "1.944", "loss_0": "4.633", "loss_1": "0.132", "loss_2": "0.02", "accuracy": "0.25543", "wps": "22864", "ups": "3.22", "wpb": "7102.5", "bsz": "25", "num_updates": "5800", "lr": "9.0625e-05", "gnorm": "0.895", "loss_scale": "16", "train_wall": "62", "gb_free": "17.4", "wall": "1877"}
[2023-09-08 18:54:47,133][train_inner][INFO] - {"epoch": 1, "update": 0.54, "loss": "4.771", "ntokens": "7085.78", "nsentences": "25.885", "prob_perplexity": "55.775", "code_perplexity": "55.706", "temp": "1.942", "loss_0": "4.62", "loss_1": "0.132", "loss_2": "0.02", "accuracy": "0.25777", "wps": "22797.3", "ups": "3.22", "wpb": "7085.8", "bsz": "25.9", "num_updates": "6000", "lr": "9.375e-05", "gnorm": "0.868", "loss_scale": "16", "train_wall": "62", "gb_free": "16.7", "wall": "1939"}
[2023-09-08 18:55:49,932][train_inner][INFO] - {"epoch": 1, "update": 0.558, "loss": "4.737", "ntokens": "7053.07", "nsentences": "25.25", "prob_perplexity": "56.277", "code_perplexity": "56.21", "temp": "1.94", "loss_0": "4.585", "loss_1": "0.132", "loss_2": "0.02", "accuracy": "0.26076", "wps": "22462.5", "ups": "3.18", "wpb": "7053.1", "bsz": "25.2", "num_updates": "6200", "lr": "9.6875e-05", "gnorm": "0.843", "loss_scale": "16", "train_wall": "62", "gb_free": "17.8", "wall": "2002"}
[2023-09-08 18:56:51,967][train_inner][INFO] - {"epoch": 1, "update": 0.576, "loss": "4.744", "ntokens": "7062.26", "nsentences": "24.625", "prob_perplexity": "56.701", "code_perplexity": "56.644", "temp": "1.938", "loss_0": "4.593", "loss_1": "0.131", "loss_2": "0.02", "accuracy": "0.2585", "wps": "22769.1", "ups": "3.22", "wpb": "7062.3", "bsz": "24.6", "num_updates": "6400", "lr": "0.0001", "gnorm": "0.812", "loss_scale": "16", "train_wall": "62", "gb_free": "16.2", "wall": "2064"}
[2023-09-08 18:56:56,491][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2023-09-08 18:57:54,608][train_inner][INFO] - {"epoch": 1, "update": 0.594, "loss": "4.72", "ntokens": "7029.23", "nsentences": "25.37", "prob_perplexity": "57.348", "code_perplexity": "57.285", "temp": "1.936", "loss_0": "4.568", "loss_1": "0.131", "loss_2": "0.02", "accuracy": "0.26033", "wps": "22443.2", "ups": "3.19", "wpb": "7029.2", "bsz": "25.4", "num_updates": "6600", "lr": "0.000103125", "gnorm": "0.804", "loss_scale": "8", "train_wall": "62", "gb_free": "15.7", "wall": "2127"}
[2023-09-08 18:58:58,107][train_inner][INFO] - {"epoch": 1, "update": 0.612, "loss": "4.72", "ntokens": "7120.91", "nsentences": "24.5", "prob_perplexity": "57.394", "code_perplexity": "57.339", "temp": "1.934", "loss_0": "4.568", "loss_1": "0.131", "loss_2": "0.021", "accuracy": "0.26068", "wps": "22428.7", "ups": "3.15", "wpb": "7120.9", "bsz": "24.5", "num_updates": "6800", "lr": "0.00010625", "gnorm": "0.799", "loss_scale": "8", "train_wall": "63", "gb_free": "17.2", "wall": "2190"}
[2023-09-08 19:00:00,642][train_inner][INFO] - {"epoch": 1, "update": 0.63, "loss": "4.686", "ntokens": "7005.27", "nsentences": "25.885", "prob_perplexity": "57.909", "code_perplexity": "57.854", "temp": "1.932", "loss_0": "4.534", "loss_1": "0.131", "loss_2": "0.021", "accuracy": "0.26502", "wps": "22404.4", "ups": "3.2", "wpb": "7005.3", "bsz": "25.9", "num_updates": "7000", "lr": "0.000109375", "gnorm": "0.806", "loss_scale": "8", "train_wall": "62", "gb_free": "17.5", "wall": "2253"}
[2023-09-08 19:01:03,118][train_inner][INFO] - {"epoch": 1, "update": 0.648, "loss": "4.687", "ntokens": "7045.2", "nsentences": "25.31", "prob_perplexity": "58.115", "code_perplexity": "58.063", "temp": "1.93", "loss_0": "4.535", "loss_1": "0.131", "loss_2": "0.021", "accuracy": "0.26402", "wps": "22553.5", "ups": "3.2", "wpb": "7045.2", "bsz": "25.3", "num_updates": "7200", "lr": "0.0001125", "gnorm": "0.761", "loss_scale": "8", "train_wall": "62", "gb_free": "15.7", "wall": "2315"}
[2023-09-08 19:02:06,768][train_inner][INFO] - {"epoch": 1, "update": 0.666, "loss": "4.669", "ntokens": "7079.42", "nsentences": "24.86", "prob_perplexity": "58.612", "code_perplexity": "58.556", "temp": "1.928", "loss_0": "4.517", "loss_1": "0.131", "loss_2": "0.021", "accuracy": "0.26525", "wps": "22245.2", "ups": "3.14", "wpb": "7079.4", "bsz": "24.9", "num_updates": "7400", "lr": "0.000115625", "gnorm": "0.748", "loss_scale": "8", "train_wall": "63", "gb_free": "15.6", "wall": "2379"}
[2023-09-08 19:03:09,503][train_inner][INFO] - {"epoch": 1, "update": 0.684, "loss": "4.641", "ntokens": "7118.75", "nsentences": "25.145", "prob_perplexity": "59.333", "code_perplexity": "59.276", "temp": "1.926", "loss_0": "4.489", "loss_1": "0.131", "loss_2": "0.022", "accuracy": "0.27045", "wps": "22694.7", "ups": "3.19", "wpb": "7118.8", "bsz": "25.1", "num_updates": "7600", "lr": "0.00011875", "gnorm": "0.762", "loss_scale": "8", "train_wall": "62", "gb_free": "16.3", "wall": "2442"}
[2023-09-08 19:04:12,299][train_inner][INFO] - {"epoch": 1, "update": 0.702, "loss": "4.643", "ntokens": "7028.43", "nsentences": "25.95", "prob_perplexity": "59.69", "code_perplexity": "59.64", "temp": "1.924", "loss_0": "4.49", "loss_1": "0.131", "loss_2": "0.022", "accuracy": "0.26953", "wps": "22385.4", "ups": "3.18", "wpb": "7028.4", "bsz": "25.9", "num_updates": "7800", "lr": "0.000121875", "gnorm": "0.729", "loss_scale": "8", "train_wall": "62", "gb_free": "17.7", "wall": "2505"}
[2023-09-08 19:05:14,403][train_inner][INFO] - {"epoch": 1, "update": 0.72, "loss": "4.629", "ntokens": "7070.03", "nsentences": "25.295", "prob_perplexity": "60.158", "code_perplexity": "60.103", "temp": "1.923", "loss_0": "4.476", "loss_1": "0.131", "loss_2": "0.022", "accuracy": "0.26946", "wps": "22768.4", "ups": "3.22", "wpb": "7070", "bsz": "25.3", "num_updates": "8000", "lr": "0.000125", "gnorm": "0.736", "loss_scale": "8", "train_wall": "62", "gb_free": "17.8", "wall": "2567"}
[2023-09-08 19:06:17,035][train_inner][INFO] - {"epoch": 1, "update": 0.738, "loss": "4.622", "ntokens": "7083.9", "nsentences": "24.945", "prob_perplexity": "60.698", "code_perplexity": "60.65", "temp": "1.921", "loss_0": "4.469", "loss_1": "0.131", "loss_2": "0.023", "accuracy": "0.27064", "wps": "22620.7", "ups": "3.19", "wpb": "7083.9", "bsz": "24.9", "num_updates": "8200", "lr": "0.000128125", "gnorm": "0.722", "loss_scale": "8", "train_wall": "62", "gb_free": "16.1", "wall": "2629"}
[2023-09-08 19:07:18,814][train_inner][INFO] - {"epoch": 1, "update": 0.756, "loss": "4.582", "ntokens": "7045.37", "nsentences": "25.425", "prob_perplexity": "60.779", "code_perplexity": "60.73", "temp": "1.919", "loss_0": "4.428", "loss_1": "0.131", "loss_2": "0.023", "accuracy": "0.27686", "wps": "22808.6", "ups": "3.24", "wpb": "7045.4", "bsz": "25.4", "num_updates": "8400", "lr": "0.00013125", "gnorm": "0.706", "loss_scale": "8", "train_wall": "61", "gb_free": "16", "wall": "2691"}
[2023-09-08 19:08:20,897][train_inner][INFO] - {"epoch": 1, "update": 0.774, "loss": "4.6", "ntokens": "7073.61", "nsentences": "24.85", "prob_perplexity": "60.689", "code_perplexity": "60.636", "temp": "1.917", "loss_0": "4.446", "loss_1": "0.131", "loss_2": "0.023", "accuracy": "0.27415", "wps": "22788", "ups": "3.22", "wpb": "7073.6", "bsz": "24.9", "num_updates": "8600", "lr": "0.000134375", "gnorm": "0.703", "loss_scale": "8", "train_wall": "62", "gb_free": "15.7", "wall": "2753"}
[2023-09-08 19:09:24,168][train_inner][INFO] - {"epoch": 1, "update": 0.792, "loss": "4.582", "ntokens": "7097.23", "nsentences": "24.865", "prob_perplexity": "61.589", "code_perplexity": "61.535", "temp": "1.915", "loss_0": "4.428", "loss_1": "0.13", "loss_2": "0.023", "accuracy": "0.27515", "wps": "22434.4", "ups": "3.16", "wpb": "7097.2", "bsz": "24.9", "num_updates": "8800", "lr": "0.0001375", "gnorm": "0.699", "loss_scale": "8", "train_wall": "63", "gb_free": "16.3", "wall": "2816"}
[2023-09-08 19:10:02,910][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-09-08 19:10:27,372][train_inner][INFO] - {"epoch": 1, "update": 0.81, "loss": "4.582", "ntokens": "7056.94", "nsentences": "25.635", "prob_perplexity": "62.074", "code_perplexity": "62.019", "temp": "1.913", "loss_0": "4.428", "loss_1": "0.13", "loss_2": "0.024", "accuracy": "0.27471", "wps": "22330.9", "ups": "3.16", "wpb": "7056.9", "bsz": "25.6", "num_updates": "9000", "lr": "0.000140625", "gnorm": "0.719", "loss_scale": "4", "train_wall": "63", "gb_free": "16.2", "wall": "2880"}
[2023-09-08 19:11:28,327][train_inner][INFO] - {"epoch": 1, "update": 0.828, "loss": "4.561", "ntokens": "7062.86", "nsentences": "24.905", "prob_perplexity": "61.997", "code_perplexity": "61.943", "temp": "1.911", "loss_0": "4.407", "loss_1": "0.13", "loss_2": "0.024", "accuracy": "0.27847", "wps": "23174.1", "ups": "3.28", "wpb": "7062.9", "bsz": "24.9", "num_updates": "9200", "lr": "0.00014375", "gnorm": "0.671", "loss_scale": "4", "train_wall": "60", "gb_free": "17.8", "wall": "2941"}
[2023-09-08 19:12:31,423][train_inner][INFO] - {"epoch": 1, "update": 0.846, "loss": "4.57", "ntokens": "7115.82", "nsentences": "24.995", "prob_perplexity": "62.249", "code_perplexity": "62.202", "temp": "1.909", "loss_0": "4.415", "loss_1": "0.13", "loss_2": "0.025", "accuracy": "0.27614", "wps": "22555.9", "ups": "3.17", "wpb": "7115.8", "bsz": "25", "num_updates": "9400", "lr": "0.000146875", "gnorm": "0.662", "loss_scale": "4", "train_wall": "63", "gb_free": "17.6", "wall": "3004"}
[2023-09-08 19:13:34,527][train_inner][INFO] - {"epoch": 1, "update": 0.864, "loss": "4.558", "ntokens": "7116.98", "nsentences": "25.02", "prob_perplexity": "62.611", "code_perplexity": "62.554", "temp": "1.907", "loss_0": "4.403", "loss_1": "0.13", "loss_2": "0.025", "accuracy": "0.27786", "wps": "22556.4", "ups": "3.17", "wpb": "7117", "bsz": "25", "num_updates": "9600", "lr": "0.00015", "gnorm": "0.681", "loss_scale": "4", "train_wall": "63", "gb_free": "18.3", "wall": "3067"}
[2023-09-08 19:14:37,077][train_inner][INFO] - {"epoch": 1, "update": 0.882, "loss": "4.53", "ntokens": "7064.31", "nsentences": "26.53", "prob_perplexity": "62.649", "code_perplexity": "62.601", "temp": "1.905", "loss_0": "4.375", "loss_1": "0.13", "loss_2": "0.025", "accuracy": "0.28235", "wps": "22587.9", "ups": "3.2", "wpb": "7064.3", "bsz": "26.5", "num_updates": "9800", "lr": "0.000153125", "gnorm": "0.675", "loss_scale": "4", "train_wall": "62", "gb_free": "16", "wall": "3129"}
[2023-09-08 19:15:39,620][train_inner][INFO] - {"epoch": 1, "update": 0.9, "loss": "4.496", "ntokens": "7071.85", "nsentences": "25.98", "prob_perplexity": "62.689", "code_perplexity": "62.641", "temp": "1.903", "loss_0": "4.34", "loss_1": "0.13", "loss_2": "0.025", "accuracy": "0.28626", "wps": "22614.8", "ups": "3.2", "wpb": "7071.9", "bsz": "26", "num_updates": "10000", "lr": "0.00015625", "gnorm": "0.655", "loss_scale": "4", "train_wall": "62", "gb_free": "17.6", "wall": "3192"}
[2023-09-08 19:16:42,195][train_inner][INFO] - {"epoch": 1, "update": 0.918, "loss": "4.496", "ntokens": "7069.95", "nsentences": "24.525", "prob_perplexity": "63.205", "code_perplexity": "63.157", "temp": "1.902", "loss_0": "4.341", "loss_1": "0.13", "loss_2": "0.025", "accuracy": "0.28586", "wps": "22597", "ups": "3.2", "wpb": "7069.9", "bsz": "24.5", "num_updates": "10200", "lr": "0.000159375", "gnorm": "0.665", "loss_scale": "4", "train_wall": "62", "gb_free": "16.5", "wall": "3254"}
[2023-09-08 19:17:44,163][train_inner][INFO] - {"epoch": 1, "update": 0.936, "loss": "4.506", "ntokens": "7086.59", "nsentences": "25", "prob_perplexity": "63.372", "code_perplexity": "63.319", "temp": "1.9", "loss_0": "4.35", "loss_1": "0.13", "loss_2": "0.026", "accuracy": "0.28404", "wps": "22872.1", "ups": "3.23", "wpb": "7086.6", "bsz": "25", "num_updates": "10400", "lr": "0.0001625", "gnorm": "0.65", "loss_scale": "4", "train_wall": "61", "gb_free": "17.3", "wall": "3316"}
[2023-09-08 19:18:46,238][train_inner][INFO] - {"epoch": 1, "update": 0.954, "loss": "4.464", "ntokens": "7069.9", "nsentences": "25.785", "prob_perplexity": "63.498", "code_perplexity": "63.451", "temp": "1.898", "loss_0": "4.308", "loss_1": "0.13", "loss_2": "0.026", "accuracy": "0.29148", "wps": "22778.6", "ups": "3.22", "wpb": "7069.9", "bsz": "25.8", "num_updates": "10600", "lr": "0.000165625", "gnorm": "0.625", "loss_scale": "4", "train_wall": "62", "gb_free": "17.6", "wall": "3379"}
[2023-09-08 19:19:47,678][train_inner][INFO] - {"epoch": 1, "update": 0.972, "loss": "4.499", "ntokens": "7051.66", "nsentences": "24.5", "prob_perplexity": "63.994", "code_perplexity": "63.946", "temp": "1.896", "loss_0": "4.343", "loss_1": "0.13", "loss_2": "0.026", "accuracy": "0.28423", "wps": "22955.1", "ups": "3.26", "wpb": "7051.7", "bsz": "24.5", "num_updates": "10800", "lr": "0.00016875", "gnorm": "0.631", "loss_scale": "4", "train_wall": "61", "gb_free": "16", "wall": "3440"}
[2023-09-08 19:20:50,760][train_inner][INFO] - {"epoch": 1, "update": 0.99, "loss": "4.483", "ntokens": "7150.36", "nsentences": "24.625", "prob_perplexity": "64.35", "code_perplexity": "64.299", "temp": "1.894", "loss_0": "4.326", "loss_1": "0.13", "loss_2": "0.027", "accuracy": "0.28734", "wps": "22670", "ups": "3.17", "wpb": "7150.4", "bsz": "24.6", "num_updates": "11000", "lr": "0.000171875", "gnorm": "0.654", "loss_scale": "4", "train_wall": "63", "gb_free": "18.9", "wall": "3503"}
[2023-09-08 19:21:24,867][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-09-08 19:21:24,868][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-09-08 19:21:25,008][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 2
[2023-09-08 19:21:42,626][valid][INFO] - {"epoch": 1, "valid_loss": "4.229", "valid_ntokens": "6014.02", "valid_nsentences": "41.4167", "valid_prob_perplexity": "63.891", "valid_code_perplexity": "63.843", "valid_temp": "1.892", "valid_loss_0": "4.071", "valid_loss_1": "0.13", "valid_loss_2": "0.028", "valid_accuracy": "0.33677", "valid_wps": "45297.5", "valid_wpb": "6014", "valid_bsz": "41.4", "valid_num_updates": "11111"}
[2023-09-08 19:21:42,628][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 11111 updates
[2023-09-08 19:21:42,629][fairseq.trainer][INFO] - Saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/checkpoint_best.pt
[2023-09-08 19:21:44,483][fairseq.trainer][INFO] - Finished saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/checkpoint_best.pt
[2023-09-08 19:21:45,246][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 1 @ 11111 updates, score 4.229) (writing took 2.6175177220720798 seconds)
[2023-09-08 19:21:45,246][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2023-09-08 19:21:45,247][train][INFO] - {"epoch": 1, "train_loss": "5.22", "train_ntokens": "7072.01", "train_nsentences": "25.2348", "train_prob_perplexity": "138.607", "train_code_perplexity": "135.016", "train_temp": "1.945", "train_loss_0": "5.033", "train_loss_1": "0.113", "train_loss_2": "0.074", "train_accuracy": "0.20509", "train_wps": "22466.3", "train_ups": "3.18", "train_wpb": "7072", "train_bsz": "25.2", "train_num_updates": "11111", "train_lr": "0.000173609", "train_gnorm": "0.795", "train_loss_scale": "4", "train_train_wall": "3452", "train_gb_free": "17.4", "train_wall": "3558"}
[2023-09-08 19:21:45,248][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-09-08 19:21:45,295][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 2
[2023-09-08 19:21:45,546][fairseq.data.iterators][INFO] - grouped total_num_itrs = 11116
[2023-09-08 19:21:45,549][fairseq.trainer][INFO] - begin training epoch 2
[2023-09-08 19:21:45,549][fairseq_cli.train][INFO] - Start iterating over samples
[2023-09-08 19:22:13,199][train_inner][INFO] - {"epoch": 2, "update": 1.008, "loss": "4.449", "ntokens": "7012.4", "nsentences": "25.585", "prob_perplexity": "64.357", "code_perplexity": "64.312", "temp": "1.892", "loss_0": "4.291", "loss_1": "0.13", "loss_2": "0.028", "accuracy": "0.29319", "wps": "17012.7", "ups": "2.43", "wpb": "7012.4", "bsz": "25.6", "num_updates": "11200", "lr": "0.000175", "gnorm": "0.617", "loss_scale": "4", "train_wall": "61", "gb_free": "16.8", "wall": "3585"}
[2023-09-08 19:23:16,043][train_inner][INFO] - {"epoch": 2, "update": 1.026, "loss": "4.449", "ntokens": "7028.28", "nsentences": "25.14", "prob_perplexity": "64.974", "code_perplexity": "64.929", "temp": "1.89", "loss_0": "4.292", "loss_1": "0.13", "loss_2": "0.028", "accuracy": "0.29218", "wps": "22367.6", "ups": "3.18", "wpb": "7028.3", "bsz": "25.1", "num_updates": "11400", "lr": "0.000178125", "gnorm": "0.59", "loss_scale": "4", "train_wall": "62", "gb_free": "15.4", "wall": "3648"}
[2023-09-08 19:24:18,518][train_inner][INFO] - {"epoch": 2, "update": 1.044, "loss": "4.425", "ntokens": "7025.39", "nsentences": "25.595", "prob_perplexity": "65.134", "code_perplexity": "65.085", "temp": "1.888", "loss_0": "4.268", "loss_1": "0.13", "loss_2": "0.028", "accuracy": "0.29496", "wps": "22490.5", "ups": "3.2", "wpb": "7025.4", "bsz": "25.6", "num_updates": "11600", "lr": "0.00018125", "gnorm": "0.606", "loss_scale": "4", "train_wall": "62", "gb_free": "17.7", "wall": "3711"}
[2023-09-08 19:25:21,041][train_inner][INFO] - {"epoch": 2, "update": 1.062, "loss": "4.425", "ntokens": "7101.69", "nsentences": "25.295", "prob_perplexity": "64.897", "code_perplexity": "64.847", "temp": "1.886", "loss_0": "4.267", "loss_1": "0.13", "loss_2": "0.028", "accuracy": "0.29541", "wps": "22717.3", "ups": "3.2", "wpb": "7101.7", "bsz": "25.3", "num_updates": "11800", "lr": "0.000184375", "gnorm": "0.582", "loss_scale": "4", "train_wall": "62", "gb_free": "15.8", "wall": "3773"}
[2023-09-08 19:26:24,387][train_inner][INFO] - {"epoch": 2, "update": 1.08, "loss": "4.423", "ntokens": "7087.72", "nsentences": "25.3", "prob_perplexity": "65.973", "code_perplexity": "65.922", "temp": "1.884", "loss_0": "4.265", "loss_1": "0.129", "loss_2": "0.029", "accuracy": "0.2951", "wps": "22377.9", "ups": "3.16", "wpb": "7087.7", "bsz": "25.3", "num_updates": "12000", "lr": "0.0001875", "gnorm": "0.614", "loss_scale": "4", "train_wall": "63", "gb_free": "16", "wall": "3837"}
[2023-09-08 19:27:27,571][train_inner][INFO] - {"epoch": 2, "update": 1.098, "loss": "4.421", "ntokens": "7070.87", "nsentences": "24.425", "prob_perplexity": "66.087", "code_perplexity": "66.037", "temp": "1.883", "loss_0": "4.263", "loss_1": "0.129", "loss_2": "0.028", "accuracy": "0.2945", "wps": "22382", "ups": "3.17", "wpb": "7070.9", "bsz": "24.4", "num_updates": "12200", "lr": "0.000190625", "gnorm": "0.573", "loss_scale": "4", "train_wall": "63", "gb_free": "16.1", "wall": "3900"}
[2023-09-08 19:28:31,190][train_inner][INFO] - {"epoch": 2, "update": 1.116, "loss": "4.414", "ntokens": "7102.97", "nsentences": "24.96", "prob_perplexity": "66.265", "code_perplexity": "66.211", "temp": "1.881", "loss_0": "4.256", "loss_1": "0.129", "loss_2": "0.029", "accuracy": "0.29639", "wps": "22329.9", "ups": "3.14", "wpb": "7103", "bsz": "25", "num_updates": "12400", "lr": "0.00019375", "gnorm": "0.595", "loss_scale": "4", "train_wall": "63", "gb_free": "17.7", "wall": "3963"}
[2023-09-08 19:29:33,694][train_inner][INFO] - {"epoch": 2, "update": 1.134, "loss": "4.385", "ntokens": "7045.16", "nsentences": "25.625", "prob_perplexity": "66.392", "code_perplexity": "66.343", "temp": "1.879", "loss_0": "4.226", "loss_1": "0.129", "loss_2": "0.029", "accuracy": "0.30059", "wps": "22543", "ups": "3.2", "wpb": "7045.2", "bsz": "25.6", "num_updates": "12600", "lr": "0.000196875", "gnorm": "0.554", "loss_scale": "4", "train_wall": "62", "gb_free": "17.8", "wall": "4026"}
[2023-09-08 19:30:35,760][train_inner][INFO] - {"epoch": 2, "update": 1.152, "loss": "4.364", "ntokens": "7071.91", "nsentences": "25.65", "prob_perplexity": "66.344", "code_perplexity": "66.296", "temp": "1.877", "loss_0": "4.205", "loss_1": "0.129", "loss_2": "0.03", "accuracy": "0.30402", "wps": "22788.8", "ups": "3.22", "wpb": "7071.9", "bsz": "25.6", "num_updates": "12800", "lr": "0.0002", "gnorm": "0.566", "loss_scale": "4", "train_wall": "62", "gb_free": "17.7", "wall": "4088"}
[2023-09-08 19:31:38,895][train_inner][INFO] - {"epoch": 2, "update": 1.17, "loss": "4.35", "ntokens": "7046.23", "nsentences": "25.91", "prob_perplexity": "67.038", "code_perplexity": "66.985", "temp": "1.875", "loss_0": "4.191", "loss_1": "0.129", "loss_2": "0.03", "accuracy": "0.30548", "wps": "22321.3", "ups": "3.17", "wpb": "7046.2", "bsz": "25.9", "num_updates": "13000", "lr": "0.000203125", "gnorm": "0.565", "loss_scale": "4", "train_wall": "63", "gb_free": "17.2", "wall": "4151"}
[2023-09-08 19:32:40,651][train_inner][INFO] - {"epoch": 2, "update": 1.188, "loss": "4.365", "ntokens": "7113.69", "nsentences": "24.385", "prob_perplexity": "67.234", "code_perplexity": "67.181", "temp": "1.873", "loss_0": "4.206", "loss_1": "0.129", "loss_2": "0.03", "accuracy": "0.30338", "wps": "23038.4", "ups": "3.24", "wpb": "7113.7", "bsz": "24.4", "num_updates": "13200", "lr": "0.00020625", "gnorm": "0.555", "loss_scale": "8", "train_wall": "61", "gb_free": "15.7", "wall": "4213"}
[2023-09-08 19:33:43,487][train_inner][INFO] - {"epoch": 2, "update": 1.206, "loss": "4.36", "ntokens": "7090.77", "nsentences": "24.815", "prob_perplexity": "67.923", "code_perplexity": "67.867", "temp": "1.871", "loss_0": "4.201", "loss_1": "0.129", "loss_2": "0.03", "accuracy": "0.30276", "wps": "22569.6", "ups": "3.18", "wpb": "7090.8", "bsz": "24.8", "num_updates": "13400", "lr": "0.000209375", "gnorm": "0.559", "loss_scale": "8", "train_wall": "62", "gb_free": "17.7", "wall": "4276"}
[2023-09-08 19:34:45,705][train_inner][INFO] - {"epoch": 2, "update": 1.224, "loss": "4.344", "ntokens": "7074.5", "nsentences": "25.37", "prob_perplexity": "68.456", "code_perplexity": "68.402", "temp": "1.869", "loss_0": "4.186", "loss_1": "0.129", "loss_2": "0.03", "accuracy": "0.30446", "wps": "22741", "ups": "3.21", "wpb": "7074.5", "bsz": "25.4", "num_updates": "13600", "lr": "0.0002125", "gnorm": "0.551", "loss_scale": "8", "train_wall": "62", "gb_free": "16.5", "wall": "4338"}
[2023-09-08 19:34:46,279][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-09-08 19:35:48,846][train_inner][INFO] - {"epoch": 2, "update": 1.242, "loss": "4.33", "ntokens": "7068.27", "nsentences": "25.31", "prob_perplexity": "69.212", "code_perplexity": "69.155", "temp": "1.868", "loss_0": "4.171", "loss_1": "0.129", "loss_2": "0.031", "accuracy": "0.30606", "wps": "22389.4", "ups": "3.17", "wpb": "7068.3", "bsz": "25.3", "num_updates": "13800", "lr": "0.000215625", "gnorm": "0.559", "loss_scale": "4", "train_wall": "63", "gb_free": "17.5", "wall": "4401"}
[2023-09-08 19:36:51,342][train_inner][INFO] - {"epoch": 2, "update": 1.26, "loss": "4.344", "ntokens": "7073.51", "nsentences": "25.285", "prob_perplexity": "69.433", "code_perplexity": "69.374", "temp": "1.866", "loss_0": "4.184", "loss_1": "0.129", "loss_2": "0.032", "accuracy": "0.3041", "wps": "22637.1", "ups": "3.2", "wpb": "7073.5", "bsz": "25.3", "num_updates": "14000", "lr": "0.00021875", "gnorm": "0.542", "loss_scale": "4", "train_wall": "62", "gb_free": "16.5", "wall": "4464"}
[2023-09-08 19:37:53,845][train_inner][INFO] - {"epoch": 2, "update": 1.278, "loss": "4.328", "ntokens": "7051.83", "nsentences": "25.28", "prob_perplexity": "69.585", "code_perplexity": "69.524", "temp": "1.864", "loss_0": "4.168", "loss_1": "0.129", "loss_2": "0.031", "accuracy": "0.30551", "wps": "22564.7", "ups": "3.2", "wpb": "7051.8", "bsz": "25.3", "num_updates": "14200", "lr": "0.000221875", "gnorm": "0.54", "loss_scale": "4", "train_wall": "62", "gb_free": "16.2", "wall": "4526"}
[2023-09-08 19:38:57,271][train_inner][INFO] - {"epoch": 2, "update": 1.296, "loss": "4.333", "ntokens": "7103.53", "nsentences": "25.49", "prob_perplexity": "70.228", "code_perplexity": "70.164", "temp": "1.862", "loss_0": "4.173", "loss_1": "0.128", "loss_2": "0.032", "accuracy": "0.30588", "wps": "22399.8", "ups": "3.15", "wpb": "7103.5", "bsz": "25.5", "num_updates": "14400", "lr": "0.000225", "gnorm": "0.544", "loss_scale": "4", "train_wall": "63", "gb_free": "17.8", "wall": "4590"}
[2023-09-08 19:39:59,724][train_inner][INFO] - {"epoch": 2, "update": 1.314, "loss": "4.298", "ntokens": "7051.04", "nsentences": "25.28", "prob_perplexity": "70.34", "code_perplexity": "70.281", "temp": "1.86", "loss_0": "4.138", "loss_1": "0.128", "loss_2": "0.031", "accuracy": "0.30958", "wps": "22580.6", "ups": "3.2", "wpb": "7051", "bsz": "25.3", "num_updates": "14600", "lr": "0.000228125", "gnorm": "0.521", "loss_scale": "4", "train_wall": "62", "gb_free": "16.2", "wall": "4652"}
[2023-09-08 19:41:01,987][train_inner][INFO] - {"epoch": 2, "update": 1.332, "loss": "4.32", "ntokens": "7127.09", "nsentences": "24.805", "prob_perplexity": "70.658", "code_perplexity": "70.595", "temp": "1.858", "loss_0": "4.16", "loss_1": "0.128", "loss_2": "0.032", "accuracy": "0.30686", "wps": "22893.7", "ups": "3.21", "wpb": "7127.1", "bsz": "24.8", "num_updates": "14800", "lr": "0.00023125", "gnorm": "0.533", "loss_scale": "4", "train_wall": "62", "gb_free": "15.4", "wall": "4714"}
[2023-09-08 19:42:04,131][train_inner][INFO] - {"epoch": 2, "update": 1.35, "loss": "4.296", "ntokens": "7051.26", "nsentences": "25.445", "prob_perplexity": "71.123", "code_perplexity": "71.055", "temp": "1.856", "loss_0": "4.136", "loss_1": "0.128", "loss_2": "0.032", "accuracy": "0.30883", "wps": "22693.6", "ups": "3.22", "wpb": "7051.3", "bsz": "25.4", "num_updates": "15000", "lr": "0.000234375", "gnorm": "0.525", "loss_scale": "4", "train_wall": "62", "gb_free": "17.5", "wall": "4776"}
[2023-09-08 19:43:07,281][train_inner][INFO] - {"epoch": 2, "update": 1.368, "loss": "4.29", "ntokens": "7059.73", "nsentences": "25.425", "prob_perplexity": "71.109", "code_perplexity": "71.045", "temp": "1.855", "loss_0": "4.13", "loss_1": "0.128", "loss_2": "0.032", "accuracy": "0.31011", "wps": "22359.1", "ups": "3.17", "wpb": "7059.7", "bsz": "25.4", "num_updates": "15200", "lr": "0.0002375", "gnorm": "0.518", "loss_scale": "4", "train_wall": "63", "gb_free": "17.5", "wall": "4840"}
[2023-09-08 19:44:09,703][train_inner][INFO] - {"epoch": 2, "update": 1.386, "loss": "4.269", "ntokens": "7127.24", "nsentences": "25.22", "prob_perplexity": "71.393", "code_perplexity": "71.325", "temp": "1.853", "loss_0": "4.109", "loss_1": "0.128", "loss_2": "0.032", "accuracy": "0.31424", "wps": "22836", "ups": "3.2", "wpb": "7127.2", "bsz": "25.2", "num_updates": "15400", "lr": "0.000240625", "gnorm": "0.52", "loss_scale": "4", "train_wall": "62", "gb_free": "15.5", "wall": "4902"}
[2023-09-08 19:45:10,144][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-09-08 19:45:12,506][train_inner][INFO] - {"epoch": 2, "update": 1.404, "loss": "4.285", "ntokens": "7122.26", "nsentences": "25.075", "prob_perplexity": "71.877", "code_perplexity": "71.811", "temp": "1.851", "loss_0": "4.125", "loss_1": "0.128", "loss_2": "0.032", "accuracy": "0.31117", "wps": "22681.3", "ups": "3.18", "wpb": "7122.3", "bsz": "25.1", "num_updates": "15600", "lr": "0.00024375", "gnorm": "0.512", "loss_scale": "2", "train_wall": "62", "gb_free": "17.7", "wall": "4965"}
[2023-09-08 19:46:15,303][train_inner][INFO] - {"epoch": 2, "update": 1.422, "loss": "4.276", "ntokens": "7039.01", "nsentences": "25.335", "prob_perplexity": "72.512", "code_perplexity": "72.434", "temp": "1.849", "loss_0": "4.115", "loss_1": "0.128", "loss_2": "0.033", "accuracy": "0.31202", "wps": "22418.6", "ups": "3.18", "wpb": "7039", "bsz": "25.3", "num_updates": "15800", "lr": "0.000246875", "gnorm": "0.511", "loss_scale": "2", "train_wall": "62", "gb_free": "17.4", "wall": "5028"}
[2023-09-08 19:47:18,145][train_inner][INFO] - {"epoch": 2, "update": 1.44, "loss": "4.269", "ntokens": "7084.3", "nsentences": "25.015", "prob_perplexity": "72.692", "code_perplexity": "72.625", "temp": "1.847", "loss_0": "4.108", "loss_1": "0.128", "loss_2": "0.033", "accuracy": "0.31241", "wps": "22546.5", "ups": "3.18", "wpb": "7084.3", "bsz": "25", "num_updates": "16000", "lr": "0.00025", "gnorm": "0.511", "loss_scale": "2", "train_wall": "62", "gb_free": "17.4", "wall": "5090"}
[2023-09-08 19:48:20,877][train_inner][INFO] - {"epoch": 2, "update": 1.458, "loss": "4.265", "ntokens": "7074.57", "nsentences": "25.32", "prob_perplexity": "73.027", "code_perplexity": "72.958", "temp": "1.845", "loss_0": "4.104", "loss_1": "0.128", "loss_2": "0.033", "accuracy": "0.31408", "wps": "22555.2", "ups": "3.19", "wpb": "7074.6", "bsz": "25.3", "num_updates": "16200", "lr": "0.000253125", "gnorm": "0.518", "loss_scale": "2", "train_wall": "62", "gb_free": "17.6", "wall": "5153"}
[2023-09-08 19:49:23,595][train_inner][INFO] - {"epoch": 2, "update": 1.476, "loss": "4.247", "ntokens": "7048.35", "nsentences": "25.43", "prob_perplexity": "73.226", "code_perplexity": "73.159", "temp": "1.843", "loss_0": "4.086", "loss_1": "0.128", "loss_2": "0.033", "accuracy": "0.31642", "wps": "22476.5", "ups": "3.19", "wpb": "7048.3", "bsz": "25.4", "num_updates": "16400", "lr": "0.00025625", "gnorm": "0.506", "loss_scale": "2", "train_wall": "62", "gb_free": "17.8", "wall": "5216"}
[2023-09-08 19:50:26,203][train_inner][INFO] - {"epoch": 2, "update": 1.494, "loss": "4.262", "ntokens": "7091.82", "nsentences": "24.81", "prob_perplexity": "73.936", "code_perplexity": "73.856", "temp": "1.842", "loss_0": "4.101", "loss_1": "0.128", "loss_2": "0.034", "accuracy": "0.31214", "wps": "22654.7", "ups": "3.19", "wpb": "7091.8", "bsz": "24.8", "num_updates": "16600", "lr": "0.000259375", "gnorm": "0.525", "loss_scale": "2", "train_wall": "62", "gb_free": "15.7", "wall": "5278"}
[2023-09-08 19:51:28,168][train_inner][INFO] - {"epoch": 2, "update": 1.512, "loss": "4.241", "ntokens": "7049.21", "nsentences": "25.27", "prob_perplexity": "74.403", "code_perplexity": "74.329", "temp": "1.84", "loss_0": "4.079", "loss_1": "0.127", "loss_2": "0.034", "accuracy": "0.3165", "wps": "22752.5", "ups": "3.23", "wpb": "7049.2", "bsz": "25.3", "num_updates": "16800", "lr": "0.0002625", "gnorm": "0.496", "loss_scale": "2", "train_wall": "61", "gb_free": "16", "wall": "5340"}
[2023-09-08 19:52:30,722][train_inner][INFO] - {"epoch": 2, "update": 1.53, "loss": "4.249", "ntokens": "7049.88", "nsentences": "25.68", "prob_perplexity": "74.173", "code_perplexity": "74.094", "temp": "1.838", "loss_0": "4.087", "loss_1": "0.128", "loss_2": "0.034", "accuracy": "0.3162", "wps": "22540.3", "ups": "3.2", "wpb": "7049.9", "bsz": "25.7", "num_updates": "17000", "lr": "0.000265625", "gnorm": "0.498", "loss_scale": "2", "train_wall": "62", "gb_free": "16.3", "wall": "5403"}
[2023-09-08 19:53:33,312][train_inner][INFO] - {"epoch": 2, "update": 1.548, "loss": "4.233", "ntokens": "7064.15", "nsentences": "25.035", "prob_perplexity": "74.654", "code_perplexity": "74.578", "temp": "1.836", "loss_0": "4.071", "loss_1": "0.127", "loss_2": "0.034", "accuracy": "0.31893", "wps": "22573", "ups": "3.2", "wpb": "7064.1", "bsz": "25", "num_updates": "17200", "lr": "0.00026875", "gnorm": "0.499", "loss_scale": "2", "train_wall": "62", "gb_free": "16.2", "wall": "5466"}
[2023-09-08 19:54:34,598][train_inner][INFO] - {"epoch": 2, "update": 1.566, "loss": "4.232", "ntokens": "7080.97", "nsentences": "25.07", "prob_perplexity": "75.825", "code_perplexity": "75.749", "temp": "1.834", "loss_0": "4.071", "loss_1": "0.127", "loss_2": "0.034", "accuracy": "0.3171", "wps": "23108.1", "ups": "3.26", "wpb": "7081", "bsz": "25.1", "num_updates": "17400", "lr": "0.000271875", "gnorm": "0.507", "loss_scale": "2", "train_wall": "61", "gb_free": "16.2", "wall": "5527"}
[2023-09-08 19:55:36,976][train_inner][INFO] - {"epoch": 2, "update": 1.584, "loss": "4.221", "ntokens": "7075.53", "nsentences": "25.215", "prob_perplexity": "76.011", "code_perplexity": "75.926", "temp": "1.832", "loss_0": "4.059", "loss_1": "0.127", "loss_2": "0.035", "accuracy": "0.319", "wps": "22686.6", "ups": "3.21", "wpb": "7075.5", "bsz": "25.2", "num_updates": "17600", "lr": "0.000275", "gnorm": "0.497", "loss_scale": "2", "train_wall": "62", "gb_free": "15.9", "wall": "5589"}
[2023-09-08 19:56:39,887][train_inner][INFO] - {"epoch": 2, "update": 1.602, "loss": "4.225", "ntokens": "7096.86", "nsentences": "25.425", "prob_perplexity": "76.049", "code_perplexity": "75.974", "temp": "1.831", "loss_0": "4.062", "loss_1": "0.127", "loss_2": "0.035", "accuracy": "0.31876", "wps": "22561.9", "ups": "3.18", "wpb": "7096.9", "bsz": "25.4", "num_updates": "17800", "lr": "0.000278125", "gnorm": "0.493", "loss_scale": "2", "train_wall": "62", "gb_free": "18", "wall": "5652"}
[2023-09-08 19:57:41,477][train_inner][INFO] - {"epoch": 2, "update": 1.62, "loss": "4.199", "ntokens": "7023.86", "nsentences": "25.29", "prob_perplexity": "76.754", "code_perplexity": "76.678", "temp": "1.829", "loss_0": "4.037", "loss_1": "0.127", "loss_2": "0.035", "accuracy": "0.32239", "wps": "22808.6", "ups": "3.25", "wpb": "7023.9", "bsz": "25.3", "num_updates": "18000", "lr": "0.00028125", "gnorm": "0.494", "loss_scale": "2", "train_wall": "61", "gb_free": "17.8", "wall": "5714"}
[2023-09-08 19:58:44,201][train_inner][INFO] - {"epoch": 2, "update": 1.638, "loss": "4.206", "ntokens": "7088.29", "nsentences": "25.36", "prob_perplexity": "77.414", "code_perplexity": "77.331", "temp": "1.827", "loss_0": "4.044", "loss_1": "0.127", "loss_2": "0.035", "accuracy": "0.32117", "wps": "22601.9", "ups": "3.19", "wpb": "7088.3", "bsz": "25.4", "num_updates": "18200", "lr": "0.000284375", "gnorm": "0.515", "loss_scale": "2", "train_wall": "62", "gb_free": "15.6", "wall": "5776"}
[2023-09-08 19:59:45,784][train_inner][INFO] - {"epoch": 2, "update": 1.656, "loss": "4.195", "ntokens": "7065.64", "nsentences": "25.625", "prob_perplexity": "77.93", "code_perplexity": "77.842", "temp": "1.825", "loss_0": "4.032", "loss_1": "0.127", "loss_2": "0.036", "accuracy": "0.32205", "wps": "22946.9", "ups": "3.25", "wpb": "7065.6", "bsz": "25.6", "num_updates": "18400", "lr": "0.0002875", "gnorm": "0.496", "loss_scale": "2", "train_wall": "61", "gb_free": "17.6", "wall": "5838"}
[2023-09-08 20:00:49,715][train_inner][INFO] - {"epoch": 2, "update": 1.674, "loss": "4.189", "ntokens": "7095.43", "nsentences": "24.915", "prob_perplexity": "78.995", "code_perplexity": "78.905", "temp": "1.823", "loss_0": "4.027", "loss_1": "0.126", "loss_2": "0.035", "accuracy": "0.32147", "wps": "22197.4", "ups": "3.13", "wpb": "7095.4", "bsz": "24.9", "num_updates": "18600", "lr": "0.000290625", "gnorm": "0.503", "loss_scale": "2", "train_wall": "63", "gb_free": "15.1", "wall": "5902"}
[2023-09-08 20:01:52,409][train_inner][INFO] - {"epoch": 2, "update": 1.692, "loss": "4.196", "ntokens": "7091.94", "nsentences": "25.915", "prob_perplexity": "79.347", "code_perplexity": "79.256", "temp": "1.821", "loss_0": "4.034", "loss_1": "0.126", "loss_2": "0.035", "accuracy": "0.32165", "wps": "22624.4", "ups": "3.19", "wpb": "7091.9", "bsz": "25.9", "num_updates": "18800", "lr": "0.00029375", "gnorm": "0.503", "loss_scale": "2", "train_wall": "62", "gb_free": "19.3", "wall": "5965"}
[2023-09-08 20:02:54,929][train_inner][INFO] - {"epoch": 2, "update": 1.71, "loss": "4.196", "ntokens": "7069.71", "nsentences": "25.105", "prob_perplexity": "79.518", "code_perplexity": "79.437", "temp": "1.82", "loss_0": "4.034", "loss_1": "0.126", "loss_2": "0.036", "accuracy": "0.32106", "wps": "22616.2", "ups": "3.2", "wpb": "7069.7", "bsz": "25.1", "num_updates": "19000", "lr": "0.000296875", "gnorm": "0.496", "loss_scale": "2", "train_wall": "62", "gb_free": "15.5", "wall": "6027"}
[2023-09-08 20:03:57,192][train_inner][INFO] - {"epoch": 2, "update": 1.728, "loss": "4.186", "ntokens": "7064.98", "nsentences": "25.25", "prob_perplexity": "80.105", "code_perplexity": "80.018", "temp": "1.818", "loss_0": "4.024", "loss_1": "0.126", "loss_2": "0.036", "accuracy": "0.32179", "wps": "22694.1", "ups": "3.21", "wpb": "7065", "bsz": "25.2", "num_updates": "19200", "lr": "0.0003", "gnorm": "0.484", "loss_scale": "2", "train_wall": "62", "gb_free": "16.1", "wall": "6089"}
[2023-09-08 20:04:59,970][train_inner][INFO] - {"epoch": 2, "update": 1.746, "loss": "4.194", "ntokens": "7122.51", "nsentences": "25.07", "prob_perplexity": "80.59", "code_perplexity": "80.503", "temp": "1.816", "loss_0": "4.032", "loss_1": "0.126", "loss_2": "0.036", "accuracy": "0.32047", "wps": "22691.6", "ups": "3.19", "wpb": "7122.5", "bsz": "25.1", "num_updates": "19400", "lr": "0.000303125", "gnorm": "0.492", "loss_scale": "2", "train_wall": "62", "gb_free": "16.1", "wall": "6152"}
[2023-09-08 20:06:01,915][train_inner][INFO] - {"epoch": 2, "update": 1.764, "loss": "4.175", "ntokens": "7082.77", "nsentences": "25.325", "prob_perplexity": "81.473", "code_perplexity": "81.378", "temp": "1.814", "loss_0": "4.013", "loss_1": "0.126", "loss_2": "0.036", "accuracy": "0.32367", "wps": "22868.1", "ups": "3.23", "wpb": "7082.8", "bsz": "25.3", "num_updates": "19600", "lr": "0.00030625", "gnorm": "0.491", "loss_scale": "2", "train_wall": "61", "gb_free": "16.8", "wall": "6214"}
[2023-09-08 20:07:03,861][train_inner][INFO] - {"epoch": 2, "update": 1.782, "loss": "4.166", "ntokens": "7027.72", "nsentences": "25.44", "prob_perplexity": "82.279", "code_perplexity": "82.184", "temp": "1.812", "loss_0": "4.004", "loss_1": "0.126", "loss_2": "0.036", "accuracy": "0.32436", "wps": "22689.9", "ups": "3.23", "wpb": "7027.7", "bsz": "25.4", "num_updates": "19800", "lr": "0.000309375", "gnorm": "0.483", "loss_scale": "4", "train_wall": "61", "gb_free": "18.2", "wall": "6276"}
[2023-09-08 20:08:06,184][train_inner][INFO] - {"epoch": 2, "update": 1.8, "loss": "4.17", "ntokens": "7088.17", "nsentences": "25.3", "prob_perplexity": "82.407", "code_perplexity": "82.31", "temp": "1.811", "loss_0": "4.008", "loss_1": "0.126", "loss_2": "0.037", "accuracy": "0.32314", "wps": "22746.9", "ups": "3.21", "wpb": "7088.2", "bsz": "25.3", "num_updates": "20000", "lr": "0.0003125", "gnorm": "0.481", "loss_scale": "4", "train_wall": "62", "gb_free": "15.6", "wall": "6338"}
[2023-09-08 20:08:17,980][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-09-08 20:09:09,384][train_inner][INFO] - {"epoch": 2, "update": 1.818, "loss": "4.176", "ntokens": "7071.43", "nsentences": "24.83", "prob_perplexity": "82.654", "code_perplexity": "82.554", "temp": "1.809", "loss_0": "4.014", "loss_1": "0.126", "loss_2": "0.037", "accuracy": "0.32303", "wps": "22378.1", "ups": "3.16", "wpb": "7071.4", "bsz": "24.8", "num_updates": "20200", "lr": "0.000315625", "gnorm": "0.494", "loss_scale": "2", "train_wall": "63", "gb_free": "17.6", "wall": "6402"}
[2023-09-08 20:10:12,495][train_inner][INFO] - {"epoch": 2, "update": 1.836, "loss": "4.155", "ntokens": "7074.16", "nsentences": "24.54", "prob_perplexity": "83.08", "code_perplexity": "82.972", "temp": "1.807", "loss_0": "3.993", "loss_1": "0.126", "loss_2": "0.037", "accuracy": "0.32505", "wps": "22418.7", "ups": "3.17", "wpb": "7074.2", "bsz": "24.5", "num_updates": "20400", "lr": "0.00031875", "gnorm": "0.506", "loss_scale": "2", "train_wall": "63", "gb_free": "17.6", "wall": "6465"}
[2023-09-08 20:11:15,709][train_inner][INFO] - {"epoch": 2, "update": 1.854, "loss": "4.147", "ntokens": "7067.56", "nsentences": "24.59", "prob_perplexity": "83.796", "code_perplexity": "83.687", "temp": "1.805", "loss_0": "3.984", "loss_1": "0.125", "loss_2": "0.037", "accuracy": "0.32628", "wps": "22360.7", "ups": "3.16", "wpb": "7067.6", "bsz": "24.6", "num_updates": "20600", "lr": "0.000321875", "gnorm": "0.523", "loss_scale": "2", "train_wall": "63", "gb_free": "17.5", "wall": "6528"}
[2023-09-08 20:12:19,846][train_inner][INFO] - {"epoch": 2, "update": 1.872, "loss": "4.15", "ntokens": "7113.97", "nsentences": "25.175", "prob_perplexity": "84.413", "code_perplexity": "84.312", "temp": "1.803", "loss_0": "3.988", "loss_1": "0.125", "loss_2": "0.037", "accuracy": "0.32587", "wps": "22184", "ups": "3.12", "wpb": "7114", "bsz": "25.2", "num_updates": "20800", "lr": "0.000325", "gnorm": "0.498", "loss_scale": "2", "train_wall": "64", "gb_free": "18.3", "wall": "6592"}
[2023-09-08 20:13:22,688][train_inner][INFO] - {"epoch": 2, "update": 1.89, "loss": "4.156", "ntokens": "7041.56", "nsentences": "25.025", "prob_perplexity": "84.728", "code_perplexity": "84.622", "temp": "1.802", "loss_0": "3.993", "loss_1": "0.125", "loss_2": "0.037", "accuracy": "0.3249", "wps": "22410.5", "ups": "3.18", "wpb": "7041.6", "bsz": "25", "num_updates": "21000", "lr": "0.000328125", "gnorm": "0.51", "loss_scale": "2", "train_wall": "62", "gb_free": "17.9", "wall": "6655"}
[2023-09-08 20:14:25,036][train_inner][INFO] - {"epoch": 2, "update": 1.908, "loss": "4.142", "ntokens": "7034.76", "nsentences": "25.425", "prob_perplexity": "85.249", "code_perplexity": "85.141", "temp": "1.8", "loss_0": "3.98", "loss_1": "0.125", "loss_2": "0.037", "accuracy": "0.32601", "wps": "22566.4", "ups": "3.21", "wpb": "7034.8", "bsz": "25.4", "num_updates": "21200", "lr": "0.00033125", "gnorm": "0.495", "loss_scale": "2", "train_wall": "62", "gb_free": "15.8", "wall": "6717"}
[2023-09-08 20:15:27,310][train_inner][INFO] - {"epoch": 2, "update": 1.926, "loss": "4.144", "ntokens": "7063.85", "nsentences": "25.37", "prob_perplexity": "85.585", "code_perplexity": "85.471", "temp": "1.798", "loss_0": "3.981", "loss_1": "0.125", "loss_2": "0.038", "accuracy": "0.32643", "wps": "22686.4", "ups": "3.21", "wpb": "7063.9", "bsz": "25.4", "num_updates": "21400", "lr": "0.000334375", "gnorm": "0.487", "loss_scale": "2", "train_wall": "62", "gb_free": "17.6", "wall": "6780"}
[2023-09-08 20:16:29,511][train_inner][INFO] - {"epoch": 2, "update": 1.944, "loss": "4.108", "ntokens": "7010.1", "nsentences": "25.925", "prob_perplexity": "85.971", "code_perplexity": "85.853", "temp": "1.796", "loss_0": "3.946", "loss_1": "0.125", "loss_2": "0.037", "accuracy": "0.33185", "wps": "22540.5", "ups": "3.22", "wpb": "7010.1", "bsz": "25.9", "num_updates": "21600", "lr": "0.0003375", "gnorm": "0.493", "loss_scale": "2", "train_wall": "62", "gb_free": "15.7", "wall": "6842"}
[2023-09-08 20:17:31,840][train_inner][INFO] - {"epoch": 2, "update": 1.962, "loss": "4.147", "ntokens": "7103.57", "nsentences": "25.27", "prob_perplexity": "86.67", "code_perplexity": "86.544", "temp": "1.794", "loss_0": "3.985", "loss_1": "0.125", "loss_2": "0.037", "accuracy": "0.32517", "wps": "22793.9", "ups": "3.21", "wpb": "7103.6", "bsz": "25.3", "num_updates": "21800", "lr": "0.000340625", "gnorm": "0.482", "loss_scale": "2", "train_wall": "62", "gb_free": "17.5", "wall": "6904"}
[2023-09-08 20:18:34,104][train_inner][INFO] - {"epoch": 2, "update": 1.98, "loss": "4.117", "ntokens": "7034.13", "nsentences": "25.53", "prob_perplexity": "87.298", "code_perplexity": "87.158", "temp": "1.793", "loss_0": "3.955", "loss_1": "0.125", "loss_2": "0.038", "accuracy": "0.32943", "wps": "22595", "ups": "3.21", "wpb": "7034.1", "bsz": "25.5", "num_updates": "22000", "lr": "0.00034375", "gnorm": "0.491", "loss_scale": "2", "train_wall": "62", "gb_free": "15.6", "wall": "6966"}
[2023-09-08 20:19:37,406][train_inner][INFO] - {"epoch": 2, "update": 1.998, "loss": "4.124", "ntokens": "7082.8", "nsentences": "25.15", "prob_perplexity": "87.58", "code_perplexity": "87.437", "temp": "1.791", "loss_0": "3.962", "loss_1": "0.125", "loss_2": "0.038", "accuracy": "0.32826", "wps": "22378", "ups": "3.16", "wpb": "7082.8", "bsz": "25.1", "num_updates": "22200", "lr": "0.000346875", "gnorm": "0.481", "loss_scale": "2", "train_wall": "63", "gb_free": "15.7", "wall": "7030"}
[2023-09-08 20:19:44,696][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-09-08 20:19:44,697][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-09-08 20:19:44,780][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 3
[2023-09-08 20:20:02,929][valid][INFO] - {"epoch": 2, "valid_loss": "3.846", "valid_ntokens": "5994.52", "valid_nsentences": "41.4167", "valid_prob_perplexity": "88.135", "valid_code_perplexity": "88.007", "valid_temp": "1.79", "valid_loss_0": "3.683", "valid_loss_1": "0.124", "valid_loss_2": "0.038", "valid_accuracy": "0.37974", "valid_wps": "43748.7", "valid_wpb": "5994.5", "valid_bsz": "41.4", "valid_num_updates": "22224", "valid_best_loss": "3.846"}
[2023-09-08 20:20:02,931][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 22224 updates
[2023-09-08 20:20:02,932][fairseq.trainer][INFO] - Saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/checkpoint_best.pt
[2023-09-08 20:20:05,318][fairseq.trainer][INFO] - Finished saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/checkpoint_best.pt
[2023-09-08 20:20:06,602][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_best.pt (epoch 2 @ 22224 updates, score 3.846) (writing took 3.670677980990149 seconds)
[2023-09-08 20:20:06,602][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2023-09-08 20:20:06,603][train][INFO] - {"epoch": 2, "train_loss": "4.259", "train_ntokens": "7071.3", "train_nsentences": "25.235", "train_prob_perplexity": "75.068", "train_code_perplexity": "74.99", "train_temp": "1.84", "train_loss_0": "4.098", "train_loss_1": "0.127", "train_loss_2": "0.033", "train_accuracy": "0.31407", "train_wps": "22443.7", "train_ups": "3.17", "train_wpb": "7071.3", "train_bsz": "25.2", "train_num_updates": "22224", "train_lr": "0.00034725", "train_gnorm": "0.522", "train_loss_scale": "2", "train_train_wall": "3452", "train_gb_free": "15.6", "train_wall": "7059"}
[2023-09-08 20:20:06,605][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-09-08 20:20:06,673][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 3
[2023-09-08 20:20:06,915][fairseq.data.iterators][INFO] - grouped total_num_itrs = 11116
[2023-09-08 20:20:06,918][fairseq.trainer][INFO] - begin training epoch 3
[2023-09-08 20:20:06,919][fairseq_cli.train][INFO] - Start iterating over samples
[2023-09-08 20:21:01,667][train_inner][INFO] - {"epoch": 3, "update": 2.016, "loss": "4.112", "ntokens": "7079.23", "nsentences": "24.875", "prob_perplexity": "88.266", "code_perplexity": "88.119", "temp": "1.789", "loss_0": "3.95", "loss_1": "0.124", "loss_2": "0.038", "accuracy": "0.32934", "wps": "16803.1", "ups": "2.37", "wpb": "7079.2", "bsz": "24.9", "num_updates": "22400", "lr": "0.00035", "gnorm": "0.497", "loss_scale": "2", "train_wall": "61", "gb_free": "17.7", "wall": "7114"}
[2023-09-08 20:22:04,434][train_inner][INFO] - {"epoch": 3, "update": 2.034, "loss": "4.131", "ntokens": "7070.07", "nsentences": "24.775", "prob_perplexity": "88.315", "code_perplexity": "88.165", "temp": "1.787", "loss_0": "3.968", "loss_1": "0.124", "loss_2": "0.039", "accuracy": "0.32734", "wps": "22528.3", "ups": "3.19", "wpb": "7070.1", "bsz": "24.8", "num_updates": "22600", "lr": "0.000353125", "gnorm": "0.499", "loss_scale": "2", "train_wall": "62", "gb_free": "17.4", "wall": "7177"}
[2023-09-08 20:23:06,959][train_inner][INFO] - {"epoch": 3, "update": 2.052, "loss": "4.125", "ntokens": "7071.84", "nsentences": "25.96", "prob_perplexity": "89.374", "code_perplexity": "89.212", "temp": "1.785", "loss_0": "3.959", "loss_1": "0.124", "loss_2": "0.041", "accuracy": "0.32817", "wps": "22620.9", "ups": "3.2", "wpb": "7071.8", "bsz": "26", "num_updates": "22800", "lr": "0.00035625", "gnorm": "0.569", "loss_scale": "2", "train_wall": "62", "gb_free": "17.5", "wall": "7239"}
[2023-09-08 20:23:30,027][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-09-08 20:24:09,010][train_inner][INFO] - {"epoch": 3, "update": 2.07, "loss": "5.794", "ntokens": "7056.56", "nsentences": "25.84", "prob_perplexity": "125.052", "code_perplexity": "123.114", "temp": "1.784", "loss_0": "5.599", "loss_1": "0.116", "loss_2": "0.078", "accuracy": "0.13871", "wps": "22744.7", "ups": "3.22", "wpb": "7056.6", "bsz": "25.8", "num_updates": "23000", "lr": "0.000359375", "gnorm": "2.711", "loss_scale": "1", "train_wall": "62", "gb_free": "18", "wall": "7301"}
[2023-09-08 20:25:11,727][train_inner][INFO] - {"epoch": 3, "update": 2.088, "loss": "6.715", "ntokens": "7128.09", "nsentences": "24.79", "prob_perplexity": "482.115", "code_perplexity": "470.346", "temp": "1.782", "loss_0": "6.658", "loss_1": "0.035", "loss_2": "0.021", "accuracy": "0.01212", "wps": "22731.3", "ups": "3.19", "wpb": "7128.1", "bsz": "24.8", "num_updates": "23200", "lr": "0.0003625", "gnorm": "0.046", "loss_scale": "1", "train_wall": "62", "gb_free": "16.2", "wall": "7364"}
[2023-09-08 20:26:14,352][train_inner][INFO] - {"epoch": 3, "update": 2.106, "loss": "6.687", "ntokens": "7066.9", "nsentences": "25.12", "prob_perplexity": "552.477", "code_perplexity": "540.179", "temp": "1.78", "loss_0": "6.658", "loss_1": "0.02", "loss_2": "0.009", "accuracy": "0.01215", "wps": "22568.8", "ups": "3.19", "wpb": "7066.9", "bsz": "25.1", "num_updates": "23400", "lr": "0.000365625", "gnorm": "0.03", "loss_scale": "1", "train_wall": "62", "gb_free": "15.7", "wall": "7427"}
[2023-09-08 20:27:17,394][train_inner][INFO] - {"epoch": 3, "update": 2.124, "loss": "6.681", "ntokens": "7087.94", "nsentences": "25.07", "prob_perplexity": "562.505", "code_perplexity": "550.426", "temp": "1.778", "loss_0": "6.658", "loss_1": "0.017", "loss_2": "0.006", "accuracy": "0.01348", "wps": "22486.9", "ups": "3.17", "wpb": "7087.9", "bsz": "25.1", "num_updates": "23600", "lr": "0.00036875", "gnorm": "0.036", "loss_scale": "1", "train_wall": "63", "gb_free": "15.8", "wall": "7490"}
[2023-09-08 20:28:19,517][train_inner][INFO] - {"epoch": 3, "update": 2.142, "loss": "6.671", "ntokens": "7082.22", "nsentences": "25.68", "prob_perplexity": "592.104", "code_perplexity": "431.047", "temp": "1.777", "loss_0": "6.658", "loss_1": "0.011", "loss_2": "0.003", "accuracy": "0.01781", "wps": "22800.5", "ups": "3.22", "wpb": "7082.2", "bsz": "25.7", "num_updates": "23800", "lr": "0.000371875", "gnorm": "0.017", "loss_scale": "1", "train_wall": "62", "gb_free": "18.2", "wall": "7552"}
[2023-09-08 20:29:22,388][train_inner][INFO] - {"epoch": 3, "update": 2.16, "loss": "6.666", "ntokens": "7029.48", "nsentences": "25.11", "prob_perplexity": "613.876", "code_perplexity": "321.477", "temp": "1.775", "loss_0": "6.658", "loss_1": "0.006", "loss_2": "0.001", "accuracy": "0.03395", "wps": "22361.8", "ups": "3.18", "wpb": "7029.5", "bsz": "25.1", "num_updates": "24000", "lr": "0.000375", "gnorm": "0.013", "loss_scale": "1", "train_wall": "62", "gb_free": "17.6", "wall": "7615"}
[2023-09-08 20:30:25,487][train_inner][INFO] - {"epoch": 3, "update": 2.178, "loss": "6.664", "ntokens": "7055.06", "nsentences": "24.935", "prob_perplexity": "618.676", "code_perplexity": "271.133", "temp": "1.773", "loss_0": "6.658", "loss_1": "0.005", "loss_2": "0.001", "accuracy": "0.05206", "wps": "22362", "ups": "3.17", "wpb": "7055.1", "bsz": "24.9", "num_updates": "24200", "lr": "0.000378125", "gnorm": "0.014", "loss_scale": "1", "train_wall": "63", "gb_free": "17.4", "wall": "7678"}
[2023-09-08 20:31:27,709][train_inner][INFO] - {"epoch": 3, "update": 2.196, "loss": "6.663", "ntokens": "7028.88", "nsentences": "25.795", "prob_perplexity": "622.272", "code_perplexity": "249.082", "temp": "1.771", "loss_0": "6.658", "loss_1": "0.004", "loss_2": "0.001", "accuracy": "0.06886", "wps": "22593.1", "ups": "3.21", "wpb": "7028.9", "bsz": "25.8", "num_updates": "24400", "lr": "0.00038125", "gnorm": "0.013", "loss_scale": "1", "train_wall": "62", "gb_free": "17.8", "wall": "7740"}
[2023-09-08 20:32:29,837][train_inner][INFO] - {"epoch": 3, "update": 2.214, "loss": "6.662", "ntokens": "7020.64", "nsentences": "25.29", "prob_perplexity": "625.248", "code_perplexity": "219.065", "temp": "1.769", "loss_0": "6.658", "loss_1": "0.003", "loss_2": "0.001", "accuracy": "0.08381", "wps": "22600.8", "ups": "3.22", "wpb": "7020.6", "bsz": "25.3", "num_updates": "24600", "lr": "0.000384375", "gnorm": "0.014", "loss_scale": "1", "train_wall": "62", "gb_free": "17.6", "wall": "7802"}
[2023-09-08 20:33:33,132][train_inner][INFO] - {"epoch": 3, "update": 2.232, "loss": "6.662", "ntokens": "7095.26", "nsentences": "24.965", "prob_perplexity": "628.023", "code_perplexity": "182.986", "temp": "1.768", "loss_0": "6.658", "loss_1": "0.003", "loss_2": "0.001", "accuracy": "0.09734", "wps": "22420", "ups": "3.16", "wpb": "7095.3", "bsz": "25", "num_updates": "24800", "lr": "0.0003875", "gnorm": "0.013", "loss_scale": "1", "train_wall": "63", "gb_free": "15.7", "wall": "7865"}
[2023-09-08 20:34:36,027][train_inner][INFO] - {"epoch": 3, "update": 2.25, "loss": "6.661", "ntokens": "7116.28", "nsentences": "24.29", "prob_perplexity": "629.31", "code_perplexity": "178.229", "temp": "1.766", "loss_0": "6.658", "loss_1": "0.002", "loss_2": "0.001", "accuracy": "0.115", "wps": "22629.4", "ups": "3.18", "wpb": "7116.3", "bsz": "24.3", "num_updates": "25000", "lr": "0.000390625", "gnorm": "0.013", "loss_scale": "1", "train_wall": "62", "gb_free": "16", "wall": "7928"}
[2023-09-08 20:34:36,027][fairseq_cli.train][INFO] - begin validation on "valid" subset
[2023-09-08 20:34:36,028][fairseq.tasks.fairseq_task][INFO] - can_reuse_epoch_itr = True
[2023-09-08 20:34:36,156][fairseq.tasks.fairseq_task][INFO] - creating new batches for epoch 4
[2023-09-08 20:34:55,415][valid][INFO] - {"epoch": 3, "valid_loss": "3.234", "valid_ntokens": "6005.5", "valid_nsentences": "41.4167", "valid_prob_perplexity": "628.94", "valid_code_perplexity": "5.065", "valid_temp": "1.765", "valid_loss_0": "3.231", "valid_loss_1": "0.002", "valid_loss_2": "0.001", "valid_accuracy": "0.45056", "valid_wps": "41275.7", "valid_wpb": "6005.5", "valid_bsz": "41.4", "valid_num_updates": "25000", "valid_best_loss": "3.234"}
[2023-09-08 20:34:55,416][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 3 @ 25000 updates
[2023-09-08 20:34:55,418][fairseq.trainer][INFO] - Saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/checkpoint_3_25000.pt
[2023-09-08 20:34:57,256][fairseq.trainer][INFO] - Finished saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/checkpoint_3_25000.pt
[2023-09-08 20:34:59,887][fairseq.checkpoint_utils][INFO] - Saved checkpoint checkpoints/checkpoint_3_25000.pt (epoch 3 @ 25000 updates, score 3.234) (writing took 4.470513532985933 seconds)
[2023-09-08 20:36:01,377][train_inner][INFO] - {"epoch": 3, "update": 2.268, "loss": "6.661", "ntokens": "7012.09", "nsentences": "25.85", "prob_perplexity": "631.287", "code_perplexity": "162.864", "temp": "1.764", "loss_0": "6.658", "loss_1": "0.002", "loss_2": "0.001", "accuracy": "0.13095", "wps": "16431.3", "ups": "2.34", "wpb": "7012.1", "bsz": "25.9", "num_updates": "25200", "lr": "0.00039375", "gnorm": "0.01", "loss_scale": "1", "train_wall": "61", "gb_free": "17.8", "wall": "8014"}
[2023-09-08 20:36:43,984][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2023-09-08 20:37:04,065][train_inner][INFO] - {"epoch": 3, "update": 2.286, "loss": "6.66", "ntokens": "7114.52", "nsentences": "25.25", "prob_perplexity": "632.033", "code_perplexity": "142.746", "temp": "1.762", "loss_0": "6.658", "loss_1": "0.002", "loss_2": "0", "accuracy": "0.14395", "wps": "22698.4", "ups": "3.19", "wpb": "7114.5", "bsz": "25.2", "num_updates": "25400", "lr": "0.000396875", "gnorm": "0.011", "loss_scale": "0.5", "train_wall": "62", "gb_free": "17.9", "wall": "8076"}
[2023-09-08 20:37:57,257][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2023-09-08 20:38:03,913][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.125
[2023-09-08 20:38:07,332][train_inner][INFO] - {"epoch": 3, "update": 2.304, "loss": "6.66", "ntokens": "7109.91", "nsentences": "24.91", "prob_perplexity": "632.489", "code_perplexity": "124.825", "temp": "1.761", "loss_0": "6.658", "loss_1": "0.002", "loss_2": "0.001", "accuracy": "0.16497", "wps": "22476.2", "ups": "3.16", "wpb": "7109.9", "bsz": "24.9", "num_updates": "25600", "lr": "0.0004", "gnorm": "0.01", "loss_scale": "0.125", "train_wall": "63", "gb_free": "17.8", "wall": "8140"}
[2023-09-08 20:38:17,670][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0625
[2023-09-08 20:38:27,415][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.03125
[2023-09-08 20:38:28,863][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.015625
[2023-09-08 20:38:31,598][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0078125
[2023-09-08 20:38:41,521][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.00390625
[2023-09-08 20:38:48,943][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.001953125
[2023-09-08 20:38:54,605][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0009765625
[2023-09-08 20:38:56,432][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.00048828125
[2023-09-08 20:39:00,066][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.000244140625
[2023-09-08 20:39:06,557][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.0001220703125
[2023-09-08 20:39:13,149][train_inner][INFO] - {"epoch": 3, "update": 2.323, "loss": "6.66", "ntokens": "7063.73", "nsentences": "25.175", "prob_perplexity": "632.934", "code_perplexity": "102.595", "temp": "1.759", "loss_0": "6.658", "loss_1": "0.002", "loss_2": "0.001", "accuracy": "0.17694", "wps": "21465", "ups": "3.04", "wpb": "7063.7", "bsz": "25.2", "num_updates": "25800", "lr": "0.000403125", "gnorm": "0.023", "loss_scale": "0.0001", "train_wall": "65", "gb_free": "17.7", "wall": "8205"}
[2023-09-08 20:39:18,777][fairseq.trainer][INFO] - Saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/crash.pt
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
WARNING:fairseq.nan_detector:Inf detected in output of feature_extractor.conv_layers.4.0, shape: torch.Size([6, 512, 2768]), forward input max: 32048.0, input min: -0.169921875
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1309: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using non-full backward hooks on a Module that does not return a "
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1309: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using non-full backward hooks on a Module that does not return a "
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1309: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using non-full backward hooks on a Module that does not return a "
WARNING:fairseq.nan_detector:NaN detected in output of , shape: torch.Size([101, 6, 319]), backward
WARNING:fairseq.nan_detector:Inf detected in output of , shape: torch.Size([101, 6, 331]), forward
WARNING:fairseq.nan_detector:Inf detected in output of , shape: torch.Size([101, 6, 289]), forward
[2023-09-08 20:39:20,681][fairseq.trainer][INFO] - Finished saving checkpoint to /home/Workspace/fairseq/outputs/2023-09-08/18-22-21/checkpoints/crash.pt
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
/root/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1309: UserWarning: Using non-full backward hooks on a Module that does not return a single Tensor or a tuple of Tensors is deprecated and will be removed in future versions. This hook will be missing some of the grad_output. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using non-full backward hooks on a Module that does not return a "
Traceback (most recent call last):
  File "/home/Workspace/fairseq/fairseq_cli/hydra_train.py", line 27, in hydra_main
    _hydra_main(cfg)
  File "/home/Workspace/fairseq/fairseq_cli/hydra_train.py", line 56, in _hydra_main
    distributed_utils.call_main(cfg, pre_main, **kwargs)
  File "/home/Workspace/fairseq/fairseq/distributed/utils.py", line 379, in call_main
    torch.multiprocessing.spawn(
  File "/root/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/root/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/root/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 160, in join
    raise ProcessRaisedException(msg, error_index, failed_process.pid)
torch.multiprocessing.spawn.ProcessRaisedException: 

-- Process 3 terminated with the following error:
Traceback (most recent call last):
  File "/root/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 69, in _wrap
    fn(i, *args)
  File "/home/Workspace/fairseq/fairseq/distributed/utils.py", line 362, in distributed_main
    main(cfg, **kwargs)
  File "/home/Workspace/fairseq/fairseq_cli/train.py", line 205, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/root/anaconda3/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/Workspace/fairseq/fairseq_cli/train.py", line 331, in train
    log_output = trainer.train_step(samples)
  File "/root/anaconda3/lib/python3.9/contextlib.py", line 79, in inner
    return func(*args, **kwds)
  File "/home/Workspace/fairseq/fairseq/trainer.py", line 953, in train_step
    grad_norm = self.clip_grad_norm(self.cfg.optimization.clip_norm)
  File "/home/Workspace/fairseq/fairseq/trainer.py", line 1295, in clip_grad_norm
    return self.optimizer.clip_grad_norm(
  File "/home/Workspace/fairseq/fairseq/optim/fp16_optimizer.py", line 206, in clip_grad_norm
    self.scaler.check_overflow(grad_norm)
  File "/home/Workspace/fairseq/fairseq/optim/dynamic_loss_scaler.py", line 61, in check_overflow
    raise FloatingPointError(
FloatingPointError: Minimum loss scale reached (0.0001). Your loss is probably exploding. Try lowering the learning rate, using gradient clipping or increasing the batch size.


Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
/root/anaconda3/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 100 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
