INFO:fairseq_cli.preprocess:Namespace(beam_search_hyps=False, segment_level_training_start_iter=0, no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', scoring='bleu', task='translation', source_lang='en', target_lang='de', trainpref='examples/translation/wmt14_en_de/train', validpref='examples/translation/wmt14_en_de/valid', testpref='examples/translation/wmt14_en_de/test', align_suffix=None, destdir='data-bin/wmt14_en_de', thresholdtgt=0, thresholdsrc=0, tgtdict=None, srcdict=None, nwordstgt=-1, nwordssrc=-1, alignfile=None, dataset_impl='mmap', joined_dictionary=False, only_source=False, padding_factor=8, workers=20, dict_only=False)
Traceback (most recent call last):
  File "/root/anaconda3/bin/fairseq-preprocess", line 8, in <module>
    sys.exit(cli_main())
  File "/home/Workspace/fairseq/fairseq_cli/preprocess.py", line 389, in cli_main
    main(args)
  File "/home/Workspace/fairseq/fairseq_cli/preprocess.py", line 299, in main
    raise FileExistsError(_dict_path(args.source_lang, args.destdir))
FileExistsError: data-bin/wmt14_en_de/dict.en.txt
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:58737
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:58737
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:58737
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:58737
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | initialized host 19e0b2a19b1c as rank 0
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | initialized host 19e0b2a19b1c as rank 2
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-20 10:40:01 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | initialized host 19e0b2a19b1c as rank 1
2023-09-20 10:40:01 | INFO | fairseq.distributed.utils | initialized host 19e0b2a19b1c as rank 3
2023-09-20 10:40:03 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'beam_search_hyps': True, 'segment_level_training_start_iter': 30000, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:58737', 'distributed_port': 58737, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3584, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3584, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'bleu', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 3, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(beam_search_hyps=True, segment_level_training_start_iter=30000, no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='segment_level_training', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=3584, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=3584, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=4, distributed_num_procs=4, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=4, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer_vaswani_wmt_en_de_big', max_epoch=0, max_update=0, stop_time_hours=0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='bleu', maximize_best_checkpoint_metric=True, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='data-bin/wmt14_en_de', source_lang=None, target_lang=None, load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=True, eval_bleu_args='{"beam": 3, "max_len_a": 1.2, "max_len_b": 10}', eval_bleu_detok='moses', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe='@@ ', eval_bleu_print_samples=True, label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, dropout=0.3, no_seed_provided=False, encoder_embed_dim=1024, encoder_ffn_embed_dim=4096, encoder_attention_heads=16, encoder_normalize_before=False, decoder_embed_dim=1024, decoder_ffn_embed_dim=4096, decoder_attention_heads=16, encoder_embed_path=None, encoder_layers=6, encoder_learned_pos=False, decoder_embed_path=None, decoder_layers=6, decoder_normalize_before=False, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, activation_fn='relu', adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_all_embeddings=False, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=1024, decoder_input_dim=1024, no_scale_embedding=False, layernorm_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer_vaswani_wmt_en_de_big'), 'task': {'_name': 'translation', 'data': 'data-bin/wmt14_en_de', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': True, 'eval_bleu_args': '{"beam": 3, "max_len_a": 1.2, "max_len_b": 10}', 'eval_bleu_detok': 'moses', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': '@@ ', 'eval_bleu_print_samples': True}, 'criterion': {'_name': 'segment_level_training', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2023-09-20 10:40:03 | INFO | fairseq.tasks.translation | [en] dictionary: 40576 types
2023-09-20 10:40:03 | INFO | fairseq.tasks.translation | [de] dictionary: 42808 types
2023-09-20 10:40:06 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(40576, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(42808, 1024, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1024, out_features=42808, bias=False)
  )
)
2023-09-20 10:40:06 | INFO | fairseq_cli.train | task: TranslationTask
2023-09-20 10:40:06 | INFO | fairseq_cli.train | model: TransformerModel
2023-09-20 10:40:06 | INFO | fairseq_cli.train | criterion: SegmentLevelTraining
2023-09-20 10:40:06 | INFO | fairseq_cli.train | num. shared model params: 261,742,592 (num. trained: 261,742,592)
2023-09-20 10:40:06 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2023-09-20 10:40:06 | INFO | fairseq.data.data_utils | loaded 39,421 examples from: data-bin/wmt14_en_de/valid.en-de.en
2023-09-20 10:40:06 | INFO | fairseq.data.data_utils | loaded 39,421 examples from: data-bin/wmt14_en_de/valid.en-de.de
2023-09-20 10:40:06 | INFO | fairseq.tasks.translation | data-bin/wmt14_en_de valid en-de 39421 examples
2023-09-20 10:40:06 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2023-09-20 10:40:06 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
2023-09-20 10:40:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2023-09-20 10:40:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-09-20 10:40:07 | INFO | fairseq.utils | rank   0: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
2023-09-20 10:40:07 | INFO | fairseq.utils | rank   1: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
2023-09-20 10:40:07 | INFO | fairseq.utils | rank   2: capabilities =  8.9  ; total memory = 23.650 GB ; name = NVIDIA GeForce RTX 4090                 
2023-09-20 10:40:07 | INFO | fairseq.utils | rank   3: capabilities =  8.9  ; total memory = 23.648 GB ; name = NVIDIA GeForce RTX 4090                 
2023-09-20 10:40:07 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2023-09-20 10:40:07 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2023-09-20 10:40:07 | INFO | fairseq_cli.train | max tokens per device = 3584 and max sentences per device = None
2023-09-20 10:40:07 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/checkpoint_last.pt
2023-09-20 10:40:07 | INFO | fairseq.trainer | No existing checkpoint found checkpoints/checkpoint_last.pt
2023-09-20 10:40:07 | INFO | fairseq.trainer | loading train data for epoch 1
2023-09-20 10:40:07 | INFO | fairseq.data.data_utils | loaded 3,900,974 examples from: data-bin/wmt14_en_de/train.en-de.en
2023-09-20 10:40:07 | INFO | fairseq.data.data_utils | loaded 3,900,974 examples from: data-bin/wmt14_en_de/train.en-de.de
2023-09-20 10:40:07 | INFO | fairseq.tasks.translation | data-bin/wmt14_en_de train en-de 3900974 examples
2023-09-20 10:40:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 10:40:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2023-09-20 10:40:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2023-09-20 10:40:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2023-09-20 10:40:08 | INFO | fairseq_cli.train | begin dry-run validation on "valid" subset
2023-09-20 10:40:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 10:40:08 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2023-09-20 10:40:08 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2023-09-20 10:40:08 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2023-09-20 10:40:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-20 10:40:12 | INFO | fairseq.trainer | begin training epoch 1
2023-09-20 10:40:12 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-20 10:40:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2023-09-20 10:40:16 | INFO | torch.nn.parallel.distributed | Reducer buckets have been rebuilt in this iteration.
/root/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/root/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/root/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-20 10:40:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
/root/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
2023-09-20 10:40:33 | INFO | train_inner | epoch 001:    102 / 9060 loss=14.074, nll_loss=12.451, ppl=5598.54, wps=77579.6, ups=5.99, wpb=12951.2, bsz=437.1, num_updates=100, lr=1.25975e-05, gnorm=3.07, loss_scale=32, train_wall=17, gb_free=15.3, wall=26
lprobs.size(): torch.Size([3016, 42808])
2023-09-20 10:40:49 | INFO | train_inner | epoch 001:    202 / 9060 loss=12.342, nll_loss=10.704, ppl=1668.54, wps=80506.5, ups=6.21, wpb=12955.2, bsz=429.4, num_updates=200, lr=2.5095e-05, gnorm=1.541, loss_scale=32, train_wall=16, gb_free=15.4, wall=42
2023-09-20 10:41:05 | INFO | train_inner | epoch 001:    302 / 9060 loss=11.504, nll_loss=9.809, ppl=897.11, wps=80888.2, ups=6.23, wpb=12978.9, bsz=442.5, num_updates=300, lr=3.75925e-05, gnorm=1.559, loss_scale=32, train_wall=16, gb_free=15.2, wall=58
2023-09-20 10:41:21 | INFO | train_inner | epoch 001:    402 / 9060 loss=11.223, nll_loss=9.497, ppl=722.78, wps=81196.4, ups=6.25, wpb=12990.7, bsz=435.6, num_updates=400, lr=5.009e-05, gnorm=1.593, loss_scale=32, train_wall=16, gb_free=15.4, wall=74
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 10:41:37 | INFO | train_inner | epoch 001:    502 / 9060 loss=10.993, nll_loss=9.258, ppl=612.05, wps=80309.6, ups=6.25, wpb=12843.2, bsz=411.8, num_updates=500, lr=6.25875e-05, gnorm=1.652, loss_scale=32, train_wall=16, gb_free=15.4, wall=90
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([2736, 42808])
2023-09-20 10:41:53 | INFO | train_inner | epoch 001:    602 / 9060 loss=10.644, nll_loss=8.896, ppl=476.49, wps=81287.5, ups=6.25, wpb=13004.1, bsz=419.8, num_updates=600, lr=7.5085e-05, gnorm=1.54, loss_scale=32, train_wall=16, gb_free=14.9, wall=106
lprobs.size(): torch.Size([3528, 42808])
2023-09-20 10:42:09 | INFO | train_inner | epoch 001:    702 / 9060 loss=10.367, nll_loss=8.606, ppl=389.71, wps=80813.6, ups=6.26, wpb=12916.6, bsz=426, num_updates=700, lr=8.75825e-05, gnorm=1.492, loss_scale=32, train_wall=16, gb_free=15.2, wall=122
lprobs.size(): torch.Size([2784, 42808])
2023-09-20 10:42:25 | INFO | train_inner | epoch 001:    802 / 9060 loss=10.081, nll_loss=8.308, ppl=316.83, wps=81552.2, ups=6.25, wpb=13038.6, bsz=450.2, num_updates=800, lr=0.00010008, gnorm=1.648, loss_scale=32, train_wall=16, gb_free=15.4, wall=138
2023-09-20 10:42:35 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-20 10:42:41 | INFO | train_inner | epoch 001:    903 / 9060 loss=9.878, nll_loss=8.095, ppl=273.38, wps=80428.5, ups=6.21, wpb=12955.8, bsz=421, num_updates=900, lr=0.000112578, gnorm=1.438, loss_scale=16, train_wall=16, gb_free=15.1, wall=154
lprobs.size(): torch.Size([2968, 42808])
2023-09-20 10:42:57 | INFO | train_inner | epoch 001:   1003 / 9060 loss=9.611, nll_loss=7.819, ppl=225.74, wps=81207.1, ups=6.26, wpb=12970.4, bsz=449.7, num_updates=1000, lr=0.000125075, gnorm=1.382, loss_scale=16, train_wall=16, gb_free=15.6, wall=170
2023-09-20 10:43:13 | INFO | train_inner | epoch 001:   1103 / 9060 loss=9.452, nll_loss=7.652, ppl=201.17, wps=81663.9, ups=6.26, wpb=13050.9, bsz=443.3, num_updates=1100, lr=0.000137573, gnorm=1.315, loss_scale=16, train_wall=16, gb_free=15.6, wall=186
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 10:43:29 | INFO | train_inner | epoch 001:   1203 / 9060 loss=9.343, nll_loss=7.536, ppl=185.58, wps=81297.8, ups=6.26, wpb=12980.2, bsz=412.2, num_updates=1200, lr=0.00015007, gnorm=1.277, loss_scale=16, train_wall=16, gb_free=15.3, wall=202
2023-09-20 10:43:45 | INFO | train_inner | epoch 001:   1303 / 9060 loss=9.126, nll_loss=7.311, ppl=158.8, wps=81413.2, ups=6.26, wpb=13003.1, bsz=437, num_updates=1300, lr=0.000162568, gnorm=1.263, loss_scale=16, train_wall=16, gb_free=15.1, wall=218
2023-09-20 10:44:01 | INFO | train_inner | epoch 001:   1403 / 9060 loss=9.022, nll_loss=7.202, ppl=147.23, wps=81650.5, ups=6.27, wpb=13020.4, bsz=431.4, num_updates=1400, lr=0.000175065, gnorm=1.2, loss_scale=16, train_wall=16, gb_free=15.1, wall=234
2023-09-20 10:44:17 | INFO | train_inner | epoch 001:   1503 / 9060 loss=8.912, nll_loss=7.087, ppl=135.92, wps=81307.3, ups=6.27, wpb=12974.3, bsz=415.8, num_updates=1500, lr=0.000187563, gnorm=1.158, loss_scale=16, train_wall=16, gb_free=15.3, wall=250
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 10:44:33 | INFO | train_inner | epoch 001:   1603 / 9060 loss=8.786, nll_loss=6.955, ppl=124.06, wps=80981.1, ups=6.28, wpb=12903.7, bsz=417.3, num_updates=1600, lr=0.00020006, gnorm=1.075, loss_scale=16, train_wall=16, gb_free=15.3, wall=266
2023-09-20 10:44:49 | INFO | train_inner | epoch 001:   1703 / 9060 loss=8.703, nll_loss=6.867, ppl=116.75, wps=81351.9, ups=6.27, wpb=12975, bsz=414.5, num_updates=1700, lr=0.000212558, gnorm=1.128, loss_scale=16, train_wall=16, gb_free=15, wall=282
2023-09-20 10:45:04 | INFO | train_inner | epoch 001:   1803 / 9060 loss=8.553, nll_loss=6.712, ppl=104.83, wps=81261.7, ups=6.26, wpb=12980.2, bsz=415, num_updates=1800, lr=0.000225055, gnorm=1.075, loss_scale=16, train_wall=16, gb_free=14.9, wall=298
lprobs.size(): torch.Size([3432, 42808])
2023-09-20 10:45:20 | INFO | train_inner | epoch 001:   1903 / 9060 loss=8.442, nll_loss=6.596, ppl=96.74, wps=81546.5, ups=6.27, wpb=13007.2, bsz=438.2, num_updates=1900, lr=0.000237553, gnorm=1.054, loss_scale=16, train_wall=16, gb_free=15.3, wall=314
2023-09-20 10:45:36 | INFO | train_inner | epoch 001:   2003 / 9060 loss=8.383, nll_loss=6.534, ppl=92.65, wps=80875.3, ups=6.28, wpb=12881, bsz=418.2, num_updates=2000, lr=0.00025005, gnorm=1.047, loss_scale=16, train_wall=16, gb_free=15.4, wall=330
2023-09-20 10:45:52 | INFO | train_inner | epoch 001:   2103 / 9060 loss=8.273, nll_loss=6.42, ppl=85.6, wps=81673.2, ups=6.26, wpb=13047.4, bsz=442.8, num_updates=2100, lr=0.000262548, gnorm=1.015, loss_scale=16, train_wall=16, gb_free=15.3, wall=346
2023-09-20 10:46:08 | INFO | train_inner | epoch 001:   2203 / 9060 loss=8.159, nll_loss=6.302, ppl=78.93, wps=81245.3, ups=6.26, wpb=12971, bsz=435.4, num_updates=2200, lr=0.000275045, gnorm=1.012, loss_scale=16, train_wall=16, gb_free=15.5, wall=362
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([2464, 42808])
2023-09-20 10:46:24 | INFO | train_inner | epoch 001:   2303 / 9060 loss=8.05, nll_loss=6.189, ppl=72.94, wps=80474.1, ups=6.2, wpb=12973.1, bsz=443.4, num_updates=2300, lr=0.000287543, gnorm=1.211, loss_scale=16, train_wall=16, gb_free=15.1, wall=378
2023-09-20 10:46:41 | INFO | train_inner | epoch 001:   2403 / 9060 loss=7.962, nll_loss=6.098, ppl=68.5, wps=80480.4, ups=6.19, wpb=12992.1, bsz=412.1, num_updates=2400, lr=0.00030004, gnorm=1.025, loss_scale=16, train_wall=16, gb_free=15.9, wall=394
lprobs.size(): torch.Size([3024, 42808])
2023-09-20 10:46:57 | INFO | train_inner | epoch 001:   2503 / 9060 loss=7.778, nll_loss=5.908, ppl=60.06, wps=80984.2, ups=6.26, wpb=12929.1, bsz=438.2, num_updates=2500, lr=0.000312538, gnorm=1.077, loss_scale=16, train_wall=16, gb_free=16, wall=410
2023-09-20 10:47:12 | INFO | train_inner | epoch 001:   2603 / 9060 loss=7.708, nll_loss=5.835, ppl=57.08, wps=81555.3, ups=6.27, wpb=12997.7, bsz=435.6, num_updates=2600, lr=0.000325035, gnorm=0.997, loss_scale=16, train_wall=16, gb_free=16, wall=426
lprobs.size(): torch.Size([3248, 42808])
2023-09-20 10:47:28 | INFO | train_inner | epoch 001:   2703 / 9060 loss=7.559, nll_loss=5.682, ppl=51.33, wps=81635.4, ups=6.27, wpb=13012.2, bsz=429.6, num_updates=2700, lr=0.000337533, gnorm=1.041, loss_scale=16, train_wall=16, gb_free=15.2, wall=442
2023-09-20 10:47:44 | INFO | train_inner | epoch 001:   2803 / 9060 loss=7.427, nll_loss=5.545, ppl=46.69, wps=81661.7, ups=6.24, wpb=13078, bsz=456.4, num_updates=2800, lr=0.00035003, gnorm=1.071, loss_scale=16, train_wall=16, gb_free=15.3, wall=458
lprobs.size(): torch.Size([3168, 42808])
2023-09-20 10:48:00 | INFO | train_inner | epoch 001:   2903 / 9060 loss=7.394, nll_loss=5.509, ppl=45.53, wps=81439.4, ups=6.27, wpb=12987.4, bsz=414, num_updates=2900, lr=0.000362528, gnorm=1.047, loss_scale=16, train_wall=16, gb_free=15.3, wall=474
2023-09-20 10:48:16 | INFO | train_inner | epoch 001:   3003 / 9060 loss=7.214, nll_loss=5.326, ppl=40.11, wps=80743.6, ups=6.26, wpb=12903.5, bsz=437.7, num_updates=3000, lr=0.000375025, gnorm=1.008, loss_scale=16, train_wall=16, gb_free=15.3, wall=490
lprobs.size(): torch.Size([3536, 42808])
2023-09-20 10:48:32 | INFO | train_inner | epoch 001:   3103 / 9060 loss=7.084, nll_loss=5.192, ppl=36.55, wps=81549.7, ups=6.23, wpb=13082.4, bsz=435.6, num_updates=3100, lr=0.000387523, gnorm=1.025, loss_scale=16, train_wall=16, gb_free=15, wall=506
2023-09-20 10:48:48 | INFO | train_inner | epoch 001:   3203 / 9060 loss=6.967, nll_loss=5.072, ppl=33.63, wps=81481.9, ups=6.26, wpb=13007.4, bsz=438.8, num_updates=3200, lr=0.00040002, gnorm=0.999, loss_scale=16, train_wall=16, gb_free=16, wall=522
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 10:49:04 | INFO | train_inner | epoch 001:   3303 / 9060 loss=6.84, nll_loss=4.939, ppl=30.69, wps=81690.3, ups=6.27, wpb=13019.1, bsz=432.1, num_updates=3300, lr=0.000412518, gnorm=1, loss_scale=16, train_wall=16, gb_free=15.4, wall=538
lprobs.size(): torch.Size([3496, 42808])
2023-09-20 10:49:20 | INFO | train_inner | epoch 001:   3403 / 9060 loss=6.698, nll_loss=4.794, ppl=27.75, wps=81655.8, ups=6.27, wpb=13026.3, bsz=433.1, num_updates=3400, lr=0.000425015, gnorm=0.97, loss_scale=16, train_wall=16, gb_free=16.2, wall=554
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 10:49:36 | INFO | train_inner | epoch 001:   3503 / 9060 loss=6.675, nll_loss=4.77, ppl=27.28, wps=81453.2, ups=6.27, wpb=12992, bsz=395.3, num_updates=3500, lr=0.000437513, gnorm=1.005, loss_scale=16, train_wall=16, gb_free=15.7, wall=570
2023-09-20 10:49:52 | INFO | train_inner | epoch 001:   3603 / 9060 loss=6.497, nll_loss=4.588, ppl=24.05, wps=81692.3, ups=6.27, wpb=13031.2, bsz=457.6, num_updates=3600, lr=0.00045001, gnorm=0.984, loss_scale=16, train_wall=16, gb_free=15.3, wall=586
2023-09-20 10:50:08 | INFO | train_inner | epoch 001:   3703 / 9060 loss=6.414, nll_loss=4.502, ppl=22.66, wps=80852.4, ups=6.26, wpb=12908.7, bsz=431.3, num_updates=3700, lr=0.000462508, gnorm=0.987, loss_scale=16, train_wall=16, gb_free=15.3, wall=602
lprobs.size(): torch.Size([3096, 42808])
2023-09-20 10:50:24 | INFO | train_inner | epoch 001:   3803 / 9060 loss=6.365, nll_loss=4.452, ppl=21.88, wps=81789.3, ups=6.26, wpb=13060.2, bsz=427, num_updates=3800, lr=0.000475005, gnorm=1.001, loss_scale=16, train_wall=16, gb_free=15.1, wall=618
2023-09-20 10:50:40 | INFO | train_inner | epoch 001:   3903 / 9060 loss=6.295, nll_loss=4.38, ppl=20.82, wps=80955.5, ups=6.26, wpb=12925.5, bsz=429.7, num_updates=3900, lr=0.000487503, gnorm=0.98, loss_scale=16, train_wall=16, gb_free=15.1, wall=634
2023-09-20 10:50:56 | INFO | train_inner | epoch 001:   4003 / 9060 loss=6.24, nll_loss=4.323, ppl=20.01, wps=81148.6, ups=6.26, wpb=12953.6, bsz=434.1, num_updates=4000, lr=0.0005, gnorm=0.976, loss_scale=16, train_wall=16, gb_free=15, wall=649
2023-09-20 10:51:12 | INFO | train_inner | epoch 001:   4103 / 9060 loss=6.136, nll_loss=4.217, ppl=18.6, wps=81774.3, ups=6.27, wpb=13049.7, bsz=443.2, num_updates=4100, lr=0.000493865, gnorm=0.961, loss_scale=16, train_wall=16, gb_free=15.5, wall=665
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3128, 42808])
2023-09-20 10:51:28 | INFO | train_inner | epoch 001:   4203 / 9060 loss=6.048, nll_loss=4.127, ppl=17.47, wps=81223.9, ups=6.27, wpb=12961.3, bsz=430.6, num_updates=4200, lr=0.00048795, gnorm=0.937, loss_scale=16, train_wall=16, gb_free=15.2, wall=681
2023-09-20 10:51:44 | INFO | train_inner | epoch 001:   4303 / 9060 loss=5.967, nll_loss=4.044, ppl=16.49, wps=82019.3, ups=6.26, wpb=13095.2, bsz=441.5, num_updates=4300, lr=0.000482243, gnorm=0.951, loss_scale=16, train_wall=16, gb_free=16.3, wall=697
lprobs.size(): torch.Size([3248, 42808])
2023-09-20 10:52:00 | INFO | train_inner | epoch 001:   4403 / 9060 loss=6.003, nll_loss=4.08, ppl=16.92, wps=81087.6, ups=6.27, wpb=12931.8, bsz=419, num_updates=4400, lr=0.000476731, gnorm=0.976, loss_scale=16, train_wall=16, gb_free=15.2, wall=713
2023-09-20 10:52:16 | INFO | train_inner | epoch 001:   4503 / 9060 loss=5.913, nll_loss=3.99, ppl=15.89, wps=81771.4, ups=6.26, wpb=13053, bsz=435.5, num_updates=4500, lr=0.000471405, gnorm=0.961, loss_scale=16, train_wall=16, gb_free=15.5, wall=729
2023-09-20 10:52:32 | INFO | train_inner | epoch 001:   4603 / 9060 loss=5.813, nll_loss=3.888, ppl=14.8, wps=80893.3, ups=6.28, wpb=12890.7, bsz=433.1, num_updates=4600, lr=0.000466252, gnorm=0.905, loss_scale=16, train_wall=16, gb_free=15.1, wall=745
lprobs.size(): torch.Size([3240, 42808])
2023-09-20 10:52:48 | INFO | train_inner | epoch 001:   4703 / 9060 loss=5.768, nll_loss=3.843, ppl=14.35, wps=81573.1, ups=6.27, wpb=13017.3, bsz=422.5, num_updates=4700, lr=0.000461266, gnorm=0.897, loss_scale=16, train_wall=16, gb_free=15.3, wall=761
2023-09-20 10:53:04 | INFO | train_inner | epoch 001:   4803 / 9060 loss=5.787, nll_loss=3.862, ppl=14.55, wps=81047.6, ups=6.26, wpb=12937.7, bsz=413.7, num_updates=4800, lr=0.000456435, gnorm=0.916, loss_scale=16, train_wall=16, gb_free=15.9, wall=777
lprobs.size(): torch.Size([3280, 42808])
2023-09-20 10:53:20 | INFO | train_inner | epoch 001:   4903 / 9060 loss=5.695, nll_loss=3.771, ppl=13.65, wps=81279.5, ups=6.25, wpb=13014.6, bsz=435.9, num_updates=4900, lr=0.000451754, gnorm=0.904, loss_scale=16, train_wall=16, gb_free=15.1, wall=793
2023-09-20 10:53:36 | INFO | train_inner | epoch 001:   5003 / 9060 loss=5.706, nll_loss=3.781, ppl=13.75, wps=80944.4, ups=6.26, wpb=12930.9, bsz=410.8, num_updates=5000, lr=0.000447214, gnorm=0.902, loss_scale=32, train_wall=16, gb_free=15, wall=809
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2688, 42808])
2023-09-20 10:53:52 | INFO | train_inner | epoch 001:   5103 / 9060 loss=5.713, nll_loss=3.79, ppl=13.83, wps=80547.8, ups=6.25, wpb=12892.1, bsz=429, num_updates=5100, lr=0.000442807, gnorm=0.89, loss_scale=32, train_wall=16, gb_free=15.8, wall=825
2023-09-20 10:54:08 | INFO | train_inner | epoch 001:   5203 / 9060 loss=5.564, nll_loss=3.638, ppl=12.45, wps=81472.3, ups=6.25, wpb=13036, bsz=438.4, num_updates=5200, lr=0.000438529, gnorm=0.873, loss_scale=32, train_wall=16, gb_free=15.5, wall=841
2023-09-20 10:54:24 | INFO | train_inner | epoch 001:   5303 / 9060 loss=5.567, nll_loss=3.642, ppl=12.48, wps=80797.2, ups=6.22, wpb=12993.6, bsz=450, num_updates=5300, lr=0.000434372, gnorm=0.852, loss_scale=32, train_wall=16, gb_free=15.6, wall=857
2023-09-20 10:54:40 | INFO | train_inner | epoch 001:   5403 / 9060 loss=5.558, nll_loss=3.632, ppl=12.4, wps=81126, ups=6.25, wpb=12981.8, bsz=419.2, num_updates=5400, lr=0.000430331, gnorm=0.828, loss_scale=32, train_wall=16, gb_free=15.1, wall=873
2023-09-20 10:54:56 | INFO | train_inner | epoch 001:   5503 / 9060 loss=5.513, nll_loss=3.589, ppl=12.03, wps=81387.1, ups=6.26, wpb=13005.2, bsz=415.7, num_updates=5500, lr=0.000426401, gnorm=0.84, loss_scale=32, train_wall=16, gb_free=16.1, wall=889
2023-09-20 10:55:12 | INFO | train_inner | epoch 001:   5603 / 9060 loss=5.483, nll_loss=3.558, ppl=11.78, wps=81262.4, ups=6.25, wpb=12991.9, bsz=415, num_updates=5600, lr=0.000422577, gnorm=0.833, loss_scale=32, train_wall=16, gb_free=15.5, wall=905
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 10:55:28 | INFO | train_inner | epoch 001:   5703 / 9060 loss=5.5, nll_loss=3.576, ppl=11.93, wps=80425.3, ups=6.25, wpb=12866.8, bsz=427.8, num_updates=5700, lr=0.000418854, gnorm=0.829, loss_scale=32, train_wall=16, gb_free=15.6, wall=921
2023-09-20 10:55:44 | INFO | train_inner | epoch 001:   5803 / 9060 loss=5.471, nll_loss=3.547, ppl=11.69, wps=80528, ups=6.24, wpb=12903.6, bsz=411.7, num_updates=5800, lr=0.000415227, gnorm=0.825, loss_scale=32, train_wall=16, gb_free=15.1, wall=937
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 10:56:00 | INFO | train_inner | epoch 001:   5903 / 9060 loss=5.423, nll_loss=3.499, ppl=11.3, wps=80851.5, ups=6.25, wpb=12944.8, bsz=436.2, num_updates=5900, lr=0.000411693, gnorm=0.829, loss_scale=32, train_wall=16, gb_free=15.2, wall=953
2023-09-20 10:56:16 | INFO | train_inner | epoch 001:   6003 / 9060 loss=5.39, nll_loss=3.465, ppl=11.05, wps=81238.4, ups=6.26, wpb=12986.8, bsz=420.5, num_updates=6000, lr=0.000408248, gnorm=0.797, loss_scale=32, train_wall=16, gb_free=15.3, wall=969
2023-09-20 10:56:32 | INFO | train_inner | epoch 001:   6103 / 9060 loss=5.345, nll_loss=3.421, ppl=10.71, wps=81153.9, ups=6.26, wpb=12965.7, bsz=456.6, num_updates=6100, lr=0.000404888, gnorm=0.795, loss_scale=32, train_wall=16, gb_free=15.1, wall=985
lprobs.size(): torch.Size([2464, 42808])
2023-09-20 10:56:48 | INFO | train_inner | epoch 001:   6203 / 9060 loss=5.364, nll_loss=3.44, ppl=10.85, wps=80954.9, ups=6.26, wpb=12926.4, bsz=433, num_updates=6200, lr=0.00040161, gnorm=0.807, loss_scale=32, train_wall=16, gb_free=15.2, wall=1001
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 10:57:04 | INFO | train_inner | epoch 001:   6303 / 9060 loss=5.376, nll_loss=3.453, ppl=10.95, wps=81268.2, ups=6.25, wpb=12995.2, bsz=422.2, num_updates=6300, lr=0.00039841, gnorm=0.809, loss_scale=32, train_wall=16, gb_free=15.2, wall=1017
2023-09-20 10:57:20 | INFO | train_inner | epoch 001:   6403 / 9060 loss=5.357, nll_loss=3.435, ppl=10.81, wps=80781.5, ups=6.25, wpb=12933.9, bsz=423.1, num_updates=6400, lr=0.000395285, gnorm=0.803, loss_scale=32, train_wall=16, gb_free=15.2, wall=1033
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-20 10:57:36 | INFO | train_inner | epoch 001:   6503 / 9060 loss=5.277, nll_loss=3.353, ppl=10.22, wps=81168, ups=6.26, wpb=12957, bsz=426.1, num_updates=6500, lr=0.000392232, gnorm=0.777, loss_scale=32, train_wall=16, gb_free=15, wall=1049
2023-09-20 10:57:52 | INFO | train_inner | epoch 001:   6603 / 9060 loss=5.285, nll_loss=3.362, ppl=10.28, wps=81643.4, ups=6.27, wpb=13027.5, bsz=433.8, num_updates=6600, lr=0.000389249, gnorm=0.769, loss_scale=32, train_wall=16, gb_free=15.5, wall=1065
2023-09-20 10:58:08 | INFO | train_inner | epoch 001:   6703 / 9060 loss=5.269, nll_loss=3.346, ppl=10.17, wps=81118.4, ups=6.26, wpb=12955, bsz=434.8, num_updates=6700, lr=0.000386334, gnorm=0.784, loss_scale=32, train_wall=16, gb_free=15.1, wall=1081
2023-09-20 10:58:24 | INFO | train_inner | epoch 001:   6803 / 9060 loss=5.267, nll_loss=3.345, ppl=10.16, wps=80747, ups=6.26, wpb=12901.1, bsz=429.3, num_updates=6800, lr=0.000383482, gnorm=0.765, loss_scale=32, train_wall=16, gb_free=15.6, wall=1097
2023-09-20 10:58:39 | INFO | train_inner | epoch 001:   6903 / 9060 loss=5.224, nll_loss=3.301, ppl=9.85, wps=81293.8, ups=6.27, wpb=12958.9, bsz=442.5, num_updates=6900, lr=0.000380693, gnorm=0.758, loss_scale=32, train_wall=16, gb_free=15.2, wall=1113
2023-09-20 10:58:55 | INFO | train_inner | epoch 001:   7003 / 9060 loss=5.235, nll_loss=3.314, ppl=9.94, wps=80950.2, ups=6.27, wpb=12914.7, bsz=440.9, num_updates=7000, lr=0.000377964, gnorm=0.769, loss_scale=32, train_wall=16, gb_free=15.4, wall=1129
2023-09-20 10:58:59 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-20 10:59:12 | INFO | train_inner | epoch 001:   7104 / 9060 loss=5.218, nll_loss=3.295, ppl=9.82, wps=80990.3, ups=6.22, wpb=13026.5, bsz=427.4, num_updates=7100, lr=0.000375293, gnorm=0.758, loss_scale=16, train_wall=16, gb_free=15.4, wall=1145
lprobs.size(): torch.Size([2912, 42808])
2023-09-20 10:59:28 | INFO | train_inner | epoch 001:   7204 / 9060 loss=5.221, nll_loss=3.3, ppl=9.85, wps=80198.4, ups=6.25, wpb=12826, bsz=432.6, num_updates=7200, lr=0.000372678, gnorm=0.765, loss_scale=16, train_wall=16, gb_free=15.3, wall=1161
2023-09-20 10:59:44 | INFO | train_inner | epoch 001:   7304 / 9060 loss=5.158, nll_loss=3.235, ppl=9.42, wps=81191.4, ups=6.26, wpb=12978.9, bsz=438, num_updates=7300, lr=0.000370117, gnorm=0.747, loss_scale=16, train_wall=16, gb_free=15.1, wall=1177
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([2288, 42808])
2023-09-20 11:00:00 | INFO | train_inner | epoch 001:   7404 / 9060 loss=5.229, nll_loss=3.309, ppl=9.91, wps=78939.4, ups=6.13, wpb=12880.8, bsz=432.2, num_updates=7400, lr=0.000367607, gnorm=0.757, loss_scale=16, train_wall=16, gb_free=15.3, wall=1193
2023-09-20 11:00:16 | INFO | train_inner | epoch 001:   7504 / 9060 loss=5.2, nll_loss=3.28, ppl=9.71, wps=81340.7, ups=6.26, wpb=12995.1, bsz=425.3, num_updates=7500, lr=0.000365148, gnorm=0.724, loss_scale=16, train_wall=16, gb_free=15, wall=1209
2023-09-20 11:00:32 | INFO | train_inner | epoch 001:   7604 / 9060 loss=5.136, nll_loss=3.215, ppl=9.28, wps=81153.3, ups=6.27, wpb=12946.4, bsz=440.7, num_updates=7600, lr=0.000362738, gnorm=0.75, loss_scale=16, train_wall=16, gb_free=15.2, wall=1225
2023-09-20 11:00:48 | INFO | train_inner | epoch 001:   7704 / 9060 loss=5.146, nll_loss=3.225, ppl=9.35, wps=81419, ups=6.27, wpb=12987.3, bsz=425.4, num_updates=7700, lr=0.000360375, gnorm=0.752, loss_scale=16, train_wall=16, gb_free=15.7, wall=1241
lprobs.size(): torch.Size([2720, 42808])
2023-09-20 11:01:04 | INFO | train_inner | epoch 001:   7804 / 9060 loss=5.118, nll_loss=3.197, ppl=9.17, wps=81007, ups=6.27, wpb=12915.6, bsz=443.4, num_updates=7800, lr=0.000358057, gnorm=0.752, loss_scale=16, train_wall=16, gb_free=15.4, wall=1257
2023-09-20 11:01:20 | INFO | train_inner | epoch 001:   7904 / 9060 loss=5.048, nll_loss=3.126, ppl=8.73, wps=82161.4, ups=6.26, wpb=13135, bsz=445.8, num_updates=7900, lr=0.000355784, gnorm=0.716, loss_scale=16, train_wall=16, gb_free=15.5, wall=1273
2023-09-20 11:01:36 | INFO | train_inner | epoch 001:   8004 / 9060 loss=5.099, nll_loss=3.178, ppl=9.05, wps=80471.9, ups=6.24, wpb=12899.7, bsz=432.6, num_updates=8000, lr=0.000353553, gnorm=0.736, loss_scale=16, train_wall=16, gb_free=15.2, wall=1289
2023-09-20 11:01:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-20 11:01:52 | INFO | train_inner | epoch 001:   8105 / 9060 loss=5.099, nll_loss=3.179, ppl=9.06, wps=80831.9, ups=6.22, wpb=12998, bsz=425.5, num_updates=8100, lr=0.000351364, gnorm=0.733, loss_scale=8, train_wall=16, gb_free=15.3, wall=1305
2023-09-20 11:02:08 | INFO | train_inner | epoch 001:   8205 / 9060 loss=5.036, nll_loss=3.114, ppl=8.66, wps=81487, ups=6.27, wpb=13006.5, bsz=444.6, num_updates=8200, lr=0.000349215, gnorm=0.728, loss_scale=8, train_wall=16, gb_free=15.4, wall=1321
2023-09-20 11:02:24 | INFO | train_inner | epoch 001:   8305 / 9060 loss=5.069, nll_loss=3.149, ppl=8.87, wps=81533.2, ups=6.27, wpb=13010, bsz=424.2, num_updates=8300, lr=0.000347105, gnorm=0.702, loss_scale=8, train_wall=16, gb_free=15.1, wall=1337
2023-09-20 11:02:40 | INFO | train_inner | epoch 001:   8405 / 9060 loss=5.058, nll_loss=3.138, ppl=8.81, wps=80833.1, ups=6.26, wpb=12915.9, bsz=435.8, num_updates=8400, lr=0.000345033, gnorm=0.723, loss_scale=8, train_wall=16, gb_free=15.2, wall=1353
2023-09-20 11:02:56 | INFO | train_inner | epoch 001:   8505 / 9060 loss=4.997, nll_loss=3.076, ppl=8.43, wps=81707.6, ups=6.26, wpb=13051.8, bsz=437.2, num_updates=8500, lr=0.000342997, gnorm=0.718, loss_scale=8, train_wall=16, gb_free=15.1, wall=1369
2023-09-20 11:03:12 | INFO | train_inner | epoch 001:   8605 / 9060 loss=5.047, nll_loss=3.128, ppl=8.74, wps=81725.9, ups=6.26, wpb=13057.9, bsz=417.8, num_updates=8600, lr=0.000340997, gnorm=0.725, loss_scale=8, train_wall=16, gb_free=15.2, wall=1385
2023-09-20 11:03:28 | INFO | train_inner | epoch 001:   8705 / 9060 loss=5.063, nll_loss=3.144, ppl=8.84, wps=81397.1, ups=6.26, wpb=12996.4, bsz=416.2, num_updates=8700, lr=0.000339032, gnorm=0.701, loss_scale=8, train_wall=16, gb_free=15.1, wall=1401
2023-09-20 11:03:44 | INFO | train_inner | epoch 001:   8805 / 9060 loss=5.029, nll_loss=3.11, ppl=8.64, wps=81791.2, ups=6.26, wpb=13062, bsz=442.1, num_updates=8800, lr=0.0003371, gnorm=0.708, loss_scale=8, train_wall=16, gb_free=15.1, wall=1417
lprobs.size(): torch.Size([3432, 42808])
2023-09-20 11:03:59 | INFO | train_inner | epoch 001:   8905 / 9060 loss=5, nll_loss=3.081, ppl=8.46, wps=81524.8, ups=6.27, wpb=13001.6, bsz=429.7, num_updates=8900, lr=0.000335201, gnorm=0.709, loss_scale=8, train_wall=16, gb_free=15.6, wall=1433
2023-09-20 11:04:15 | INFO | train_inner | epoch 001:   9005 / 9060 loss=5.045, nll_loss=3.126, ppl=8.73, wps=81693, ups=6.26, wpb=13050.8, bsz=405.3, num_updates=9000, lr=0.000333333, gnorm=0.709, loss_scale=8, train_wall=16, gb_free=15.3, wall=1449
2023-09-20 11:04:24 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-20 11:04:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 11:04:25 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident!
2023-09-20 11:04:25 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-20 11:04:26 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zur Aktion ist daher völlig gerechtfertigt.
2023-09-20 11:04:26 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-20 11:04:26 | INFO | fairseq.tasks.translation | example hypothesis: Auf diese Weise gibt es keinen Anspruch auf Unterkunft.
2023-09-20 11:04:26 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-20 11:04:27 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente in dem strikten Vertrauen behandelt.
2023-09-20 11:04:27 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-20 11:04:27 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Ansicht nach sollte die Namensfrage nicht erst in der ersten Reihe stehen.
2023-09-20 11:04:27 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-20 11:04:28 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt, und es war ein großer Erfolg.
2023-09-20 11:04:28 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-20 11:04:28 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Happy new year to all and Glückwunsch an unseren Präsidenten.
2023-09-20 11:04:28 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-20 11:04:29 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, und das respektieren wir.
2023-09-20 11:04:29 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-20 11:04:29 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chat-Gesprächen.
2023-09-20 11:04:29 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-20 11:04:30 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten digitale TV und Internetzugang, die sowohl für Geschäfts- als auch für Geschäftsreisende geeignet sind.
2023-09-20 11:04:30 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-20 11:04:30 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-20 11:04:30 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-20 11:04:31 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 11:04:31 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 11:04:31 | INFO | fairseq.tasks.translation | example hypothesis: Generell wird in der EU in der gesamten EU viel Energie vergeudet.
2023-09-20 11:04:31 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-20 11:04:32 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin führt einen Artikel von Gentoo Entwickler Michael Kohl in seiner letzten Nummer.
2023-09-20 11:04:32 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-20 11:04:32 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Haltung auch noch vor langer Zeit im Haushalt der Union widerspiegeln.
2023-09-20 11:04:32 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-20 11:04:33 | INFO | fairseq.tasks.translation | example hypothesis: Die Einführung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die agro-Industrie ist inakzeptabel.
2023-09-20 11:04:33 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-20 11:04:34 | INFO | fairseq.tasks.translation | example hypothesis: Hier ist ein konkretes Beispiel: die weit verbreitete und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-20 11:04:34 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-20 11:04:34 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie darin besteht, ältere Menschen zu integrieren.
2023-09-20 11:04:34 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-20 11:04:35 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen wurden gezwungen, mehr Zeit für ihr berufliches Leben zu widmen, als es sich gewünscht hätte?
2023-09-20 11:04:35 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-20 11:04:35 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft verfügt über seine Haupt- und Produktionshallen an Stans.
2023-09-20 11:04:35 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-20 11:04:36 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Remuneration-Ausschuss, dessen Vorsitzende immer die Vorsitzende des Aufsichtsrats ist.
2023-09-20 11:04:36 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-20 11:04:36 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-20 11:04:36 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-20 11:04:37 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution einhergehen.
2023-09-20 11:04:37 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-20 11:04:38 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potentielle Käufer dazu bewegen, Unkonferenzen über die Qualität Ihres Services und Ihrer Produkte zu machen.
2023-09-20 11:04:38 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-20 11:04:38 | INFO | fairseq.tasks.translation | example hypothesis: Als die Zentralbanken in unchartierte Gebiete eindringen, argumentieren sie, dass sie am schlechtesten nicht schaden werden.
2023-09-20 11:04:38 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-20 11:04:39 | INFO | fairseq.tasks.translation | example hypothesis: Sie hat hinzugefügt, dass sie bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gibt, dass die Mitgliedstaaten zu einer Einigung gelangen konnten.
2023-09-20 11:04:39 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-20 11:04:39 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte auch die Gelegenheit nutzen, die diese Debatte bietet, um Vertreter des Rates und der Kommission zu nennen, um eine bessere interinstitutionelle Zusammenarbeit zu gewährleisten.
2023-09-20 11:04:39 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-20 11:04:40 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in etwa einem 5-Meilen-Kilometer-Radius (8 km) von The Strip.
2023-09-20 11:04:40 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-20 11:04:41 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web-Portal, das auf dem berühmten Open Source Php-Nuke Web Portal basiert.
2023-09-20 11:04:41 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-20 11:04:41 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis die Realisierung von Sound-Handbüchern akustisch, interaktiv oder in schriftlicher Form.
2023-09-20 11:04:41 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-20 11:04:42 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für den Transfer von Druck und Direktdruck erhältlich.
2023-09-20 11:04:42 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-20 11:04:42 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihre Unterstützung im eigenen Land aufbauen, aber sie kann sich auf die wirtschaftliche und Sicherheitskooperation mit Amerika verlassen, um die Stabilität des Landes zu sichern.
2023-09-20 11:04:42 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-20 11:04:43 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsflüchtlinge nach ihrem Abflug Zugang zu dem Geld erhalten, das sie für sie in die europäischen Sozialversicherungssysteme zahlen.
2023-09-20 11:04:43 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-20 11:04:43 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) haben das Ascent Ti Modell als Basis genutzt.
2023-09-20 11:04:43 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-20 11:04:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir suchen immer kostenlose Dateiformate für Sie und leider gibt es für einige Formate keine kostenlose Alternative, die auf allen Computer-Plattformen läuft.
2023-09-20 11:04:44 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-20 11:04:45 | INFO | fairseq.tasks.translation | example hypothesis: Der Weiler wird auch wissen, wie man Ihnen bei der Suche nach qualifizierten Fachleuten helfen kann, die beste Lösung zu finden, wenn er Ihre Bedürfnisse und Wünsche hat.
2023-09-20 11:04:45 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-20 11:04:45 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherite-Ideen über die niedrigeren und transparenteren Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselbestandteile seiner Agenda.
2023-09-20 11:04:45 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-20 11:04:46 | INFO | fairseq.tasks.translation | example hypothesis: Mediengfx / splashutils Benutzer müssen die splashutils neu erstellen, damit sie richtig arbeiten können.
2023-09-20 11:04:46 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-20 11:04:47 | INFO | fairseq.tasks.translation | example hypothesis: Die Spieler der Horde und der Allianz können keine Gegenstücke kaufen oder verkaufen, es sei denn, sie benutzen die neutralen Auction-Häuser, die unten aufgelistet sind, und fragen Sie sich um eine Garant für Richtung.
2023-09-20 11:04:47 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-20 11:04:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund dafür, dass diese Kriterien nur innerhalb der Grenzen Europas gelten.
2023-09-20 11:04:47 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-20 11:04:48 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt der Kommission, die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-20 11:04:48 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-20 11:04:48 | INFO | fairseq.tasks.translation | example hypothesis: Nach dem Vorschlag der Kommission muss der Rat formelle Ansichten zu bestimmten Einzelheiten der Vereinbarung im Prinzip mit den Vereinigten Staaten abgeben.
2023-09-20 11:04:48 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-20 11:04:49 | INFO | fairseq.tasks.translation | example hypothesis: Trend- oder klassische Farben, zeitloses Design oder spezielle Auflage - unser breites Sortiment an Kunststoffkindstücken ist beeindruckend, nicht zuletzt wegen seiner herausragenden Endbearbeitung.
2023-09-20 11:04:49 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-20 11:04:50 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... Medical Tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 11:04:50 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 11:04:50 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx von sachlichen Situationen zu unterrichten, die nicht mit diesen AGB in kürzester Zeit vereinbar sind, sobald er sich dessen bewußt wird.
2023-09-20 11:04:50 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-20 11:04:51 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die die Notwendigkeit institutioneller Veränderungen voranschreitet und realisiert hat, was sie als eine stärkere Präsenz auf dem Gebiet der Außenpolitik und der Verteidigung betrachtet.
2023-09-20 11:04:51 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-20 11:04:51 | INFO | fairseq.tasks.translation | example hypothesis: Neben unserem Shop-Angebot haben wir einen Blog erstellt, der als Informationsportal für unsere Kunden gedacht ist, mit Produktnachrichten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-20 11:04:51 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-20 11:04:52 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die wir bei der Behandlung aller Themen erzielt haben, die jetzt über etwas diskutiert werden, das kaum zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-20 11:04:52 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-20 11:04:53 | INFO | fairseq.tasks.translation | example hypothesis: BILSTEIN B12 BTK: Für optimale Lenkdynamik - die ideale Mischung aus Loung- und Schockdämpfern für den ersten Einsteiger-Spaß am Rad.
2023-09-20 11:04:53 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-20 11:04:53 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal hat der Berichterstatter in der Lage sein können, in einem äußerst ausgewogenen Text - wie ich sagen möchte - die zuweilen unterschiedlichen Meinungen und Beiträge zu verfassen und sie - wie ich meine - in einem sehr unterschiedlichen Text zusammenzufassen.
2023-09-20 11:04:53 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-20 11:04:54 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm der trockenen elektrostatischen Prostituatoren mit einer trockenen ESP für den unteren Leistungsbereich.
2023-09-20 11:04:54 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-20 11:04:55 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seit Jahrhunderten seine Freiheit und Unabhängigkeit verteidigt hat, sind Sie bereits in einem fremden Land.
2023-09-20 11:04:55 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-20 11:04:55 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und im Fernen Osten wandern, müssen wir auf unsere Innovation und die Erfindbarkeit vertrauen, um unseren Lebensunterhalt zu verdienen.
2023-09-20 11:04:55 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-20 11:04:56 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich verfügt über ein Handelsdefizit mit der EU und setzt sich auf Verhandlungen mit Drittländern ab, von denen viele seit Jahren in Kraft sind und sich auf unser Commonwealth der Nationen beziehen.
2023-09-20 11:04:56 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-20 11:04:56 | INFO | fairseq.tasks.translation | example hypothesis: La findes des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-20 11:04:56 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-20 11:04:57 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht der Freizügigkeit real sein sollen, dann ist die rasche Kodifizierung dieses Rechtsraums der Gemeinschaft längst überfällig.
2023-09-20 11:04:57 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-20 11:04:58 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die zunehmende Zahl der Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-20 11:04:58 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-20 11:04:58 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notlage gibt es jedoch noch eine weitere: die Notlage, die die Kinder, den schwächsten Bevölkerungssektor, mit dem keine Familie, keinen Schutz und keinen Staat mehr zu tun hat, in Verbindung bringt.
2023-09-20 11:04:58 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-20 11:04:59 | INFO | fairseq.tasks.translation | example hypothesis: Zunächst sollte klargestellt und hervorgehoben werden, dass die Praxis der Findung seit 2003 von der EU reguliert wurde, was bedeutet, dass Haie nicht allein für ihre Findungen gefangen werden kann.
2023-09-20 11:04:59 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-20 11:05:00 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei gesetzt wird, nicht innerhalb der ersten, dann bleiben alle externen Beziehungen von diesem Mangel an Umsetzung bestimmt, und man kann niemanden wirklich wissen, bis man weiß, dass es sich wirklich um sich selbst handelt.
2023-09-20 11:05:00 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-20 11:05:00 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, um alles Mögliche zu tun, um einen gewaltfreien Zeitraum vor den Wahlen zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu öffnen.
2023-09-20 11:05:00 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-20 11:05:01 | INFO | fairseq.tasks.translation | example hypothesis: Die Gesetzgebung, die den Bürgern die Meinungsfreiheit, freie und unabhängige Wahl und die Vereinigungsfreiheit verleiht, ist von entscheidender Bedeutung, und sie muss der Öffentlichkeit deutlich gemacht werden, dass niemand über dem Gesetz steht.
2023-09-20 11:05:01 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-20 11:05:02 | INFO | fairseq.tasks.translation | example hypothesis: Das System wird in Java-Programmiersprache mit J2EE-Techniken implementiert, die Plattform und Betriebssystem-Unabhängigkeit (Anwendung wurde auf Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-20 11:05:02 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-20 11:05:02 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur Koordinierung der europäischen Sozialversicherung, und deshalb stimmen wir für die Klarstellung des Anhangs.
2023-09-20 11:05:02 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-20 11:05:03 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist auch der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen haben und die WTO auffordern, klar zu sagen, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen betrachtet werden.
2023-09-20 11:05:03 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-20 11:05:04 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische öffentlich-rechtliche Rundfunk teilgenommen, mit einer Frau, die sehr besorgt war, dass wir die Ausgaben für die Gesundheit kürzen und nicht genug tun, um die Ausgaben für die Entwicklungshilfe zurückzukürzen.
2023-09-20 11:05:04 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-20 11:05:04 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird und die Kommission erneut zu ihrer hochrangigen Haltung beglückwünschen möchte.
2023-09-20 11:05:04 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-20 11:05:05 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie nach Ihren Lehren oder konkreten Informationen über die europäische Geschichte, die Staatsbürgerschaft oder etwas ganz besonderes suchen, als den individuellen Energieverbrauch zu reduzieren, sollten Sie für die Altersgruppe Ihrer Studierenden etwas nützliches finden.
2023-09-20 11:05:05 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-20 11:05:06 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, der schönen Wien und dem bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen.
2023-09-20 11:05:06 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-20 11:05:07 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte einen nützlichen und wichtigen Beitrag zur Diskussion über Flexicurity leistet, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 11:05:07 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 11:05:07 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls ist es, zu denken, dass die Natur und mystisieren, was eine bestimmte Art von vertraglichen Beziehungen zwischen den Personen mit gemeinsamen Bedenken ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Bedrohung, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-20 11:05:07 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-20 11:05:08 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft in Bezug auf persönliche Daten sollte der Gerichtshof und der Gerichtshof der ersten Instanz eingreifen können, wenn beispielsweise die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-20 11:05:08 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-20 11:05:09 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3 Series ist eine der schönsten Autos, die unter $50.000 fahren, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-20 11:05:09 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-20 11:05:09 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für seinen ausgezeichneten Bericht danken, und das Gleiche gilt auch dem Ausschuß für auswärtige Angelegenheiten, Menschenrechte und gemeinsame Sicherheit und Verteidigungspolitik für ihre realistische Darstellung der Angelegenheit.
2023-09-20 11:05:09 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-20 11:05:10 | INFO | fairseq.tasks.translation | example hypothesis: Sie müssen die Fische Sup, Hühner Paprika, ein gut gefertigtes Pörkölt (Stew) und den ausgezeichneten Süßwasserfisch: grillte pike-perch, Trout mit Mandelmond, probieren.
2023-09-20 11:05:10 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 11:05:11 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, daran zu erinnern, was eine politische Aktion bedeutet, eine allgemeine Sichtweise zu bieten, die es uns ermöglicht, in die verschiedenen Fragen eingehender zu gehen und zu sehen, welche Impulse die Europäische Union für die Zukunft bringen kann.
2023-09-20 11:05:11 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-20 11:05:12 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Eigentümer von "Scardona Records", Herr Branko Paić, haben sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009" geeinigt.
2023-09-20 11:05:12 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-20 11:05:12 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen echten Wohlstand, wenn es Arbeitslosigkeit gibt, wo die drohenden Bedrohungen für bestehende Arbeitsplätze und Wettbewerbsfähigkeit durch makroökonomische Strategien, steuerliche Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst werden, schrittweise untergraben werden.
2023-09-20 11:05:12 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-20 11:05:13 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den die Kommission uns vorlegt, entspricht den gleichen allgemeinen Linien wie die bestehende Verordnung von 1994: Das Europäische Parlament hat durch ein hervorragendes Beispiel für die Zusammenarbeit mit dem Rat, die alle unsere Änderungsanträge in den Text aufgenommen haben, zu dieser Verordnung beigetragen.
2023-09-20 11:05:13 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-20 11:05:14 | INFO | fairseq.tasks.translation | example hypothesis: Daher erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus, mit den entsprechenden Folgen für den Rechts- und Rechtsbereich, Norwegen und Island, in dem die gemeinsamen Regeln für die Auslieferung des Schengen-Besitzstands gelten.
2023-09-20 11:05:14 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-20 11:05:15 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden in vollem Tempo in einem Make-Shift-Boot unter Mississippi gehen, suchen nach dem großen versteckten Schatz, fallen in der Liebe zu den schönen Becky Thatcher, der rein dynamisch ist und mehr als alles, wir werden große Freunde sein.
2023-09-20 11:05:15 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-20 11:05:15 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der Schiffsverseuchung, die durch Einzelpersonen oder juristische Personen verursacht wird, durch den Geltungsbereich der Reaktion auf diese und durch die Art der Sanktionen, die bei solchen Verletzungen von Personen angewendet werden können.
2023-09-20 11:05:15 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-20 11:05:16 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Fising und Vincent Reynaud wurden in der Tat verurteilt, weil sie ihre Arbeit als Journalisten und Kameramänner einfach geleistet haben, indem sie eine Gruppe von Bergregionen, die seit Jahren von einem autoritären Regime verletzt wurden, die jedes Prinzip der Demokratie auslöst.
2023-09-20 11:05:16 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-20 11:05:17 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Dienstleistungen des Hotels gehören Concierge-Hilfe, ein Friseur-Geschäft und Schönheitsshop, Transport und Besichtigungstouren, Mending und Presseservice, Währungsaustausch, kostenloser Shoeshine und WLAN-Internetzugang. Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-20 11:05:17 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-20 11:05:18 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen dem ThermalFrühling zu verdanken hat, der von Queen D. Leonor, der Frau König D. João II, sehr beliebt ist, bekannt ist und von ihren Keramik international berühmt ist für ihre bildende und satirische Werke, ist es auch wert zu besichtigen.
2023-09-20 11:05:18 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-20 11:05:19 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Menschen, die behaupten, dass es sich um gute pro-Westerner auf der einen Seite und um die Anhänger des früheren Regimes auf der anderen Seite handelt - das ist auch verwerflich, da die Rollen von allen, jetzt und so weiter, bekannt sind.
2023-09-20 11:05:19 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-20 11:05:20 | INFO | fairseq.tasks.translation | example hypothesis: Ich weiß, dass wir nicht sagen können, aber ich kann nicht darauf hinweisen, dass etwas an dieser Reihe von Regeln fehlt, weil viele Schiffe, die undifferenziert zwischen den Flüssen und dem Meer reisen, auf diese Weise nicht behandelt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-20 11:05:20 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-20 11:05:20 | INFO | fairseq.tasks.translation | example hypothesis: (4) Sofern außerhalb des Aktionärsgipfels Informationen an einen Aktionär weitergegeben wurden, der aus Gründen seines Status als Aktionär stammt, werden solche Informationen an alle anderen Aktionäre auf der Hauptversammlung weitergegeben, auch wenn solche Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes auf der Tagesordnung zu ermöglichen.
2023-09-20 11:05:20 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-20 11:05:21 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme gegossen werden, die normalerweise in den Taschen verschiedener Diktatoren fallen, ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Millionen Menschen in unseren eigenen Ländern leben, die auch sehr miserabel sind.
2023-09-20 11:05:21 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-20 11:05:22 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - denn sie sagen Flugzeuge aus einem der Mitgliedstaaten oder der NATO hätten an diesem Kriegsakt beteiligt sein können -, um mit Informationen zu helfen, die es nicht mehr gibt, vertrauliche, verdeckte oder geheime Daten zu speichern, damit wir wirklich die Fakten zu Licht bringen und die ganze Wahrheit zu sagen.
2023-09-20 11:05:22 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-20 11:05:23 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im Nordwesten von Reinickendorf ist nur 5 Gehminuten von der U-Bahnstation Waidmannslust und einer 30-minütigen Bahnfahrt von der Innenstadt entfernt. Die bequemen Zimmer der Pension NomErweiterGuest House befinden sich in einem charmanten Landhaus.
2023-09-20 11:05:23 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 11:05:24 | INFO | fairseq.tasks.translation | example hypothesis: "Mit unseren Partnern für das Radar unter Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularsten Sensor- und Datenverbindungen integrieren, die für nachhaltige und verlässliche ISTAR-Missionen von entscheidender Bedeutung sind, die sich von den Regalen niemals erreichen lassen.
2023-09-20 11:05:24 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-20 11:05:25 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen deutlich machen, dass wir auch in der Lage sein werden, vom Markt zu profitieren, und zwar nicht nur für uns, sondern für uns weltweit, die Produkte, die ein ernsthaftes Risiko darstellen, nicht nur für den Inlandsverbrauch, sondern auch für den globalen Markt, denn diese Produkte können leicht recycelt werden, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-20 11:05:25 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-20 11:05:25 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Grundstück der Moderne und der PostModernität oder der klaren Opposition der reinen Kunst und der engagierten Kunst müssen wir die originelle und andauernde Spannung der beiden Politiken der Ästhetik anerkennen, die in den Formen der Sichtbarkeit und der Verständlichkeit, die Kunst als solche kennzeichnbar machen, entfestigt werden - diese beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-20 11:05:25 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-20 11:05:26 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute die Bedeutung der Debatten und die Meinungen angeht, die Sie mir gegeben haben, die ich ganz klar unterstütze, und auf der Grundlage der vorangegangenen Beschlüsse werden wir unsere Debatten führen, und wenn die 40 Petenten nicht anwesend sind, werde ich nicht darum bitten, das Kollegium zu kontrollieren.
2023-09-20 11:05:26 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-20 11:05:27 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker niemals die Beschränkung des Nationalstaatsprinzips akzeptiert haben, ist es paradox, gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, ohne dass ein einheitliches Ziel besteht, eine einheitliche Kultur zu schaffen, sondern ethnische, religiöse, sprachliche und kulturelle Vielfalt zu entwickeln.
2023-09-20 11:05:27 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-20 11:05:28 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: die Zeitschrift - oder vielmehr ihr Inhalt - wurde in mehrfacher Weise als hybride Form bis 2008 veröffentlicht, die Rezensionen und Artikel, die in der vierteljährlichen Zeitschrift enthalten sind, werden für H-Soz-u-Kult geschrieben und wurden an ihre Abonnenten über Mailing-Listen und die Webseiten der Berlin-basierten H-Soz-Kult und Michigan-based H-Net verteilt.
2023-09-20 11:05:28 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-20 11:05:30 | INFO | fairseq.tasks.translation | example hypothesis: Es ist nicht nur die Ankunft der neuen smartphone-Generation, dass Mobiltelefone nicht nur ihre Fathers signifikant geschmückt haben, sondern dass sie sich von einst fließenden Taschenlampen durch Polyphonisch tootling Game Boy-Tarrants bis hin zu einem niedrigeren Mini-PCs mit einem knappen CD-Qualität Stereo-Sound: Hencefort, dank ihrer besonderen Kombination aus Fähigkeiten, können sie von den ehemaligen zu mir überlappenden Bannen bis zu untrackeln neuer technologischer Entwicklung.
2023-09-20 11:05:30 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-20 11:05:32 | INFO | fairseq.tasks.translation | example hypothesis: A Pesar del fin científico del proyecto, el coronel Quaritch, quien dirigien la defensa de la base humana en Pandora, Kloster a Jake para que la verhältnismäßig información por los nativos de caso de fuera ario suprir a la fuerza para que que que se marchen, En un primio, ake prople fesionaciones su misión, enora de la nada, enora de la Nacional de la Nacional de la nlicación de los los los los nlicos de los los los los los los los nlicos en caso de fuera, y que la fuera por la fuera por la cuerza para la cir a la fuerza para que que que que que que que que que que que la ciudad de la ciudad de la ciudad de la ciudad de la ciudad de la marchina de los los las
2023-09-20 11:05:32 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-20 11:05:32 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 4.86 | nll_loss 2.816 | ppl 7.04 | bleu 24.23 | wps 17531.2 | wpb 12011.9 | bsz 398.1 | num_updates 9055
2023-09-20 11:05:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 9055 updates
2023-09-20 11:05:32 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint1.pt
2023-09-20 11:05:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint1.pt
2023-09-20 11:05:43 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 9055 updates, score 24.23) (writing took 10.868530930019915 seconds)
2023-09-20 11:05:43 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2023-09-20 11:05:43 | INFO | train | epoch 001 | loss 6.79 | nll_loss 4.907 | ppl 30 | wps 76945.7 | ups 5.93 | wpb 12977.3 | bsz 430.4 | num_updates 9055 | lr 0.000332319 | gnorm 0.988 | loss_scale 8 | train_wall 1430 | gb_free 15.6 | wall 1537
2023-09-20 11:05:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 11:05:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-20 11:05:43 | INFO | fairseq.trainer | begin training epoch 2
2023-09-20 11:05:43 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-20 11:05:50 | INFO | train_inner | epoch 002:     45 / 9060 loss=4.993, nll_loss=3.073, ppl=8.42, wps=13562.5, ups=1.05, wpb=12882, bsz=429.5, num_updates=9100, lr=0.000331497, gnorm=0.703, loss_scale=8, train_wall=16, gb_free=15.6, wall=1544
2023-09-20 11:06:06 | INFO | train_inner | epoch 002:    145 / 9060 loss=4.944, nll_loss=3.024, ppl=8.13, wps=81369.9, ups=6.26, wpb=13004.9, bsz=441.5, num_updates=9200, lr=0.00032969, gnorm=0.692, loss_scale=8, train_wall=16, gb_free=15.3, wall=1560
2023-09-20 11:06:22 | INFO | train_inner | epoch 002:    245 / 9060 loss=4.923, nll_loss=3.002, ppl=8.01, wps=81444.4, ups=6.26, wpb=13003.5, bsz=438.6, num_updates=9300, lr=0.000327913, gnorm=0.689, loss_scale=8, train_wall=16, gb_free=15, wall=1576
2023-09-20 11:06:38 | INFO | train_inner | epoch 002:    345 / 9060 loss=4.933, nll_loss=3.012, ppl=8.07, wps=81049.7, ups=6.24, wpb=12983.1, bsz=409.3, num_updates=9400, lr=0.000326164, gnorm=0.716, loss_scale=8, train_wall=16, gb_free=15.4, wall=1592
2023-09-20 11:06:54 | INFO | train_inner | epoch 002:    445 / 9060 loss=4.9, nll_loss=2.98, ppl=7.89, wps=81497.5, ups=6.26, wpb=13021.6, bsz=466.4, num_updates=9500, lr=0.000324443, gnorm=0.694, loss_scale=8, train_wall=16, gb_free=15.3, wall=1608
2023-09-20 11:07:10 | INFO | train_inner | epoch 002:    545 / 9060 loss=4.937, nll_loss=3.017, ppl=8.1, wps=81436.8, ups=6.25, wpb=13025.1, bsz=430.9, num_updates=9600, lr=0.000322749, gnorm=0.718, loss_scale=8, train_wall=16, gb_free=15.4, wall=1624
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 11:07:26 | INFO | train_inner | epoch 002:    645 / 9060 loss=4.896, nll_loss=2.976, ppl=7.87, wps=81249.3, ups=6.26, wpb=12971, bsz=434.6, num_updates=9700, lr=0.000321081, gnorm=0.686, loss_scale=8, train_wall=16, gb_free=15.2, wall=1640
lprobs.size(): torch.Size([3384, 42808])
2023-09-20 11:07:42 | INFO | train_inner | epoch 002:    745 / 9060 loss=4.885, nll_loss=2.964, ppl=7.8, wps=81341.4, ups=6.26, wpb=12987.9, bsz=429.7, num_updates=9800, lr=0.000319438, gnorm=0.688, loss_scale=8, train_wall=16, gb_free=15.8, wall=1656
2023-09-20 11:07:58 | INFO | train_inner | epoch 002:    845 / 9060 loss=4.887, nll_loss=2.968, ppl=7.82, wps=80817.5, ups=6.25, wpb=12923.4, bsz=438.9, num_updates=9900, lr=0.000317821, gnorm=0.783, loss_scale=8, train_wall=16, gb_free=15.5, wall=1672
2023-09-20 11:08:14 | INFO | train_inner | epoch 002:    945 / 9060 loss=4.915, nll_loss=2.996, ppl=7.98, wps=81368.5, ups=6.25, wpb=13016.7, bsz=448.6, num_updates=10000, lr=0.000316228, gnorm=0.689, loss_scale=8, train_wall=16, gb_free=15.3, wall=1688
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 11:08:30 | INFO | train_inner | epoch 002:   1045 / 9060 loss=4.872, nll_loss=2.952, ppl=7.74, wps=81143.7, ups=6.26, wpb=12969.6, bsz=432.6, num_updates=10100, lr=0.000314658, gnorm=0.69, loss_scale=8, train_wall=16, gb_free=16, wall=1704
2023-09-20 11:08:46 | INFO | train_inner | epoch 002:   1145 / 9060 loss=4.9, nll_loss=2.981, ppl=7.9, wps=81808.3, ups=6.26, wpb=13078.1, bsz=425.4, num_updates=10200, lr=0.000313112, gnorm=0.694, loss_scale=8, train_wall=16, gb_free=15.3, wall=1720
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 11:09:02 | INFO | train_inner | epoch 002:   1245 / 9060 loss=4.921, nll_loss=3.003, ppl=8.02, wps=80841.9, ups=6.26, wpb=12918.1, bsz=432.8, num_updates=10300, lr=0.000311588, gnorm=0.683, loss_scale=8, train_wall=16, gb_free=15.1, wall=1736
2023-09-20 11:09:18 | INFO | train_inner | epoch 002:   1345 / 9060 loss=4.883, nll_loss=2.964, ppl=7.8, wps=81142.7, ups=6.26, wpb=12961.3, bsz=415.8, num_updates=10400, lr=0.000310087, gnorm=0.691, loss_scale=8, train_wall=16, gb_free=15.3, wall=1752
2023-09-20 11:09:34 | INFO | train_inner | epoch 002:   1445 / 9060 loss=4.9, nll_loss=2.982, ppl=7.9, wps=80574.9, ups=6.25, wpb=12893.8, bsz=419.4, num_updates=10500, lr=0.000308607, gnorm=0.698, loss_scale=8, train_wall=16, gb_free=15.1, wall=1768
2023-09-20 11:09:50 | INFO | train_inner | epoch 002:   1545 / 9060 loss=4.876, nll_loss=2.957, ppl=7.77, wps=81108.1, ups=6.26, wpb=12961.8, bsz=432.1, num_updates=10600, lr=0.000307148, gnorm=0.689, loss_scale=8, train_wall=16, gb_free=15, wall=1784
2023-09-20 11:10:06 | INFO | train_inner | epoch 002:   1645 / 9060 loss=4.857, nll_loss=2.938, ppl=7.67, wps=81337.9, ups=6.25, wpb=13006.1, bsz=415.3, num_updates=10700, lr=0.000305709, gnorm=0.679, loss_scale=8, train_wall=16, gb_free=15.6, wall=1800
2023-09-20 11:10:22 | INFO | train_inner | epoch 002:   1745 / 9060 loss=4.859, nll_loss=2.941, ppl=7.68, wps=81074.6, ups=6.26, wpb=12957.6, bsz=422.5, num_updates=10800, lr=0.00030429, gnorm=0.671, loss_scale=8, train_wall=16, gb_free=15.3, wall=1816
2023-09-20 11:10:38 | INFO | train_inner | epoch 002:   1845 / 9060 loss=4.865, nll_loss=2.946, ppl=7.71, wps=81950.4, ups=6.26, wpb=13087.6, bsz=432.5, num_updates=10900, lr=0.000302891, gnorm=0.667, loss_scale=8, train_wall=16, gb_free=15.2, wall=1832
2023-09-20 11:10:54 | INFO | train_inner | epoch 002:   1945 / 9060 loss=4.864, nll_loss=2.945, ppl=7.7, wps=81121.3, ups=6.26, wpb=12962, bsz=416.3, num_updates=11000, lr=0.000301511, gnorm=0.692, loss_scale=8, train_wall=16, gb_free=15.6, wall=1848
lprobs.size(): torch.Size([2976, 42808])
2023-09-20 11:11:10 | INFO | train_inner | epoch 002:   2045 / 9060 loss=4.843, nll_loss=2.925, ppl=7.59, wps=81499.2, ups=6.26, wpb=13012.1, bsz=433, num_updates=11100, lr=0.00030015, gnorm=0.664, loss_scale=8, train_wall=16, gb_free=15.3, wall=1864
2023-09-20 11:11:26 | INFO | train_inner | epoch 002:   2145 / 9060 loss=4.838, nll_loss=2.92, ppl=7.57, wps=80801.7, ups=6.25, wpb=12923.3, bsz=452.7, num_updates=11200, lr=0.000298807, gnorm=0.67, loss_scale=8, train_wall=16, gb_free=15.4, wall=1880
lprobs.size(): torch.Size([2408, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-20 11:11:42 | INFO | train_inner | epoch 002:   2245 / 9060 loss=4.822, nll_loss=2.903, ppl=7.48, wps=81766.6, ups=6.26, wpb=13069.6, bsz=424.9, num_updates=11300, lr=0.000297482, gnorm=0.651, loss_scale=8, train_wall=16, gb_free=15.2, wall=1896
2023-09-20 11:11:58 | INFO | train_inner | epoch 002:   2345 / 9060 loss=4.818, nll_loss=2.9, ppl=7.46, wps=81027.8, ups=6.25, wpb=12958.7, bsz=415.8, num_updates=11400, lr=0.000296174, gnorm=0.671, loss_scale=8, train_wall=16, gb_free=15.2, wall=1912
2023-09-20 11:12:14 | INFO | train_inner | epoch 002:   2445 / 9060 loss=4.828, nll_loss=2.911, ppl=7.52, wps=81679.5, ups=6.25, wpb=13064.4, bsz=428.6, num_updates=11500, lr=0.000294884, gnorm=0.662, loss_scale=8, train_wall=16, gb_free=15.3, wall=1928
2023-09-20 11:12:30 | INFO | train_inner | epoch 002:   2545 / 9060 loss=4.775, nll_loss=2.856, ppl=7.24, wps=81320.2, ups=6.23, wpb=13049.2, bsz=443.3, num_updates=11600, lr=0.00029361, gnorm=0.664, loss_scale=8, train_wall=16, gb_free=15, wall=1944
lprobs.size(): torch.Size([3344, 42808])
2023-09-20 11:12:46 | INFO | train_inner | epoch 002:   2645 / 9060 loss=4.819, nll_loss=2.902, ppl=7.47, wps=80989.3, ups=6.26, wpb=12943.9, bsz=413.5, num_updates=11700, lr=0.000292353, gnorm=0.684, loss_scale=8, train_wall=16, gb_free=15.2, wall=1960
2023-09-20 11:13:02 | INFO | train_inner | epoch 002:   2745 / 9060 loss=4.829, nll_loss=2.912, ppl=7.52, wps=80768.5, ups=6.26, wpb=12901.1, bsz=409.3, num_updates=11800, lr=0.000291111, gnorm=0.67, loss_scale=8, train_wall=16, gb_free=15.3, wall=1976
2023-09-20 11:13:16 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-20 11:13:18 | INFO | train_inner | epoch 002:   2846 / 9060 loss=4.816, nll_loss=2.899, ppl=7.46, wps=80846, ups=6.18, wpb=13072.8, bsz=446.1, num_updates=11900, lr=0.000289886, gnorm=0.764, loss_scale=4, train_wall=16, gb_free=15.2, wall=1992
2023-09-20 11:13:34 | INFO | train_inner | epoch 002:   2946 / 9060 loss=4.832, nll_loss=2.916, ppl=7.55, wps=80705.8, ups=6.25, wpb=12917, bsz=426.3, num_updates=12000, lr=0.000288675, gnorm=0.654, loss_scale=4, train_wall=16, gb_free=15.3, wall=2008
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 11:13:50 | INFO | train_inner | epoch 002:   3046 / 9060 loss=4.807, nll_loss=2.89, ppl=7.41, wps=80627.4, ups=6.25, wpb=12899.3, bsz=423.5, num_updates=12100, lr=0.00028748, gnorm=0.661, loss_scale=4, train_wall=16, gb_free=15.2, wall=2024
lprobs.size(): torch.Size([3264, 42808])
2023-09-20 11:14:06 | INFO | train_inner | epoch 002:   3146 / 9060 loss=4.802, nll_loss=2.885, ppl=7.39, wps=80837.1, ups=6.26, wpb=12911.5, bsz=414.2, num_updates=12200, lr=0.000286299, gnorm=0.649, loss_scale=4, train_wall=16, gb_free=15.3, wall=2040
lprobs.size(): torch.Size([3432, 42808])
2023-09-20 11:14:22 | INFO | train_inner | epoch 002:   3246 / 9060 loss=4.808, nll_loss=2.892, ppl=7.42, wps=80841.2, ups=6.25, wpb=12926.2, bsz=428.2, num_updates=12300, lr=0.000285133, gnorm=0.652, loss_scale=4, train_wall=16, gb_free=15.2, wall=2056
lprobs.size(): torch.Size([2256, 42808])
2023-09-20 11:14:38 | INFO | train_inner | epoch 002:   3346 / 9060 loss=4.775, nll_loss=2.857, ppl=7.25, wps=81754.8, ups=6.25, wpb=13081.1, bsz=425.4, num_updates=12400, lr=0.000283981, gnorm=0.663, loss_scale=4, train_wall=16, gb_free=15.2, wall=2072
2023-09-20 11:14:54 | INFO | train_inner | epoch 002:   3446 / 9060 loss=4.781, nll_loss=2.864, ppl=7.28, wps=81113.8, ups=6.26, wpb=12966.6, bsz=427.8, num_updates=12500, lr=0.000282843, gnorm=0.66, loss_scale=4, train_wall=16, gb_free=15.1, wall=2088
2023-09-20 11:15:10 | INFO | train_inner | epoch 002:   3546 / 9060 loss=4.777, nll_loss=2.86, ppl=7.26, wps=80573.6, ups=6.24, wpb=12908.2, bsz=431.6, num_updates=12600, lr=0.000281718, gnorm=0.656, loss_scale=4, train_wall=16, gb_free=15.5, wall=2104
2023-09-20 11:15:26 | INFO | train_inner | epoch 002:   3646 / 9060 loss=4.823, nll_loss=2.907, ppl=7.5, wps=80496.1, ups=6.22, wpb=12948.5, bsz=413.6, num_updates=12700, lr=0.000280607, gnorm=0.681, loss_scale=4, train_wall=16, gb_free=15.6, wall=2120
2023-09-20 11:15:42 | INFO | train_inner | epoch 002:   3746 / 9060 loss=4.781, nll_loss=2.864, ppl=7.28, wps=80713.1, ups=6.25, wpb=12917.5, bsz=418.2, num_updates=12800, lr=0.000279508, gnorm=0.651, loss_scale=4, train_wall=16, gb_free=15.3, wall=2136
2023-09-20 11:15:58 | INFO | train_inner | epoch 002:   3846 / 9060 loss=4.751, nll_loss=2.835, ppl=7.13, wps=81497.8, ups=6.23, wpb=13081.9, bsz=437.5, num_updates=12900, lr=0.000278423, gnorm=0.642, loss_scale=4, train_wall=16, gb_free=15, wall=2152
lprobs.size(): torch.Size([3392, 42808])
2023-09-20 11:16:14 | INFO | train_inner | epoch 002:   3946 / 9060 loss=4.738, nll_loss=2.821, ppl=7.07, wps=81252.1, ups=6.25, wpb=13005, bsz=436.3, num_updates=13000, lr=0.00027735, gnorm=0.64, loss_scale=4, train_wall=16, gb_free=15.2, wall=2168
2023-09-20 11:16:30 | INFO | train_inner | epoch 002:   4046 / 9060 loss=4.777, nll_loss=2.862, ppl=7.27, wps=80599.1, ups=6.24, wpb=12909.6, bsz=461.3, num_updates=13100, lr=0.000276289, gnorm=0.65, loss_scale=4, train_wall=16, gb_free=15.1, wall=2184
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 11:16:46 | INFO | train_inner | epoch 002:   4146 / 9060 loss=4.777, nll_loss=2.862, ppl=7.27, wps=81027.8, ups=6.24, wpb=12992.2, bsz=440.7, num_updates=13200, lr=0.000275241, gnorm=0.645, loss_scale=4, train_wall=16, gb_free=14.9, wall=2200
lprobs.size(): torch.Size([3360, 42808])
2023-09-20 11:17:02 | INFO | train_inner | epoch 002:   4246 / 9060 loss=4.819, nll_loss=2.904, ppl=7.49, wps=81028.5, ups=6.25, wpb=12955, bsz=427, num_updates=13300, lr=0.000274204, gnorm=0.633, loss_scale=4, train_wall=16, gb_free=15.2, wall=2216
2023-09-20 11:17:18 | INFO | train_inner | epoch 002:   4346 / 9060 loss=4.752, nll_loss=2.836, ppl=7.14, wps=81014.7, ups=6.25, wpb=12961, bsz=430.6, num_updates=13400, lr=0.000273179, gnorm=0.671, loss_scale=4, train_wall=16, gb_free=15.2, wall=2232
2023-09-20 11:17:35 | INFO | train_inner | epoch 002:   4446 / 9060 loss=4.771, nll_loss=2.856, ppl=7.24, wps=80235, ups=6.19, wpb=12953.2, bsz=433.7, num_updates=13500, lr=0.000272166, gnorm=0.648, loss_scale=4, train_wall=16, gb_free=15.1, wall=2248
2023-09-20 11:17:51 | INFO | train_inner | epoch 002:   4546 / 9060 loss=4.797, nll_loss=2.883, ppl=7.38, wps=81170.4, ups=6.25, wpb=12993.8, bsz=420.2, num_updates=13600, lr=0.000271163, gnorm=0.647, loss_scale=4, train_wall=16, gb_free=15.1, wall=2264
lprobs.size(): torch.Size([3024, 42808])
2023-09-20 11:18:07 | INFO | train_inner | epoch 002:   4646 / 9060 loss=4.774, nll_loss=2.859, ppl=7.25, wps=80789.4, ups=6.25, wpb=12930.9, bsz=428.8, num_updates=13700, lr=0.000270172, gnorm=0.653, loss_scale=4, train_wall=16, gb_free=15.3, wall=2280
2023-09-20 11:18:23 | INFO | train_inner | epoch 002:   4746 / 9060 loss=4.739, nll_loss=2.823, ppl=7.08, wps=81278.9, ups=6.24, wpb=13015.1, bsz=416.8, num_updates=13800, lr=0.000269191, gnorm=0.642, loss_scale=4, train_wall=16, gb_free=15.3, wall=2296
2023-09-20 11:18:39 | INFO | train_inner | epoch 002:   4846 / 9060 loss=4.75, nll_loss=2.835, ppl=7.14, wps=80476.4, ups=6.26, wpb=12865.3, bsz=440.9, num_updates=13900, lr=0.000268221, gnorm=0.642, loss_scale=4, train_wall=16, gb_free=15, wall=2312
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:18:55 | INFO | train_inner | epoch 002:   4946 / 9060 loss=4.725, nll_loss=2.81, ppl=7.01, wps=81739.8, ups=6.25, wpb=13076.5, bsz=439, num_updates=14000, lr=0.000267261, gnorm=0.648, loss_scale=4, train_wall=16, gb_free=15.5, wall=2328
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:19:11 | INFO | train_inner | epoch 002:   5046 / 9060 loss=4.72, nll_loss=2.804, ppl=6.98, wps=80614, ups=6.26, wpb=12887.4, bsz=431.4, num_updates=14100, lr=0.000266312, gnorm=0.664, loss_scale=4, train_wall=16, gb_free=15.1, wall=2344
2023-09-20 11:19:27 | INFO | train_inner | epoch 002:   5146 / 9060 loss=4.718, nll_loss=2.803, ppl=6.98, wps=81232.5, ups=6.25, wpb=13004.3, bsz=439.8, num_updates=14200, lr=0.000265372, gnorm=0.632, loss_scale=4, train_wall=16, gb_free=15.1, wall=2360
2023-09-20 11:19:43 | INFO | train_inner | epoch 002:   5246 / 9060 loss=4.717, nll_loss=2.802, ppl=6.97, wps=81528.1, ups=6.25, wpb=13042.4, bsz=444.6, num_updates=14300, lr=0.000264443, gnorm=0.725, loss_scale=4, train_wall=16, gb_free=15.3, wall=2376
2023-09-20 11:19:59 | INFO | train_inner | epoch 002:   5346 / 9060 loss=4.719, nll_loss=2.803, ppl=6.98, wps=81505.4, ups=6.25, wpb=13035.8, bsz=412.7, num_updates=14400, lr=0.000263523, gnorm=0.655, loss_scale=4, train_wall=16, gb_free=15.5, wall=2392
lprobs.size(): torch.Size([3200, 42808])
2023-09-20 11:20:15 | INFO | train_inner | epoch 002:   5446 / 9060 loss=4.722, nll_loss=2.807, ppl=7, wps=81332.6, ups=6.25, wpb=13014.8, bsz=431, num_updates=14500, lr=0.000262613, gnorm=0.622, loss_scale=4, train_wall=16, gb_free=15, wall=2408
2023-09-20 11:20:31 | INFO | train_inner | epoch 002:   5546 / 9060 loss=4.687, nll_loss=2.772, ppl=6.83, wps=81688.1, ups=6.24, wpb=13084.2, bsz=445, num_updates=14600, lr=0.000261712, gnorm=0.625, loss_scale=4, train_wall=16, gb_free=15.7, wall=2424
2023-09-20 11:20:47 | INFO | train_inner | epoch 002:   5646 / 9060 loss=4.679, nll_loss=2.763, ppl=6.79, wps=81009.1, ups=6.25, wpb=12963, bsz=441.9, num_updates=14700, lr=0.00026082, gnorm=0.633, loss_scale=4, train_wall=16, gb_free=15.6, wall=2440
2023-09-20 11:21:03 | INFO | train_inner | epoch 002:   5746 / 9060 loss=4.623, nll_loss=2.707, ppl=6.53, wps=80997.3, ups=6.21, wpb=13042.6, bsz=470.1, num_updates=14800, lr=0.000259938, gnorm=0.677, loss_scale=4, train_wall=16, gb_free=15.1, wall=2456
2023-09-20 11:21:19 | INFO | train_inner | epoch 002:   5846 / 9060 loss=4.689, nll_loss=2.774, ppl=6.84, wps=81153.8, ups=6.25, wpb=12991.5, bsz=421.2, num_updates=14900, lr=0.000259064, gnorm=0.645, loss_scale=4, train_wall=16, gb_free=15.6, wall=2472
2023-09-20 11:21:35 | INFO | train_inner | epoch 002:   5946 / 9060 loss=4.689, nll_loss=2.775, ppl=6.84, wps=80903.7, ups=6.25, wpb=12945.9, bsz=413.4, num_updates=15000, lr=0.000258199, gnorm=0.635, loss_scale=4, train_wall=16, gb_free=15.3, wall=2488
2023-09-20 11:21:51 | INFO | train_inner | epoch 002:   6046 / 9060 loss=4.661, nll_loss=2.747, ppl=6.71, wps=81198.9, ups=6.25, wpb=12983.6, bsz=438.6, num_updates=15100, lr=0.000257343, gnorm=0.643, loss_scale=4, train_wall=16, gb_free=15.2, wall=2504
lprobs.size(): torch.Size([3440, 42808])
2023-09-20 11:22:07 | INFO | train_inner | epoch 002:   6146 / 9060 loss=4.649, nll_loss=2.733, ppl=6.65, wps=81485.5, ups=6.24, wpb=13054.6, bsz=436.9, num_updates=15200, lr=0.000256495, gnorm=0.63, loss_scale=4, train_wall=16, gb_free=15.9, wall=2520
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 11:22:23 | INFO | train_inner | epoch 002:   6246 / 9060 loss=4.66, nll_loss=2.746, ppl=6.71, wps=81587.4, ups=6.26, wpb=13043, bsz=444.2, num_updates=15300, lr=0.000255655, gnorm=0.634, loss_scale=4, train_wall=16, gb_free=15.3, wall=2536
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 11:22:39 | INFO | train_inner | epoch 002:   6346 / 9060 loss=4.655, nll_loss=2.74, ppl=6.68, wps=81705.4, ups=6.26, wpb=13058.8, bsz=449, num_updates=15400, lr=0.000254824, gnorm=0.617, loss_scale=4, train_wall=16, gb_free=14.9, wall=2552
lprobs.size(): torch.Size([3072, 42808])
2023-09-20 11:22:55 | INFO | train_inner | epoch 002:   6446 / 9060 loss=4.662, nll_loss=2.747, ppl=6.71, wps=81239.1, ups=6.25, wpb=12988.2, bsz=429.9, num_updates=15500, lr=0.000254, gnorm=0.619, loss_scale=4, train_wall=16, gb_free=15.1, wall=2568
2023-09-20 11:23:11 | INFO | train_inner | epoch 002:   6546 / 9060 loss=4.675, nll_loss=2.761, ppl=6.78, wps=80982.7, ups=6.26, wpb=12935.5, bsz=431.3, num_updates=15600, lr=0.000253185, gnorm=0.649, loss_scale=4, train_wall=16, gb_free=15.4, wall=2584
2023-09-20 11:23:27 | INFO | train_inner | epoch 002:   6646 / 9060 loss=4.686, nll_loss=2.773, ppl=6.83, wps=81164.8, ups=6.26, wpb=12975.6, bsz=428.5, num_updates=15700, lr=0.000252377, gnorm=0.625, loss_scale=4, train_wall=16, gb_free=15.2, wall=2600
2023-09-20 11:23:43 | INFO | train_inner | epoch 002:   6746 / 9060 loss=4.623, nll_loss=2.708, ppl=6.53, wps=81303.8, ups=6.25, wpb=13001.5, bsz=434.9, num_updates=15800, lr=0.000251577, gnorm=0.619, loss_scale=4, train_wall=16, gb_free=15.2, wall=2616
lprobs.size(): torch.Size([3280, 42808])
2023-09-20 11:23:59 | INFO | train_inner | epoch 002:   6846 / 9060 loss=4.666, nll_loss=2.752, ppl=6.74, wps=81019.6, ups=6.25, wpb=12964.5, bsz=439.9, num_updates=15900, lr=0.000250785, gnorm=0.619, loss_scale=4, train_wall=16, gb_free=15.3, wall=2632
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 11:24:15 | INFO | train_inner | epoch 002:   6946 / 9060 loss=4.68, nll_loss=2.767, ppl=6.81, wps=81026, ups=6.26, wpb=12950.5, bsz=427.2, num_updates=16000, lr=0.00025, gnorm=0.611, loss_scale=8, train_wall=16, gb_free=15.6, wall=2648
2023-09-20 11:24:31 | INFO | train_inner | epoch 002:   7046 / 9060 loss=4.684, nll_loss=2.771, ppl=6.82, wps=81258.6, ups=6.25, wpb=12999.5, bsz=415.9, num_updates=16100, lr=0.000249222, gnorm=0.624, loss_scale=8, train_wall=16, gb_free=15.3, wall=2664
2023-09-20 11:24:47 | INFO | train_inner | epoch 002:   7146 / 9060 loss=4.702, nll_loss=2.789, ppl=6.91, wps=80876.6, ups=6.25, wpb=12943.4, bsz=433.8, num_updates=16200, lr=0.000248452, gnorm=0.632, loss_scale=8, train_wall=16, gb_free=15.2, wall=2680
2023-09-20 11:25:03 | INFO | train_inner | epoch 002:   7246 / 9060 loss=4.665, nll_loss=2.752, ppl=6.74, wps=81700.8, ups=6.25, wpb=13063.5, bsz=452.6, num_updates=16300, lr=0.000247689, gnorm=0.617, loss_scale=8, train_wall=16, gb_free=15.2, wall=2696
lprobs.size(): torch.Size([3136, 42808])
2023-09-20 11:25:19 | INFO | train_inner | epoch 002:   7346 / 9060 loss=4.659, nll_loss=2.746, ppl=6.71, wps=81334.1, ups=6.25, wpb=13013.5, bsz=446.6, num_updates=16400, lr=0.000246932, gnorm=0.618, loss_scale=8, train_wall=16, gb_free=15.4, wall=2712
lprobs.size(): torch.Size([3040, 42808])
2023-09-20 11:25:35 | INFO | train_inner | epoch 002:   7446 / 9060 loss=4.653, nll_loss=2.739, ppl=6.68, wps=81004.9, ups=6.25, wpb=12950.6, bsz=417.9, num_updates=16500, lr=0.000246183, gnorm=0.63, loss_scale=8, train_wall=16, gb_free=15.4, wall=2728
2023-09-20 11:25:51 | INFO | train_inner | epoch 002:   7546 / 9060 loss=4.654, nll_loss=2.74, ppl=6.68, wps=81087, ups=6.26, wpb=12949.1, bsz=439.6, num_updates=16600, lr=0.00024544, gnorm=0.618, loss_scale=8, train_wall=16, gb_free=15, wall=2744
2023-09-20 11:26:07 | INFO | train_inner | epoch 002:   7646 / 9060 loss=4.625, nll_loss=2.71, ppl=6.54, wps=81005.3, ups=6.26, wpb=12943.4, bsz=419.2, num_updates=16700, lr=0.000244704, gnorm=0.626, loss_scale=8, train_wall=16, gb_free=15.1, wall=2760
2023-09-20 11:26:23 | INFO | train_inner | epoch 002:   7746 / 9060 loss=4.671, nll_loss=2.758, ppl=6.76, wps=80147.3, ups=6.26, wpb=12808.9, bsz=436.6, num_updates=16800, lr=0.000243975, gnorm=0.63, loss_scale=8, train_wall=16, gb_free=15.1, wall=2776
2023-09-20 11:26:38 | INFO | train_inner | epoch 002:   7846 / 9060 loss=4.675, nll_loss=2.762, ppl=6.78, wps=81380, ups=6.26, wpb=13003.9, bsz=433.6, num_updates=16900, lr=0.000243252, gnorm=0.616, loss_scale=8, train_wall=16, gb_free=15.4, wall=2792
2023-09-20 11:26:54 | INFO | train_inner | epoch 002:   7946 / 9060 loss=4.67, nll_loss=2.757, ppl=6.76, wps=80981.9, ups=6.26, wpb=12941.9, bsz=407.5, num_updates=17000, lr=0.000242536, gnorm=0.646, loss_scale=8, train_wall=16, gb_free=15.1, wall=2808
2023-09-20 11:27:10 | INFO | train_inner | epoch 002:   8046 / 9060 loss=4.615, nll_loss=2.701, ppl=6.5, wps=81159.5, ups=6.25, wpb=12979.1, bsz=409.4, num_updates=17100, lr=0.000241825, gnorm=0.626, loss_scale=8, train_wall=16, gb_free=15, wall=2824
2023-09-20 11:27:26 | INFO | train_inner | epoch 002:   8146 / 9060 loss=4.627, nll_loss=2.713, ppl=6.56, wps=80869.1, ups=6.25, wpb=12938.7, bsz=418.6, num_updates=17200, lr=0.000241121, gnorm=0.619, loss_scale=8, train_wall=16, gb_free=15.3, wall=2840
lprobs.size(): torch.Size([3536, 42808])
2023-09-20 11:27:42 | INFO | train_inner | epoch 002:   8246 / 9060 loss=4.681, nll_loss=2.768, ppl=6.81, wps=81707.2, ups=6.27, wpb=13031.8, bsz=418.4, num_updates=17300, lr=0.000240424, gnorm=0.609, loss_scale=8, train_wall=16, gb_free=16, wall=2856
2023-09-20 11:27:58 | INFO | train_inner | epoch 002:   8346 / 9060 loss=4.674, nll_loss=2.762, ppl=6.78, wps=80692.2, ups=6.26, wpb=12892.5, bsz=433, num_updates=17400, lr=0.000239732, gnorm=0.651, loss_scale=8, train_wall=16, gb_free=15.6, wall=2872
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-20 11:28:14 | INFO | train_inner | epoch 002:   8446 / 9060 loss=4.652, nll_loss=2.74, ppl=6.68, wps=81350.7, ups=6.25, wpb=13012.5, bsz=426.6, num_updates=17500, lr=0.000239046, gnorm=0.612, loss_scale=8, train_wall=16, gb_free=15.6, wall=2888
2023-09-20 11:28:31 | INFO | train_inner | epoch 002:   8546 / 9060 loss=4.64, nll_loss=2.727, ppl=6.62, wps=79606.9, ups=6.17, wpb=12904.1, bsz=397.9, num_updates=17600, lr=0.000238366, gnorm=0.641, loss_scale=8, train_wall=16, gb_free=15.2, wall=2904
2023-09-20 11:28:47 | INFO | train_inner | epoch 002:   8646 / 9060 loss=4.611, nll_loss=2.697, ppl=6.49, wps=79371.1, ups=6.11, wpb=12997.1, bsz=435.6, num_updates=17700, lr=0.000237691, gnorm=0.611, loss_scale=8, train_wall=16, gb_free=15.1, wall=2920
lprobs.size(): torch.Size([3480, 42808])
2023-09-20 11:29:03 | INFO | train_inner | epoch 002:   8746 / 9060 loss=4.677, nll_loss=2.765, ppl=6.8, wps=78955.9, ups=6.09, wpb=12955, bsz=408.1, num_updates=17800, lr=0.000237023, gnorm=0.625, loss_scale=8, train_wall=16, gb_free=15.9, wall=2937
2023-09-20 11:29:20 | INFO | train_inner | epoch 002:   8846 / 9060 loss=4.632, nll_loss=2.72, ppl=6.59, wps=79238.6, ups=6.11, wpb=12977.3, bsz=428.2, num_updates=17900, lr=0.00023636, gnorm=0.611, loss_scale=8, train_wall=16, gb_free=15.4, wall=2953
lprobs.size(): torch.Size([3416, 42808])
2023-09-20 11:29:36 | INFO | train_inner | epoch 002:   8946 / 9060 loss=4.624, nll_loss=2.711, ppl=6.55, wps=78681, ups=6.12, wpb=12850.7, bsz=425, num_updates=18000, lr=0.000235702, gnorm=0.631, loss_scale=8, train_wall=16, gb_free=15.1, wall=2970
2023-09-20 11:29:52 | INFO | train_inner | epoch 002:   9046 / 9060 loss=4.603, nll_loss=2.691, ppl=6.46, wps=79375.4, ups=6.12, wpb=12959.9, bsz=449.8, num_updates=18100, lr=0.00023505, gnorm=0.613, loss_scale=8, train_wall=16, gb_free=15.1, wall=2986
2023-09-20 11:29:55 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-20 11:29:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 11:29:55 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-20 11:29:55 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-20 11:29:56 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zu Maßnahmen ist daher völlig gerechtfertigt.
2023-09-20 11:29:56 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-20 11:29:56 | INFO | fairseq.tasks.translation | example hypothesis: Danach gibt es keinen Anspruch auf Unterkunft.
2023-09-20 11:29:56 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-20 11:29:57 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente in höchstem Maße vertraulich behandelt.
2023-09-20 11:29:57 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-20 11:29:57 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-20 11:29:57 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-20 11:29:58 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein ravierender Erfolg.
2023-09-20 11:29:58 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-20 11:29:59 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Frohe Neujahrsfeier für alle und Glückwünsche an unseren Präsidenten.
2023-09-20 11:29:59 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-20 11:29:59 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Initiativrecht, das wir respektieren.
2023-09-20 11:29:59 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-20 11:30:00 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-20 11:30:00 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-20 11:30:00 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer sind mit digitalem TV und Internetzugang ausgestattet, der sowohl für Geschäfts- als auch für Freizeitreisende attraktiv ist.
2023-09-20 11:30:00 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-20 11:30:01 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-20 11:30:01 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-20 11:30:02 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 11:30:02 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 11:30:02 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU als Ganzes riesige Mengen an Energie verschwendet.
2023-09-20 11:30:02 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-20 11:30:03 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin führt einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner letzten Nummer.
2023-09-20 11:30:03 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-20 11:30:03 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich auch die Änderung der Einstellung noch lange im Haushalt der Union widerspiegeln.
2023-09-20 11:30:03 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-20 11:30:04 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für die kleinen Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-20 11:30:04 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-20 11:30:05 | INFO | fairseq.tasks.translation | example hypothesis: Hier ist ein konkretes Beispiel: die allgemein bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-20 11:30:05 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-20 11:30:05 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte daran erinnern, dass eines der Hauptziele der Beschäftigungsstrategie darin besteht, ältere Menschen zu integrieren.
2023-09-20 11:30:05 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-20 11:30:06 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen wurden gezwungen, mehr Zeit auf ihr Berufsleben zu verwenden, als sie es sich gewünscht hätten?
2023-09-20 11:30:06 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-20 11:30:07 | INFO | fairseq.tasks.translation | example hypothesis: Der größte Schweizer Flugzeughersteller Pilatus Aircraft verfügt über seine Haupt- und Produktionsräume in Stans.
2023-09-20 11:30:07 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-20 11:30:07 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Remuneration Committee, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-20 11:30:07 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-20 11:30:08 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-20 11:30:08 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-20 11:30:08 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verknüpfung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution erfolgen.
2023-09-20 11:30:08 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-20 11:30:09 | INFO | fairseq.tasks.translation | example hypothesis: Eine Fehlermeldung kann potentielle Käufer dazu veranlassen, sich über die Qualität Ihres Dienstes und Ihrer Produkte zu informieren.
2023-09-20 11:30:09 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-20 11:30:10 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Notenbanken weiter in unbefrorene Gebiete wagen, argumentieren die Befürworter, dass sie im schlimmsten Fall keinen Schaden anrichten werden.
2023-09-20 11:30:10 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-20 11:30:10 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-20 11:30:10 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-20 11:30:11 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Aussprache, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit zu aufrufen.
2023-09-20 11:30:11 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-20 11:30:12 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte innerhalb von etwa 5 Meilen (8 km) Radius von The Strip.
2023-09-20 11:30:12 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-20 11:30:12 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web Portal basiert.
2023-09-20 11:30:12 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-20 11:30:13 | INFO | fairseq.tasks.translation | example hypothesis: Aus diesem Grund bietet HörDis! die Umsetzung von Klanghandbüchern akustisch, interaktiv oder schriftlich an.
2023-09-20 11:30:13 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-20 11:30:14 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel steht mit der neuen Lotos-Beschichtung für den Transferdruck sowie dem Direktdruck zur Verfügung.
2023-09-20 11:30:14 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-20 11:30:14 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer Unterstützung im Lande aufbauen, aber sie kann sich auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika stützen, um die Stabilität des Landes zu sichern.
2023-09-20 11:30:14 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-20 11:30:15 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu den von ihnen in die europäischen Sozialversicherungssysteme gezahlten Mitteln erhalten.
2023-09-20 11:30:15 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-20 11:30:16 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti Modell als Basis.
2023-09-20 11:30:16 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-20 11:30:16 | INFO | fairseq.tasks.translation | example hypothesis: Wir suchen immer nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf allen Computern läuft.
2023-09-20 11:30:16 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-20 11:30:17 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie Sie bei der Suche nach qualifizierten Fachkräften helfen können, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche ist.
2023-09-20 11:30:17 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-20 11:30:18 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherite-Ideen über niedrigere und transparentere Steuerstrukturen und eine zentrale Kontrolle der Haushaltsausgaben zweifellos Schlüsselelemente seiner Agenda.
2023-09-20 11:30:18 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-20 11:30:18 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen neu emerge splashutils damit es korrekt funktioniert.
2023-09-20 11:30:18 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-20 11:30:19 | INFO | fairseq.tasks.translation | example hypothesis: Horde und Allianz Spieler können sich keine Gegenstände kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-20 11:30:19 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-20 11:30:20 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-20 11:30:20 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-20 11:30:20 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuss für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-20 11:30:20 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-20 11:30:21 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission muss der Rat formelle Ansichten zu bestimmten Details des Abkommens im Prinzip mit den Vereinigten Staaten abgeben.
2023-09-20 11:30:21 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-20 11:30:22 | INFO | fairseq.tasks.translation | example hypothesis: Steigende oder klassische Farben, zeitloses Design oder Sonderausgabe - unser breites Sortiment an Plastikkindern ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Oberfläche.
2023-09-20 11:30:22 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-20 11:30:22 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourismus"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 11:30:22 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 11:30:23 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx über sachliche Situationen zu informieren, die mit diesen AGB nicht rechtzeitig vereinbar sind, nachdem er sich darüber im Klaren ist.
2023-09-20 11:30:23 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-20 11:30:24 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die die Notwendigkeit institutioneller Veränderungen vorangetrieben und verwirklicht hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung erfordern.
2023-09-20 11:30:24 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-20 11:30:25 | INFO | fairseq.tasks.translation | example hypothesis: Neben unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktnews und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-20 11:30:25 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-20 11:30:25 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei allen Fragen erzielt wurden, die jetzt zur Diskussion stehen, nämlich etwas, das kaum zwei Jahre alt ist, nämlich die neue transatlantische Agenda.
2023-09-20 11:30:25 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-20 11:30:26 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus geraden Quellen und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-20 11:30:26 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-20 11:30:27 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es dem Berichterstatter gelungen, in einem - wie ich sagen würde - sehr ausgewogenen Text die zuweilen unterschiedlichen Meinungen und Beiträge zu erarbeiten und zusammenzufassen.
2023-09-20 11:30:27 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-20 11:30:27 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochqualitativen Technologie ergänzt unser COMPACT-Modell unser Programm von trockenen elektrostatischen Vorläufern mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-20 11:30:27 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-20 11:30:28 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 m hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-20 11:30:28 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-20 11:30:29 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und den Fernen Osten migriert werden, müssen wir uns auf unsere Innovationskraft und unsere Erfindbarkeit verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-20 11:30:29 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-20 11:30:30 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich verfügt über ein Handelsdefizit mit der EU und stützt sich auf Verhandlungen mit Drittländern, von denen viele seit Jahren in Kraft sind und sich auf unseren Commonwealth of Nations beziehen.
2023-09-20 11:30:30 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-20 11:30:30 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-20 11:30:30 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-20 11:30:31 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürgerinnen und Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist die schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-20 11:30:31 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-20 11:30:32 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die zunehmende Anzahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-20 11:30:32 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-20 11:30:33 | INFO | fairseq.tasks.translation | example hypothesis: Innerhalb dieser Notsituation gibt es jedoch noch einen weiteren: den Notstand mit den Kindern, den schwächsten Sektor der Bevölkerung, der ohne Familie, ohne Schutz und ohne Staat gelassen wurde.
2023-09-20 11:30:33 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-20 11:30:33 | INFO | fairseq.tasks.translation | example hypothesis: Vor allem sollte klargestellt und hervorgehoben werden, dass die Praxis des Fräsches seit 2003 von der EU geregelt wurde, was bedeutet, dass Haie nicht allein für ihre Flossen gefangen werden kann.
2023-09-20 11:30:33 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-20 11:30:34 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei gesetzt wird und nicht erst innerhalb der ersten realisiert wird, bleiben alle äußeren Beziehungen von diesem Mangel an Realisation geprägt, und man kann niemanden wirklich kennen, bis man das wahre Selbst kennt.
2023-09-20 11:30:34 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-20 11:30:35 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Periode zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu öffnen.
2023-09-20 11:30:35 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-20 11:30:36 | INFO | fairseq.tasks.translation | example hypothesis: Gesetze, die den Bürgerinnen und Bürgern die Freiheit der Meinungsäußerung, freie und unabhängige Wahlen und die Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-20 11:30:36 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-20 11:30:36 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java-Programmiersprache mit J2EE-Techniken implementiert, die Plattform und Betriebssystem-Unabhängigkeit (Anwendung wurde auf Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-20 11:30:36 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-20 11:30:37 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab, und wir stimmen daher für eine Klarstellung des Anhangs.
2023-09-20 11:30:37 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-20 11:30:38 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist auch der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung haben, grundlegende Arbeitsnormen einzuhalten, und fordert die WTO auf, klar zu sagen, dass Sanktionen, die von der ILO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen betrachtet werden.
2023-09-20 11:30:38 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-20 11:30:39 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich habe ich an einer Debatte über das öffentlich-rechtliche Rundfunk in Irland mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Entwicklungshilfeausgaben zu kürzen.
2023-09-20 11:30:39 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-20 11:30:39 | INFO | fairseq.tasks.translation | example hypothesis: Vor diesem Hintergrund hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission noch einmal zu ihrer hochrangigen Haltung beglückwünschen.
2023-09-20 11:30:39 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-20 11:30:40 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie sich nach Ihren Lektionen oder konkreten Informationen über die europäische Geschichte, die Unionsbürgerschaft oder etwas Besonderes suchen, wie die Reduzierung des individuellen Energieverbrauchs, sollten Sie etwas hilfreiches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-20 11:30:40 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-20 11:30:41 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.
2023-09-20 11:30:41 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-20 11:30:42 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-20 11:30:42 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 11:30:43 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken ist, das, was eine bestimmte Art von vertraglichen Beziehungen zwischen Menschen mit gemeinsamen Bedenken ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Gefahr, von der institutionellen Hegemonie zerschlagen zu werden)!
2023-09-20 11:30:43 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-20 11:30:43 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das sich auf die persönlichen Daten bezieht, sollte der Gerichtshof und der Gerichtshof erster Instanz eingreifen können, wenn zum Beispiel die Bürger Forderungen stellen oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-20 11:30:43 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-20 11:30:44 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3 Series ist eine der lustigsten Autos, die unter 50.000 US-Dollar fahren, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-20 11:30:44 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-20 11:30:45 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, und das gilt auch für den Ausschuss für auswärtige Angelegenheiten, Menschenrechte und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-20 11:30:45 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-20 11:30:46 | INFO | fairseq.tasks.translation | example hypothesis: Sie müssen Fischsuppe, Hühnerpaprika, eine gute hausgemachte Pörkölt (Stew) und die ausgezeichnete Süßwasserfische probieren: grillte Schweinefleisch, Forellen mit Mandeln.
2023-09-20 11:30:46 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-20 11:30:47 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, statt daran zu erinnern, was eine politische Aktion bedeutet, eine allgemeine Auffassung abzugeben, die es uns ermöglicht, tiefer auf die verschiedenen Themen einzugehen und zu sehen, welche Impulse die Europäische Union in Bezug auf die Zukunft erhalten kann.
2023-09-20 11:30:47 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-20 11:30:48 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-20 11:30:48 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-20 11:30:48 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und kein wirklicher Wohlstand, wenn es Arbeitslosigkeit gibt, wo die drohenden Gefahren für bestehende Arbeitsplätze und die Wettbewerbsfähigkeit durch makroökonomische Maßnahmen, steuerliche Maßnahmen und Einschränkungen, die sich nicht an die bestehende Situation vor Ort anpassen, schrittweise untergraben werden.
2023-09-20 11:30:48 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-20 11:30:49 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche Richtung wie die bestehende Verordnung von 1994, die das Europäische Parlament mit einem ausgezeichneten Beispiel für die Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text aufgenommen hat, zu dieser Verordnung beitrug.
2023-09-20 11:30:49 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-20 11:30:50 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert also den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Folgen für den rechtlichen und rechtlichen Bereich, wodurch Norwegen und Island Länder, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsregeln gelten, zu einem Teil machen.
2023-09-20 11:30:50 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-20 11:30:51 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Make-Shift-Boot unter den Mississippi fahren, nach dem großen verborgenen Schatz suchen, mit dem schönen Becky Thatcher in Liebe gehen, der rein dynamisch ist, und vor allem werden wir große Freunde sein.
2023-09-20 11:30:51 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-20 11:30:52 | INFO | fairseq.tasks.translation | example hypothesis: Praktisch gesehen harmonisiert die Richtlinie die Definition der von Einzelpersonen oder juristischen Einrichtungen verursachten Meeresverschmutzung, den Umfang der Antwort und die Strafbarkeit der Sanktionen, die im Falle von Verletzungen, die von Einzelpersonen begangen werden, angewendet werden können.
2023-09-20 11:30:52 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-20 11:30:53 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falisation und Vincent Reynaud wurden in der Tat dafür verurteilt, dass sie ihre Arbeit als Journalisten und Kameraden geleistet haben, indem sie eine Gruppe von Bergregionen errichteten, die seit Jahren von einem autoritären Regime angegriffen wurden, das jeden Grundsatz der Demokratie missachtet.
2023-09-20 11:30:53 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-20 11:30:54 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen ein Concierge-Service, ein Friseur- und Schönheitsladen, Transport und Sightseeing-Rezeption, Wechselstube, kostenloser Schuhputz- und WLAN-Internetzugang. Die Omni Royal Orleans bietet 346 Gästezimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-20 11:30:54 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-20 11:30:55 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen dem thermischen Frühling sehr beliebt von Königin D. Leonor, Frau von König D. João II, und bekannt durch ihre Keramiken international bekannt für ihre bildlichen und satirischen Werke ist es auch wert, zu besuchen.
2023-09-20 11:30:55 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-20 11:30:56 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Menschen, die behaupten, es handele sich um gute Pro-Westerner auf der einen Seite und Anhänger des früheren Regimes auf der anderen Seite - und das ist auch angesichts der Tatsache, dass die Rolle aller, die jetzt und früher bekannt sind, verwerflich ist.
2023-09-20 11:30:56 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-20 11:30:57 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die undifferenziert zwischen Flüssen und Meer reisen, auf diese Weise nicht abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-20 11:30:57 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-20 11:30:58 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wenn außerhalb des Aktionärsversammlers Informationen an einen Aktionär übermittelt wurden, die aufgrund seines Status als Aktionär vorliegen, werden diese Informationen auf Anfrage an andere Aktionärinnen und Aktionärinnen und Aktionärinnen weitergegeben, auch wenn solche Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Gegenstandes auf der Tagesordnung zu ermöglichen.
2023-09-20 11:30:58 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-20 11:30:59 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme gesteckt werden, die in der Regel in den Taschen verschiedener Diktatoren landen und deren gute Lebensführung finanziert wird, während gleichzeitig Millionen und Millionen Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr schlechtes Leben führen.
2023-09-20 11:30:59 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-20 11:31:00 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder die NATO hätten in diesen Kriegsakt einbezogen werden können -, mit Informationen zu helfen, die keinen Grund mehr haben, geheim, verschwiegen oder geheim zu bleiben, damit wir wirklich die Fakten ans Licht bringen und die ganze Wahrheit erzählt werden kann.
2023-09-20 11:31:00 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-20 11:31:01 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Berliner Stadtteil Reinickendorf liegt nur 5 Gehminuten vom Bahnhof Waidmannslust S-Bahn und 30 Fahrminuten vom Hauptbahnhof entfernt. Die komfortablen Zimmer des Pension Nomaden sind in einem charmanten Landhausstil eingerichtet.
2023-09-20 11:31:01 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 11:31:02 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Geschäftseinheit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularen Sensor- und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen von entscheidender Bedeutung sind und die sich bis heute nicht mehr als bisher in den Regalen befindlichen Plattformen entfalten lassen.
2023-09-20 11:31:02 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-20 11:31:03 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir auch in der Lage sein werden, den Markt zu nutzen, und zwar nicht nur für uns, sondern weltweit, die Produkte, die ein ernsthaftes Risiko darstellen, nicht nur für den Inlandsverbrauch, sondern auch für den Weltmarkt, denn solche Produkte können leicht recycelt werden, wie es Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-20 11:31:03 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-20 11:31:04 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Plot der Modernität und Postmoderne oder der klaren Opposition reiner Kunst und Kunst müssen wir die ursprüngliche und dauerhafte Spannung dieser beiden ästhetischen Politik anerkennen, die sich in den Formen der Sichtbarkeit und Verständlichkeit niederschlagen, die uns die Kunst als solche kennzeichnen - jene beiden Politiken, die letztlich zu ihrer Selbstunterdrückung führen.
2023-09-20 11:31:04 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-20 11:31:05 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute angesichts der Bedeutung der Aussprachen und angesichts der Stellungnahmen, die Sie mir gegeben haben und die das, was ich gerade gesagt habe, eindeutig weitgehend unterstützen, und auf der Grundlage der vorhergehenden Beschlüsse werden wir unsere Debatten führen, und wenn es um die Abstimmung geht, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht darum bitten, das Quorum zu überprüfen.
2023-09-20 11:31:05 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-20 11:31:06 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker niemals die Beschränkung des Nationalstaatsprinzips akzeptiert haben, ist es paradoxerweise genau jene, die, wie niemandem bekannt ist, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen gestrichen wurden, ohne jedoch eine einheitliche Kultur zu schaffen, sondern auch ethnische, religiöse, sprachliche und kulturelle Vielfalt zu entwickeln.
2023-09-20 11:31:06 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-20 11:31:07 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihre Inhalte - wurde in mehrfacher Weise als Hybridform bis 2008 veröffentlicht, die Rezensionen und Artikel in der vierteljährlichen Zeitschrift sind für H-Soz-u-Kult geschrieben und an ihre Abonnenten über Mailinglisten sowie die Webseiten der Berlin-basierten H-Soz-u-Kult und der Michigan-basierten H-Kult verteilt.
2023-09-20 11:31:07 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-20 11:31:08 | INFO | fairseq.tasks.translation | example hypothesis: Mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone nicht nur ihre Federn deutlich verfeinert, sondern auch von den einst düsteren Taschenlampen über Polyphonisch-toottelnde Game Boy-Targets bis hin zu hochrechten Mini-PCs mit knusprigem CD-hochwertigen Stereo-Sound: Henceout, dank ihrer besonderen Kombination von Fähigkeiten, könnten sie von den ehemaligen I-Wannabes bis hin zu Trailblazers neuer technischer Entwicklungen absolviert werden.
2023-09-20 11:31:08 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-20 11:31:10 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien diehen la defensa de la base humana en Pandora, confesence a Jake para que le verhältnismäßig información sobre los nativos en caso de que fuera requiario suprir a la fuerza para que se marchen. En un principio, Jake cumple profesionalmente su misión, pero se enamora de las nativas, Netiri y y que que que que que que que que que no que que no que que que que que que no que que que que no pués de un fierlo que no que que que que que no que que que que que que que que un qué de un marqué de un marqué, Jake cumple profesionalmente de la que de la que de la mundo.
2023-09-20 11:31:10 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-20 11:31:11 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 4.513 | nll_loss 2.484 | ppl 5.6 | bleu 26.51 | wps 15563.1 | wpb 12011.9 | bsz 398.1 | num_updates 18114 | best_bleu 26.51
2023-09-20 11:31:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 18114 updates
2023-09-20 11:31:11 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint2.pt
2023-09-20 11:31:17 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint2.pt
2023-09-20 11:31:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 18114 updates, score 26.51) (writing took 13.61407781401067 seconds)
2023-09-20 11:31:25 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2023-09-20 11:31:25 | INFO | train | epoch 002 | loss 4.757 | nll_loss 2.841 | ppl 7.16 | wps 76264.8 | ups 5.88 | wpb 12977.2 | bsz 430.5 | num_updates 18114 | lr 0.000234959 | gnorm 0.654 | loss_scale 8 | train_wall 1432 | gb_free 15 | wall 3078
2023-09-20 11:31:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 11:31:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-20 11:31:25 | INFO | fairseq.trainer | begin training epoch 3
2023-09-20 11:31:25 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-20 11:31:39 | INFO | train_inner | epoch 003:     86 / 9060 loss=4.536, nll_loss=2.621, ppl=6.15, wps=12044.4, ups=0.94, wpb=12818.2, bsz=438.1, num_updates=18200, lr=0.000234404, gnorm=0.615, loss_scale=8, train_wall=16, gb_free=15.1, wall=3092
2023-09-20 11:31:55 | INFO | train_inner | epoch 003:    186 / 9060 loss=4.526, nll_loss=2.611, ppl=6.11, wps=79500.7, ups=6.11, wpb=13018.7, bsz=436.2, num_updates=18300, lr=0.000233762, gnorm=0.6, loss_scale=8, train_wall=16, gb_free=15.3, wall=3109
2023-09-20 11:32:12 | INFO | train_inner | epoch 003:    286 / 9060 loss=4.527, nll_loss=2.611, ppl=6.11, wps=80137.7, ups=6.11, wpb=13126.3, bsz=449.4, num_updates=18400, lr=0.000233126, gnorm=0.596, loss_scale=8, train_wall=16, gb_free=15, wall=3125
2023-09-20 11:32:28 | INFO | train_inner | epoch 003:    386 / 9060 loss=4.555, nll_loss=2.64, ppl=6.23, wps=78704.3, ups=6.11, wpb=12890.7, bsz=406.2, num_updates=18500, lr=0.000232495, gnorm=0.612, loss_scale=8, train_wall=16, gb_free=15.4, wall=3141
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 11:32:44 | INFO | train_inner | epoch 003:    486 / 9060 loss=4.607, nll_loss=2.694, ppl=6.47, wps=80425.9, ups=6.25, wpb=12862.3, bsz=429.3, num_updates=18600, lr=0.000231869, gnorm=0.617, loss_scale=8, train_wall=16, gb_free=15.3, wall=3157
2023-09-20 11:33:00 | INFO | train_inner | epoch 003:    586 / 9060 loss=4.575, nll_loss=2.66, ppl=6.32, wps=81465.7, ups=6.25, wpb=13024.3, bsz=445.1, num_updates=18700, lr=0.000231249, gnorm=0.672, loss_scale=8, train_wall=16, gb_free=15, wall=3173
2023-09-20 11:33:16 | INFO | train_inner | epoch 003:    686 / 9060 loss=4.534, nll_loss=2.619, ppl=6.14, wps=81536.3, ups=6.25, wpb=13044.2, bsz=434.5, num_updates=18800, lr=0.000230633, gnorm=0.621, loss_scale=8, train_wall=16, gb_free=15.1, wall=3189
2023-09-20 11:33:32 | INFO | train_inner | epoch 003:    786 / 9060 loss=4.591, nll_loss=2.677, ppl=6.39, wps=81276.9, ups=6.26, wpb=12988.8, bsz=410.2, num_updates=18900, lr=0.000230022, gnorm=0.645, loss_scale=8, train_wall=16, gb_free=15.1, wall=3205
2023-09-20 11:33:48 | INFO | train_inner | epoch 003:    886 / 9060 loss=4.563, nll_loss=2.649, ppl=6.27, wps=80968.4, ups=6.25, wpb=12950.4, bsz=429.4, num_updates=19000, lr=0.000229416, gnorm=0.604, loss_scale=8, train_wall=16, gb_free=15.2, wall=3221
2023-09-20 11:34:04 | INFO | train_inner | epoch 003:    986 / 9060 loss=4.527, nll_loss=2.612, ppl=6.11, wps=81605, ups=6.25, wpb=13061.1, bsz=439.4, num_updates=19100, lr=0.000228814, gnorm=0.596, loss_scale=8, train_wall=16, gb_free=15.2, wall=3237
2023-09-20 11:34:20 | INFO | train_inner | epoch 003:   1086 / 9060 loss=4.571, nll_loss=2.657, ppl=6.31, wps=81079, ups=6.26, wpb=12957.4, bsz=439.7, num_updates=19200, lr=0.000228218, gnorm=0.592, loss_scale=8, train_wall=16, gb_free=15.3, wall=3253
2023-09-20 11:34:36 | INFO | train_inner | epoch 003:   1186 / 9060 loss=4.591, nll_loss=2.677, ppl=6.4, wps=80745.2, ups=6.25, wpb=12918.5, bsz=426, num_updates=19300, lr=0.000227626, gnorm=0.61, loss_scale=8, train_wall=16, gb_free=15.4, wall=3269
2023-09-20 11:34:52 | INFO | train_inner | epoch 003:   1286 / 9060 loss=4.551, nll_loss=2.637, ppl=6.22, wps=80759.9, ups=6.26, wpb=12905, bsz=449.5, num_updates=19400, lr=0.000227038, gnorm=0.608, loss_scale=8, train_wall=16, gb_free=15.2, wall=3285
2023-09-20 11:35:08 | INFO | train_inner | epoch 003:   1386 / 9060 loss=4.561, nll_loss=2.646, ppl=6.26, wps=80926.7, ups=6.25, wpb=12939.4, bsz=407, num_updates=19500, lr=0.000226455, gnorm=0.597, loss_scale=8, train_wall=16, gb_free=15.1, wall=3301
2023-09-20 11:35:24 | INFO | train_inner | epoch 003:   1486 / 9060 loss=4.52, nll_loss=2.605, ppl=6.08, wps=80980.3, ups=6.25, wpb=12958.4, bsz=430.3, num_updates=19600, lr=0.000225877, gnorm=0.63, loss_scale=8, train_wall=16, gb_free=15.8, wall=3317
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:35:40 | INFO | train_inner | epoch 003:   1586 / 9060 loss=4.589, nll_loss=2.676, ppl=6.39, wps=80875.2, ups=6.21, wpb=13018.9, bsz=417.4, num_updates=19700, lr=0.000225303, gnorm=0.611, loss_scale=8, train_wall=16, gb_free=15.1, wall=3333
2023-09-20 11:35:56 | INFO | train_inner | epoch 003:   1686 / 9060 loss=4.539, nll_loss=2.625, ppl=6.17, wps=79031.3, ups=6.09, wpb=12971.5, bsz=430.6, num_updates=19800, lr=0.000224733, gnorm=0.603, loss_scale=8, train_wall=16, gb_free=15.1, wall=3350
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:36:13 | INFO | train_inner | epoch 003:   1786 / 9060 loss=4.575, nll_loss=2.661, ppl=6.33, wps=78916.5, ups=6.1, wpb=12934.3, bsz=426.9, num_updates=19900, lr=0.000224168, gnorm=0.636, loss_scale=8, train_wall=16, gb_free=15.4, wall=3366
2023-09-20 11:36:29 | INFO | train_inner | epoch 003:   1886 / 9060 loss=4.595, nll_loss=2.682, ppl=6.42, wps=79643.5, ups=6.14, wpb=12980.1, bsz=423.3, num_updates=20000, lr=0.000223607, gnorm=0.677, loss_scale=8, train_wall=16, gb_free=15.1, wall=3383
2023-09-20 11:36:45 | INFO | train_inner | epoch 003:   1986 / 9060 loss=4.54, nll_loss=2.626, ppl=6.17, wps=79272, ups=6.14, wpb=12920.6, bsz=426.2, num_updates=20100, lr=0.00022305, gnorm=0.596, loss_scale=16, train_wall=16, gb_free=15.2, wall=3399
lprobs.size(): torch.Size([3328, 42808])
2023-09-20 11:37:02 | INFO | train_inner | epoch 003:   2086 / 9060 loss=4.532, nll_loss=2.619, ppl=6.14, wps=80047.6, ups=6.13, wpb=13056.8, bsz=441.4, num_updates=20200, lr=0.000222497, gnorm=0.598, loss_scale=16, train_wall=16, gb_free=15.3, wall=3415
2023-09-20 11:37:18 | INFO | train_inner | epoch 003:   2186 / 9060 loss=4.562, nll_loss=2.649, ppl=6.27, wps=79687.5, ups=6.14, wpb=12987.5, bsz=427.7, num_updates=20300, lr=0.000221948, gnorm=0.589, loss_scale=16, train_wall=16, gb_free=15.8, wall=3431
lprobs.size(): torch.Size([2720, 42808])
2023-09-20 11:37:34 | INFO | train_inner | epoch 003:   2286 / 9060 loss=4.567, nll_loss=2.654, ppl=6.29, wps=79235.8, ups=6.14, wpb=12899.4, bsz=416, num_updates=20400, lr=0.000221404, gnorm=0.617, loss_scale=16, train_wall=16, gb_free=15.5, wall=3448
2023-09-20 11:37:51 | INFO | train_inner | epoch 003:   2386 / 9060 loss=4.525, nll_loss=2.611, ppl=6.11, wps=79009.8, ups=6.13, wpb=12895.9, bsz=436.8, num_updates=20500, lr=0.000220863, gnorm=0.613, loss_scale=16, train_wall=16, gb_free=15.3, wall=3464
lprobs.size(): torch.Size([3120, 42808])
2023-09-20 11:38:07 | INFO | train_inner | epoch 003:   2486 / 9060 loss=4.524, nll_loss=2.611, ppl=6.11, wps=79798, ups=6.11, wpb=13056.2, bsz=426.9, num_updates=20600, lr=0.000220326, gnorm=0.585, loss_scale=16, train_wall=16, gb_free=15, wall=3480
2023-09-20 11:38:23 | INFO | train_inner | epoch 003:   2586 / 9060 loss=4.571, nll_loss=2.658, ppl=6.31, wps=79137.2, ups=6.11, wpb=12943, bsz=424.8, num_updates=20700, lr=0.000219793, gnorm=0.609, loss_scale=16, train_wall=16, gb_free=15.9, wall=3497
2023-09-20 11:38:40 | INFO | train_inner | epoch 003:   2686 / 9060 loss=4.581, nll_loss=2.668, ppl=6.35, wps=79508.2, ups=6.12, wpb=12989.3, bsz=413.3, num_updates=20800, lr=0.000219265, gnorm=0.6, loss_scale=16, train_wall=16, gb_free=15.2, wall=3513
lprobs.size(): torch.Size([3304, 42808])
2023-09-20 11:38:56 | INFO | train_inner | epoch 003:   2786 / 9060 loss=4.559, nll_loss=2.647, ppl=6.26, wps=79504.8, ups=6.12, wpb=12981.2, bsz=441.9, num_updates=20900, lr=0.000218739, gnorm=0.592, loss_scale=16, train_wall=16, gb_free=15.1, wall=3529
2023-09-20 11:39:12 | INFO | train_inner | epoch 003:   2886 / 9060 loss=4.522, nll_loss=2.608, ppl=6.1, wps=79134.6, ups=6.11, wpb=12949.1, bsz=431.2, num_updates=21000, lr=0.000218218, gnorm=0.595, loss_scale=16, train_wall=16, gb_free=15.6, wall=3546
2023-09-20 11:39:29 | INFO | train_inner | epoch 003:   2986 / 9060 loss=4.497, nll_loss=2.583, ppl=5.99, wps=79557.6, ups=6.12, wpb=12996.7, bsz=455.6, num_updates=21100, lr=0.0002177, gnorm=0.614, loss_scale=16, train_wall=16, gb_free=15.4, wall=3562
2023-09-20 11:39:45 | INFO | train_inner | epoch 003:   3086 / 9060 loss=4.507, nll_loss=2.594, ppl=6.04, wps=79638.7, ups=6.14, wpb=12978.1, bsz=438.4, num_updates=21200, lr=0.000217186, gnorm=0.597, loss_scale=16, train_wall=16, gb_free=15.5, wall=3578
2023-09-20 11:40:01 | INFO | train_inner | epoch 003:   3186 / 9060 loss=4.531, nll_loss=2.618, ppl=6.14, wps=80787.5, ups=6.27, wpb=12892.3, bsz=438.7, num_updates=21300, lr=0.000216676, gnorm=0.589, loss_scale=16, train_wall=16, gb_free=15.1, wall=3594
2023-09-20 11:40:17 | INFO | train_inner | epoch 003:   3286 / 9060 loss=4.493, nll_loss=2.579, ppl=5.98, wps=81406.1, ups=6.26, wpb=13005.5, bsz=454.2, num_updates=21400, lr=0.000216169, gnorm=0.596, loss_scale=16, train_wall=16, gb_free=15, wall=3610
2023-09-20 11:40:33 | INFO | train_inner | epoch 003:   3386 / 9060 loss=4.497, nll_loss=2.584, ppl=6, wps=81428.7, ups=6.26, wpb=13000.6, bsz=460.4, num_updates=21500, lr=0.000215666, gnorm=0.601, loss_scale=16, train_wall=16, gb_free=15.6, wall=3626
2023-09-20 11:40:49 | INFO | train_inner | epoch 003:   3486 / 9060 loss=4.486, nll_loss=2.572, ppl=5.95, wps=81589.9, ups=6.27, wpb=13022.8, bsz=440.7, num_updates=21600, lr=0.000215166, gnorm=0.583, loss_scale=16, train_wall=16, gb_free=15, wall=3642
2023-09-20 11:41:05 | INFO | train_inner | epoch 003:   3586 / 9060 loss=4.538, nll_loss=2.626, ppl=6.17, wps=80845.1, ups=6.25, wpb=12926.4, bsz=437.9, num_updates=21700, lr=0.000214669, gnorm=0.613, loss_scale=16, train_wall=16, gb_free=15.1, wall=3658
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:41:21 | INFO | train_inner | epoch 003:   3686 / 9060 loss=4.512, nll_loss=2.599, ppl=6.06, wps=81674.3, ups=6.26, wpb=13056.2, bsz=452.4, num_updates=21800, lr=0.000214176, gnorm=0.597, loss_scale=16, train_wall=16, gb_free=15.1, wall=3674
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:41:37 | INFO | train_inner | epoch 003:   3786 / 9060 loss=4.556, nll_loss=2.645, ppl=6.25, wps=81076, ups=6.26, wpb=12960.3, bsz=448.6, num_updates=21900, lr=0.000213687, gnorm=0.607, loss_scale=16, train_wall=16, gb_free=15.3, wall=3690
2023-09-20 11:41:53 | INFO | train_inner | epoch 003:   3886 / 9060 loss=4.515, nll_loss=2.602, ppl=6.07, wps=81472.3, ups=6.25, wpb=13039, bsz=408.7, num_updates=22000, lr=0.000213201, gnorm=0.592, loss_scale=16, train_wall=16, gb_free=15.3, wall=3706
2023-09-20 11:42:09 | INFO | train_inner | epoch 003:   3986 / 9060 loss=4.496, nll_loss=2.583, ppl=5.99, wps=81384.6, ups=6.25, wpb=13013.5, bsz=421.5, num_updates=22100, lr=0.000212718, gnorm=0.588, loss_scale=16, train_wall=16, gb_free=15.4, wall=3722
2023-09-20 11:42:25 | INFO | train_inner | epoch 003:   4086 / 9060 loss=4.525, nll_loss=2.612, ppl=6.11, wps=81048.3, ups=6.26, wpb=12944.6, bsz=411.2, num_updates=22200, lr=0.000212238, gnorm=0.606, loss_scale=16, train_wall=16, gb_free=15.5, wall=3738
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:42:41 | INFO | train_inner | epoch 003:   4186 / 9060 loss=4.493, nll_loss=2.58, ppl=5.98, wps=81364.7, ups=6.26, wpb=12992.8, bsz=455.5, num_updates=22300, lr=0.000211762, gnorm=0.589, loss_scale=16, train_wall=16, gb_free=15, wall=3754
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-20 11:42:57 | INFO | train_inner | epoch 003:   4286 / 9060 loss=4.529, nll_loss=2.617, ppl=6.13, wps=81212.6, ups=6.26, wpb=12969.5, bsz=430.9, num_updates=22400, lr=0.000211289, gnorm=0.596, loss_scale=16, train_wall=16, gb_free=15.3, wall=3770
2023-09-20 11:43:13 | INFO | train_inner | epoch 003:   4386 / 9060 loss=4.475, nll_loss=2.562, ppl=5.91, wps=81559.4, ups=6.25, wpb=13047.3, bsz=433, num_updates=22500, lr=0.000210819, gnorm=0.607, loss_scale=16, train_wall=16, gb_free=15.1, wall=3786
lprobs.size(): torch.Size([3192, 42808])
2023-09-20 11:43:29 | INFO | train_inner | epoch 003:   4486 / 9060 loss=4.545, nll_loss=2.633, ppl=6.2, wps=81194.2, ups=6.26, wpb=12975.4, bsz=440, num_updates=22600, lr=0.000210352, gnorm=0.586, loss_scale=16, train_wall=16, gb_free=15.4, wall=3802
lprobs.size(): torch.Size([3416, 42808])
2023-09-20 11:43:45 | INFO | train_inner | epoch 003:   4586 / 9060 loss=4.515, nll_loss=2.602, ppl=6.07, wps=81110.3, ups=6.26, wpb=12957.6, bsz=417.2, num_updates=22700, lr=0.000209888, gnorm=0.596, loss_scale=16, train_wall=16, gb_free=15.2, wall=3818
lprobs.size(): torch.Size([3264, 42808])
2023-09-20 11:44:01 | INFO | train_inner | epoch 003:   4686 / 9060 loss=4.491, nll_loss=2.578, ppl=5.97, wps=81598.8, ups=6.25, wpb=13062.6, bsz=436.6, num_updates=22800, lr=0.000209427, gnorm=0.6, loss_scale=16, train_wall=16, gb_free=15.6, wall=3834
2023-09-20 11:44:17 | INFO | train_inner | epoch 003:   4786 / 9060 loss=4.477, nll_loss=2.564, ppl=5.91, wps=80728.9, ups=6.25, wpb=12911.5, bsz=425.1, num_updates=22900, lr=0.000208969, gnorm=0.607, loss_scale=16, train_wall=16, gb_free=15.1, wall=3850
2023-09-20 11:44:33 | INFO | train_inner | epoch 003:   4886 / 9060 loss=4.5, nll_loss=2.588, ppl=6.01, wps=81354, ups=6.26, wpb=12993.3, bsz=430.1, num_updates=23000, lr=0.000208514, gnorm=0.596, loss_scale=16, train_wall=16, gb_free=15.1, wall=3866
lprobs.size(): torch.Size([3432, 42808])
2023-09-20 11:44:49 | INFO | train_inner | epoch 003:   4986 / 9060 loss=4.529, nll_loss=2.617, ppl=6.14, wps=81181.2, ups=6.26, wpb=12975.1, bsz=414.8, num_updates=23100, lr=0.000208063, gnorm=0.601, loss_scale=16, train_wall=16, gb_free=15.1, wall=3882
2023-09-20 11:45:05 | INFO | train_inner | epoch 003:   5086 / 9060 loss=4.525, nll_loss=2.614, ppl=6.12, wps=80723.9, ups=6.26, wpb=12888.9, bsz=423.6, num_updates=23200, lr=0.000207614, gnorm=0.593, loss_scale=16, train_wall=16, gb_free=15.7, wall=3898
2023-09-20 11:45:21 | INFO | train_inner | epoch 003:   5186 / 9060 loss=4.509, nll_loss=2.597, ppl=6.05, wps=81176.7, ups=6.26, wpb=12971.7, bsz=453.4, num_updates=23300, lr=0.000207168, gnorm=0.593, loss_scale=16, train_wall=16, gb_free=15.4, wall=3914
2023-09-20 11:45:37 | INFO | train_inner | epoch 003:   5286 / 9060 loss=4.504, nll_loss=2.592, ppl=6.03, wps=81060.6, ups=6.26, wpb=12949.1, bsz=423.7, num_updates=23400, lr=0.000206725, gnorm=0.618, loss_scale=16, train_wall=16, gb_free=15.9, wall=3930
2023-09-20 11:45:53 | INFO | train_inner | epoch 003:   5386 / 9060 loss=4.509, nll_loss=2.597, ppl=6.05, wps=81500.7, ups=6.26, wpb=13021.6, bsz=421.4, num_updates=23500, lr=0.000206284, gnorm=0.586, loss_scale=16, train_wall=16, gb_free=15.2, wall=3946
lprobs.size(): torch.Size([3328, 42808])
2023-09-20 11:46:09 | INFO | train_inner | epoch 003:   5486 / 9060 loss=4.447, nll_loss=2.534, ppl=5.79, wps=81218.8, ups=6.25, wpb=12993.4, bsz=438.7, num_updates=23600, lr=0.000205847, gnorm=0.584, loss_scale=16, train_wall=16, gb_free=15.1, wall=3962
lprobs.size(): torch.Size([2904, 42808])
2023-09-20 11:46:24 | INFO | train_inner | epoch 003:   5586 / 9060 loss=4.485, nll_loss=2.573, ppl=5.95, wps=80992.6, ups=6.26, wpb=12930.8, bsz=434.7, num_updates=23700, lr=0.000205412, gnorm=0.589, loss_scale=16, train_wall=16, gb_free=15.3, wall=3978
lprobs.size(): torch.Size([2960, 42808])
2023-09-20 11:46:40 | INFO | train_inner | epoch 003:   5686 / 9060 loss=4.511, nll_loss=2.6, ppl=6.06, wps=80959.6, ups=6.26, wpb=12936.8, bsz=426.9, num_updates=23800, lr=0.00020498, gnorm=0.599, loss_scale=16, train_wall=16, gb_free=15.9, wall=3994
2023-09-20 11:46:56 | INFO | train_inner | epoch 003:   5786 / 9060 loss=4.482, nll_loss=2.569, ppl=5.94, wps=81310.1, ups=6.24, wpb=13024.5, bsz=425.9, num_updates=23900, lr=0.000204551, gnorm=0.586, loss_scale=16, train_wall=16, gb_free=15.5, wall=4010
2023-09-20 11:47:13 | INFO | train_inner | epoch 003:   5886 / 9060 loss=4.56, nll_loss=2.649, ppl=6.27, wps=78977.8, ups=6.12, wpb=12903.2, bsz=418, num_updates=24000, lr=0.000204124, gnorm=0.588, loss_scale=16, train_wall=16, gb_free=15.5, wall=4026
2023-09-20 11:47:29 | INFO | train_inner | epoch 003:   5986 / 9060 loss=4.468, nll_loss=2.556, ppl=5.88, wps=79951.3, ups=6.12, wpb=13055.6, bsz=454.1, num_updates=24100, lr=0.0002037, gnorm=0.579, loss_scale=16, train_wall=16, gb_free=15.2, wall=4043
2023-09-20 11:47:45 | INFO | train_inner | epoch 003:   6086 / 9060 loss=4.469, nll_loss=2.558, ppl=5.89, wps=80296.4, ups=6.18, wpb=12994.9, bsz=452, num_updates=24200, lr=0.000203279, gnorm=0.591, loss_scale=32, train_wall=16, gb_free=15.2, wall=4059
lprobs.size(): torch.Size([2944, 42808])
2023-09-20 11:48:01 | INFO | train_inner | epoch 003:   6186 / 9060 loss=4.506, nll_loss=2.594, ppl=6.04, wps=81083.8, ups=6.25, wpb=12972.4, bsz=425.3, num_updates=24300, lr=0.00020286, gnorm=0.599, loss_scale=32, train_wall=16, gb_free=15.6, wall=4075
2023-09-20 11:48:17 | INFO | train_inner | epoch 003:   6286 / 9060 loss=4.465, nll_loss=2.553, ppl=5.87, wps=81033.7, ups=6.26, wpb=12944.3, bsz=439.6, num_updates=24400, lr=0.000202444, gnorm=0.601, loss_scale=32, train_wall=16, gb_free=15.4, wall=4091
lprobs.size(): torch.Size([2496, 42808])
2023-09-20 11:48:33 | INFO | train_inner | epoch 003:   6386 / 9060 loss=4.515, nll_loss=2.604, ppl=6.08, wps=80640.7, ups=6.26, wpb=12889.2, bsz=431.1, num_updates=24500, lr=0.000202031, gnorm=0.601, loss_scale=32, train_wall=16, gb_free=15.2, wall=4107
2023-09-20 11:48:49 | INFO | train_inner | epoch 003:   6486 / 9060 loss=4.475, nll_loss=2.563, ppl=5.91, wps=81596.8, ups=6.26, wpb=13035.4, bsz=431.8, num_updates=24600, lr=0.000201619, gnorm=0.589, loss_scale=32, train_wall=16, gb_free=15.1, wall=4123
2023-09-20 11:48:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
2023-09-20 11:49:05 | INFO | train_inner | epoch 003:   6587 / 9060 loss=4.475, nll_loss=2.563, ppl=5.91, wps=80804.1, ups=6.21, wpb=13012.1, bsz=427.7, num_updates=24700, lr=0.000201211, gnorm=0.585, loss_scale=16, train_wall=16, gb_free=15.1, wall=4139
2023-09-20 11:49:21 | INFO | train_inner | epoch 003:   6687 / 9060 loss=4.508, nll_loss=2.597, ppl=6.05, wps=81491.9, ups=6.25, wpb=13030.4, bsz=424, num_updates=24800, lr=0.000200805, gnorm=0.583, loss_scale=16, train_wall=16, gb_free=15.5, wall=4155
2023-09-20 11:49:37 | INFO | train_inner | epoch 003:   6787 / 9060 loss=4.477, nll_loss=2.565, ppl=5.92, wps=80620.1, ups=6.26, wpb=12884.6, bsz=416.8, num_updates=24900, lr=0.000200401, gnorm=0.593, loss_scale=16, train_wall=16, gb_free=15.6, wall=4171
lprobs.size(): torch.Size([2880, 42808])
2023-09-20 11:49:53 | INFO | train_inner | epoch 003:   6887 / 9060 loss=4.476, nll_loss=2.564, ppl=5.91, wps=80828.2, ups=6.26, wpb=12919.1, bsz=416.7, num_updates=25000, lr=0.0002, gnorm=0.609, loss_scale=16, train_wall=16, gb_free=15.5, wall=4187
2023-09-20 11:50:09 | INFO | train_inner | epoch 003:   6987 / 9060 loss=4.507, nll_loss=2.596, ppl=6.05, wps=81536.7, ups=6.25, wpb=13044.6, bsz=440.3, num_updates=25100, lr=0.000199601, gnorm=0.599, loss_scale=16, train_wall=16, gb_free=15.3, wall=4203
2023-09-20 11:50:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-20 11:50:26 | INFO | train_inner | epoch 003:   7088 / 9060 loss=4.478, nll_loss=2.566, ppl=5.92, wps=79479.4, ups=6.11, wpb=13016.6, bsz=430.2, num_updates=25200, lr=0.000199205, gnorm=0.58, loss_scale=8, train_wall=16, gb_free=15.2, wall=4219
2023-09-20 11:50:42 | INFO | train_inner | epoch 003:   7188 / 9060 loss=4.461, nll_loss=2.549, ppl=5.85, wps=78904.2, ups=6.12, wpb=12901.1, bsz=427.2, num_updates=25300, lr=0.000198811, gnorm=0.612, loss_scale=8, train_wall=16, gb_free=15.3, wall=4236
2023-09-20 11:50:58 | INFO | train_inner | epoch 003:   7288 / 9060 loss=4.493, nll_loss=2.582, ppl=5.99, wps=78864.5, ups=6.11, wpb=12907.6, bsz=432.8, num_updates=25400, lr=0.000198419, gnorm=0.593, loss_scale=8, train_wall=16, gb_free=15, wall=4252
2023-09-20 11:51:15 | INFO | train_inner | epoch 003:   7388 / 9060 loss=4.503, nll_loss=2.592, ppl=6.03, wps=78829.7, ups=6.11, wpb=12901.7, bsz=413.7, num_updates=25500, lr=0.00019803, gnorm=0.598, loss_scale=8, train_wall=16, gb_free=15.2, wall=4268
lprobs.size(): torch.Size([3240, 42808])
2023-09-20 11:51:31 | INFO | train_inner | epoch 003:   7488 / 9060 loss=4.473, nll_loss=2.562, ppl=5.91, wps=79292.4, ups=6.11, wpb=12971.6, bsz=445, num_updates=25600, lr=0.000197642, gnorm=0.583, loss_scale=8, train_wall=16, gb_free=15.4, wall=4285
lprobs.size(): torch.Size([3536, 42808])
2023-09-20 11:51:47 | INFO | train_inner | epoch 003:   7588 / 9060 loss=4.498, nll_loss=2.588, ppl=6.01, wps=79248.3, ups=6.12, wpb=12940.6, bsz=428.2, num_updates=25700, lr=0.000197257, gnorm=0.587, loss_scale=8, train_wall=16, gb_free=15.6, wall=4301
2023-09-20 11:52:04 | INFO | train_inner | epoch 003:   7688 / 9060 loss=4.435, nll_loss=2.523, ppl=5.75, wps=80191.7, ups=6.11, wpb=13121.7, bsz=446.5, num_updates=25800, lr=0.000196875, gnorm=0.576, loss_scale=8, train_wall=16, gb_free=15.2, wall=4317
2023-09-20 11:52:20 | INFO | train_inner | epoch 003:   7788 / 9060 loss=4.458, nll_loss=2.546, ppl=5.84, wps=79565.2, ups=6.12, wpb=13004.4, bsz=421.6, num_updates=25900, lr=0.000196494, gnorm=0.593, loss_scale=8, train_wall=16, gb_free=15.4, wall=4334
2023-09-20 11:52:37 | INFO | train_inner | epoch 003:   7888 / 9060 loss=4.51, nll_loss=2.6, ppl=6.06, wps=78291.3, ups=6.12, wpb=12783.9, bsz=411.3, num_updates=26000, lr=0.000196116, gnorm=0.624, loss_scale=8, train_wall=16, gb_free=15.1, wall=4350
2023-09-20 11:52:53 | INFO | train_inner | epoch 003:   7988 / 9060 loss=4.478, nll_loss=2.566, ppl=5.92, wps=79273.8, ups=6.12, wpb=12958.7, bsz=420.1, num_updates=26100, lr=0.00019574, gnorm=0.593, loss_scale=8, train_wall=16, gb_free=15, wall=4366
lprobs.size(): torch.Size([3024, 42808])
2023-09-20 11:53:09 | INFO | train_inner | epoch 003:   8088 / 9060 loss=4.472, nll_loss=2.561, ppl=5.9, wps=79618.2, ups=6.1, wpb=13042.4, bsz=423.4, num_updates=26200, lr=0.000195366, gnorm=0.582, loss_scale=8, train_wall=16, gb_free=15.2, wall=4383
lprobs.size(): torch.Size([3432, 42808])
2023-09-20 11:53:26 | INFO | train_inner | epoch 003:   8188 / 9060 loss=4.495, nll_loss=2.585, ppl=6, wps=79526.5, ups=6.11, wpb=13022, bsz=424.9, num_updates=26300, lr=0.000194994, gnorm=0.601, loss_scale=8, train_wall=16, gb_free=15.4, wall=4399
2023-09-20 11:53:42 | INFO | train_inner | epoch 003:   8288 / 9060 loss=4.483, nll_loss=2.573, ppl=5.95, wps=80414.7, ups=6.21, wpb=12958.1, bsz=434.6, num_updates=26400, lr=0.000194625, gnorm=0.603, loss_scale=8, train_wall=16, gb_free=15.1, wall=4415
2023-09-20 11:53:58 | INFO | train_inner | epoch 003:   8388 / 9060 loss=4.399, nll_loss=2.487, ppl=5.61, wps=81612.3, ups=6.26, wpb=13046.7, bsz=420.9, num_updates=26500, lr=0.000194257, gnorm=0.577, loss_scale=8, train_wall=16, gb_free=15.4, wall=4431
lprobs.size(): torch.Size([3200, 42808])
2023-09-20 11:54:14 | INFO | train_inner | epoch 003:   8488 / 9060 loss=4.496, nll_loss=2.585, ppl=6, wps=81010.2, ups=6.25, wpb=12971.5, bsz=407.9, num_updates=26600, lr=0.000193892, gnorm=0.596, loss_scale=8, train_wall=16, gb_free=15.4, wall=4447
2023-09-20 11:54:30 | INFO | train_inner | epoch 003:   8588 / 9060 loss=4.496, nll_loss=2.586, ppl=6, wps=82012, ups=6.26, wpb=13099.1, bsz=424.4, num_updates=26700, lr=0.000193528, gnorm=0.574, loss_scale=8, train_wall=16, gb_free=15.2, wall=4463
2023-09-20 11:54:46 | INFO | train_inner | epoch 003:   8688 / 9060 loss=4.399, nll_loss=2.487, ppl=5.61, wps=81851.7, ups=6.26, wpb=13074.3, bsz=442, num_updates=26800, lr=0.000193167, gnorm=0.573, loss_scale=8, train_wall=16, gb_free=15.2, wall=4479
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([2920, 42808])
2023-09-20 11:55:02 | INFO | train_inner | epoch 003:   8788 / 9060 loss=4.479, nll_loss=2.569, ppl=5.93, wps=81235.2, ups=6.26, wpb=12983.7, bsz=422.4, num_updates=26900, lr=0.000192807, gnorm=0.578, loss_scale=8, train_wall=16, gb_free=15.1, wall=4495
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 11:55:18 | INFO | train_inner | epoch 003:   8888 / 9060 loss=4.456, nll_loss=2.545, ppl=5.84, wps=81352.6, ups=6.25, wpb=13006.2, bsz=426.4, num_updates=27000, lr=0.00019245, gnorm=0.584, loss_scale=8, train_wall=16, gb_free=15.5, wall=4511
2023-09-20 11:55:34 | INFO | train_inner | epoch 003:   8988 / 9060 loss=4.459, nll_loss=2.548, ppl=5.85, wps=81665.5, ups=6.25, wpb=13074, bsz=441.8, num_updates=27100, lr=0.000192095, gnorm=0.591, loss_scale=8, train_wall=16, gb_free=15.3, wall=4527
lprobs.size(): torch.Size([3480, 42808])
2023-09-20 11:55:45 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-20 11:55:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 11:55:46 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-20 11:55:46 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-20 11:55:46 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-20 11:55:46 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-20 11:55:47 | INFO | fairseq.tasks.translation | example hypothesis: Danach gibt es keinen Anspruch auf Unterkunft.
2023-09-20 11:55:47 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-20 11:55:47 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-20 11:55:47 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-20 11:55:48 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-20 11:55:48 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-20 11:55:48 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und war ein bewegender Erfolg.
2023-09-20 11:55:48 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-20 11:55:49 | INFO | fairseq.tasks.translation | example hypothesis: - Herr Präsident! Frohe Neujahrsfeier für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-20 11:55:49 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-20 11:55:49 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das respektieren wir.
2023-09-20 11:55:49 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-20 11:55:50 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-20 11:55:50 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-20 11:55:50 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über einen digitalen TV und einen Internetzugang, der sowohl für Geschäfts- als auch für Freizeitreisende attraktiv ist.
2023-09-20 11:55:50 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-20 11:55:51 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße Richtung Chianciano Terme.
2023-09-20 11:55:51 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-20 11:55:52 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 11:55:52 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 11:55:52 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU große Mengen an Energie verschwendet.
2023-09-20 11:55:52 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-20 11:55:53 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin trägt einen Artikel von Gentoo Entwickler Michael Kohl in seiner neuesten Nummer.
2023-09-20 11:55:53 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-20 11:55:53 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Haltung auch noch vor langer Zeit im Haushalt der Union widerspiegeln.
2023-09-20 11:55:53 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-20 11:55:54 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-20 11:55:54 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-20 11:55:54 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weit bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-20 11:55:54 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-20 11:55:55 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-20 11:55:55 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-20 11:55:55 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, ihrem Berufsleben mehr Zeit zu widmen, als sie es sich gewünscht hätten?
2023-09-20 11:55:55 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-20 11:55:56 | INFO | fairseq.tasks.translation | example hypothesis: Der größte Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionsräume in Stans.
2023-09-20 11:55:56 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-20 11:55:57 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Remuneration Committee, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-20 11:55:57 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-20 11:55:57 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-20 11:55:57 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-20 11:55:58 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-20 11:55:58 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-20 11:55:58 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potenzielle Käufer dazu veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-20 11:55:58 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-20 11:55:59 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter auf ungenutztes Territorium hinwagen, argumentieren die Befürworter, dass sie im schlimmsten Fall keinen Schaden anrichten.
2023-09-20 11:55:59 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-20 11:55:59 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung gelangen könnten.
2023-09-20 11:55:59 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-20 11:56:00 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die Vertreter des Rates und der Kommission in dieser Aussprache zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-20 11:56:00 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-20 11:56:00 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in ca. 5-Meilen-Radius des Strip.
2023-09-20 11:56:00 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-20 11:56:01 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Webportal-System basiert.
2023-09-20 11:56:01 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-20 11:56:02 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die Realisierung von Tonhandbüchern akustisch, interaktiv oder schriftlich an.
2023-09-20 11:56:02 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-20 11:56:02 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-20 11:56:02 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-20 11:56:03 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer internen Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu sichern.
2023-09-20 11:56:03 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-20 11:56:03 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Abflug Zugang zu den von ihnen gezahlten Geldern in die europäischen Systeme der sozialen Sicherheit haben.
2023-09-20 11:56:03 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-20 11:56:04 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti Modell als Basis.
2023-09-20 11:56:04 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-20 11:56:04 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf allen Computerplattformen läuft.
2023-09-20 11:56:04 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-20 11:56:05 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor weiß auch, wie man Ihnen bei der Suche nach qualifizierten Fachleuten helfen kann, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche ist.
2023-09-20 11:56:05 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-20 11:56:06 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherite-Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv wesentliche Teile seiner Agenda.
2023-09-20 11:56:06 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-20 11:56:06 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen Splashutils neu emergen, damit es richtig funktioniert.
2023-09-20 11:56:06 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-20 11:56:07 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-20 11:56:07 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-20 11:56:07 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund dafür, dass diese Kriterien sich darauf beschränken sollten, nur innerhalb der Grenzen Europas anzuwenden.
2023-09-20 11:56:07 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-20 11:56:08 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuss für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-20 11:56:08 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-20 11:56:08 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission muss der Rat formelle Standpunkte zu einigen Einzelheiten des Abkommens im Prinzip mit den Vereinigten Staaten abgeben.
2023-09-20 11:56:08 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-20 11:56:09 | INFO | fairseq.tasks.translation | example hypothesis: Trendy oder klassische Farben, zeitloses Design oder besondere Edition - unsere breite Palette an PlastikBabyartikeln ist beeindruckend, nicht zuletzt wegen ihrer herausragenden Oberfläche.
2023-09-20 11:56:09 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-20 11:56:10 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 11:56:10 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 11:56:10 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx über sachliche Situationen zu informieren, die mit diesen AGB nicht unmittelbar vereinbar sind, nachdem er sie zur Kenntnis genommen hat.
2023-09-20 11:56:10 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-20 11:56:11 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die vorangekommen ist und die die Notwendigkeit institutioneller Veränderungen erkannt hat, die ihrer Ansicht nach eine stärkere Präsenz auf dem Gebiet der Außenpolitik und Verteidigung erfordern.
2023-09-20 11:56:11 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-20 11:56:12 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir einen Blog erstellt, der als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-20 11:56:12 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-20 11:56:12 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Behandlung aller Fragen erzielt wurden, die jetzt diskutiert werden, und zwar bezüglich der neuen transatlantischen Agenda, die kaum zwei Jahre alt ist.
2023-09-20 11:56:12 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-20 11:56:13 | INFO | fairseq.tasks.translation | example hypothesis: BILSTEIN B12 BTK: Für eine optimale Fahrdynamik - die ideale Kombination aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-20 11:56:13 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-20 11:56:13 | INFO | fairseq.tasks.translation | example hypothesis: Der Berichterstatter hat einmal mehr in der Lage sein, manchmal unterschiedliche Meinungen und Beiträge zu erarbeiten und sie - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-20 11:56:13 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-20 11:56:14 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm von trockenen elektrostatischen Niederschlägen mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-20 11:56:14 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-20 11:56:15 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seit Jahrhunderten seine Freiheit und Unabhängigkeit verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-20 11:56:15 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-20 11:56:15 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und den Fernen Osten wandern, müssen wir uns auf unsere Innovation und Erfindungskraft verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-20 11:56:15 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-20 11:56:16 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und stützt sich auf Verhandlungen mit Drittländern, von denen viele seit Jahren in Kraft sind und sich auf unseren Commonwealth of Nations beziehen.
2023-09-20 11:56:16 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-20 11:56:16 | INFO | fairseq.tasks.translation | example hypothesis: La final des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-20 11:56:16 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-20 11:56:17 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-20 11:56:17 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-20 11:56:18 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Stoffe nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-20 11:56:18 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-20 11:56:18 | INFO | fairseq.tasks.translation | example hypothesis: Im Rahmen dieser Notsituation gibt es jedoch noch einen anderen: den Notfall der Kinder, den schwächsten Sektor der Bevölkerung, die keine Familie, keinen Schutz und keinen Staat mehr haben.
2023-09-20 11:56:18 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-20 11:56:19 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis der Findung seit 2003 von der EU geregelt wurde, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-20 11:56:19 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-20 11:56:20 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei gesetzt ist, nicht erst realisiert wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, solange man sich selbst nicht selbst kennt.
2023-09-20 11:56:20 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-20 11:56:20 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen einen gewaltfreien Zeitraum zu schaffen und das Verfahren für die Wählerregistrierung wieder zu öffnen.
2023-09-20 11:56:20 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-20 11:56:21 | INFO | fairseq.tasks.translation | example hypothesis: Gesetze, die den Bürgern die Meinungsfreiheit, freie und unabhängige Wahlen und die Vereinigungsfreiheit verleihen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit deutlich gemacht werden, dass niemand über dem Gesetz steht.
2023-09-20 11:56:21 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-20 11:56:22 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java-Programmiersprache mit J2EE-Techniken implementiert, was Plattform und Betriebssystem unabhängig (Anwendung wurde auf Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-20 11:56:22 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-20 11:56:22 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur klareren Koordinierung der sozialen Sicherheit in Europa ab, und wir stimmen daher für eine Klärung des Anhangs.
2023-09-20 11:56:22 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-20 11:56:23 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist auch der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung tragen, die grundlegenden Arbeitsnormen einzuhalten, und fordert die WTO auf, klar zu sagen, dass die von der IAO verhängten Sanktionen nicht mit den WTO-Verträgen unvereinbar sind.
2023-09-20 11:56:23 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-20 11:56:24 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich habe ich an einer Aussprache über das irische öffentlich-rechtliche Radio RTE teilgenommen, bei der eine Frau, die sehr besorgt darüber war, dass wir die Ausgaben für Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-20 11:56:24 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-20 11:56:24 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und ich möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-20 11:56:24 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-20 11:56:25 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihre Lektionen oder konkrete Informationen über die europäische Geschichte, die Staatsbürgerschaft oder etwas ganz Besonderes suchen, wie die Reduzierung des individuellen Energieverbrauchs, sollten Sie etwas Sinnvolles finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-20 11:56:25 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-20 11:56:26 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen.
2023-09-20 11:56:26 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-20 11:56:26 | INFO | fairseq.tasks.translation | example hypothesis: (EN) Herr Präsident! Ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-20 11:56:26 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 11:56:27 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, ist es, das, was eine bestimmte Art von vertraglicher Beziehung zwischen Individuen mit gemeinsamen Bedenken ist, zu naturalisieren und zu mystifizieren (unter ihnen ist oft die tatsächliche oder wahrgenommene Bedrohung, von der institutionellen Vorherrschaft zerschlagen zu werden)!
2023-09-20 11:56:27 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-20 11:56:28 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft zu einem Thema, das sich auf personenbezogene Daten bezieht, sollte der Gerichtshof und der Gerichtshof erster Instanz in der Lage sein, einzugreifen, wenn zum Beispiel die Bürger Forderungen stellen oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-20 11:56:28 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-20 11:56:28 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er Serie ist eines der aufregendsten Fahrzeuge für unter 50.000 $und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-20 11:56:28 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-20 11:56:29 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, und das gilt auch für den Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-20 11:56:29 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-20 11:56:30 | INFO | fairseq.tasks.translation | example hypothesis: Man muss versuchen, Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt (Stew) und den ausgezeichneten frischen Fisch: gegrillte Schweinefleisch, Forelle mit Mandelfisch.
2023-09-20 11:56:30 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-20 11:56:31 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, nicht daran zu erinnern, was ein politisches Handeln bedeutet, sondern es wäre besser, eine Gesamtansicht zu geben, die es uns ermöglicht, die verschiedenen Fragen stärker zu behandeln und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft haben kann.
2023-09-20 11:56:31 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-20 11:56:31 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber der "Scardona Records", Herr Branko Paić, haben sich darauf geeinigt, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-20 11:56:31 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-20 11:56:32 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen echten Wohlstand, wenn es Arbeitslosigkeit gibt, wo die drohende Bedrohung bestehender Arbeitsplätze und Wettbewerbsfähigkeit allmählich durch makroökonomische Politik, fiskalische Maßnahmen und Zwänge untergraben wird, die sich nicht an die bestehende Situation vor Ort anpassen.
2023-09-20 11:56:32 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-20 11:56:33 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe Richtung wie die bestehende Verordnung aus dem Jahr 1994, die das Europäische Parlament durch ein ausgezeichnetes Beispiel für die Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text aufgenommen hat, zu dieser Verordnung beigetragen hat.
2023-09-20 11:56:33 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-20 11:56:34 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert daher den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den juristischen und justiziellen Bereich, wodurch Norwegen und Island-Länder, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsvorschriften gelten, zur Anwendung kommen.
2023-09-20 11:56:34 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-20 11:56:34 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Make-Shift-Boot den Mississippi hinunter fahren, nach dem großen versteckten Schatz suchen, uns mit dem schönen Becky Thatcher, der reine Dynamik ist, vertraut machen, und vor allem werden wir große Freunde sein.
2023-09-20 11:56:34 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-20 11:56:35 | INFO | fairseq.tasks.translation | example hypothesis: In der Praxis harmonisiert die Richtlinie die Definition der von Einzelpersonen oder juristischen Personen verursachten Meeresverschmutzung, den Umfang der Reaktion und die Strafbarkeit der Sanktionen, die bei solchen von Einzelpersonen begangenen Verstößen angewendet werden können.
2023-09-20 11:56:35 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-20 11:56:36 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat verurteilt, einfach weil sie ihre Arbeit als Journalisten und Kameränner geleistet haben, indem sie eine Gruppe von Bergbewohnern erschossen haben, die seit Jahren von einem autoritären Regime angeklagt wurden, das jeden Grundsatz der Demokratie missachtet.
2023-09-20 11:56:36 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-20 11:56:37 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseurgeschäft und Schönheitssalon, Transport und Sightseeing-Rezeption, Wechselstube, kostenloser Schuh- und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-20 11:56:37 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-20 11:56:37 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen dem Thermalfeder verdankt, der von Königin D. Leonor, Frau von König D. João II, sehr geschätzt wurde, und die von ihren Keramiken, die international bekannt sind für ihre bildhaften und satirischen Werke, auch sehenswert ist.
2023-09-20 11:56:37 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-20 11:56:38 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Menschen, die behaupten, dass es sich um gute Verfechter der westlichen Seite und Anhänger des früheren Regimes auf der einen Seite handelt - das ist auch verwerflich, da die Rollen aller, jetzt und früher bekannt sind.
2023-09-20 11:56:38 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-20 11:56:39 | INFO | fairseq.tasks.translation | example hypothesis: Ich muss sagen, dass ich nicht umhin, darauf hinzuweisen, dass in dieser Regelung etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer reisen, auf diese Weise nicht abgedeckt sind, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-20 11:56:39 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-20 11:56:40 | INFO | fairseq.tasks.translation | example hypothesis: (4) Werden Informationen aus Gründen seines Status als Aktionär außerhalb einer Aktionärsversammlung an einen Aktionär übermittelt, so werden diese Informationen auf Verlangen jedem anderen Aktionär auf der Hauptversammlung zur Verfügung gestellt, auch wenn solche Informationen nicht notwendig sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-20 11:56:40 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-20 11:56:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme fließen, die in der Regel in die Taschen verschiedener Diktatoren fließen und ihren schönen Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr miserables Leben führen.
2023-09-20 11:56:41 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-20 11:56:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder die NATO an diesem Kriegsakt beteiligt gewesen wären -, Informationen zu unterstützen, die keinen Grund mehr haben, geheim zu bleiben, zu verschweigen oder geheim zu bleiben, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit erzählt werden kann.
2023-09-20 11:56:41 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-20 11:56:42 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im Stadtteil Reinickendorf im Nordwesten Berlins liegt nur 5 Gehminuten vom Bahnhof Waidmannslust S-Bahn und einer 30-minütigen Zugfahrt von der Innenstadt entfernt. Die komfortablen Zimmer des Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 11:56:42 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 11:56:43 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radarsystem unter der Leitung von Thales in Frankreich, zusammen mit unserer Geschäftseinheit Defence Electronics und Indra in Spanien wird die Advanced UAV modernste, modulare Sensorsuite und Datenverknüpfungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen von entscheidender Bedeutung sind, die die modernen Offshallen-Plattformen niemals erreichen können.
2023-09-20 11:56:43 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-20 11:56:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte, die ein ernstes Risiko darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-20 11:56:44 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-20 11:56:45 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem bloßen Pseudonym der Moderne und Postmoderne oder der klaren Opposition reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung dieser beiden ästhetischen Politik anerkennen, die in den Formen der Sichtbarkeit und Verständlichkeit steckt, die Kunst als solche kennzeichnen - jene beiden politischen, die letztlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-20 11:56:45 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-20 11:56:46 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werden wir angesichts der Bedeutung der Aussprachen und angesichts der von Ihnen gegebenen Ansichten, die meine Ausführungen eindeutig unterstützen, und aufgrund der vorhergehenden Beschlüsse unsere Aussprachen führen, und wenn es um die Abstimmung geht, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht darum bitten, die Beschlußfähigkeit zu überprüfen.
2023-09-20 11:56:46 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-20 11:56:47 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker niemals die Einschränkung des Nationalstaatsprinzips akzeptiert haben, sind es paradoxerweise gerade sie, die kaum jemand weiß, nicht nur Zeugen eines alten, vergessenen Europa sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem die nationalen Grenzen aufgehoben wurden, ohne jedoch eine einheitliche Kultur zu schaffen, sondern die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.
2023-09-20 11:56:47 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-20 11:56:48 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Weise als hybride Form publiziert, die Rezensionen und Artikel der vierteljährlichen Zeitschrift werden für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Websites der Berlin-basierten H-Soz-u-Kult und des Michigan-basierten H-Netzes an ihre Abonnenten verteilt.
2023-09-20 11:56:48 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-20 11:56:49 | INFO | fairseq.tasks.translation | example hypothesis: Es ist nicht nur mit der Ankunft der neuen Smartphone-Generation, dass Mobiltelefone ihre Federn nicht nur stark verfärbt haben, sondern auch von einst düsteren Taschenlampen über polyphonisch tootternde Game Boy-Bestrebungen bis hin zu heruntergefahrenen Mini-PCs mit knappen CD-Qualität Stereo-Sound: Henceaus könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den früheren mir-zu-zu-zu-Trailblazer neuer technologischer Entwicklungen lernen.
2023-09-20 11:56:49 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-20 11:56:50 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien diehen la defensa de la base humana en Pandora, kloence a Jake para que le proportionación sobre los nativos en caso de que fuera requiario resprir a la fuerza para que se marchen.
2023-09-20 11:56:50 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-20 11:56:51 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 4.396 | nll_loss 2.381 | ppl 5.21 | bleu 27.31 | wps 17977.4 | wpb 12011.9 | bsz 398.1 | num_updates 27172 | best_bleu 27.31
2023-09-20 11:56:51 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 27172 updates
2023-09-20 11:56:51 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint3.pt
2023-09-20 11:56:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint3.pt
2023-09-20 11:57:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint3.pt (epoch 3 @ 27172 updates, score 27.31) (writing took 15.833397581998724 seconds)
2023-09-20 11:57:07 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2023-09-20 11:57:07 | INFO | train | epoch 003 | loss 4.512 | nll_loss 2.599 | ppl 6.06 | wps 76204 | ups 5.87 | wpb 12977.3 | bsz 430.6 | num_updates 27172 | lr 0.00019184 | gnorm 0.599 | loss_scale 8 | train_wall 1442 | gb_free 15.4 | wall 4621
2023-09-20 11:57:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 11:57:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-20 11:57:07 | INFO | fairseq.trainer | begin training epoch 4
2023-09-20 11:57:07 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-20 11:57:12 | INFO | train_inner | epoch 004:     28 / 9060 loss=4.421, nll_loss=2.509, ppl=5.69, wps=13246.2, ups=1.02, wpb=12996.8, bsz=415.2, num_updates=27200, lr=0.000191741, gnorm=0.58, loss_scale=8, train_wall=16, gb_free=15.4, wall=4625
lprobs.size(): torch.Size([3536, 42808])
2023-09-20 11:57:28 | INFO | train_inner | epoch 004:    128 / 9060 loss=4.373, nll_loss=2.46, ppl=5.5, wps=80153.5, ups=6.19, wpb=12945.6, bsz=436.3, num_updates=27300, lr=0.00019139, gnorm=0.572, loss_scale=8, train_wall=16, gb_free=15.1, wall=4641
2023-09-20 11:57:44 | INFO | train_inner | epoch 004:    228 / 9060 loss=4.396, nll_loss=2.482, ppl=5.59, wps=81422.4, ups=6.25, wpb=13024.8, bsz=433.6, num_updates=27400, lr=0.00019104, gnorm=0.573, loss_scale=8, train_wall=16, gb_free=15.8, wall=4657
2023-09-20 11:58:00 | INFO | train_inner | epoch 004:    328 / 9060 loss=4.415, nll_loss=2.502, ppl=5.67, wps=81021.6, ups=6.23, wpb=13009, bsz=415.7, num_updates=27500, lr=0.000190693, gnorm=0.572, loss_scale=8, train_wall=16, gb_free=15.1, wall=4673
lprobs.size(): torch.Size([3328, 42808])
2023-09-20 11:58:16 | INFO | train_inner | epoch 004:    428 / 9060 loss=4.405, nll_loss=2.492, ppl=5.62, wps=79266.3, ups=6.12, wpb=12954.5, bsz=423.8, num_updates=27600, lr=0.000190347, gnorm=0.576, loss_scale=8, train_wall=16, gb_free=15.3, wall=4690
2023-09-20 11:58:33 | INFO | train_inner | epoch 004:    528 / 9060 loss=4.447, nll_loss=2.535, ppl=5.8, wps=78968.5, ups=6.13, wpb=12890.2, bsz=431.6, num_updates=27700, lr=0.000190003, gnorm=0.585, loss_scale=8, train_wall=16, gb_free=15, wall=4706
2023-09-20 11:58:49 | INFO | train_inner | epoch 004:    628 / 9060 loss=4.428, nll_loss=2.516, ppl=5.72, wps=79099.4, ups=6.12, wpb=12928.8, bsz=441.7, num_updates=27800, lr=0.000189661, gnorm=0.584, loss_scale=8, train_wall=16, gb_free=15.2, wall=4722
lprobs.size(): torch.Size([2720, 42808])
2023-09-20 11:59:05 | INFO | train_inner | epoch 004:    728 / 9060 loss=4.409, nll_loss=2.495, ppl=5.64, wps=79086.3, ups=6.13, wpb=12911.8, bsz=397.4, num_updates=27900, lr=0.000189321, gnorm=0.598, loss_scale=8, train_wall=16, gb_free=15.2, wall=4739
2023-09-20 11:59:22 | INFO | train_inner | epoch 004:    828 / 9060 loss=4.405, nll_loss=2.492, ppl=5.63, wps=79676.9, ups=6.12, wpb=13026, bsz=423.1, num_updates=28000, lr=0.000188982, gnorm=0.573, loss_scale=8, train_wall=16, gb_free=15.1, wall=4755
lprobs.size(): torch.Size([3360, 42808])
2023-09-20 11:59:38 | INFO | train_inner | epoch 004:    928 / 9060 loss=4.375, nll_loss=2.461, ppl=5.51, wps=79453.1, ups=6.11, wpb=13004.1, bsz=428.8, num_updates=28100, lr=0.000188646, gnorm=0.576, loss_scale=8, train_wall=16, gb_free=15.3, wall=4771
2023-09-20 11:59:54 | INFO | train_inner | epoch 004:   1028 / 9060 loss=4.396, nll_loss=2.484, ppl=5.59, wps=78807.9, ups=6.12, wpb=12876.6, bsz=442.9, num_updates=28200, lr=0.000188311, gnorm=0.58, loss_scale=8, train_wall=16, gb_free=15, wall=4788
2023-09-20 12:00:11 | INFO | train_inner | epoch 004:   1128 / 9060 loss=4.41, nll_loss=2.497, ppl=5.65, wps=78702.9, ups=6.11, wpb=12877.8, bsz=420.3, num_updates=28300, lr=0.000187978, gnorm=0.584, loss_scale=8, train_wall=16, gb_free=16.9, wall=4804
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2816, 42808])
2023-09-20 12:00:27 | INFO | train_inner | epoch 004:   1228 / 9060 loss=4.426, nll_loss=2.514, ppl=5.71, wps=79381.6, ups=6.12, wpb=12979.8, bsz=436.9, num_updates=28400, lr=0.000187647, gnorm=0.586, loss_scale=8, train_wall=16, gb_free=16, wall=4821
lprobs.size(): torch.Size([3440, 42808])
2023-09-20 12:00:43 | INFO | train_inner | epoch 004:   1328 / 9060 loss=4.38, nll_loss=2.467, ppl=5.53, wps=80048.5, ups=6.11, wpb=13110.7, bsz=432.7, num_updates=28500, lr=0.000187317, gnorm=0.586, loss_scale=8, train_wall=16, gb_free=15.6, wall=4837
2023-09-20 12:01:00 | INFO | train_inner | epoch 004:   1428 / 9060 loss=4.425, nll_loss=2.513, ppl=5.71, wps=79475, ups=6.11, wpb=13013.9, bsz=422.9, num_updates=28600, lr=0.000186989, gnorm=0.594, loss_scale=8, train_wall=16, gb_free=15.9, wall=4853
2023-09-20 12:01:16 | INFO | train_inner | epoch 004:   1528 / 9060 loss=4.364, nll_loss=2.451, ppl=5.47, wps=78971.4, ups=6.11, wpb=12927.3, bsz=461.1, num_updates=28700, lr=0.000186663, gnorm=0.586, loss_scale=8, train_wall=16, gb_free=15.9, wall=4870
lprobs.size(): torch.Size([3104, 42808])
2023-09-20 12:01:33 | INFO | train_inner | epoch 004:   1628 / 9060 loss=4.404, nll_loss=2.492, ppl=5.62, wps=79173.7, ups=6.12, wpb=12942.8, bsz=415.2, num_updates=28800, lr=0.000186339, gnorm=0.587, loss_scale=8, train_wall=16, gb_free=15.2, wall=4886
2023-09-20 12:01:49 | INFO | train_inner | epoch 004:   1728 / 9060 loss=4.422, nll_loss=2.509, ppl=5.69, wps=79453.5, ups=6.1, wpb=13022.5, bsz=421.2, num_updates=28900, lr=0.000186016, gnorm=0.584, loss_scale=8, train_wall=16, gb_free=15.3, wall=4902
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 12:02:05 | INFO | train_inner | epoch 004:   1828 / 9060 loss=4.469, nll_loss=2.558, ppl=5.89, wps=79225.6, ups=6.11, wpb=12966.7, bsz=412, num_updates=29000, lr=0.000185695, gnorm=0.595, loss_scale=8, train_wall=16, gb_free=15.5, wall=4919
lprobs.size(): torch.Size([3536, 42808])
2023-09-20 12:02:22 | INFO | train_inner | epoch 004:   1928 / 9060 loss=4.439, nll_loss=2.527, ppl=5.77, wps=79083.2, ups=6.11, wpb=12934.6, bsz=423, num_updates=29100, lr=0.000185376, gnorm=0.594, loss_scale=8, train_wall=16, gb_free=15.1, wall=4935
2023-09-20 12:02:38 | INFO | train_inner | epoch 004:   2028 / 9060 loss=4.451, nll_loss=2.539, ppl=5.81, wps=79012.5, ups=6.11, wpb=12928.1, bsz=401.4, num_updates=29200, lr=0.000185058, gnorm=0.602, loss_scale=8, train_wall=16, gb_free=15, wall=4951
2023-09-20 12:02:54 | INFO | train_inner | epoch 004:   2128 / 9060 loss=4.366, nll_loss=2.453, ppl=5.48, wps=79373.4, ups=6.13, wpb=12957.9, bsz=442.1, num_updates=29300, lr=0.000184742, gnorm=0.58, loss_scale=16, train_wall=16, gb_free=15.1, wall=4968
2023-09-20 12:03:11 | INFO | train_inner | epoch 004:   2228 / 9060 loss=4.414, nll_loss=2.502, ppl=5.67, wps=80139.7, ups=6.11, wpb=13116.3, bsz=427.7, num_updates=29400, lr=0.000184428, gnorm=0.578, loss_scale=16, train_wall=16, gb_free=15.1, wall=4984
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 12:03:27 | INFO | train_inner | epoch 004:   2328 / 9060 loss=4.42, nll_loss=2.508, ppl=5.69, wps=79033.7, ups=6.12, wpb=12909.6, bsz=437.4, num_updates=29500, lr=0.000184115, gnorm=0.59, loss_scale=16, train_wall=16, gb_free=15.6, wall=5001
2023-09-20 12:03:43 | INFO | train_inner | epoch 004:   2428 / 9060 loss=4.409, nll_loss=2.497, ppl=5.65, wps=79152.5, ups=6.11, wpb=12959.8, bsz=434.6, num_updates=29600, lr=0.000183804, gnorm=0.562, loss_scale=16, train_wall=16, gb_free=15.2, wall=5017
lprobs.size(): torch.Size([3168, 42808])
2023-09-20 12:04:00 | INFO | train_inner | epoch 004:   2528 / 9060 loss=4.364, nll_loss=2.451, ppl=5.47, wps=80050.4, ups=6.18, wpb=12951.4, bsz=428.7, num_updates=29700, lr=0.000183494, gnorm=0.581, loss_scale=16, train_wall=16, gb_free=15.7, wall=5033
lprobs.size(): torch.Size([3400, 42808])
2023-09-20 12:04:16 | INFO | train_inner | epoch 004:   2628 / 9060 loss=4.37, nll_loss=2.458, ppl=5.49, wps=81077.3, ups=6.25, wpb=12964.3, bsz=462.8, num_updates=29800, lr=0.000183186, gnorm=0.568, loss_scale=16, train_wall=16, gb_free=15.3, wall=5049
2023-09-20 12:04:32 | INFO | train_inner | epoch 004:   2728 / 9060 loss=4.396, nll_loss=2.484, ppl=5.6, wps=81215.6, ups=6.25, wpb=13004.3, bsz=454.6, num_updates=29900, lr=0.000182879, gnorm=0.579, loss_scale=16, train_wall=16, gb_free=15.4, wall=5065
2023-09-20 12:04:48 | INFO | train_inner | epoch 004:   2828 / 9060 loss=4.405, nll_loss=2.493, ppl=5.63, wps=81352.7, ups=6.25, wpb=13008.8, bsz=412.6, num_updates=30000, lr=0.000182574, gnorm=0.567, loss_scale=16, train_wall=16, gb_free=15.1, wall=5081
pred_new.size(): torch.Size([2730, 42808])
lprobs.size(): torch.Size([2880, 42808])
2023-09-20 12:07:34 | INFO | train_inner | epoch 004:   2928 / 9060 loss=5.9, nll_loss=3.127, ppl=8.73, wps=7800.1, ups=0.6, wpb=12943.7, bsz=410.4, num_updates=30100, lr=0.000182271, gnorm=0.794, loss_scale=16, train_wall=166, gb_free=14.4, wall=5247
pred_new.size(): torch.Size([1120, 42808])
lprobs.size(): torch.Size([3248, 42808])
2023-09-20 12:10:13 | INFO | train_inner | epoch 004:   3028 / 9060 loss=5.964, nll_loss=3.194, ppl=9.15, wps=8076.2, ups=0.63, wpb=12857.4, bsz=425.8, num_updates=30200, lr=0.000181969, gnorm=0.796, loss_scale=16, train_wall=159, gb_free=14.5, wall=5406
pred_new.size(): torch.Size([1350, 42808])
lprobs.size(): torch.Size([2912, 42808])
2023-09-20 12:12:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-20 12:13:06 | INFO | train_inner | epoch 004:   3129 / 9060 loss=5.95, nll_loss=3.156, ppl=8.91, wps=7463.5, ups=0.58, wpb=12909.7, bsz=436.8, num_updates=30300, lr=0.000181668, gnorm=0.831, loss_scale=8, train_wall=173, gb_free=15, wall=5579
pred_new.size(): torch.Size([420, 42808])
2023-09-20 12:15:50 | INFO | train_inner | epoch 004:   3229 / 9060 loss=5.886, nll_loss=3.157, ppl=8.92, wps=7875, ups=0.61, wpb=12960.9, bsz=426.5, num_updates=30400, lr=0.000181369, gnorm=0.778, loss_scale=8, train_wall=164, gb_free=15.1, wall=5744
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2400, 42808])
2023-09-20 12:18:33 | INFO | train_inner | epoch 004:   3329 / 9060 loss=5.898, nll_loss=3.157, ppl=8.92, wps=7944.4, ups=0.61, wpb=12948.9, bsz=430.6, num_updates=30500, lr=0.000181071, gnorm=0.762, loss_scale=8, train_wall=163, gb_free=14.6, wall=5907
2023-09-20 12:21:13 | INFO | train_inner | epoch 004:   3429 / 9060 loss=5.904, nll_loss=3.109, ppl=8.63, wps=8148.5, ups=0.62, wpb=13052.4, bsz=441.8, num_updates=30600, lr=0.000180775, gnorm=0.747, loss_scale=8, train_wall=160, gb_free=14.8, wall=6067
lprobs.size(): torch.Size([2816, 42808])
2023-09-20 12:24:05 | INFO | train_inner | epoch 004:   3529 / 9060 loss=5.935, nll_loss=3.14, ppl=8.81, wps=7560.8, ups=0.58, wpb=12931.2, bsz=413.3, num_updates=30700, lr=0.000180481, gnorm=0.846, loss_scale=8, train_wall=171, gb_free=14.9, wall=6238
2023-09-20 12:26:44 | INFO | train_inner | epoch 004:   3629 / 9060 loss=5.874, nll_loss=3.128, ppl=8.74, wps=8256.7, ups=0.63, wpb=13127.7, bsz=436.2, num_updates=30800, lr=0.000180187, gnorm=0.752, loss_scale=8, train_wall=159, gb_free=14.4, wall=6397
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3400, 42808])
2023-09-20 12:29:33 | INFO | train_inner | epoch 004:   3729 / 9060 loss=5.927, nll_loss=3.125, ppl=8.72, wps=7632.7, ups=0.59, wpb=12926.3, bsz=449.1, num_updates=30900, lr=0.000179896, gnorm=0.776, loss_scale=8, train_wall=169, gb_free=13.9, wall=6566
pred_new.size(): torch.Size([1482, 42808])
lprobs.size(): torch.Size([2720, 42808])
2023-09-20 12:32:15 | INFO | train_inner | epoch 004:   3829 / 9060 loss=5.929, nll_loss=3.153, ppl=8.89, wps=7993.7, ups=0.62, wpb=12939.4, bsz=425, num_updates=31000, lr=0.000179605, gnorm=0.768, loss_scale=8, train_wall=162, gb_free=15.5, wall=6728
lprobs.size(): torch.Size([3200, 42808])
2023-09-20 12:35:04 | INFO | train_inner | epoch 004:   3929 / 9060 loss=5.892, nll_loss=3.146, ppl=8.85, wps=7710.3, ups=0.59, wpb=13023.8, bsz=423, num_updates=31100, lr=0.000179316, gnorm=0.779, loss_scale=8, train_wall=169, gb_free=15, wall=6897
lprobs.size(): torch.Size([2816, 42808])
ter_threshold: 0.331152
num_accepted / total 13 72
loss token level: tensor(9105.8584, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4936., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 12:37:42 | INFO | train_inner | epoch 004:   4029 / 9060 loss=5.942, nll_loss=3.134, ppl=8.78, wps=8243.8, ups=0.63, wpb=13037.3, bsz=439, num_updates=31200, lr=0.000179029, gnorm=0.77, loss_scale=8, train_wall=158, gb_free=15, wall=7055
pred_new.size(): torch.Size([176, 42808])
2023-09-20 12:40:20 | INFO | train_inner | epoch 004:   4129 / 9060 loss=5.872, nll_loss=3.117, ppl=8.67, wps=8223, ups=0.63, wpb=13027.3, bsz=422.3, num_updates=31300, lr=0.000178743, gnorm=0.77, loss_scale=8, train_wall=158, gb_free=15.3, wall=7214
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3496, 42808])
2023-09-20 12:43:03 | INFO | train_inner | epoch 004:   4229 / 9060 loss=5.888, nll_loss=3.133, ppl=8.77, wps=7944.9, ups=0.61, wpb=12942.3, bsz=422.4, num_updates=31400, lr=0.000178458, gnorm=0.766, loss_scale=8, train_wall=163, gb_free=15, wall=7377
pred_new.size(): torch.Size([3060, 42808])
pred_new.size(): torch.Size([2664, 42808])
pred_new.size(): torch.Size([594, 42808])
2023-09-20 12:45:46 | INFO | train_inner | epoch 004:   4329 / 9060 loss=5.944, nll_loss=3.139, ppl=8.81, wps=7988.5, ups=0.61, wpb=13007.4, bsz=446.9, num_updates=31500, lr=0.000178174, gnorm=0.747, loss_scale=8, train_wall=163, gb_free=14.1, wall=7539
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.331582
num_accepted / total 13 64
loss token level: tensor(9404.8545, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5416., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 12:48:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-20 12:48:27 | INFO | train_inner | epoch 004:   4430 / 9060 loss=5.864, nll_loss=3.116, ppl=8.67, wps=8031.8, ups=0.62, wpb=12943.1, bsz=434.2, num_updates=31600, lr=0.000177892, gnorm=0.754, loss_scale=4, train_wall=161, gb_free=14.2, wall=7701
pred_new.size(): torch.Size([2136, 42808])
ter_threshold: 0.331697
num_accepted / total 47 168
loss token level: tensor(9832.3965, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3760., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 12:51:17 | INFO | train_inner | epoch 004:   4530 / 9060 loss=5.94, nll_loss=3.134, ppl=8.78, wps=7689.9, ups=0.59, wpb=13083.7, bsz=431.2, num_updates=31700, lr=0.000177611, gnorm=0.804, loss_scale=4, train_wall=170, gb_free=14.5, wall=7871
pred_new.size(): torch.Size([336, 42808])
2023-09-20 12:53:53 | INFO | train_inner | epoch 004:   4630 / 9060 loss=5.873, nll_loss=3.112, ppl=8.65, wps=8376.6, ups=0.64, wpb=13030.7, bsz=421.3, num_updates=31800, lr=0.000177332, gnorm=0.729, loss_scale=4, train_wall=155, gb_free=14.7, wall=8026
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 12:56:30 | INFO | train_inner | epoch 004:   4730 / 9060 loss=5.904, nll_loss=3.102, ppl=8.59, wps=8352.1, ups=0.64, wpb=13100.7, bsz=459.5, num_updates=31900, lr=0.000177054, gnorm=0.758, loss_scale=4, train_wall=157, gb_free=15, wall=8183
2023-09-20 12:59:17 | INFO | train_inner | epoch 004:   4830 / 9060 loss=5.884, nll_loss=3.115, ppl=8.66, wps=7782, ups=0.6, wpb=13011.5, bsz=429.8, num_updates=32000, lr=0.000176777, gnorm=0.769, loss_scale=4, train_wall=167, gb_free=14.3, wall=8350
2023-09-20 13:01:59 | INFO | train_inner | epoch 004:   4930 / 9060 loss=5.898, nll_loss=3.109, ppl=8.63, wps=8033, ups=0.62, wpb=13027.3, bsz=428.1, num_updates=32100, lr=0.000176501, gnorm=0.79, loss_scale=4, train_wall=162, gb_free=14.7, wall=8512
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3552, 42808])
2023-09-20 13:04:37 | INFO | train_inner | epoch 004:   5030 / 9060 loss=5.967, nll_loss=3.156, ppl=8.92, wps=8219.6, ups=0.63, wpb=12973.3, bsz=449.4, num_updates=32200, lr=0.000176227, gnorm=0.763, loss_scale=4, train_wall=158, gb_free=14.8, wall=8670
ter_threshold: 0.33227
num_accepted / total 5 72
loss token level: tensor(8771.9668, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(696., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 13:07:31 | INFO | train_inner | epoch 004:   5130 / 9060 loss=5.923, nll_loss=3.143, ppl=8.84, wps=7433.6, ups=0.57, wpb=12933.8, bsz=435.6, num_updates=32300, lr=0.000175954, gnorm=0.847, loss_scale=4, train_wall=174, gb_free=15, wall=8844
2023-09-20 13:10:25 | INFO | train_inner | epoch 004:   5230 / 9060 loss=5.96, nll_loss=3.135, ppl=8.78, wps=7436.6, ups=0.57, wpb=12986, bsz=436.1, num_updates=32400, lr=0.000175682, gnorm=0.814, loss_scale=4, train_wall=174, gb_free=15.1, wall=9019
pred_new.size(): torch.Size([1512, 42808])
2023-09-20 13:13:21 | INFO | train_inner | epoch 004:   5330 / 9060 loss=5.846, nll_loss=3.104, ppl=8.6, wps=7373.3, ups=0.57, wpb=12926.5, bsz=420.2, num_updates=32500, lr=0.000175412, gnorm=0.75, loss_scale=4, train_wall=175, gb_free=14.5, wall=9194
2023-09-20 13:16:12 | INFO | train_inner | epoch 004:   5430 / 9060 loss=5.961, nll_loss=3.151, ppl=8.88, wps=7519.6, ups=0.58, wpb=12872.6, bsz=411.5, num_updates=32600, lr=0.000175142, gnorm=0.75, loss_scale=4, train_wall=171, gb_free=15.5, wall=9365
ter_threshold: 0.332605
num_accepted / total 7 48
loss token level: tensor(9203.1943, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2370., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 13:18:52 | INFO | train_inner | epoch 004:   5530 / 9060 loss=5.92, nll_loss=3.137, ppl=8.8, wps=8079.8, ups=0.62, wpb=12950.4, bsz=418.7, num_updates=32700, lr=0.000174874, gnorm=0.774, loss_scale=4, train_wall=160, gb_free=14.5, wall=9526
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 13:21:42 | INFO | train_inner | epoch 004:   5630 / 9060 loss=5.981, nll_loss=3.16, ppl=8.94, wps=7621.8, ups=0.59, wpb=12900, bsz=440, num_updates=32800, lr=0.000174608, gnorm=0.779, loss_scale=4, train_wall=169, gb_free=14.7, wall=9695
2023-09-20 13:24:22 | INFO | train_inner | epoch 004:   5730 / 9060 loss=5.929, nll_loss=3.15, ppl=8.88, wps=8094.4, ups=0.62, wpb=13017.3, bsz=446.5, num_updates=32900, lr=0.000174342, gnorm=0.755, loss_scale=4, train_wall=161, gb_free=15.5, wall=9856
lprobs.size(): torch.Size([3416, 42808])
2023-09-20 13:27:01 | INFO | train_inner | epoch 004:   5830 / 9060 loss=5.92, nll_loss=3.1, ppl=8.57, wps=8231.3, ups=0.63, wpb=13061.6, bsz=440.9, num_updates=33000, lr=0.000174078, gnorm=0.747, loss_scale=4, train_wall=158, gb_free=14.7, wall=10014
2023-09-20 13:29:37 | INFO | train_inner | epoch 004:   5930 / 9060 loss=5.877, nll_loss=3.116, ppl=8.67, wps=8304.6, ups=0.64, wpb=12960.5, bsz=424.6, num_updates=33100, lr=0.000173814, gnorm=0.741, loss_scale=4, train_wall=156, gb_free=15.7, wall=10171
pred_new.size(): torch.Size([3395, 42808])
ter_threshold: 0.333175
num_accepted / total 7 48
loss token level: tensor(8984.1719, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2102., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([840, 42808])
2023-09-20 13:32:25 | INFO | train_inner | epoch 004:   6030 / 9060 loss=5.932, nll_loss=3.149, ppl=8.87, wps=7723, ups=0.59, wpb=13006, bsz=435, num_updates=33200, lr=0.000173553, gnorm=0.813, loss_scale=4, train_wall=168, gb_free=15, wall=10339
pred_new.size(): torch.Size([1230, 42808])
ter_threshold: 0.333288
num_accepted / total 153 272
loss token level: tensor(8863.1855, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7008., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 13:35:16 | INFO | train_inner | epoch 004:   6130 / 9060 loss=5.901, nll_loss=3.119, ppl=8.69, wps=7634.3, ups=0.59, wpb=13004.3, bsz=438.9, num_updates=33300, lr=0.000173292, gnorm=0.837, loss_scale=4, train_wall=170, gb_free=14.8, wall=10509
pred_new.size(): torch.Size([104, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 13:37:57 | INFO | train_inner | epoch 004:   6230 / 9060 loss=5.959, nll_loss=3.152, ppl=8.89, wps=8058.3, ups=0.62, wpb=13007.3, bsz=431, num_updates=33400, lr=0.000173032, gnorm=0.75, loss_scale=4, train_wall=161, gb_free=15, wall=10671
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 13:40:46 | INFO | train_inner | epoch 004:   6330 / 9060 loss=6.016, nll_loss=3.186, ppl=9.1, wps=7652.1, ups=0.59, wpb=12920, bsz=434.5, num_updates=33500, lr=0.000172774, gnorm=0.819, loss_scale=4, train_wall=169, gb_free=15.4, wall=10840
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3120, 42808])
2023-09-20 13:43:29 | INFO | train_inner | epoch 004:   6430 / 9060 loss=6.048, nll_loss=3.173, ppl=9.02, wps=7976.4, ups=0.61, wpb=13026.7, bsz=424.1, num_updates=33600, lr=0.000172516, gnorm=0.81, loss_scale=4, train_wall=163, gb_free=14.5, wall=11003
lprobs.size(): torch.Size([2464, 42808])
2023-09-20 13:46:19 | INFO | train_inner | epoch 004:   6530 / 9060 loss=6.035, nll_loss=3.175, ppl=9.03, wps=7715.6, ups=0.59, wpb=13090.4, bsz=456.7, num_updates=33700, lr=0.00017226, gnorm=0.828, loss_scale=4, train_wall=169, gb_free=14.5, wall=11173
pred_new.size(): torch.Size([4183, 42808])
2023-09-20 13:49:10 | INFO | train_inner | epoch 004:   6630 / 9060 loss=5.993, nll_loss=3.17, ppl=9, wps=7508.1, ups=0.58, wpb=12845.8, bsz=410.9, num_updates=33800, lr=0.000172005, gnorm=0.772, loss_scale=4, train_wall=171, gb_free=15.5, wall=11344
2023-09-20 13:51:59 | INFO | train_inner | epoch 004:   6730 / 9060 loss=5.939, nll_loss=3.114, ppl=8.66, wps=7748.4, ups=0.59, wpb=13084.3, bsz=445, num_updates=33900, lr=0.000171751, gnorm=0.75, loss_scale=4, train_wall=169, gb_free=14.9, wall=11512
2023-09-20 13:54:49 | INFO | train_inner | epoch 004:   6830 / 9060 loss=6.056, nll_loss=3.217, ppl=9.3, wps=7646.1, ups=0.59, wpb=13011.6, bsz=433.9, num_updates=34000, lr=0.000171499, gnorm=0.785, loss_scale=4, train_wall=170, gb_free=14.8, wall=11683
2023-09-20 13:57:40 | INFO | train_inner | epoch 004:   6930 / 9060 loss=5.884, nll_loss=3.113, ppl=8.65, wps=7626.1, ups=0.58, wpb=13045.7, bsz=406.6, num_updates=34100, lr=0.000171247, gnorm=0.745, loss_scale=4, train_wall=171, gb_free=14.4, wall=11854
pred_new.size(): torch.Size([2613, 42808])
2023-09-20 14:00:27 | INFO | train_inner | epoch 004:   7030 / 9060 loss=6.075, nll_loss=3.199, ppl=9.18, wps=7719.7, ups=0.6, wpb=12901.2, bsz=428.2, num_updates=34200, lr=0.000170996, gnorm=0.817, loss_scale=4, train_wall=167, gb_free=16.1, wall=12021
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.33426
num_accepted / total 9 64
loss token level: tensor(9016.5332, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2033., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 14:03:11 | INFO | train_inner | epoch 004:   7130 / 9060 loss=5.981, nll_loss=3.207, ppl=9.23, wps=7869.6, ups=0.61, wpb=12912.5, bsz=419, num_updates=34300, lr=0.000170747, gnorm=0.769, loss_scale=4, train_wall=164, gb_free=14, wall=12185
pred_new.size(): torch.Size([704, 42808])
2023-09-20 14:06:04 | INFO | train_inner | epoch 004:   7230 / 9060 loss=5.993, nll_loss=3.167, ppl=8.98, wps=7499.7, ups=0.58, wpb=12939, bsz=416.6, num_updates=34400, lr=0.000170499, gnorm=0.807, loss_scale=4, train_wall=172, gb_free=15.1, wall=12357
lprobs.size(): torch.Size([3280, 42808])
2023-09-20 14:08:48 | INFO | train_inner | epoch 004:   7330 / 9060 loss=5.974, nll_loss=3.186, ppl=9.1, wps=7830.3, ups=0.61, wpb=12879.7, bsz=430.4, num_updates=34500, lr=0.000170251, gnorm=0.753, loss_scale=4, train_wall=164, gb_free=15.7, wall=12522
2023-09-20 14:11:31 | INFO | train_inner | epoch 004:   7430 / 9060 loss=5.899, nll_loss=3.125, ppl=8.72, wps=7920.8, ups=0.61, wpb=12889.7, bsz=421.2, num_updates=34600, lr=0.000170005, gnorm=0.744, loss_scale=4, train_wall=162, gb_free=14.7, wall=12685
pred_new.size(): torch.Size([3627, 42808])
2023-09-20 14:14:17 | INFO | train_inner | epoch 004:   7530 / 9060 loss=5.985, nll_loss=3.159, ppl=8.93, wps=7845.5, ups=0.6, wpb=13036.1, bsz=430.5, num_updates=34700, lr=0.00016976, gnorm=0.773, loss_scale=4, train_wall=166, gb_free=15.1, wall=12851
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3104, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([2392, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2808, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3504, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([2920, 42808])
lprobs.size(): torch.Size([2664, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([2096, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2664, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2752, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([396, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2958, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1500, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([128, 42808])
pred_new.size(): torch.Size([2340, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2523, 42808])
lprobs.size(): torch.Size([3504, 42808])
ter_threshold: 0.331582
num_accepted / total 3 56
loss token level: tensor(10245.0127, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1200., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3850, 42808])
ter_threshold: 0.331697
num_accepted / total 20 104
loss token level: tensor(9074.6670, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2556., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([392, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3080, 42808])
ter_threshold: 0.33227
num_accepted / total 7 96
loss token level: tensor(12120.5791, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1078., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([3680, 42808])
lprobs.size(): torch.Size([2928, 42808])
lprobs.size(): torch.Size([3288, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3080, 42808])
ter_threshold: 0.332605
num_accepted / total 2 56
loss token level: tensor(10566.7188, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(454.5000, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3784, 42808])
pred_new.size(): torch.Size([624, 42808])
ter_threshold: 0.333288
num_accepted / total 20 88
loss token level: tensor(9261.9629, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3490., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.333494
num_accepted / total 10 64
loss token level: tensor(9873.6289, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4392., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.333575
num_accepted / total 8 64
loss token level: tensor(10208.1211, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1744., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1827, 42808])
lprobs.size(): torch.Size([2432, 42808])
pred_new.size(): torch.Size([4578, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2160, 42808])
lprobs.size(): torch.Size([2432, 42808])
ter_threshold: 0.334771
num_accepted / total 6 56
loss token level: tensor(10743.5527, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1562., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 14:17:03 | INFO | train_inner | epoch 004:   7630 / 9060 loss=6.026, nll_loss=3.202, ppl=9.2, wps=7816.5, ups=0.6, wpb=12946.2, bsz=424.9, num_updates=34800, lr=0.000169516, gnorm=0.77, loss_scale=4, train_wall=165, gb_free=14.6, wall=13016
2023-09-20 14:19:45 | INFO | train_inner | epoch 004:   7730 / 9060 loss=6.066, nll_loss=3.179, ppl=9.06, wps=8081.7, ups=0.62, wpb=13057.2, bsz=428.2, num_updates=34900, lr=0.000169273, gnorm=0.761, loss_scale=4, train_wall=161, gb_free=15.2, wall=13178
2023-09-20 14:22:26 | INFO | train_inner | epoch 004:   7830 / 9060 loss=5.985, nll_loss=3.135, ppl=8.79, wps=8036.5, ups=0.62, wpb=12963, bsz=415.9, num_updates=35000, lr=0.000169031, gnorm=0.784, loss_scale=4, train_wall=161, gb_free=15.4, wall=13339
lprobs.size(): torch.Size([2600, 42808])
2023-09-20 14:25:09 | INFO | train_inner | epoch 004:   7930 / 9060 loss=6.114, nll_loss=3.211, ppl=9.26, wps=7938.9, ups=0.61, wpb=12966.3, bsz=439.8, num_updates=35100, lr=0.00016879, gnorm=0.793, loss_scale=4, train_wall=163, gb_free=13.9, wall=13503
pred_new.size(): torch.Size([896, 42808])
2023-09-20 14:27:54 | INFO | train_inner | epoch 004:   8030 / 9060 loss=5.997, nll_loss=3.171, ppl=9.01, wps=7855.2, ups=0.61, wpb=12955.3, bsz=444.3, num_updates=35200, lr=0.00016855, gnorm=0.75, loss_scale=4, train_wall=165, gb_free=15.1, wall=13668
2023-09-20 14:30:40 | INFO | train_inner | epoch 004:   8130 / 9060 loss=5.976, nll_loss=3.143, ppl=8.83, wps=7832.7, ups=0.6, wpb=12999.1, bsz=428.2, num_updates=35300, lr=0.000168311, gnorm=0.796, loss_scale=4, train_wall=166, gb_free=14.6, wall=13834
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([2856, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2624, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3096, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2752, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([2304, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3488, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1360, 42808])
pred_new.size(): torch.Size([702, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([609, 42808])
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([1664, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([484, 42808])
pred_new.size(): torch.Size([1872, 42808])
lprobs.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([9450, 42808])
lprobs.size(): torch.Size([2448, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([4560, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([3408, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([2296, 42808])
ter_threshold: 0.331275
num_accepted / total 6 48
loss token level: tensor(9857.8428, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3934., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.331314
num_accepted / total 9 48
loss token level: tensor(8991.7754, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3038., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2366, 42808])
pred_new.size(): torch.Size([3960, 42808])
pred_new.size(): torch.Size([2405, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.33157
num_accepted / total 9 48
loss token level: tensor(9278.0098, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2916., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([380, 42808])
ter_threshold: 0.331697
num_accepted / total 20 112
loss token level: tensor(10128.6592, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2588., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3320, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1656, 42808])
pred_new.size(): torch.Size([5984, 42808])
pred_new.size(): torch.Size([1870, 42808])
pred_new.size(): torch.Size([2814, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([1995, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2744, 42808])
pred_new.size(): torch.Size([1008, 42808])
pred_new.size(): torch.Size([5754, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([1800, 42808])
pred_new.size(): torch.Size([4368, 42808])
pred_new.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([1267, 42808])
ter_threshold: 0.33439599999999997
num_accepted / total 8 64
loss token level: tensor(10139.3428, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3550., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1320, 42808])
pred_new.size(): torch.Size([1750, 42808])
pred_new.size(): torch.Size([2160, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([192, 42808])
2023-09-20 14:33:29 | INFO | train_inner | epoch 004:   8230 / 9060 loss=5.989, nll_loss=3.152, ppl=8.89, wps=7743.7, ups=0.59, wpb=13063.6, bsz=428.5, num_updates=35400, lr=0.000168073, gnorm=0.752, loss_scale=4, train_wall=168, gb_free=15, wall=14002
pred_new.size(): torch.Size([1416, 42808])
2023-09-20 14:36:08 | INFO | train_inner | epoch 004:   8330 / 9060 loss=5.981, nll_loss=3.161, ppl=8.94, wps=8111.4, ups=0.63, wpb=12932, bsz=419.7, num_updates=35500, lr=0.000167836, gnorm=0.747, loss_scale=4, train_wall=159, gb_free=15.2, wall=14162
2023-09-20 14:38:54 | INFO | train_inner | epoch 004:   8430 / 9060 loss=5.98, nll_loss=3.161, ppl=8.94, wps=7902.9, ups=0.6, wpb=13071.4, bsz=421.5, num_updates=35600, lr=0.0001676, gnorm=0.772, loss_scale=4, train_wall=165, gb_free=14.5, wall=14327
2023-09-20 14:41:47 | INFO | train_inner | epoch 004:   8530 / 9060 loss=6.046, nll_loss=3.164, ppl=8.96, wps=7478.2, ups=0.58, wpb=12953.7, bsz=459, num_updates=35700, lr=0.000167365, gnorm=0.759, loss_scale=8, train_wall=173, gb_free=14.2, wall=14500
ter_threshold: 0.335781
num_accepted / total 8 64
loss token level: tensor(8775.2422, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3604., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
2023-09-20 14:44:34 | INFO | train_inner | epoch 004:   8630 / 9060 loss=6.014, nll_loss=3.165, ppl=8.97, wps=7730.3, ups=0.6, wpb=12940.7, bsz=427.4, num_updates=35800, lr=0.000167132, gnorm=0.799, loss_scale=8, train_wall=167, gb_free=15.1, wall=14668
pred_new.size(): torch.Size([1953, 42808])
2023-09-20 14:47:24 | INFO | train_inner | epoch 004:   8730 / 9060 loss=6.038, nll_loss=3.182, ppl=9.07, wps=7683.1, ups=0.59, wpb=13046.9, bsz=445.6, num_updates=35900, lr=0.000166899, gnorm=0.748, loss_scale=8, train_wall=170, gb_free=14.8, wall=14838
lprobs.size(): torch.Size([3536, 42808])
2023-09-20 14:49:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-20 14:50:13 | INFO | train_inner | epoch 004:   8831 / 9060 loss=6.09, nll_loss=3.207, ppl=9.23, wps=7702.3, ups=0.59, wpb=13045.2, bsz=458.6, num_updates=36000, lr=0.000166667, gnorm=0.743, loss_scale=4, train_wall=169, gb_free=14, wall=15007
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2680, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2336, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([2360, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3104, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2952, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([2664, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2760, 42808])
lprobs.size(): torch.Size([3408, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2288, 42808])
lprobs.size(): torch.Size([3224, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2968, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2832, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2968, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([946, 42808])
pred_new.size(): torch.Size([3648, 42808])
pred_new.size(): torch.Size([1620, 42808])
pred_new.size(): torch.Size([280, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1188, 42808])
pred_new.size(): torch.Size([1280, 42808])
pred_new.size(): torch.Size([3840, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([1008, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1276, 42808])
lprobs.size(): torch.Size([3320, 42808])
pred_new.size(): torch.Size([784, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([888, 42808])
pred_new.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.33138
num_accepted / total 1 64
loss token level: tensor(9386.3027, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(287., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.331582
num_accepted / total 8 56
loss token level: tensor(9212.7949, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3728., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.331697
num_accepted / total 32 168
loss token level: tensor(10200.1104, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2720., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2842, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([2576, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([78, 42808])
pred_new.size(): torch.Size([6401, 42808])
pred_new.size(): torch.Size([90, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2176, 42808])
pred_new.size(): torch.Size([1248, 42808])
pred_new.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([2550, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.33350399999999997
num_accepted / total 4 40
loss token level: tensor(9013.3096, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1416., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1872, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3104, 42808])
pred_new.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([3348, 42808])
pred_new.size(): torch.Size([2160, 42808])
pred_new.size(): torch.Size([1224, 42808])
ter_threshold: 0.33493799999999996
num_accepted / total 18 104
loss token level: tensor(8583.7969, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2312., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([298, 42808])
pred_new.size(): torch.Size([988, 42808])
pred_new.size(): torch.Size([226, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([936, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([624, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): 2023-09-20 14:52:58 | INFO | train_inner | epoch 004:   8931 / 9060 loss=5.95, nll_loss=3.133, ppl=8.77, wps=7875.9, ups=0.61, wpb=12926.7, bsz=432.1, num_updates=36100, lr=0.000166436, gnorm=0.769, loss_scale=4, train_wall=164, gb_free=14.7, wall=15171
lprobs.size(): torch.Size([3480, 42808])
2023-09-20 14:55:53 | INFO | train_inner | epoch 004:   9031 / 9060 loss=6.098, nll_loss=3.211, ppl=9.26, wps=7344.8, ups=0.57, wpb=12888.6, bsz=415.9, num_updates=36200, lr=0.000166206, gnorm=0.79, loss_scale=4, train_wall=175, gb_free=14.8, wall=15346
2023-09-20 14:56:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-20 14:56:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 14:56:52 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-20 14:56:52 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-20 14:56:53 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-20 14:56:53 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-20 14:56:53 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-20 14:56:53 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-20 14:56:54 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-20 14:56:54 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-20 14:56:54 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-20 14:56:54 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-20 14:56:55 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein ravierender Erfolg.
2023-09-20 14:56:55 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-20 14:56:55 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-20 14:56:55 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-20 14:56:56 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, und das respektieren wir.
2023-09-20 14:56:56 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-20 14:56:56 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-20 14:56:56 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-20 14:56:57 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende geeignet sind.
2023-09-20 14:56:57 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-20 14:56:57 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-20 14:56:57 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-20 14:56:58 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 14:56:58 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 14:56:58 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU enorme Mengen an Energie verschwendet.
2023-09-20 14:56:58 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-20 14:56:59 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin trägt einen Artikel von Gentoo-Entwickler Michael Kohl in seiner neuesten Nummer.
2023-09-20 14:56:59 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-20 14:57:00 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellung auch schon bald im Haushalt der Union widerspiegeln.
2023-09-20 14:57:00 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-20 14:57:00 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-20 14:57:00 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-20 14:57:01 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weit bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-20 14:57:01 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-20 14:57:01 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-20 14:57:01 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-20 14:57:02 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-20 14:57:02 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-20 14:57:02 | INFO | fairseq.tasks.translation | example hypothesis: Der größte Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-20 14:57:02 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-20 14:57:03 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-20 14:57:03 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-20 14:57:03 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-20 14:57:03 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-20 14:57:04 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-20 14:57:04 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-20 14:57:04 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potenzielle Käufer veranlassen, sich über die Qualität Ihres Services und Ihrer Produkte zu informieren.
2023-09-20 14:57:04 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-20 14:57:05 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in ungefestigte Gebiete wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-20 14:57:05 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-20 14:57:05 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gibt, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-20 14:57:05 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-20 14:57:06 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-20 14:57:06 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-20 14:57:07 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in etwa 5 km (8 km) Radius des Strip.
2023-09-20 14:57:07 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-20 14:57:07 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web-legale Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-20 14:57:07 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-20 14:57:08 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die Realisierung von Klanghandbüchern akustisch, interaktiv oder in schriftlicher Form an.
2023-09-20 14:57:08 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-20 14:57:08 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-20 14:57:08 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-20 14:57:09 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu gewährleisten.
2023-09-20 14:57:09 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-20 14:57:09 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu den von ihnen in die europäischen Sozialversicherungssysteme gezahlten Geldern haben.
2023-09-20 14:57:09 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-20 14:57:10 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-20 14:57:10 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-20 14:57:10 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf allen Rechnerplattformen läuft.
2023-09-20 14:57:10 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-20 14:57:11 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche ist.
2023-09-20 14:57:11 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-20 14:57:12 | INFO | fairseq.tasks.translation | example hypothesis: Thatcherite Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben sind jedoch definitiv Schlüsselelemente seiner Agenda.
2023-09-20 14:57:12 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-20 14:57:12 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen wieder Splashutils erstellen, damit sie richtig funktioniert.
2023-09-20 14:57:12 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-20 14:57:13 | INFO | fairseq.tasks.translation | example hypothesis: Spieler von Horde und Allianz können sich nur dann gegenseitig Gegenstände kaufen oder verkaufen, wenn sie die unten aufgeführten neutralen Auktionshäuser nutzen.
2023-09-20 14:57:13 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-20 14:57:14 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum sich diese Kriterien nur auf die Anwendung innerhalb der Grenzen Europas beschränken sollten.
2023-09-20 14:57:14 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-20 14:57:14 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuss für Haushaltskontrolle empfiehlt der Kommission auf der Grundlage eines Berichts von Herrn Wynn die Erteilung der Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-20 14:57:14 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-20 14:57:15 | INFO | fairseq.tasks.translation | example hypothesis: Dem Vorschlag der Kommission zufolge muss der Rat formelle Standpunkte zu einigen Details des Abkommens im Prinzip mit den Vereinigten Staaten vorlegen.
2023-09-20 14:57:15 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-20 14:57:15 | INFO | fairseq.tasks.translation | example hypothesis: Stilvolle oder klassische Farben, zeitloses Design oder eine Sonderausgabe - unser breites Sortiment an Plastikkindern ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Oberfläche.
2023-09-20 14:57:15 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-20 14:57:16 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... health tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 14:57:16 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 14:57:17 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx über sachliche Situationen zu informieren, die mit diesen AGB nicht unmittelbar nach ihrer Kenntnis vereinbar sind.
2023-09-20 14:57:17 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-20 14:57:17 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die die Notwendigkeit institutioneller Veränderungen vorangetrieben und realisiert hat, die ihrer Ansicht nach eine stärkere Präsenz im Bereich der Außen- und Verteidigungspolitik erfordert.
2023-09-20 14:57:17 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-20 14:57:18 | INFO | fairseq.tasks.translation | example hypothesis: Neben unserem Shop-Angebot haben wir einen Blog als Informationsportal für unsere Kunden, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-20 14:57:18 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-20 14:57:18 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Erörterung aller Fragen, die jetzt zur Diskussion stehen, über etwas erzielt wurden, das kaum zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-20 14:57:18 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-20 14:57:19 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Quellen und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-20 14:57:19 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-20 14:57:20 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal konnte der Berichterstatter die bisweilen unterschiedlichen Meinungen und Beiträge zusammenfassen und sie - ich würde sagen - in einem äußerst ausgewogenen Text zusammenfassen.
2023-09-20 14:57:20 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-20 14:57:20 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm der trockenen elektrostatischen Niederleger mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-20 14:57:20 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-20 14:57:21 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, sind Sie bereits in einem fremden Land.
2023-09-20 14:57:21 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-20 14:57:22 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und Fernost wandern, müssen wir uns auf unsere Innovation und Erfindungsreichtum verlassen, um unser Leben zu verdienen.
2023-09-20 14:57:22 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-20 14:57:22 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und stützt sich auf Verhandlungen mit Drittländern, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-20 14:57:22 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-20 14:57:23 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-20 14:57:23 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-20 14:57:24 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-20 14:57:24 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-20 14:57:24 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-20 14:57:24 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-20 14:57:25 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notlage gibt es jedoch noch einen anderen: den Notstand, der die Kinder betrifft, den schwächsten Sektor der Bevölkerung, der ohne Familie, keinen Schutz und keinen Staat gelassen wurde.
2023-09-20 14:57:25 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-20 14:57:26 | INFO | fairseq.tasks.translation | example hypothesis: In erster Linie sollte klargestellt und hervorgehoben werden, dass die Praxis des Fastens seit 2003 von der EU reguliert wurde, was bedeutet, dass Haie nicht allein für ihre Flossen gefangen werden können.
2023-09-20 14:57:26 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-20 14:57:26 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei gesetzt, nicht erst realisiert ist, bleiben alle äußeren Beziehungen von diesem Mangel an Realisation geprägt. Man kann niemanden wirklich kennen, bis man das wahre Selbst kennt.
2023-09-20 14:57:26 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-20 14:57:27 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen einen gewaltfreien Zeitraum zu schaffen und das Verfahren für die Wählerregistrierung wieder zu öffnen.
2023-09-20 14:57:27 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-20 14:57:27 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit verleihen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-20 14:57:27 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-20 14:57:28 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java-Programmiersprache mit J2EE-Techniken, die Plattform und Betriebssystem Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-20 14:57:28 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-20 14:57:29 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für die Klärung des Anhangs.
2023-09-20 14:57:29 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-20 14:57:29 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist ferner der Auffassung, dass die WTO-Mitgliedstaaten eine besondere Verantwortung haben, die grundlegenden Arbeitsnormen einzuhalten, und fordert die WTO auf, klar zu erklären, dass die von der IAO verhängten Sanktionen nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-20 14:57:29 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-20 14:57:30 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe vor kurzem an einer Debatte über das irische öffentlich-rechtliche Rundfunk RTA teilgenommen, bei der eine Frau sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-20 14:57:30 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-20 14:57:31 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission erneut zu ihrer sachdienlichen Haltung gratulieren.
2023-09-20 14:57:31 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-20 14:57:31 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihre Lektionen oder konkrete Informationen über die europäische Geschichte, die Staatsbürgerschaft oder etwas so Konkretes wie die Reduktion des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Studenten zugeschnitten ist.
2023-09-20 14:57:31 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-20 14:57:32 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, dem wunderschönen Wien und dem bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.
2023-09-20 14:57:32 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-20 14:57:33 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-20 14:57:33 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 14:57:33 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken heißt, zu Natralisieren und zu mystisieren, was eine bestimmte Art von Vertragsverhältnis zwischen Individuen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Gefahr, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-20 14:57:33 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-20 14:57:34 | INFO | fairseq.tasks.translation | example hypothesis: In der Gerichtsbarkeit der Gemeinschaft zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn zum Beispiel Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-20 14:57:34 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
lprobs.size(): torch.Size([3240, 42808])
2023-09-20 14:57:35 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er Serie ist eines der lustigsten Autos für unter 50.000 Dollar, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver leben, können Sie die gesamte Lineup kostenlos für Sie ausprobieren.
2023-09-20 14:57:35 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-20 14:57:36 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für seinen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte und gemeinsame Sicherheit und Verteidigungspolitik für ihre realistische Darstellung dieser Angelegenheit.
2023-09-20 14:57:36 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-20 14:57:36 | INFO | fairseq.tasks.translation | example hypothesis: Sie müssen Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt (Stew) und die ausgezeichneten Süßwasserfische: gegrillter Schweinefleisch, Forelle mit Mandelnüsse.
2023-09-20 14:57:36 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-20 14:57:37 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, wenn wir, anstatt daran zu erinnern, was eine politische Aktion bedeutet, eine Gesamtsicht bieten würden, die es uns erlaubt, näher auf die verschiedenen Fragen einzugehen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-20 14:57:37 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-20 14:57:38 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, stimmten der Veröffentlichung eines Live-Albums "Bodulska balada 2009" zu.
2023-09-20 14:57:38 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-20 14:57:38 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen echten Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit aufgrund der makroökonomischen Politik, fiskalischen Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich untergraben wird.
2023-09-20 14:57:38 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-20 14:57:39 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den die Kommission uns vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel für die Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-20 14:57:39 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-20 14:57:40 | INFO | fairseq.tasks.translation | example hypothesis: Daher erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den rechtlichen und juristischen Bereich, wodurch Norwegen und Island zu Ländern werden, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstands gelten werden.
2023-09-20 14:57:40 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-20 14:57:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Make-Shift-Boot hinunter die Mississippi, auf der Suche nach dem großen verborgenen Schatz, in die Liebe zum schönen Becky Thatcher, der rein dynamisch ist, und vor allem alles, werden wir große Freunde sein.
2023-09-20 14:57:41 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-20 14:57:41 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der von Einzelpersonen oder juristischen Personen verursachten Meeresverschmutzung, den Anwendungsbereich der Reaktion darauf und den strafrechtlichen Charakter der Sanktionen, die bei solchen Verletzungen durch Einzelpersonen angewendet werden können.
2023-09-20 14:57:41 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-20 14:57:42 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Fatisy und Vincent Reynaud wurden in der Tat einfach verurteilt, weil sie ihre Arbeit als Journalisten und Kameramänner erledigt haben, indem sie eine Gruppe von Bergregionen brachten, die seit Jahren von einem autoritären Regime gejagt wurden, das jeden Grundsatz der Demokratie missachtet.
2023-09-20 14:57:42 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-20 14:57:43 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels gehören Concierge-Service, ein Friseurshop und Schönheitssalon, Transport- und Stadtrundservice, Wechselstube, kostenloser Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-20 14:57:43 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-20 14:57:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die von Königin D. Leonor, Frau von König D. João II, und bekannt durch ihre Keramik international berühmt für ihre figurativen und satirischen Werke ist es auch einen Besuch wert.
2023-09-20 14:57:44 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-20 14:57:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es handele sich um gute Pro-Westeuropäer auf der einen Seite und Anhänger des früheren Regimes auf der anderen Seite - das ist auch verwerflich, da die Rollen aller heute und früher bekannt sind.
2023-09-20 14:57:44 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-20 14:57:45 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, lassen Sie uns sagen, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer reisen, nicht auf diese Weise erfasst werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-20 14:57:45 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-20 14:57:46 | INFO | fairseq.tasks.translation | example hypothesis: (4) Soweit Informationen außerhalb einer Aktionärsversammlung einem Aktionär aus Gründen seines Status als Aktionär zur Verfügung gestellt wurden, werden diese Informationen auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn solche Informationen nicht notwendig sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-20 14:57:46 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-20 14:57:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme gesteckt werden, die in der Regel in die Taschen verschiedener Diktatoren fließen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Millionen von Menschen in unseren eigenen Ländern leben, die auch sehr miserable Leben führen.
2023-09-20 14:57:47 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-20 14:57:48 | INFO | fairseq.tasks.translation | example hypothesis: Wir bitten die Mitgliedstaaten - weil sie sagen, Flugzeuge eines Mitgliedstaats oder die NATO hätten an diesem Kriegsakt beteiligt sein können -, bei Informationen zu helfen, die keinen Grund mehr haben, vertraulich zu bleiben, zu verschweigen oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-20 14:57:48 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-20 14:57:49 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Bezirk Reinickendorf liegt nur 5 Gehminuten vom Bahnhof Waidmannslust S-Bahn und 30 Fahrminuten vom Stadtzentrum entfernt. Die komfortablen Zimmer des Pension Nomaden Gästehaus sind im charmanten Landhausstil eingerichtet.
2023-09-20 14:57:49 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 14:57:50 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radargerät, angeführt von Thales in Frankreich, und unserer Business Unit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernste, modularste Sensorsuite und Datenlinks enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die moderne Off-the-Regal-Plattformen nie erreichen können.
2023-09-20 14:57:50 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-20 14:57:50 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen deutlich machen, dass wir auch in der Lage sein werden, aus dem Markt zu ziehen, nicht nur für uns, sondern weltweit, die Produkte, die ein ernsthaftes Risiko darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, weil diese Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-20 14:57:50 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-20 14:57:51 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem bloßen Komplott der Moderne und Postmoderne oder der klaren Opposition reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und anhaltende Spannung dieser beiden Ästhetik-Politik anerkennen, die in den Formen der Sichtbarkeit und Verständlichkeit verwurzelt sind, die Kunst als solche für uns identifizierbar machen - jener beiden Politik, die letztlich zu ihrer Selbstunterdrückung führen.
2023-09-20 14:57:51 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-20 14:57:52 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werden wir angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir gegeben haben, die eindeutig weitgehend das unterstützen, was ich gerade gesagt habe, und auf der Grundlage der früheren Entscheidungen unsere Debatten führen, und wenn es um die Abstimmung geht, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht darum bitten, das Quorum zu überprüfen.
2023-09-20 14:57:52 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-20 14:57:53 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker niemals die Einschränkung des Nationalstaatsprinzips akzeptiert haben, dann ist das paradoxerweise genau sie, die, kaum jemand weiß, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem nationale Grenzen aufgehoben wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern die ethnische, religiöse, sprachliche und kulturelle Vielfalt zu entwickeln.
2023-09-20 14:57:53 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-20 14:57:54 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Form als Hybridform veröffentlicht, die Rezensionen und Artikel in der vierteljährlichen Zeitschrift für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Webseiten der Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an ihre Abonnenten verteilt.
2023-09-20 14:57:54 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-20 14:57:55 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Handys nicht nur ihre Federn deutlich verfeinert, sondern sich von einst leuchtenden Taschenlampen über polyphonisch tootling Game Boy Ansprüche bis hin zu schrägen Mini-PCs mit knackigen CD-Qualität Stereo-Sound: Ab sofort könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den früheren me-too wannabes bis zu Trailblasatoren neuer technologischer Entwicklungen absolvieren.
2023-09-20 14:57:55 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-20 14:57:57 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dirigila defensa de la base humana en Pandora, Konence a Jake para que le proportionedad información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se marchen. In un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Netiyri, y da se cuenta que estrenás quérenás un arás, ará un konfliquero; en un dearlo de demejor.
2023-09-20 14:57:57 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-20 14:57:58 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 4.363 | nll_loss 2.373 | ppl 5.18 | bleu 28.16 | wps 17949.1 | wpb 12011.9 | bsz 398.1 | num_updates 36229 | best_bleu 28.16
2023-09-20 14:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 36229 updates
2023-09-20 14:57:58 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint4.pt
2023-09-20 14:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint4.pt
2023-09-20 14:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 36229 updates, score 28.16) (writing took 14.578619037987664 seconds)
2023-09-20 14:58:12 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2023-09-20 14:58:12 | INFO | train | epoch 004 | loss 5.473 | nll_loss 2.945 | ppl 7.7 | wps 10817.3 | ups 0.83 | wpb 12977.1 | bsz 430.6 | num_updates 36229 | lr 0.000166139 | gnorm 0.716 | loss_scale 4 | train_wall 10762 | gb_free 14.5 | wall 15486
2023-09-20 14:58:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 14:58:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-20 14:58:13 | INFO | fairseq.trainer | begin training epoch 5
2023-09-20 14:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-20 15:00:12 | INFO | train_inner | epoch 005:     71 / 9060 loss=6.054, nll_loss=3.173, ppl=9.02, wps=5001.5, ups=0.39, wpb=12929, bsz=415.4, num_updates=36300, lr=0.000165977, gnorm=0.801, loss_scale=4, train_wall=177, gb_free=15.2, wall=15605
pred_new.size(): torch.Size([1224, 42808])
pred_new.size(): torch.Size([1140, 42808])
2023-09-20 15:03:00 | INFO | train_inner | epoch 005:    171 / 9060 loss=6.03, nll_loss=3.125, ppl=8.73, wps=7729, ups=0.59, wpb=13026.4, bsz=450.5, num_updates=36400, lr=0.000165748, gnorm=0.738, loss_scale=4, train_wall=168, gb_free=15.1, wall=15774
pred_new.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1080, 42808])
ter_threshold: 0.336435
num_accepted / total 25 128
loss token level: tensor(10546.7471, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4832., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 15:05:46 | INFO | train_inner | epoch 005:    271 / 9060 loss=5.994, nll_loss=3.105, ppl=8.6, wps=7828.3, ups=0.6, wpb=13016.6, bsz=447, num_updates=36500, lr=0.000165521, gnorm=0.729, loss_scale=4, train_wall=166, gb_free=14.5, wall=15940
pred_new.size(): torch.Size([693, 42808])
2023-09-20 15:08:36 | INFO | train_inner | epoch 005:    371 / 9060 loss=6.072, nll_loss=3.15, ppl=8.88, wps=7638, ups=0.59, wpb=12983.3, bsz=452.3, num_updates=36600, lr=0.000165295, gnorm=0.766, loss_scale=4, train_wall=170, gb_free=14.1, wall=16110
2023-09-20 15:11:25 | INFO | train_inner | epoch 005:    471 / 9060 loss=6.017, nll_loss=3.136, ppl=8.79, wps=7724.4, ups=0.59, wpb=12998.5, bsz=426.4, num_updates=36700, lr=0.00016507, gnorm=0.77, loss_scale=4, train_wall=168, gb_free=15.5, wall=16278
ter_threshold: 0.33674499999999996
num_accepted / total 11 72
loss token level: tensor(9315.0332, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2148., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 15:14:21 | INFO | train_inner | epoch 005:    571 / 9060 loss=6.03, nll_loss=3.129, ppl=8.75, wps=7312.8, ups=0.57, wpb=12865.4, bsz=444.4, num_updates=36800, lr=0.000164845, gnorm=0.781, loss_scale=4, train_wall=176, gb_free=15.2, wall=16454
pred_new.size(): torch.Size([1320, 42808])
2023-09-20 15:17:11 | INFO | train_inner | epoch 005:    671 / 9060 loss=6.087, nll_loss=3.151, ppl=8.88, wps=7654, ups=0.59, wpb=13012.3, bsz=445.7, num_updates=36900, lr=0.000164622, gnorm=0.764, loss_scale=4, train_wall=170, gb_free=14.5, wall=16624
lprobs.size(): torch.Size([3304, 42808])
2023-09-20 15:20:00 | INFO | train_inner | epoch 005:    771 / 9060 loss=5.95, nll_loss=3.097, ppl=8.55, wps=7646.3, ups=0.59, wpb=12953.5, bsz=416.2, num_updates=37000, lr=0.000164399, gnorm=0.753, loss_scale=4, train_wall=169, gb_free=15.1, wall=16793
2023-09-20 15:22:58 | INFO | train_inner | epoch 005:    871 / 9060 loss=6.026, nll_loss=3.135, ppl=8.79, wps=7291, ups=0.56, wpb=12962.9, bsz=436.2, num_updates=37100, lr=0.000164177, gnorm=0.78, loss_scale=4, train_wall=178, gb_free=14.7, wall=16971
ter_threshold: 0.33716999999999997
num_accepted / total 20 96
loss token level: tensor(10457.6143, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3132., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1240, 42808])
2023-09-20 15:25:56 | INFO | train_inner | epoch 005:    971 / 9060 loss=6.003, nll_loss=3.123, ppl=8.71, wps=7268.1, ups=0.56, wpb=12938.6, bsz=408.2, num_updates=37200, lr=0.000163956, gnorm=0.823, loss_scale=4, train_wall=178, gb_free=15.1, wall=17149
ter_threshold: 0.337237
num_accepted / total 5 72
loss token level: tensor(9769.0391, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(964., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3159, 42808])
lprobs.size(): torch.Size([3344, 42808])
2023-09-20 15:28:46 | INFO | train_inner | epoch 005:   1071 / 9060 loss=5.94, nll_loss=3.097, ppl=8.56, wps=7681, ups=0.59, wpb=13042.1, bsz=443.4, num_updates=37300, lr=0.000163737, gnorm=0.742, loss_scale=4, train_wall=170, gb_free=14.4, wall=17319
pred_new.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([2880, 42808])
2023-09-20 15:31:36 | INFO | train_inner | epoch 005:   1171 / 9060 loss=6.052, nll_loss=3.152, ppl=8.89, wps=7635.4, ups=0.59, wpb=12980.1, bsz=439.7, num_updates=37400, lr=0.000163517, gnorm=0.757, loss_scale=4, train_wall=170, gb_free=14.2, wall=17489
2023-09-20 15:34:26 | INFO | train_inner | epoch 005:   1271 / 9060 loss=6.064, nll_loss=3.167, ppl=8.98, wps=7647.9, ups=0.59, wpb=13002.9, bsz=430.4, num_updates=37500, lr=0.000163299, gnorm=0.759, loss_scale=4, train_wall=170, gb_free=15.2, wall=17659
lprobs.size(): torch.Size([3384, 42808])
2023-09-20 15:37:17 | INFO | train_inner | epoch 005:   1371 / 9060 loss=6.025, nll_loss=3.114, ppl=8.66, wps=7589.4, ups=0.58, wpb=12978.3, bsz=440, num_updates=37600, lr=0.000163082, gnorm=0.786, loss_scale=4, train_wall=171, gb_free=14.5, wall=17830
pred_new.size(): torch.Size([1530, 42808])
2023-09-20 15:40:08 | INFO | train_inner | epoch 005:   1471 / 9060 loss=5.99, nll_loss=3.124, ppl=8.72, wps=7578.4, ups=0.58, wpb=13006.8, bsz=420.5, num_updates=37700, lr=0.000162866, gnorm=0.756, loss_scale=4, train_wall=171, gb_free=15.2, wall=18002
lprobs.size(): torch.Size([3384, 42808])
2023-09-20 15:42:51 | INFO | train_inner | epoch 005:   1571 / 9060 loss=5.957, nll_loss=3.091, ppl=8.52, wps=7990.6, ups=0.61, wpb=13014.8, bsz=413.5, num_updates=37800, lr=0.00016265, gnorm=0.764, loss_scale=4, train_wall=163, gb_free=14.3, wall=18165
2023-09-20 15:45:46 | INFO | train_inner | epoch 005:   1671 / 9060 loss=6.005, nll_loss=3.16, ppl=8.94, wps=7405.3, ups=0.57, wpb=12971.9, bsz=425.9, num_updates=37900, lr=0.000162435, gnorm=0.79, loss_scale=4, train_wall=175, gb_free=14.8, wall=18340
pred_new.size(): torch.Size([260, 42808])
2023-09-20 15:48:36 | INFO | train_inner | epoch 005:   1771 / 9060 loss=6.032, nll_loss=3.163, ppl=8.96, wps=7613.9, ups=0.59, wpb=12922.2, bsz=444.5, num_updates=38000, lr=0.000162221, gnorm=0.781, loss_scale=4, train_wall=169, gb_free=15, wall=18509
pred_new.size(): torch.Size([792, 42808])
2023-09-20 15:51:28 | INFO | train_inner | epoch 005:   1871 / 9060 loss=6.056, nll_loss=3.14, ppl=8.81, wps=7632.4, ups=0.58, wpb=13101.5, bsz=437.5, num_updates=38100, lr=0.000162008, gnorm=0.771, loss_scale=4, train_wall=171, gb_free=15.1, wall=18681
2023-09-20 15:51:44 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-20 15:54:10 | INFO | train_inner | epoch 005:   1972 / 9060 loss=6.065, nll_loss=3.153, ppl=8.89, wps=8015, ups=0.62, wpb=13003.2, bsz=444.5, num_updates=38200, lr=0.000161796, gnorm=0.75, loss_scale=2, train_wall=162, gb_free=14.7, wall=18843
lprobs.size(): torch.Size([3528, 42808])
2023-09-20 15:56:59 | INFO | train_inner | epoch 005:   2072 / 9060 loss=5.997, nll_loss=3.129, ppl=8.75, wps=7678.3, ups=0.59, wpb=12998.9, bsz=450.3, num_updates=38300, lr=0.000161585, gnorm=0.94, loss_scale=2, train_wall=169, gb_free=14.1, wall=19013
pred_new.size(): torch.Size([2366, 42808])
lprobs.size(): torch.Size([3472, 42808])
2023-09-20 15:59:51 | INFO | train_inner | epoch 005:   2172 / 9060 loss=6.113, nll_loss=3.188, ppl=9.11, wps=7522.1, ups=0.58, wpb=12949.1, bsz=429.4, num_updates=38400, lr=0.000161374, gnorm=0.795, loss_scale=2, train_wall=172, gb_free=13.2, wall=19185
2023-09-20 16:02:43 | INFO | train_inner | epoch 005:   2272 / 9060 loss=6.021, nll_loss=3.137, ppl=8.8, wps=7541.7, ups=0.58, wpb=12975.6, bsz=443, num_updates=38500, lr=0.000161165, gnorm=0.784, loss_scale=2, train_wall=172, gb_free=16, wall=19357
lprobs.size(): torch.Size([3088, 42808])
2023-09-20 16:05:36 | INFO | train_inner | epoch 005:   2372 / 9060 loss=6.063, nll_loss=3.151, ppl=8.88, wps=7484.2, ups=0.58, wpb=12946.1, bsz=424.8, num_updates=38600, lr=0.000160956, gnorm=0.763, loss_scale=2, train_wall=173, gb_free=14.7, wall=19530
pred_new.size(): torch.Size([1020, 42808])
2023-09-20 16:08:33 | INFO | train_inner | epoch 005:   2472 / 9060 loss=6.084, nll_loss=3.155, ppl=8.91, wps=7317, ups=0.57, wpb=12923.8, bsz=417.3, num_updates=38700, lr=0.000160748, gnorm=0.785, loss_scale=2, train_wall=176, gb_free=15.3, wall=19706
ter_threshold: 0.338728
num_accepted / total 74 176
loss token level: tensor(9403.2012, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5424., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4788, 42808])
2023-09-20 16:11:24 | INFO | train_inner | epoch 005:   2572 / 9060 loss=6.057, nll_loss=3.126, ppl=8.73, wps=7583.4, ups=0.59, wpb=12945.1, bsz=427.4, num_updates=38800, lr=0.00016054, gnorm=0.79, loss_scale=2, train_wall=170, gb_free=14.4, wall=19877
pred_new.size(): torch.Size([744, 42808])
lprobs.size(): torch.Size([2904, 42808])
2023-09-20 16:14:10 | INFO | train_inner | epoch 005:   2672 / 9060 loss=6.057, nll_loss=3.187, ppl=9.11, wps=7732.4, ups=0.6, wpb=12841.3, bsz=439.7, num_updates=38900, lr=0.000160334, gnorm=0.75, loss_scale=2, train_wall=166, gb_free=14.2, wall=20043
lprobs.size(): torch.Size([3384, 42808])
2023-09-20 16:16:59 | INFO | train_inner | epoch 005:   2772 / 9060 loss=6.034, nll_loss=3.154, ppl=8.9, wps=7647.7, ups=0.59, wpb=12951.8, bsz=409.1, num_updates=39000, lr=0.000160128, gnorm=0.754, loss_scale=2, train_wall=169, gb_free=14.8, wall=20213
pred_new.size(): torch.Size([2532, 42808])
lprobs.size(): torch.Size([2592, 42808])
2023-09-20 16:19:58 | INFO | train_inner | epoch 005:   2872 / 9060 loss=6.059, nll_loss=3.153, ppl=8.9, wps=7287, ups=0.56, wpb=13011.6, bsz=426.7, num_updates=39100, lr=0.000159923, gnorm=0.774, loss_scale=2, train_wall=178, gb_free=15.2, wall=20391
2023-09-20 16:22:50 | INFO | train_inner | epoch 005:   2972 / 9060 loss=5.993, nll_loss=3.121, ppl=8.7, wps=7549.4, ups=0.58, wpb=12980.6, bsz=450.2, num_updates=39200, lr=0.000159719, gnorm=0.742, loss_scale=2, train_wall=172, gb_free=14.4, wall=20563
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.339229
num_accepted / total 28 112
loss token level: tensor(9414.6650, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6008., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.33924899999999997
num_accepted / total 13 112
loss token level: tensor(9075.0078, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2494., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 16:25:40 | INFO | train_inner | epoch 005:   3072 / 9060 loss=5.946, nll_loss=3.092, ppl=8.53, wps=7620.6, ups=0.59, wpb=13020.4, bsz=413.4, num_updates=39300, lr=0.000159516, gnorm=0.743, loss_scale=2, train_wall=171, gb_free=14.2, wall=20734
ter_threshold: 0.3393
num_accepted / total 4 80
loss token level: tensor(10951.1553, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(771., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1760, 42808])
2023-09-20 16:28:35 | INFO | train_inner | epoch 005:   3172 / 9060 loss=5.987, nll_loss=3.113, ppl=8.65, wps=7463.3, ups=0.57, wpb=13031.9, bsz=417.6, num_updates=39400, lr=0.000159313, gnorm=0.802, loss_scale=2, train_wall=174, gb_free=15.7, wall=20909
pred_new.size(): torch.Size([1800, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4970, 42808])
ter_threshold: 0.33943599999999996
num_accepted / total 76 176
loss token level: tensor(9071.1631, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10136., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
2023-09-20 16:31:26 | INFO | train_inner | epoch 005:   3272 / 9060 loss=6.014, nll_loss=3.144, ppl=8.84, wps=7613.9, ups=0.58, wpb=13029.6, bsz=432.3, num_updates=39500, lr=0.000159111, gnorm=0.751, loss_scale=2, train_wall=171, gb_free=14.9, wall=21080
2023-09-20 16:34:15 | INFO | train_inner | epoch 005:   3372 / 9060 loss=5.953, nll_loss=3.138, ppl=8.8, wps=7695.2, ups=0.59, wpb=13012.1, bsz=402.9, num_updates=39600, lr=0.00015891, gnorm=0.755, loss_scale=2, train_wall=169, gb_free=14.6, wall=21249
2023-09-20 16:37:04 | INFO | train_inner | epoch 005:   3472 / 9060 loss=6.066, nll_loss=3.172, ppl=9.01, wps=7647.6, ups=0.59, wpb=12866.4, bsz=440.4, num_updates=39700, lr=0.00015871, gnorm=0.768, loss_scale=2, train_wall=168, gb_free=14.4, wall=21417
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([2880, 42808])
2023-09-20 16:39:49 | INFO | train_inner | epoch 005:   3572 / 9060 loss=5.998, nll_loss=3.104, ppl=8.6, wps=7848.2, ups=0.61, wpb=12952.6, bsz=423.4, num_updates=39800, lr=0.000158511, gnorm=0.776, loss_scale=2, train_wall=165, gb_free=14.3, wall=21582
ter_threshold: 0.339801
num_accepted / total 19 88
loss token level: tensor(9739.9023, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6160., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-20 16:42:38 | INFO | train_inner | epoch 005:   3672 / 9060 loss=5.959, nll_loss=3.098, ppl=8.56, wps=7633.4, ups=0.59, wpb=12951.8, bsz=413.8, num_updates=39900, lr=0.000158312, gnorm=0.758, loss_scale=2, train_wall=169, gb_free=14.3, wall=21752
pred_new.size(): torch.Size([2200, 42808])
2023-09-20 16:45:31 | INFO | train_inner | epoch 005:   3772 / 9060 loss=6.063, nll_loss=3.158, ppl=8.93, wps=7472.5, ups=0.58, wpb=12941.3, bsz=433.8, num_updates=40000, lr=0.000158114, gnorm=0.783, loss_scale=2, train_wall=173, gb_free=14.5, wall=21925
lprobs.size(): torch.Size([3400, 42808])
2023-09-20 16:48:24 | INFO | train_inner | epoch 005:   3872 / 9060 loss=6.131, nll_loss=3.171, ppl=9.01, wps=7517, ups=0.58, wpb=12996.5, bsz=456.6, num_updates=40100, lr=0.000157917, gnorm=0.774, loss_scale=2, train_wall=173, gb_free=14.1, wall=22098
pred_new.size(): torch.Size([714, 42808])
2023-09-20 16:51:11 | INFO | train_inner | epoch 005:   3972 / 9060 loss=6.036, nll_loss=3.154, ppl=8.9, wps=7758.1, ups=0.6, wpb=12898.1, bsz=462.4, num_updates=40200, lr=0.00015772, gnorm=0.774, loss_scale=2, train_wall=166, gb_free=15.6, wall=22264
2023-09-20 16:54:00 | INFO | train_inner | epoch 005:   4072 / 9060 loss=5.922, nll_loss=3.066, ppl=8.38, wps=7696, ups=0.59, wpb=13045, bsz=433.6, num_updates=40300, lr=0.000157524, gnorm=0.728, loss_scale=2, train_wall=169, gb_free=13.9, wall=22434
pred_new.size(): torch.Size([1026, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([368, 42808])
2023-09-20 16:56:54 | INFO | train_inner | epoch 005:   4172 / 9060 loss=6.14, nll_loss=3.184, ppl=9.09, wps=7494.6, ups=0.58, wpb=13014.6, bsz=459.3, num_updates=40400, lr=0.000157329, gnorm=0.777, loss_scale=2, train_wall=173, gb_free=13.7, wall=22607
pred_new.size(): torch.Size([1683, 42808])
pred_new.size(): torch.Size([1452, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([304, 42808])
2023-09-20 16:59:35 | INFO | train_inner | epoch 005:   4272 / 9060 loss=6.008, nll_loss=3.13, ppl=8.75, wps=8087.7, ups=0.62, wpb=13014.4, bsz=435.4, num_updates=40500, lr=0.000157135, gnorm=0.747, loss_scale=2, train_wall=161, gb_free=14.6, wall=22768
ter_threshold: 0.340534
num_accepted / total 45 160
loss token level: tensor(10184.9746, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7272., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1708, 42808])
2023-09-20 17:02:27 | INFO | train_inner | epoch 005:   4372 / 9060 loss=6.042, nll_loss=3.169, ppl=8.99, wps=7517.4, ups=0.58, wpb=12923.6, bsz=422.5, num_updates=40600, lr=0.000156941, gnorm=0.775, loss_scale=2, train_wall=172, gb_free=14.8, wall=22940
2023-09-20 17:05:14 | INFO | train_inner | epoch 005:   4472 / 9060 loss=6.02, nll_loss=3.174, ppl=9.03, wps=7740.6, ups=0.6, wpb=12929.4, bsz=428.9, num_updates=40700, lr=0.000156748, gnorm=0.802, loss_scale=2, train_wall=167, gb_free=15.3, wall=23107
lprobs.size(): torch.Size([2688, 42808])
2023-09-20 17:08:09 | INFO | train_inner | epoch 005:   4572 / 9060 loss=6.004, nll_loss=3.146, ppl=8.85, wps=7337.3, ups=0.57, wpb=12833.6, bsz=425.8, num_updates=40800, lr=0.000156556, gnorm=0.766, loss_scale=2, train_wall=175, gb_free=15.2, wall=23282
pred_new.size(): torch.Size([4730, 42808])
ter_threshold: 0.340896
num_accepted / total 28 136
loss token level: tensor(10217.7539, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2944., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 17:10:55 | INFO | train_inner | epoch 005:   4672 / 9060 loss=6.07, nll_loss=3.149, ppl=8.87, wps=7822, ups=0.6, wpb=13004.7, bsz=443.9, num_updates=40900, lr=0.000156365, gnorm=0.763, loss_scale=2, train_wall=166, gb_free=14, wall=23448
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([70, 42808])
2023-09-20 17:13:46 | INFO | train_inner | epoch 005:   4772 / 9060 loss=6.024, nll_loss=3.17, ppl=9, wps=7628.6, ups=0.59, wpb=13036.3, bsz=438.4, num_updates=41000, lr=0.000156174, gnorm=0.754, loss_scale=2, train_wall=171, gb_free=14.7, wall=23619
pred_new.size(): torch.Size([4048, 42808])
2023-09-20 17:16:41 | INFO | train_inner | epoch 005:   4872 / 9060 loss=6.017, nll_loss=3.113, ppl=8.65, wps=7402.5, ups=0.57, wpb=12983.1, bsz=413.8, num_updates=41100, lr=0.000155984, gnorm=0.773, loss_scale=2, train_wall=175, gb_free=15.2, wall=23795
pred_new.size(): torch.Size([1440, 42808])
2023-09-20 17:19:30 | INFO | train_inner | epoch 005:   4972 / 9060 loss=5.977, nll_loss=3.109, ppl=8.63, wps=7704.2, ups=0.59, wpb=12990.1, bsz=418.6, num_updates=41200, lr=0.000155794, gnorm=0.731, loss_scale=2, train_wall=168, gb_free=15.2, wall=23963
lprobs.size(): torch.Size([2560, 42808])
2023-09-20 17:22:19 | INFO | train_inner | epoch 005:   5072 / 9060 loss=5.939, nll_loss=3.102, ppl=8.59, wps=7634.2, ups=0.59, wpb=12921.5, bsz=431.4, num_updates=41300, lr=0.000155606, gnorm=0.747, loss_scale=2, train_wall=169, gb_free=14.8, wall=24132
2023-09-20 17:25:07 | INFO | train_inner | epoch 005:   5172 / 9060 loss=6.04, nll_loss=3.2, ppl=9.19, wps=7691.4, ups=0.59, wpb=12960.1, bsz=405.4, num_updates=41400, lr=0.000155417, gnorm=0.777, loss_scale=2, train_wall=168, gb_free=14.8, wall=24301
2023-09-20 17:27:52 | INFO | train_inner | epoch 005:   5272 / 9060 loss=5.916, nll_loss=3.077, ppl=8.44, wps=7947.1, ups=0.61, wpb=13061.5, bsz=423.7, num_updates=41500, lr=0.00015523, gnorm=0.738, loss_scale=2, train_wall=164, gb_free=15, wall=24465
2023-09-20 17:30:44 | INFO | train_inner | epoch 005:   5372 / 9060 loss=6.051, nll_loss=3.138, ppl=8.8, wps=7591.6, ups=0.58, wpb=13068, bsz=454.3, num_updates=41600, lr=0.000155043, gnorm=0.746, loss_scale=2, train_wall=172, gb_free=15, wall=24637
ter_threshold: 0.341611
num_accepted / total 30 128
loss token level: tensor(10383.8340, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5800., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
2023-09-20 17:33:29 | INFO | train_inner | epoch 005:   5472 / 9060 loss=6.021, nll_loss=3.152, ppl=8.89, wps=7945.1, ups=0.61, wpb=13077.1, bsz=428.8, num_updates=41700, lr=0.000154857, gnorm=0.748, loss_scale=2, train_wall=164, gb_free=14.5, wall=24802
2023-09-20 17:36:17 | INFO | train_inner | epoch 005:   5572 / 9060 loss=5.985, nll_loss=3.125, ppl=8.73, wps=7684.5, ups=0.59, wpb=12933.8, bsz=441.8, num_updates=41800, lr=0.000154672, gnorm=0.762, loss_scale=2, train_wall=168, gb_free=14.7, wall=24970
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([2020, 42808])
pred_new.size(): torch.Size([2610, 42808])
2023-09-20 17:39:05 | INFO | train_inner | epoch 005:   5672 / 9060 loss=5.948, nll_loss=3.141, ppl=8.82, wps=7732.6, ups=0.59, wpb=13023.9, bsz=409.9, num_updates=41900, lr=0.000154487, gnorm=0.789, loss_scale=2, train_wall=168, gb_free=15.5, wall=25139
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3510, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-20 17:41:52 | INFO | train_inner | epoch 005:   5772 / 9060 loss=6.029, nll_loss=3.13, ppl=8.75, wps=7798.1, ups=0.6, wpb=13020.5, bsz=434, num_updates=42000, lr=0.000154303, gnorm=0.762, loss_scale=2, train_wall=167, gb_free=14.4, wall=25306
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3440, 42808])
2023-09-20 17:44:42 | INFO | train_inner | epoch 005:   5872 / 9060 loss=6.065, nll_loss=3.162, ppl=8.95, wps=7610.6, ups=0.59, wpb=12900.5, bsz=432.1, num_updates=42100, lr=0.00015412, gnorm=0.777, loss_scale=2, train_wall=169, gb_free=15, wall=25475
2023-09-20 17:47:33 | INFO | train_inner | epoch 005:   5972 / 9060 loss=5.964, nll_loss=3.128, ppl=8.74, wps=7503, ups=0.58, wpb=12851.5, bsz=422.6, num_updates=42200, lr=0.000153937, gnorm=0.734, loss_scale=2, train_wall=171, gb_free=15.2, wall=25647
lprobs.size(): torch.Size([3008, 42808])
2023-09-20 17:50:26 | INFO | train_inner | epoch 005:   6072 / 9060 loss=5.985, nll_loss=3.114, ppl=8.66, wps=7486.2, ups=0.58, wpb=12978.2, bsz=431.4, num_updates=42300, lr=0.000153755, gnorm=0.766, loss_scale=4, train_wall=173, gb_free=14.4, wall=25820
ter_threshold: 0.342354
num_accepted / total 25 112
loss token level: tensor(9381.6016, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2992., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3256, 42808])
2023-09-20 17:53:16 | INFO | train_inner | epoch 005:   6172 / 9060 loss=5.985, nll_loss=3.143, ppl=8.84, wps=7616.6, ups=0.59, wpb=12951.4, bsz=424.6, num_updates=42400, lr=0.000153574, gnorm=0.803, loss_scale=4, train_wall=170, gb_free=13.9, wall=25990
2023-09-20 17:56:09 | INFO | train_inner | epoch 005:   6272 / 9060 loss=5.993, nll_loss=3.131, ppl=8.76, wps=7543.3, ups=0.58, wpb=13007.8, bsz=417.4, num_updates=42500, lr=0.000153393, gnorm=0.765, loss_scale=4, train_wall=172, gb_free=14.6, wall=26162
2023-09-20 17:59:00 | INFO | train_inner | epoch 005:   6372 / 9060 loss=5.984, nll_loss=3.111, ppl=8.64, wps=7559.6, ups=0.58, wpb=12971.6, bsz=429, num_updates=42600, lr=0.000153213, gnorm=0.75, loss_scale=4, train_wall=171, gb_free=14.8, wall=26334
lprobs.size(): torch.Size([3080, 42808])
2023-09-20 18:01:56 | INFO | train_inner | epoch 005:   6472 / 9060 loss=6.078, nll_loss=3.176, ppl=9.04, wps=7390.9, ups=0.57, wpb=12988.7, bsz=428.5, num_updates=42700, lr=0.000153033, gnorm=0.801, loss_scale=4, train_wall=175, gb_free=14.7, wall=26510
pred_new.size(): torch.Size([258, 42808])
ter_threshold: 0.342758
num_accepted / total 32 104
loss token level: tensor(9687.8281, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4680., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 18:04:53 | INFO | train_inner | epoch 005:   6572 / 9060 loss=5.997, nll_loss=3.139, ppl=8.81, wps=7222.6, ups=0.56, wpb=12785.8, bsz=396.2, num_updates=42800, lr=0.000152854, gnorm=0.768, loss_scale=4, train_wall=177, gb_free=15.7, wall=26687
2023-09-20 18:07:40 | INFO | train_inner | epoch 005:   6672 / 9060 loss=6.059, nll_loss=3.152, ppl=8.89, wps=7725.4, ups=0.6, wpb=12910.5, bsz=420.5, num_updates=42900, lr=0.000152676, gnorm=0.798, loss_scale=4, train_wall=167, gb_free=14.7, wall=26854
2023-09-20 18:10:31 | INFO | train_inner | epoch 005:   6772 / 9060 loss=6.064, nll_loss=3.173, ppl=9.02, wps=7635.1, ups=0.58, wpb=13059, bsz=448.4, num_updates=43000, lr=0.000152499, gnorm=0.74, loss_scale=4, train_wall=171, gb_free=15.1, wall=27025
2023-09-20 18:13:18 | INFO | train_inner | epoch 005:   6872 / 9060 loss=6.009, nll_loss=3.099, ppl=8.57, wps=7853.9, ups=0.6, wpb=13088.4, bsz=450.7, num_updates=43100, lr=0.000152322, gnorm=0.766, loss_scale=4, train_wall=166, gb_free=14, wall=27192
2023-09-20 18:16:05 | INFO | train_inner | epoch 005:   6972 / 9060 loss=5.982, nll_loss=3.132, ppl=8.77, wps=7720.2, ups=0.6, wpb=12889.2, bsz=418.6, num_updates=43200, lr=0.000152145, gnorm=0.752, loss_scale=4, train_wall=167, gb_free=14.5, wall=27358
pred_new.size(): torch.Size([2210, 42808])
2023-09-20 18:19:02 | INFO | train_inner | epoch 005:   7072 / 9060 loss=6.044, nll_loss=3.128, ppl=8.74, wps=7370.5, ups=0.56, wpb=13047.9, bsz=433.6, num_updates=43300, lr=0.000151969, gnorm=0.755, loss_scale=4, train_wall=177, gb_free=13.1, wall=27536
pred_new.size(): torch.Size([1798, 42808])
2023-09-20 18:21:46 | INFO | train_inner | epoch 005:   7172 / 9060 loss=6.038, nll_loss=3.136, ppl=8.79, wps=7972.2, ups=0.61, wpb=13054.1, bsz=443.5, num_updates=43400, lr=0.000151794, gnorm=0.732, loss_scale=4, train_wall=163, gb_free=13.8, wall=27699
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([1775, 42808])
ter_threshold: 0.33493799999999996
num_accepted / total 12 96
loss token level: tensor(11298.4082, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1831., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.33505399999999996
num_accepted / total 18 80
loss token level: tensor(9787.2188, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6384., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1200, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.335315
num_accepted / total 5 72
loss token level: tensor(9853.3604, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1682., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([900, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.33577799999999997
num_accepted / total 3 96
loss token level: tensor(11475.2227, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(466., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([3822, 42808])
pred_new.size(): torch.Size([660, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([2950, 42808])
pred_new.size(): torch.Size([3212, 42808])
ter_threshold: 0.336066
num_accepted / total 10 72
loss token level: tensor(9670.8535, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2182., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2829, 42808])
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([3645, 42808])
ter_threshold: 0.33638
num_accepted / total 65 160
loss token level: tensor(9071.9961, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5552., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([2958, 42808])
pred_new.size(): torch.Size([615, 42808])
lprobs.size(): torch.Size([3444, 42808])
pred_new.size(): torch.Size([2100, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([1288, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([558, 42808])
ter_threshold: 0.337622
num_accepted / total 17 72
loss token level: tensor(9229.0547, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3576., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1764, 42808])
lprobs.size(): torch.Size([2416, 42808])
pred_new.size(): torch.Size([1824, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([420, 42808])
ter_threshold: 0.338728
num_accepted / total 25 112
loss token level: tensor(9920.4824, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3288., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.338858
num_accepted / total 9 80
loss token level: tensor(10159.8047, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2744., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([1050, 42808])
pred_new.size(): torch.Size([2850, 42808])
pred_new.size(): torch.Size([3276, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4459, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3317, 42808])
pred_new.size(): torch.Size([1560, 42808])
lprobs.size(): torch.Size([2544, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([1656, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.340172
num_accepted / total 18 80
loss token level: tensor(9277.5176, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3216., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([770, 42808])
pred_new.size(): torch.Size([1533, 42808])
pred_new.size(): torch.Size([336, 42808])
pred_new.size(): torch.Size([250, 42808])
ter_threshold: 0.340534
num_accepted / total 59 184
loss token level: tensor(9349.8789, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7252., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.340896
num_accepted / total 14 136
loss token level: tensor(9197.9336, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1095., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([448, 42808])
pred_new.size(): torch.Size([756, 42808])
ter_threshold: 0.341574
num_accepted / total 7 16
loss token level: tensor(8988.1191, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5744., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.341611
num_accepted / total 49 136
loss token level: tensor(9869.5498, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8728., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.341781
num_accepted / total 4 96
loss token level: tensor(9057.4434, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(440.5000, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.34188799999999997
num_accepted / total 10 64
loss token level: tensor(9472.9805, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2496., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2535, 42808])
pred_new.size(): torch.Size([3367, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([2214, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([1120, 42808])
lprobs.size(): torch.Size([3256, 42808])
ter_threshold: 0.342354
num_accepted / total 43 136
loss token level: tensor(9426.0625, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4640., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2280, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2600, 42808])
pred_new.size(): torch.Size([980, 42808])
pred_new.size(): torch.Size([420, 42808])
pred_new.size(): torch.Size([4440, 42808])
ter_threshold: 0.342758
num_accepted / total 63 184
loss token level: tensor(9879.3584, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4896., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.34277
num_accepted / total 15 168
loss token level: tensor(13088.4639, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2254., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([570, 42808])
pred_new.size(): torch.Size([666, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3400, 42808])
ter_threshold: 0.34345
num_accepted / total 13 112
loss token level: tensor(12883.1523, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1736., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3240, 42808])
lprobs.size(): lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.34345
num_accepted / total 160 296
loss token level: tensor(9625.1182, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6816., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([129, 42808])
2023-09-20 18:24:38 | INFO | train_inner | epoch 005:   7272 / 9060 loss=6.01, nll_loss=3.113, ppl=8.65, wps=7507.9, ups=0.58, wpb=12953.5, bsz=407.1, num_updates=43500, lr=0.00015162, gnorm=0.767, loss_scale=4, train_wall=172, gb_free=15.1, wall=27872
2023-09-20 18:27:27 | INFO | train_inner | epoch 005:   7372 / 9060 loss=6.043, nll_loss=3.148, ppl=8.86, wps=7678.6, ups=0.59, wpb=12979.7, bsz=416.7, num_updates=43600, lr=0.000151446, gnorm=0.758, loss_scale=4, train_wall=169, gb_free=14.5, wall=28041
2023-09-20 18:30:23 | INFO | train_inner | epoch 005:   7472 / 9060 loss=6.096, nll_loss=3.154, ppl=8.9, wps=7406.5, ups=0.57, wpb=13033.2, bsz=419.4, num_updates=43700, lr=0.000151272, gnorm=0.788, loss_scale=4, train_wall=176, gb_free=15.3, wall=28217
2023-09-20 18:33:24 | INFO | train_inner | epoch 005:   7572 / 9060 loss=6.114, nll_loss=3.153, ppl=8.89, wps=7179.9, ups=0.55, wpb=13007.2, bsz=458.6, num_updates=43800, lr=0.000151099, gnorm=0.788, loss_scale=4, train_wall=181, gb_free=14.5, wall=28398
torch.Size([2740, 42808])
pred_new.size(): torch.Size([1992, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([2080, 42808])
pred_new.size(): torch.Size([2223, 42808])
ter_threshold: 0.33638
num_accepted / total 93 184
loss token level: tensor(9663.6074, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7112., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([864, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2142, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.337237
num_accepted / total 10 88
loss token level: tensor(10583.4326, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1790., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([936, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([2565, 42808])
ter_threshold: 0.337622
num_accepted / total 5 64
loss token level: tensor(8346.4863, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1053., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3990, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.33810799999999996
num_accepted / total 19 88
loss token level: tensor(9690.8857, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5392., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2304, 42808])
pred_new.size(): torch.Size([1519, 42808])
pred_new.size(): torch.Size([1910, 42808])
lprobs.size(): torch.Size([3296, 42808])
ter_threshold: 0.33858699999999997
num_accepted / total 10 64
loss token level: tensor(9945.9277, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2322., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([185, 42808])
ter_threshold: 0.338728
num_accepted / total 43 136
loss token level: tensor(9401.1641, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4252., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([560, 42808])
pred_new.size(): torch.Size([1102, 42808])
lprobs.size(): torch.Size([3072, 42808])
ter_threshold: 0.339229
num_accepted / total 13 112
loss token level: tensor(12104.6816, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3236., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3150, 42808])
ter_threshold: 0.33924899999999997
num_accepted / total 134 296
loss token level: tensor(9032.6641, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9120., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3880, 42808])
pred_new.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1530, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([2405, 42808])
ter_threshold: 0.33943599999999996
num_accepted / total 16 128
loss token level: tensor(11976.9229, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3016., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.339801
num_accepted / total 3 72
loss token level: tensor(9940.1895, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1070., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([470, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([4170, 42808])
pred_new.size(): torch.Size([104, 42808])
ter_threshold: 0.340654
num_accepted / total 61 192
loss token level: tensor(9455.9365, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7048., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([2976, 42808])
ter_threshold: 0.340896
num_accepted / total 32 136
loss token level: tensor(9814.3496, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3204., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.341065
num_accepted / total 5 56
loss token level: tensor(9952.6016, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1234., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3016, 42808])
ter_threshold: 0.341586
num_accepted / total 49 184
loss token level: tensor(9283.7734, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3652., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.341611
num_accepted / total 8 104
loss token level: tensor(10666., device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1990., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3185, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.34173
num_accepted / total 275 352
loss token level: tensor(8390.9062, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9568., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.341781
num_accepted / total 2 64
loss token level: tensor(9583.0078, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(265.7500, device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4917, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3978, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2244, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2250, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1088, 42808])
ter_threshold: 0.342534
num_accepted / total 80 232
loss token level: tensor(10117.3838, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4556., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([3800, 42808])
ter_threshold: 0.342758
num_accepted / total 38 128
loss token level: tensor(9497.7930, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4600., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.343231
num_accepted / total 0 88
loss token level: tensor(13952.8672, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: 0
pred_new.size(): torch.Size([540, 42808])
pred_new.size(): torch.Size([1856, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.34345
num_accepted / total 56 160
loss token level: tensor(10258.4590, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4888., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([602, 42808])
lprobs.size(): torch.Size([2840, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([528, 42808])
ter_threshold: 0.34388199999999997
num_accepted / total 7 96
loss token level: tensor(10603.3223, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: ter_threshold: 0.34388199999999997
num_accepted / total 104 224
loss token level: tensor(9668.8135, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6080., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 18:36:05 | INFO | train_inner | epoch 005:   7672 / 9060 loss=6.022, nll_loss=3.142, ppl=8.82, wps=8038.8, ups=0.62, wpb=12917.5, bsz=418, num_updates=43900, lr=0.000150927, gnorm=0.751, loss_scale=4, train_wall=160, gb_free=14.4, wall=28559
pred_new.size(): torch.Size([992, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3072, 42808])
2023-09-20 18:38:57 | INFO | train_inner | epoch 005:   7772 / 9060 loss=5.991, nll_loss=3.123, ppl=8.71, wps=7536.5, ups=0.58, wpb=12981.7, bsz=431, num_updates=44000, lr=0.000150756, gnorm=0.762, loss_scale=4, train_wall=172, gb_free=15.1, wall=28731
pred_new.size(): torch.Size([441, 42808])
2023-09-20 18:41:48 | INFO | train_inner | epoch 005:   7872 / 9060 loss=5.96, nll_loss=3.097, ppl=8.56, wps=7592.5, ups=0.58, wpb=12980.4, bsz=430.5, num_updates=44100, lr=0.000150585, gnorm=0.763, loss_scale=4, train_wall=171, gb_free=14.2, wall=28902
2023-09-20 18:44:42 | INFO | train_inner | epoch 005:   7972 / 9060 loss=6.111, nll_loss=3.152, ppl=8.89, wps=7505.7, ups=0.57, wpb=13057.5, bsz=438.4, num_updates=44200, lr=0.000150414, gnorm=0.811, loss_scale=4, train_wall=174, gb_free=14.6, wall=29076
2023-09-20 18:47:29 | INFO | train_inner | epoch 005:   8072 / 9060 loss=6.081, nll_loss=3.191, ppl=9.13, wps=7757.9, ups=0.6, wpb=12908, bsz=456, num_updates=44300, lr=0.000150244, gnorm=0.751, loss_scale=4, train_wall=166, gb_free=15.4, wall=29242
2023-09-20 18:50:29 | INFO | train_inner | epoch 005:   8172 / 9060 loss=6.038, nll_loss=3.096, ppl=8.55, wps=7287.1, ups=0.56, wpb=13123, bsz=448.3, num_updates=44400, lr=0.000150075, gnorm=0.735, loss_scale=4, train_wall=180, gb_free=14.8, wall=29422
lprobs.size(): torch.Size([3408, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1820, 42808])
2023-09-20 18:53:23 | INFO | train_inner | epoch 005:   8272 / 9060 loss=6.016, nll_loss=3.149, ppl=8.87, wps=7400.8, ups=0.57, wpb=12872.9, bsz=432.6, num_updates=44500, lr=0.000149906, gnorm=0.787, loss_scale=4, train_wall=174, gb_free=14.5, wall=29596
pred_new.size(): torch.Size([465, 42808])
2023-09-20 18:56:10 | INFO | train_inner | epoch 005:   8372 / 9060 loss=6.087, nll_loss=3.154, ppl=8.9, wps=7787.7, ups=0.6, wpb=13023.1, bsz=428.4, num_updates=44600, lr=0.000149738, gnorm=0.782, loss_scale=4, train_wall=167, gb_free=14.4, wall=29763
ter_threshold: 0.344615
num_accepted / total 20 128
loss token level: tensor(12680.6230, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2392., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([2175, 42808])
2023-09-20 18:59:02 | INFO | train_inner | epoch 005:   8472 / 9060 loss=6.139, nll_loss=3.199, ppl=9.18, wps=7563, ups=0.58, wpb=13037.9, bsz=421.2, num_updates=44700, lr=0.000149571, gnorm=0.781, loss_scale=4, train_wall=172, gb_free=14.4, wall=29936
ter_threshold: 0.344751
num_accepted / total 55 176
loss token level: tensor(8565.9121, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3892., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3024, 42808])
2023-09-20 19:01:56 | INFO | train_inner | epoch 005:   8572 / 9060 loss=5.993, nll_loss=3.126, ppl=8.73, wps=7473.9, ups=0.58, wpb=12969, bsz=431.7, num_updates=44800, lr=0.000149404, gnorm=0.741, loss_scale=4, train_wall=173, gb_free=14.2, wall=30109
lprobs.size(): torch.Size([3304, 42808])
ter_threshold: 0.344813
num_accepted / total 36 152
loss token level: tensor(8301.1543, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3636., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([460, 42808])
2023-09-20 19:04:44 | INFO | train_inner | epoch 005:   8672 / 9060 loss=6.071, nll_loss=3.175, ppl=9.03, wps=7703.4, ups=0.59, wpb=12961.1, bsz=439.8, num_updates=44900, lr=0.000149237, gnorm=0.785, loss_scale=4, train_wall=168, gb_free=14.5, wall=30278
pred_new.size(): torch.Size([4514, 42808])
2023-09-20 19:07:36 | INFO | train_inner | epoch 005:   8772 / 9060 loss=5.983, nll_loss=3.137, ppl=8.8, wps=7525.8, ups=0.58, wpb=12900.9, bsz=399.7, num_updates=45000, lr=0.000149071, gnorm=0.809, loss_scale=4, train_wall=171, gb_free=14.6, wall=30449
ter_threshold: 0.345084
num_accepted / total 19 88
loss token level: tensor(10017.1777, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5816., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 19:10:19 | INFO | train_inner | epoch 005:   8872 / 9060 loss=6.037, nll_loss=3.149, ppl=8.87, wps=7929.3, ups=0.61, wpb=12992, bsz=417.2, num_updates=45100, lr=0.000148906, gnorm=0.749, loss_scale=4, train_wall=164, gb_free=14.2, wall=30613
ter_threshold: 0.345107
num_accepted / total 4 48
loss token level: tensor(9705.9824, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2404., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([522, 42808])
lprobs.size(): torch.Size([3216, 42808])
2023-09-20 19:13:03 | INFO | train_inner | epoch 005:   8972 / 9060 loss=6.12, nll_loss=3.213, ppl=9.27, wps=7922.8, ups=0.61, wpb=12936.1, bsz=420.4, num_updates=45200, lr=0.000148741, gnorm=0.782, loss_scale=4, train_wall=163, gb_free=14.6, wall=30776
pred_new.size(): torch.Size([2250, 42808])
2023-09-20 19:15:34 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-20 19:15:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 19:15:35 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-20 19:15:35 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-20 19:15:35 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-20 19:15:35 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-20 19:15:36 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-20 19:15:36 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-20 19:15:36 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-20 19:15:36 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-20 19:15:37 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Ansicht nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-20 19:15:37 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-20 19:15:37 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein regnerischer Erfolg.
2023-09-20 19:15:37 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-20 19:15:38 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Frohes neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-20 19:15:38 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-20 19:15:38 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, und das respektieren wir.
2023-09-20 19:15:38 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-20 19:15:39 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-20 19:15:39 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-20 19:15:39 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Firmen- als auch für Freizeitreisende attraktiv sind.
2023-09-20 19:15:39 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-20 19:15:40 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-20 19:15:40 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-20 19:15:40 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 19:15:40 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 19:15:41 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU große Mengen an Energie verschwendet.
2023-09-20 19:15:41 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-20 19:15:41 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin trägt einen Artikel von Gentoo Entwickler Michael Kohl in seiner neuesten Nummer.
2023-09-20 19:15:41 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-20 19:15:42 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellung auch bald im Haushalt der Union widerspiegeln.
2023-09-20 19:15:42 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-20 19:15:43 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-20 19:15:43 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-20 19:15:43 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-20 19:15:43 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-20 19:15:44 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-20 19:15:44 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-20 19:15:44 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen wurden gezwungen, ihrem Berufsleben mehr Zeit zu widmen, als sie sich gewünscht hätten?
2023-09-20 19:15:44 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-20 19:15:45 | INFO | fairseq.tasks.translation | example hypothesis: Der größte Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-20 19:15:45 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-20 19:15:45 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-20 19:15:45 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-20 19:15:46 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-20 19:15:46 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-20 19:15:46 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-20 19:15:46 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-20 19:15:47 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potenzielle Käufer dazu bewegen, sich über die Qualität Ihres Services und Ihrer Produkte zu informieren.
2023-09-20 19:15:47 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-20 19:15:48 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in ungenutzte Gebiete begeben, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-20 19:15:48 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-20 19:15:48 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-20 19:15:48 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-20 19:15:49 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-20 19:15:49 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-20 19:15:49 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in etwa 5 Meilen (8 km) Radius des Strip.
2023-09-20 19:15:49 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-20 19:15:50 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-20 19:15:50 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-20 19:15:51 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die Realisierung akustischer, interaktiver oder schriftlicher Tonhandbücher an.
2023-09-20 19:15:51 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-20 19:15:51 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel steht mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck zur Verfügung.
2023-09-20 19:15:51 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-20 19:15:52 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu gewährleisten.
2023-09-20 19:15:52 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-20 19:15:52 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu dem von ihnen in die europäischen Sozialversicherungssysteme gezahlten Geld haben müssen.
2023-09-20 19:15:52 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-20 19:15:53 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-20 19:15:53 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-20 19:15:54 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf allen Rechnerplattformen läuft.
2023-09-20 19:15:54 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-20 19:15:54 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie Sie Ihnen helfen können, qualifizierte Fachkräfte zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche ist.
2023-09-20 19:15:54 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-20 19:15:55 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherische Ideen über niedrigere und transparentere Steuerstrukturen und eine zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-20 19:15:55 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-20 19:15:55 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen Splashutils neu emergen, um korrekt zu funktionieren.
2023-09-20 19:15:55 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-20 19:15:56 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht kaufen oder verkaufen, wenn sie die unten aufgeführten neutralen Auktionshäuser nicht benutzen.
2023-09-20 19:15:56 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-20 19:15:57 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum sich diese Kriterien auf die Anwendung nur innerhalb der Grenzen Europas beschränken sollten.
2023-09-20 19:15:57 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-20 19:15:57 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn die Entlastung der Kommission für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-20 19:15:57 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-20 19:15:58 | INFO | fairseq.tasks.translation | example hypothesis: Dem Vorschlag der Kommission zufolge muss der Rat formelle Standpunkte zu bestimmten Details des Abkommens im Prinzip mit den Vereinigten Staaten einreichen.
2023-09-20 19:15:58 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-20 19:15:58 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder spezielle Edition - unser breites Sortiment an Plastikkindartikeln ist beeindruckend, nicht zuletzt wegen seiner herausragenden Oberfläche.
2023-09-20 19:15:58 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-20 19:15:59 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 19:15:59 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 19:15:59 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx über Sachsituationen zu informieren, die mit diesen AGB nicht kompatibel sind, nachdem er sie bekannt geworden ist.
2023-09-20 19:15:59 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-20 19:16:00 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die die Notwendigkeit institutioneller Veränderungen vorangetrieben und erkannt hat, die sie für eine stärkere Präsenz im Bereich der Außen- und Verteidigungspolitik benötigt.
2023-09-20 19:16:00 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-20 19:16:01 | INFO | fairseq.tasks.translation | example hypothesis: Neben unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-20 19:16:01 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-20 19:16:01 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Prüfung aller Themen erzielt wurden, die derzeit über etwas diskutiert werden, das nur zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-20 19:16:01 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-20 19:16:02 | INFO | fairseq.tasks.translation | example hypothesis: BILSTEIN B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus gesenkten Quellen und Stoßdämpfern für erstklassigen Spaß am Steuer.
2023-09-20 19:16:02 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-20 19:16:03 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal konnte der Berichterstatter die zuweilen unterschiedlichen Meinungen und Beiträge zusammenstellen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenfassen.
2023-09-20 19:16:03 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-20 19:16:03 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm von trockenen elektrostatischen Niederläufern mit einem trockenen ESP für den niedrigeren Leistungsbereich.
2023-09-20 19:16:03 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-20 19:16:04 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, sind Sie bereits in einem fremden Land.
2023-09-20 19:16:04 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-20 19:16:04 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungskraft verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-20 19:16:04 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-20 19:16:05 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren in Kraft sind und sich auf unser Völkergemeinschaft beziehen.
2023-09-20 19:16:05 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-20 19:16:06 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-20 19:16:06 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-20 19:16:06 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-20 19:16:06 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-20 19:16:07 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die zunehmende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-20 19:16:07 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-20 19:16:08 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Notfall gibt es jedoch noch einen anderen: den Notfall, der die Kinder, den schwächsten Sektor der Bevölkerung, betrifft, die ohne Familie, ohne Schutz und ohne Staat zurückgelassen wurden.
2023-09-20 19:16:08 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-20 19:16:08 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Fastens seit 2003 von der EU geregelt ist, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-20 19:16:08 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-20 19:16:09 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei gesetzt ist, nicht innerhalb der ersten erst realisiert ist, dann bleiben alle äußeren Beziehungen durch diesen Mangel an Erkenntnis befleckt.
2023-09-20 19:16:09 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-20 19:16:10 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen.
2023-09-20 19:16:10 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-20 19:16:10 | INFO | fairseq.tasks.translation | example hypothesis: Gesetze, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit geben, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-20 19:16:10 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-20 19:16:11 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-20 19:16:11 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-20 19:16:12 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für eine Klärung des Anhangs.
2023-09-20 19:16:12 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-20 19:16:12 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuß ist außerdem der Ansicht, daß die WTO-Mitgliedsländer eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen haben, und fordert die WTO auf, klar zu sagen, daß Sanktionen der IAO nicht mit den WTO-Verträgen unvereinbar sind.
2023-09-20 19:16:12 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-20 19:16:13 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische öffentlich-rechtliche Rundfunk RTÉ mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben senken und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu senken.
2023-09-20 19:16:13 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-20 19:16:14 | INFO | fairseq.tasks.translation | example hypothesis: Vor diesem Hintergrund hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und ich möchte der Kommission noch einmal zu ihrer besonnenen Haltung gratulieren.
2023-09-20 19:16:14 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-20 19:16:14 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Bürgerschaft oder etwas so Konkretes wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-20 19:16:14 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-20 19:16:15 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen.
2023-09-20 19:16:15 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-20 19:16:16 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 19:16:16 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 19:16:16 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken bedeutet, zu naturalisieren und zu mystisieren, was eine bestimmte Art von Vertragsbeziehung zwischen Einzelpersonen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Bedrohung, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-20 19:16:16 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-20 19:16:17 | INFO | fairseq.tasks.translation | example hypothesis: In der Gemeinschaftsgerichtsbarkeit zu einem Thema, das personenbezogene Daten betrifft, sollte der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise die Bürger Ansprüche geltend machen oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-20 19:16:17 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-20 19:16:18 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er Serie ist eines der lustigsten Autos für unter 50.000 Dollar, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos für Sie ausprobieren.
2023-09-20 19:16:18 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-20 19:16:18 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für seinen ausgezeichneten Bericht danken, und ebenso dem Ausschuß für auswärtige Angelegenheiten, Menschenrechte und Verteidigungspolitik für seine realistische Darstellung der Angelegenheit.
2023-09-20 19:16:18 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-20 19:16:19 | INFO | fairseq.tasks.translation | example hypothesis: Sie müssen Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt (Stew) und den ausgezeichneten Frischwasserfisch probieren: gegrillter Schweinefleisch, Forellen mit Mandeln.
2023-09-20 19:16:19 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-20 19:16:20 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, nicht daran zu erinnern, was eine politische Maßnahme bedeutet, sondern eine Gesamtsicht zu bieten, die es uns ermöglicht, intensiver auf die verschiedenen Fragen einzugehen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-20 19:16:20 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-20 19:16:21 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-20 19:16:21 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-20 19:16:21 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen echten Wohlstand, wo es Arbeitslosigkeit gibt, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit allmählich durch makroökonomische Strategien, steuerliche Maßnahmen und Zwänge, die nicht an die derzeitige Situation vor Ort angepasst sind, untergraben wird.
2023-09-20 19:16:21 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-20 19:16:22 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-20 19:16:22 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-20 19:16:23 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus um die entsprechenden Konsequenzen für den rechtlichen und justiziellen Bereich, wodurch Norwegen und Island Länder werden, in denen die gemeinsamen Auslieferungsregeln des Schengen-Besitzstands gelten.
2023-09-20 19:16:23 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-20 19:16:23 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Make-Shift-Boot den Mississippi hinunterfahren, nach dem großen verborgenen Schatz suchen, in die Liebe zum schönen Becky Thatcher verfallen, der rein dynamisch ist, und vor allem werden wir große Freunde sein.
2023-09-20 19:16:23 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-20 19:16:24 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Schiffe verursachten Verschmutzung durch Einzelpersonen oder juristische Personen, den Anwendungsbereich der Antwort und den strafrechtlichen Charakter der Sanktionen, die bei Verletzungen durch Einzelpersonen verhängt werden können.
2023-09-20 19:16:24 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-20 19:16:25 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falization und Vincent Reynaud wurden in der Tat einfach dafür verurteilt, dass sie ihre Arbeit als Journalisten und Kameramänner ausführen und eine Gruppe von Bergregionen filmen, die seit Jahren von einem autoritären Regime verfolgt wurden, das jedes Prinzip der Demokratie missachtet.
2023-09-20 19:16:25 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-20 19:16:26 | INFO | fairseq.tasks.translation | example hypothesis: Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel. Das Hotel bietet seinen Gästen eine Empfangshalle, einen Friseursalon, einen Friseursalon und einen Schönheitssalon, einen Verkehrs- und Sightseeing-Service, einen Wechselstube, einen kostenfreien Schuhsalon und WLAN-Internetzugang.
2023-09-20 19:16:26 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-20 19:16:27 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen dem Thermalquellen verdankt, das von Königin D. Leonor, Ehefrau von König D. João II, und bekannt durch ihre Keramiken, die international für ihre bildlichen und satirischen Werke bekannt sind, sehr geschätzt wird, ist es auch einen Besuch wert.
2023-09-20 19:16:27 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-20 19:16:27 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute Pro-Westerner auf der einen Seite und Anhänger des früheren Regimes auf der anderen Seite handelt - auch das ist verwerflich, da die Rolle aller, jetzt und davor, bekannt ist.
2023-09-20 19:16:27 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-20 19:16:28 | INFO | fairseq.tasks.translation | example hypothesis: Ich weiß, sagen wir es, aber ich muss darauf hinweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer reisen, auf diese Weise nicht abgedeckt sind, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-20 19:16:28 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-20 19:16:29 | INFO | fairseq.tasks.translation | example hypothesis: (4) Sofern Informationen aus Gründen seines Status als Gesellschafter außerhalb einer Aktionärsversammlung an einen Gesellschafter weitergegeben wurden, werden diese Informationen auf Anforderung an jeden anderen Gesellschafter in der Aktionärsversammlung zur Verfügung gestellt, auch wenn solche Informationen nicht notwendig sind, um eine ordnungsgemäße Bewertung eines Elements auf der Tagesordnung zu ermöglichen.
2023-09-20 19:16:29 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-20 19:16:30 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch die nachfolgende Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme fließen, die in der Regel in die Taschen verschiedener Diktatoren gelangen und ihren feinen Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr miserables Leben führen.
2023-09-20 19:16:30 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-20 19:16:31 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder die NATO an diesem Kriegsakt beteiligt gewesen sein könnten -, bei der Information zu helfen, die es keinen Grund mehr gibt, geheim, verschwiegen oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-20 19:16:31 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-20 19:16:32 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom Bahnhof Waidmannslust S-Bahn und 30 Minuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer des Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 19:16:32 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 19:16:33 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich und unserer Business Unit Defence Electronics und Indra in Spanien wird der Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die modernen nicht-der-Regal-Plattformen niemals erreichen können.
2023-09-20 19:16:33 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-20 19:16:33 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen unmissverständlich klarstellen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit jene Produkte aus dem Markt zu nehmen, die ein ernsthaftes Risiko darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-20 19:16:33 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-20 19:16:34 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem bloßen Plot der Moderne und Postmoderne oder der klaren Opposition reiner Kunst und engagierter Kunst müssen wir die ursprünglichen und dauerhaften Spannungen dieser beiden ästhetischen Politik erkennen, die in eben den Formen der Sichtbarkeit und Verständbarkeit verstrickt sind, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztendlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-20 19:16:34 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-20 19:16:35 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werden wir angesichts der Bedeutung der Aussprachen und angesichts der Meinungen, die Sie mir gegeben haben, die eindeutig weitgehend unterstützen, was ich gerade gesagt habe, und auf der Grundlage der früheren Entscheidungen werden wir unsere Aussprachen führen, und wenn es um die Abstimmung geht, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht darum bitten, die Beschlussfähigkeit zu überprüfen.
2023-09-20 19:16:35 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-20 19:16:36 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips niemals akzeptiert haben, sind es paradoxerweise genau diejenigen, die kaum jemand weiß, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem nationale Grenzen entfernt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt ermöglichen.
2023-09-20 19:16:36 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-20 19:16:37 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Hinsicht als Hybridform veröffentlicht, die Rezensionen und Artikel der Quartalzeitschrift für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Webseiten des Berlin-basierten H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten weitergegeben.
2023-09-20 19:16:37 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-20 19:16:38 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone ihre Federn nicht nur deutlich verfeinert, sondern konnten sich von einst schlauen Taschenlampen bis hin zu polyphonisch tootternden Game Boy-Sehnsümpfen bis hin zu schrägen Mini-PCs mit knackigem CD-Qualität-Stereo-Sound fortan, dank ihrer besonderen Kombination von Fähigkeiten, von den ehemaligen mir-zu-Wannabes bis hin zu Trailblazern neuer technologischer Entwicklungen, von den früheren mir-zu wannabes.
2023-09-20 19:16:38 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-20 19:16:40 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dirigia de la defensa de la base humana en Pandora, Kloster a Jake para que le proportionedad información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se marchen. En un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y da se cuenta de éstás renarás, su tiera unausweichlich hun hun mesa; en un mado de la demejor; en la demejor.
2023-09-20 19:16:40 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-20 19:16:41 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 4.318 | nll_loss 2.32 | ppl 4.99 | bleu 28.5 | wps 17799.6 | wpb 12011.9 | bsz 398.1 | num_updates 45288 | best_bleu 28.5
2023-09-20 19:16:41 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 45288 updates
2023-09-20 19:16:41 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint5.pt
2023-09-20 19:16:47 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint5.pt
2023-09-20 19:16:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint5.pt (epoch 5 @ 45288 updates, score 28.5) (writing took 14.654833126987796 seconds)
2023-09-20 19:16:56 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2023-09-20 19:16:56 | INFO | train | epoch 005 | loss 6.027 | nll_loss 3.14 | ppl 8.82 | wps 7573.2 | ups 0.58 | wpb 12977.1 | bsz 430.6 | num_updates 45288 | lr 0.000148596 | gnorm 0.768 | loss_scale 4 | train_wall 15418 | gb_free 13.8 | wall 31009
2023-09-20 19:16:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 19:16:56 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-20 19:16:56 | INFO | fairseq.trainer | begin training epoch 6
2023-09-20 19:16:56 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-20 19:17:16 | INFO | train_inner | epoch 006:     12 / 9060 loss=6.026, nll_loss=3.154, ppl=8.9, wps=5106.3, ups=0.39, wpb=12940.2, bsz=418.4, num_updates=45300, lr=0.000148577, gnorm=0.745, loss_scale=4, train_wall=172, gb_free=14.3, wall=31030
2023-09-20 19:20:05 | INFO | train_inner | epoch 006:    112 / 9060 loss=5.959, nll_loss=3.033, ppl=8.19, wps=7713.4, ups=0.59, wpb=12999.4, bsz=431.3, num_updates=45400, lr=0.000148413, gnorm=0.725, loss_scale=4, train_wall=168, gb_free=14.1, wall=31198
ter_threshold: 0.335315
num_accepted / total 2 72
loss token level: tensor(10178.7119, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(778., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.335517
num_accepted / total 14 64
loss token level: tensor(8754.4033, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5756., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.335714
num_accepted / total 9 80
loss token level: tensor(9062.9258, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1615., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.33577799999999997
num_accepted / total 55 208
loss token level: tensor(10245.6396, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3852., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1890, 42808])
lprobs.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([1980, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2904, 42808])
ter_threshold: 0.33638
num_accepted / total 19 88
loss token level: tensor(9954.9707, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3342., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([492, 42808])
ter_threshold: 0.336435
num_accepted / total 40 152
loss token level: tensor(8675.0986, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5704., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([600, 42808])
pred_new.size(): torch.Size([106, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([728, 42808])
ter_threshold: 0.33823
num_accepted / total 1 32
loss token level: tensor(8229.2959, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(779., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1386, 42808])
pred_new.size(): torch.Size([1430, 42808])
ter_threshold: 0.338728
num_accepted / total 30 136
loss token level: tensor(10220.1426, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3082., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([1260, 42808])
pred_new.size(): torch.Size([696, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([2958, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1386, 42808])
ter_threshold: 0.33924899999999997
num_accepted / total 11 104
loss token level: tensor(10012.1836, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2724., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2240, 42808])
ter_threshold: 0.3393
num_accepted / total 6 56
loss token level: tensor(9253.8828, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1279., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2211, 42808])
pred_new.size(): torch.Size([1944, 42808])
pred_new.size(): torch.Size([1016, 42808])
ter_threshold: 0.33943599999999996
num_accepted / total 35 120
loss token level: tensor(9334.9736, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7352., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([798, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3232, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([1078, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([996, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([2828, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.340654
num_accepted / total 24 144
loss token level: tensor(8794.5918, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3184., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([480, 42808])
pred_new.size(): torch.Size([3534, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([138, 42808])
pred_new.size(): torch.Size([300, 42808])
lprobs.size(): torch.Size([2688, 42808])
ter_threshold: 0.341781
num_accepted / total 35 112
loss token level: tensor(9458.1133, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3816., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3402, 42808])
pred_new.size(): torch.Size([1155, 42808])
pred_new.size(): torch.Size([2613, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1924, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([1022, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([600, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([3052, 42808])
ter_threshold: 0.34277
num_accepted / total 3 72
loss token level: tensor(8252.3584, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(850., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([616, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([2040, 42808])
pred_new.size(): torch.Size([2220, 42808])
lprobs.size(): torch.Size([3408, 42808])
pred_new.size(): torch.Size([2860, 42808])
ter_threshold: 0.343895
num_accepted / total 7 48
loss token level: tensor(9988.1113, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2286., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([760, 42808])
lprobs.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([396, 42808])
pred_new.size(): torch.Size([1520, 42808])
pred_new.size(): torch.Size([483, 42808])
ter_threshold: 0.344615
num_accepted / total 29 104
loss token level: tensor(9145.7207, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4136., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.344813
num_accepted / total 20 120
loss token level: tensor(9558.6914, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4332., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.344858
num_accepted / total 17 104
loss token level: tensor(9601.6719, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3286., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1352, 42808])
pred_new.size(): torch.Size([1280, 42808])
ter_threshold: 0.345084
num_accepted / total 68 176
loss token level: tensor(9199.1445, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8368., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([580, 42808])
pred_new.size(): torch.Size([1298, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2916, 42808])
lprobs.size(): torch.Size([2640, 42808])
ter_threshold: 0.34549399999999997
lprobs.size(): torch.Size([3240, 42808])
2023-09-20 19:23:04 | INFO | train_inner | epoch 006:    212 / 9060 loss=6.121, nll_loss=3.103, ppl=8.59, wps=7243.1, ups=0.56, wpb=12993.4, bsz=451, num_updates=45500, lr=0.00014825, gnorm=0.781, loss_scale=4, train_wall=179, gb_free=13.9, wall=31378
2023-09-20 19:25:58 | INFO | train_inner | epoch 006:    312 / 9060 loss=6.154, nll_loss=3.138, ppl=8.8, wps=7472.8, ups=0.57, wpb=13025.4, bsz=450.6, num_updates=45600, lr=0.000148087, gnorm=0.761, loss_scale=4, train_wall=174, gb_free=14.7, wall=31552
2023-09-20 19:28:53 | INFO | train_inner | epoch 006:    412 / 9060 loss=6.192, nll_loss=3.206, ppl=9.23, wps=7385, ups=0.57, wpb=12890.6, bsz=426.6, num_updates=45700, lr=0.000147925, gnorm=0.812, loss_scale=4, train_wall=174, gb_free=15.4, wall=31726
pred_new.size(): torch.Size([3565, 42808])
2023-09-20 19:31:45 | INFO | train_inner | epoch 006:    512 / 9060 loss=6.069, nll_loss=3.119, ppl=8.69, wps=7453.4, ups=0.58, wpb=12828.4, bsz=400, num_updates=45800, lr=0.000147764, gnorm=0.795, loss_scale=4, train_wall=172, gb_free=15.2, wall=31898
pred_new.size(): torch.Size([660, 42808])
2023-09-20 19:34:35 | INFO | train_inner | epoch 006:    612 / 9060 loss=5.98, nll_loss=3.096, ppl=8.55, wps=7671.8, ups=0.59, wpb=13051, bsz=431.9, num_updates=45900, lr=0.000147602, gnorm=0.759, loss_scale=4, train_wall=170, gb_free=14.4, wall=32069
2023-09-20 19:37:25 | INFO | train_inner | epoch 006:    712 / 9060 loss=6, nll_loss=3.088, ppl=8.5, wps=7621.7, ups=0.59, wpb=12974.7, bsz=433, num_updates=46000, lr=0.000147442, gnorm=0.74, loss_scale=4, train_wall=170, gb_free=13.9, wall=32239
2023-09-20 19:40:21 | INFO | train_inner | epoch 006:    812 / 9060 loss=5.983, nll_loss=3.079, ppl=8.45, wps=7449.9, ups=0.57, wpb=13076.3, bsz=427, num_updates=46100, lr=0.000147282, gnorm=0.774, loss_scale=4, train_wall=175, gb_free=15, wall=32414
pred_new.size(): torch.Size([1677, 42808])
pred_new.size(): torch.Size([720, 42808])
2023-09-20 19:43:21 | INFO | train_inner | epoch 006:    912 / 9060 loss=6.08, nll_loss=3.13, ppl=8.75, wps=7083.9, ups=0.56, wpb=12732.2, bsz=424.1, num_updates=46200, lr=0.000147122, gnorm=0.795, loss_scale=4, train_wall=179, gb_free=15, wall=32594
pred_new.size(): torch.Size([2310, 42808])
2023-09-20 19:46:18 | INFO | train_inner | epoch 006:   1012 / 9060 loss=6.052, nll_loss=3.107, ppl=8.61, wps=7347.3, ups=0.56, wpb=13066.8, bsz=423.4, num_updates=46300, lr=0.000146964, gnorm=0.765, loss_scale=4, train_wall=178, gb_free=15.2, wall=32772
2023-09-20 19:49:08 | INFO | train_inner | epoch 006:   1112 / 9060 loss=6.074, nll_loss=3.144, ppl=8.84, wps=7641.8, ups=0.59, wpb=12991.5, bsz=443.3, num_updates=46400, lr=0.000146805, gnorm=0.765, loss_scale=8, train_wall=170, gb_free=15.1, wall=32942
ter_threshold: 0.34642
num_accepted / total 28 104
loss token level: tensor(9395.8418, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3840., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.346421
num_accepted / total 24 96
loss token level: tensor(9623.7314, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3560., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2457, 42808])
lprobs.size(): torch.Size([2392, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 19:52:11 | INFO | train_inner | epoch 006:   1212 / 9060 loss=6.13, nll_loss=3.136, ppl=8.79, wps=7095.9, ups=0.55, wpb=12985.9, bsz=430.7, num_updates=46500, lr=0.000146647, gnorm=0.786, loss_scale=8, train_wall=183, gb_free=15.2, wall=33125
2023-09-20 19:54:57 | INFO | train_inner | epoch 006:   1312 / 9060 loss=6.052, nll_loss=3.154, ppl=8.9, wps=7796.4, ups=0.6, wpb=12903.6, bsz=406.9, num_updates=46600, lr=0.00014649, gnorm=0.763, loss_scale=8, train_wall=165, gb_free=14.8, wall=33290
pred_new.size(): torch.Size([720, 42808])
pred_new.size(): torch.Size([2349, 42808])
2023-09-20 19:57:44 | INFO | train_inner | epoch 006:   1412 / 9060 loss=5.988, nll_loss=3.065, ppl=8.37, wps=7802.6, ups=0.6, wpb=13033.8, bsz=427.8, num_updates=46700, lr=0.000146333, gnorm=0.773, loss_scale=8, train_wall=167, gb_free=14.6, wall=33458
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 20:00:51 | INFO | train_inner | epoch 006:   1512 / 9060 loss=6.045, nll_loss=3.108, ppl=8.62, wps=6918, ups=0.54, wpb=12902.4, bsz=423.2, num_updates=46800, lr=0.000146176, gnorm=0.782, loss_scale=8, train_wall=186, gb_free=14.8, wall=33644
pred_new.size(): torch.Size([2430, 42808])
ter_threshold: 0.346813
num_accepted / total 50 152
loss token level: tensor(8841.5938, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7020., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([192, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 20:03:40 | INFO | train_inner | epoch 006:   1612 / 9060 loss=6.007, nll_loss=3.138, ppl=8.8, wps=7595.5, ups=0.59, wpb=12857.1, bsz=403.1, num_updates=46900, lr=0.00014602, gnorm=0.748, loss_scale=8, train_wall=169, gb_free=15, wall=33813
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-20 20:06:44 | INFO | train_inner | epoch 006:   1712 / 9060 loss=6.013, nll_loss=3.075, ppl=8.43, wps=7035, ups=0.54, wpb=12990.2, bsz=427.2, num_updates=47000, lr=0.000145865, gnorm=0.82, loss_scale=8, train_wall=184, gb_free=14.2, wall=33998
ter_threshold: 0.347009
num_accepted / total 51 168
loss token level: tensor(10067.1992, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7448., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 20:09:37 | INFO | train_inner | epoch 006:   1812 / 9060 loss=6.082, nll_loss=3.14, ppl=8.82, wps=7527.1, ups=0.58, wpb=12998, bsz=421.6, num_updates=47100, lr=0.00014571, gnorm=0.766, loss_scale=8, train_wall=172, gb_free=15.2, wall=34171
lprobs.size(): torch.Size([2520, 42808])
2023-09-20 20:12:23 | INFO | train_inner | epoch 006:   1912 / 9060 loss=6.136, nll_loss=3.151, ppl=8.88, wps=7850.5, ups=0.6, wpb=13014.6, bsz=433.2, num_updates=47200, lr=0.000145556, gnorm=0.769, loss_scale=8, train_wall=166, gb_free=14.3, wall=34336
pred_new.size(): torch.Size([1820, 42808])
2023-09-20 20:15:24 | INFO | train_inner | epoch 006:   2012 / 9060 loss=6.096, nll_loss=3.098, ppl=8.56, wps=7182.8, ups=0.55, wpb=13034.4, bsz=450.1, num_updates=47300, lr=0.000145402, gnorm=0.764, loss_scale=8, train_wall=181, gb_free=13.9, wall=34518
pred_new.size(): torch.Size([1024, 42808])
lprobs.size(): torch.Size([3400, 42808])
2023-09-20 20:18:18 | INFO | train_inner | epoch 006:   2112 / 9060 loss=6.156, nll_loss=3.157, ppl=8.92, wps=7472.8, ups=0.58, wpb=12949.3, bsz=435.5, num_updates=47400, lr=0.000145248, gnorm=0.76, loss_scale=8, train_wall=173, gb_free=14.2, wall=34691
2023-09-20 20:21:12 | INFO | train_inner | epoch 006:   2212 / 9060 loss=6.053, nll_loss=3.105, ppl=8.6, wps=7494.6, ups=0.57, wpb=13075, bsz=432.7, num_updates=47500, lr=0.000145095, gnorm=0.761, loss_scale=8, train_wall=174, gb_free=14.5, wall=34866
2023-09-20 20:23:51 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-20 20:24:04 | INFO | train_inner | epoch 006:   2313 / 9060 loss=6.024, nll_loss=3.119, ppl=8.69, wps=7558.8, ups=0.58, wpb=12984.8, bsz=414.1, num_updates=47600, lr=0.000144943, gnorm=0.769, loss_scale=4, train_wall=172, gb_free=15.2, wall=35037
lprobs.size(): torch.Size([2560, 42808])
pred_new.size(): torch.Size([2925, 42808])
2023-09-20 20:26:51 | INFO | train_inner | epoch 006:   2413 / 9060 loss=6.045, nll_loss=3.145, ppl=8.85, wps=7769.4, ups=0.6, wpb=12943.4, bsz=395.9, num_updates=47700, lr=0.000144791, gnorm=0.771, loss_scale=4, train_wall=166, gb_free=14.2, wall=35204
pred_new.size(): torch.Size([609, 42808])
2023-09-20 20:29:34 | INFO | train_inner | epoch 006:   2513 / 9060 loss=6.039, nll_loss=3.122, ppl=8.71, wps=7969.1, ups=0.61, wpb=12995.7, bsz=421.4, num_updates=47800, lr=0.000144639, gnorm=0.784, loss_scale=4, train_wall=163, gb_free=14.5, wall=35367
pred_new.size(): torch.Size([672, 42808])
lprobs.size(): torch.Size([3552, 42808])
2023-09-20 20:32:28 | INFO | train_inner | epoch 006:   2613 / 9060 loss=6.046, nll_loss=3.119, ppl=8.68, wps=7461.3, ups=0.57, wpb=13011.1, bsz=438.1, num_updates=47900, lr=0.000144488, gnorm=0.74, loss_scale=4, train_wall=174, gb_free=14.4, wall=35541
pred_new.size(): torch.Size([1702, 42808])
lprobs.size(): torch.Size([3496, 42808])
2023-09-20 20:35:28 | INFO | train_inner | epoch 006:   2713 / 9060 loss=6.178, nll_loss=3.173, ppl=9.02, wps=7279, ups=0.56, wpb=13078.3, bsz=442.7, num_updates=48000, lr=0.000144338, gnorm=0.807, loss_scale=4, train_wall=179, gb_free=14.2, wall=35721
pred_new.size(): torch.Size([950, 42808])
2023-09-20 20:38:26 | INFO | train_inner | epoch 006:   2813 / 9060 loss=6.109, nll_loss=3.146, ppl=8.85, wps=7327, ups=0.56, wpb=13037.6, bsz=423.1, num_updates=48100, lr=0.000144187, gnorm=0.859, loss_scale=4, train_wall=178, gb_free=15.2, wall=35899
pred_new.size(): torch.Size([1887, 42808])
2023-09-20 20:41:32 | INFO | train_inner | epoch 006:   2913 / 9060 loss=6.016, nll_loss=3.084, ppl=8.48, wps=6994.1, ups=0.54, wpb=13016, bsz=428.5, num_updates=48200, lr=0.000144038, gnorm=0.763, loss_scale=4, train_wall=186, gb_free=14.5, wall=36085
2023-09-20 20:44:22 | INFO | train_inner | epoch 006:   3013 / 9060 loss=5.985, nll_loss=3.114, ppl=8.65, wps=7654.3, ups=0.59, wpb=13014, bsz=409.8, num_updates=48300, lr=0.000143889, gnorm=0.744, loss_scale=4, train_wall=170, gb_free=15, wall=36255
2023-09-20 20:47:15 | INFO | train_inner | epoch 006:   3113 / 9060 loss=6.034, nll_loss=3.135, ppl=8.78, wps=7470.5, ups=0.58, wpb=12915.2, bsz=441, num_updates=48400, lr=0.00014374, gnorm=0.779, loss_scale=4, train_wall=173, gb_free=14.8, wall=36428
ter_threshold: 0.348444
num_accepted / total 15 96
loss token level: tensor(9835.9229, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4088., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 20:50:11 | INFO | train_inner | epoch 006:   3213 / 9060 loss=6.098, nll_loss=3.146, ppl=8.85, wps=7348.4, ups=0.57, wpb=12964.8, bsz=437.6, num_updates=48500, lr=0.000143592, gnorm=0.786, loss_scale=4, train_wall=176, gb_free=14.8, wall=36604
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([2132, 42808])
2023-09-20 20:53:17 | INFO | train_inner | epoch 006:   3313 / 9060 loss=6.072, nll_loss=3.136, ppl=8.79, wps=6961.8, ups=0.54, wpb=12974.2, bsz=436.2, num_updates=48600, lr=0.000143444, gnorm=0.794, loss_scale=4, train_wall=186, gb_free=14.5, wall=36791
2023-09-20 20:56:13 | INFO | train_inner | epoch 006:   3413 / 9060 loss=6.157, nll_loss=3.139, ppl=8.81, wps=7435.1, ups=0.57, wpb=13021, bsz=422.5, num_updates=48700, lr=0.000143296, gnorm=0.808, loss_scale=4, train_wall=175, gb_free=15.9, wall=36966
pred_new.size(): torch.Size([1496, 42808])
2023-09-20 20:59:11 | INFO | train_inner | epoch 006:   3513 / 9060 loss=6.238, nll_loss=3.176, ppl=9.04, wps=7312.6, ups=0.56, wpb=13041.2, bsz=439.5, num_updates=48800, lr=0.00014315, gnorm=0.795, loss_scale=4, train_wall=178, gb_free=15.2, wall=37144
lprobs.size(): torch.Size([3264, 42808])
2023-09-20 21:02:01 | INFO | train_inner | epoch 006:   3613 / 9060 loss=6.091, nll_loss=3.129, ppl=8.75, wps=7669, ups=0.59, wpb=13010.1, bsz=417.7, num_updates=48900, lr=0.000143003, gnorm=0.766, loss_scale=4, train_wall=169, gb_free=14.2, wall=37314
pred_new.size(): torch.Size([685, 42808])
ter_threshold: 0.34893399999999997
num_accepted / total 8 136
loss token level: tensor(9288.3145, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(614., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 21:04:51 | INFO | train_inner | epoch 006:   3713 / 9060 loss=6.081, nll_loss=3.146, ppl=8.85, wps=7641.9, ups=0.59, wpb=13030.9, bsz=438.4, num_updates=49000, lr=0.000142857, gnorm=0.789, loss_scale=4, train_wall=170, gb_free=14.8, wall=37484
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.349022
num_accepted / total 2 96
loss token level: tensor(9776.5879, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(377.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1460, 42808])
pred_new.size(): torch.Size([3096, 42808])
2023-09-20 21:07:56 | INFO | train_inner | epoch 006:   3813 / 9060 loss=6.09, nll_loss=3.11, ppl=8.64, wps=6975.8, ups=0.54, wpb=12936.7, bsz=459.9, num_updates=49100, lr=0.000142712, gnorm=0.752, loss_scale=4, train_wall=185, gb_free=14.6, wall=37670
2023-09-20 21:10:50 | INFO | train_inner | epoch 006:   3913 / 9060 loss=6.137, nll_loss=3.155, ppl=8.91, wps=7448.6, ups=0.58, wpb=12935.4, bsz=431.8, num_updates=49200, lr=0.000142566, gnorm=0.848, loss_scale=4, train_wall=173, gb_free=14.1, wall=37844
pred_new.size(): torch.Size([4161, 42808])
2023-09-20 21:13:50 | INFO | train_inner | epoch 006:   4013 / 9060 loss=6.221, nll_loss=3.176, ppl=9.04, wps=7261.2, ups=0.56, wpb=13025.6, bsz=457.4, num_updates=49300, lr=0.000142422, gnorm=0.784, loss_scale=4, train_wall=179, gb_free=14.8, wall=38023
2023-09-20 21:16:38 | INFO | train_inner | epoch 006:   4113 / 9060 loss=6.026, nll_loss=3.091, ppl=8.52, wps=7707.8, ups=0.59, wpb=12992.2, bsz=450.2, num_updates=49400, lr=0.000142278, gnorm=0.765, loss_scale=4, train_wall=168, gb_free=15.6, wall=38192
2023-09-20 21:19:33 | INFO | train_inner | epoch 006:   4213 / 9060 loss=6.076, nll_loss=3.135, ppl=8.79, wps=7450.8, ups=0.57, wpb=13022.4, bsz=422.1, num_updates=49500, lr=0.000142134, gnorm=0.781, loss_scale=4, train_wall=175, gb_free=14.7, wall=38366
ter_threshold: 0.349522
num_accepted / total 17 72
loss token level: tensor(9189.3428, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3472., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2718, 42808])
ter_threshold: 0.34954599999999997
num_accepted / total 66 152
loss token level: tensor(9142.7256, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6128., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([196, 42808])
2023-09-20 21:22:29 | INFO | train_inner | epoch 006:   4313 / 9060 loss=6.099, nll_loss=3.116, ppl=8.67, wps=7400, ups=0.57, wpb=13031.6, bsz=431.8, num_updates=49600, lr=0.00014199, gnorm=0.751, loss_scale=4, train_wall=176, gb_free=14.6, wall=38542
lprobs.size(): torch.Size([3136, 42808])
2023-09-20 21:25:22 | INFO | train_inner | epoch 006:   4413 / 9060 loss=6.167, nll_loss=3.2, ppl=9.19, wps=7452.8, ups=0.58, wpb=12869.6, bsz=416.6, num_updates=49700, lr=0.000141848, gnorm=0.798, loss_scale=4, train_wall=172, gb_free=14.7, wall=38715
pred_new.size(): torch.Size([2754, 42808])
lprobs.size(): torch.Size([3264, 42808])
2023-09-20 21:28:15 | INFO | train_inner | epoch 006:   4513 / 9060 loss=6.136, nll_loss=3.161, ppl=8.94, wps=7505.6, ups=0.58, wpb=13017.1, bsz=423.8, num_updates=49800, lr=0.000141705, gnorm=0.78, loss_scale=4, train_wall=173, gb_free=14.5, wall=38889
pred_new.size(): torch.Size([1824, 42808])
2023-09-20 21:31:09 | INFO | train_inner | epoch 006:   4613 / 9060 loss=6.071, nll_loss=3.099, ppl=8.57, wps=7466.9, ups=0.57, wpb=13015.7, bsz=438.1, num_updates=49900, lr=0.000141563, gnorm=0.763, loss_scale=4, train_wall=174, gb_free=14.8, wall=39063
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([2394, 42808])
2023-09-20 21:34:05 | INFO | train_inner | epoch 006:   4713 / 9060 loss=6.024, nll_loss=3.106, ppl=8.61, wps=7417.4, ups=0.57, wpb=13032.4, bsz=427.8, num_updates=50000, lr=0.000141421, gnorm=0.767, loss_scale=4, train_wall=175, gb_free=15.5, wall=39239
2023-09-20 21:36:55 | INFO | train_inner | epoch 006:   4813 / 9060 loss=6.134, nll_loss=3.182, ppl=9.08, wps=7658.8, ups=0.59, wpb=13041.8, bsz=437.7, num_updates=50100, lr=0.00014128, gnorm=0.77, loss_scale=4, train_wall=170, gb_free=14.5, wall=39409
pred_new.size(): torch.Size([2640, 42808])
2023-09-20 21:39:47 | INFO | train_inner | epoch 006:   4913 / 9060 loss=6.073, nll_loss=3.106, ppl=8.61, wps=7601.9, ups=0.58, wpb=13016.5, bsz=448.6, num_updates=50200, lr=0.000141139, gnorm=0.746, loss_scale=4, train_wall=171, gb_free=15.3, wall=39580
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([1596, 42808])
2023-09-20 21:42:48 | INFO | train_inner | epoch 006:   5013 / 9060 loss=6.123, nll_loss=3.121, ppl=8.7, wps=7243.3, ups=0.55, wpb=13102.3, bsz=426.1, num_updates=50300, lr=0.000140999, gnorm=0.806, loss_scale=4, train_wall=181, gb_free=14.7, wall=39761
2023-09-20 21:45:42 | INFO | train_inner | epoch 006:   5113 / 9060 loss=6.097, nll_loss=3.165, ppl=8.97, wps=7394.4, ups=0.57, wpb=12914.3, bsz=403, num_updates=50400, lr=0.000140859, gnorm=0.816, loss_scale=4, train_wall=174, gb_free=14.2, wall=39936
2023-09-20 21:48:45 | INFO | train_inner | epoch 006:   5213 / 9060 loss=6.177, nll_loss=3.209, ppl=9.25, wps=7046.8, ups=0.55, wpb=12904.1, bsz=433.9, num_updates=50500, lr=0.00014072, gnorm=0.814, loss_scale=4, train_wall=183, gb_free=14.5, wall=40119
2023-09-20 21:51:47 | INFO | train_inner | epoch 006:   5313 / 9060 loss=6.147, nll_loss=3.205, ppl=9.22, wps=7088.3, ups=0.55, wpb=12890.6, bsz=431.9, num_updates=50600, lr=0.00014058, gnorm=0.819, loss_scale=4, train_wall=182, gb_free=14.7, wall=40301
ter_threshold: 0.350691
num_accepted / total 53 136
loss token level: tensor(9109.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5400., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2208, 42808])
2023-09-20 21:54:40 | INFO | train_inner | epoch 006:   5413 / 9060 loss=6.093, nll_loss=3.14, ppl=8.82, wps=7540.4, ups=0.58, wpb=13012.2, bsz=425.8, num_updates=50700, lr=0.000140442, gnorm=0.783, loss_scale=4, train_wall=172, gb_free=15.5, wall=40473
pred_new.size(): torch.Size([5040, 42808])
2023-09-20 21:57:37 | INFO | train_inner | epoch 006:   5513 / 9060 loss=6.067, nll_loss=3.147, ppl=8.86, wps=7318.1, ups=0.56, wpb=12964.2, bsz=406.8, num_updates=50800, lr=0.000140303, gnorm=0.752, loss_scale=4, train_wall=177, gb_free=15, wall=40650
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([3640, 42808])
pred_new.size(): torch.Size([2940, 42808])
2023-09-20 22:00:36 | INFO | train_inner | epoch 006:   5613 / 9060 loss=6.127, nll_loss=3.133, ppl=8.78, wps=7190.9, ups=0.56, wpb=12878.7, bsz=423.8, num_updates=50900, lr=0.000140165, gnorm=0.774, loss_scale=4, train_wall=179, gb_free=13.9, wall=40829
2023-09-20 22:03:28 | INFO | train_inner | epoch 006:   5713 / 9060 loss=6.096, nll_loss=3.146, ppl=8.85, wps=7528.3, ups=0.58, wpb=12955.1, bsz=410.8, num_updates=51000, lr=0.000140028, gnorm=0.771, loss_scale=4, train_wall=172, gb_free=14.1, wall=41001
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([1104, 42808])
2023-09-20 22:06:22 | INFO | train_inner | epoch 006:   5813 / 9060 loss=6.129, nll_loss=3.144, ppl=8.84, wps=7466.7, ups=0.57, wpb=13017, bsz=403.9, num_updates=51100, lr=0.000139891, gnorm=0.779, loss_scale=4, train_wall=174, gb_free=14.6, wall=41176
2023-09-20 22:09:26 | INFO | train_inner | epoch 006:   5913 / 9060 loss=6.111, nll_loss=3.146, ppl=8.85, wps=7111, ups=0.54, wpb=13075.2, bsz=432.9, num_updates=51200, lr=0.000139754, gnorm=0.775, loss_scale=4, train_wall=184, gb_free=14.4, wall=41360
pred_new.size(): torch.Size([3915, 42808])
2023-09-20 22:12:34 | INFO | train_inner | epoch 006:   6013 / 9060 loss=6.165, nll_loss=3.144, ppl=8.84, wps=6881.6, ups=0.53, wpb=12948.6, bsz=453.7, num_updates=51300, lr=0.000139618, gnorm=0.802, loss_scale=4, train_wall=188, gb_free=14.7, wall=41548
pred_new.size(): torch.Size([2660, 42808])
lprobs.size(): torch.Size([3168, 42808])
2023-09-20 22:15:27 | INFO | train_inner | epoch 006:   6113 / 9060 loss=6.16, nll_loss=3.16, ppl=8.94, wps=7527.2, ups=0.58, wpb=13004.2, bsz=424.6, num_updates=51400, lr=0.000139482, gnorm=0.789, loss_scale=4, train_wall=173, gb_free=13.7, wall=41721
torch.Size([3328, 42808])
pred_new.size(): torch.Size([1350, 42808])
pred_new.size(): torch.Size([2340, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.343945
num_accepted / total 14 136
loss token level: tensor(8970.4746, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1656., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1530, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([76, 42808])
pred_new.size(): torch.Size([1456, 42808])
pred_new.size(): torch.Size([4048, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.344813
num_accepted / total 34 144
loss token level: tensor(9820.6660, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5520., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.344858
num_accepted / total 20 96
loss token level: tensor(9704.2441, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5192., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1360, 42808])
pred_new.size(): torch.Size([2208, 42808])
ter_threshold: 0.345285
num_accepted / total 11 80
loss token level: tensor(11745.0205, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3428., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.34549399999999997
num_accepted / total 14 96
loss token level: tensor(9091.4629, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3560., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3220, 42808])
pred_new.size(): torch.Size([4816, 42808])
ter_threshold: 0.345861
num_accepted / total 7 48
loss token level: tensor(10272.7969, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2124., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([728, 42808])
pred_new.size(): torch.Size([2775, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([232, 42808])
pred_new.size(): torch.Size([480, 42808])
ter_threshold: 0.34642
num_accepted / total 55 144
loss token level: tensor(8317.3516, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5064., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2205, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([396, 42808])
pred_new.size(): torch.Size([2871, 42808])
pred_new.size(): torch.Size([5307, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([2448, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.346968
num_accepted / total 6 32
loss token level: tensor(9278.5938, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5396., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([897, 42808])
ter_threshold: 0.347009
num_accepted / total 9 80
loss token level: tensor(9025.2148, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2630., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([133, 42808])
ter_threshold: 0.34706
num_accepted / total 1 56
loss token level: tensor(14576.9688, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(261.7500, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3542, 42808])
pred_new.size(): torch.Size([1888, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.347373
num_accepted / total 26 112
loss token level: tensor(10008.4141, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3484., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2900, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([1425, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([341, 42808])
pred_new.size(): torch.Size([1350, 42808])
pred_new.size(): torch.Size([1050, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2424, 42808])
pred_new.size(): torch.Size([1260, 42808])
pred_new.size(): torch.Size([1312, 42808])
ter_threshold: 0.34829899999999997
num_accepted / total 8 48
loss token level: tensor(9936.1904, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2804., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.348444
num_accepted / total 15 96
loss token level: tensor(8544.0840, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3628., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([1400, 42808])
pred_new.size(): torch.Size([3416, 42808])
pred_new.size(): torch.Size([4205, 42808])
ter_threshold: 0.34893399999999997
num_accepted / total 4 96
loss token level: tensor(9070.8037, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(403., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2193, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([924, 42808])
pred_new.size(): torch.Size([3335, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.349493
num_accepted / total 6 80
loss token level: tensor(9503.0996, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1550., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([780, 42808])
lprobs.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([3483, 42808])
ter_threshold: 0.349798
num_accepted / total 30 56
loss token level: tensor(7803.1909, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7872., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.349997
num_accepted / total 11 64
loss token level: tensor(9757.3594, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2764., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.350029
num_accepted / total 21 96
loss token level: tensor(8759.0635, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5012., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2250, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2160, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([456, 42808])
pred_new.size(): torch.Size([952, 42808])
pred_new.size(): torch.Size([782, 42808])
pred_new.size(): torch.Size([2370, 42808])
pred_new.size(): torch.Size([2304, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1326, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.35098399999999996
num_accepted / total 1 56
loss token level: tensor(10793.2051, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(631., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.351005
num_accepted / total 14 72
loss token level: tensor(8391.5537, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4844., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1824, 42808])
pred_new.size(): torch.Size([4760, 42808])
lprobs.size(): torch.Size([3256, 42808])
ter_threshold: 0.351462
ter_threshold: 0.351462
num_accepted / total 61 136
loss token level: tensor(8808.7852, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5896., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 22:18:21 | INFO | train_inner | epoch 006:   6213 / 9060 loss=6.231, nll_loss=3.206, ppl=9.23, wps=7460, ups=0.57, wpb=12977.2, bsz=452, num_updates=51500, lr=0.000139347, gnorm=0.782, loss_scale=4, train_wall=174, gb_free=14.4, wall=41895
lprobs.size(): torch.Size([3024, 42808])
2023-09-20 22:21:17 | INFO | train_inner | epoch 006:   6313 / 9060 loss=6.13, nll_loss=3.166, ppl=8.98, wps=7338.7, ups=0.57, wpb=12897, bsz=421.4, num_updates=51600, lr=0.000139212, gnorm=0.799, loss_scale=4, train_wall=175, gb_free=14.9, wall=42070
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-20 22:24:09 | INFO | train_inner | epoch 006:   6413 / 9060 loss=6.13, nll_loss=3.198, ppl=9.18, wps=7574.9, ups=0.58, wpb=13022.5, bsz=436.2, num_updates=51700, lr=0.000139077, gnorm=0.754, loss_scale=8, train_wall=172, gb_free=15, wall=42242
ter_threshold: 0.351704
num_accepted / total 23 88
loss token level: tensor(9620.7852, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4052., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 22:25:54 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-20 22:27:14 | INFO | train_inner | epoch 006:   6514 / 9060 loss=6.203, nll_loss=3.179, ppl=9.06, wps=7081.7, ups=0.54, wpb=13147.9, bsz=449.3, num_updates=51800, lr=0.000138943, gnorm=0.748, loss_scale=4, train_wall=185, gb_free=15.1, wall=42428
2023-09-20 22:30:02 | INFO | train_inner | epoch 006:   6614 / 9060 loss=6.094, nll_loss=3.135, ppl=8.79, wps=7749.1, ups=0.6, wpb=13018.5, bsz=436.9, num_updates=51900, lr=0.000138809, gnorm=0.751, loss_scale=4, train_wall=168, gb_free=15.1, wall=42596
pred_new.size(): torch.Size([4092, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 22:33:07 | INFO | train_inner | epoch 006:   6714 / 9060 loss=6.146, nll_loss=3.138, ppl=8.8, wps=7018.5, ups=0.54, wpb=12947.4, bsz=437.1, num_updates=52000, lr=0.000138675, gnorm=0.774, loss_scale=4, train_wall=184, gb_free=14.9, wall=42780
pred_new.size(): torch.Size([2016, 42808])
2023-09-20 22:35:57 | INFO | train_inner | epoch 006:   6814 / 9060 loss=6.015, nll_loss=3.156, ppl=8.91, wps=7603.8, ups=0.59, wpb=12927.2, bsz=424.6, num_updates=52100, lr=0.000138542, gnorm=0.787, loss_scale=4, train_wall=170, gb_free=15.1, wall=42950
lprobs.size(): torch.Size([3312, 42808])
2023-09-20 22:38:57 | INFO | train_inner | epoch 006:   6914 / 9060 loss=6.063, nll_loss=3.113, ppl=8.65, wps=7250.4, ups=0.56, wpb=13026.2, bsz=437.1, num_updates=52200, lr=0.000138409, gnorm=0.752, loss_scale=4, train_wall=179, gb_free=14.2, wall=43130
2023-09-20 22:41:55 | INFO | train_inner | epoch 006:   7014 / 9060 loss=6.106, nll_loss=3.165, ppl=8.97, wps=7233.4, ups=0.56, wpb=12888.7, bsz=417.1, num_updates=52300, lr=0.000138277, gnorm=0.839, loss_scale=4, train_wall=178, gb_free=14.5, wall=43308
pred_new.size(): torch.Size([836, 42808])
pred_new.size(): torch.Size([1204, 42808])
2023-09-20 22:44:49 | INFO | train_inner | epoch 006:   7114 / 9060 loss=6.194, nll_loss=3.182, ppl=9.08, wps=7454.2, ups=0.57, wpb=12969.3, bsz=427.4, num_updates=52400, lr=0.000138145, gnorm=0.876, loss_scale=4, train_wall=174, gb_free=14.7, wall=43482
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-20 22:47:46 | INFO | train_inner | epoch 006:   7214 / 9060 loss=6.075, nll_loss=3.143, ppl=8.84, wps=7292.9, ups=0.56, wpb=12916, bsz=421.4, num_updates=52500, lr=0.000138013, gnorm=0.773, loss_scale=4, train_wall=177, gb_free=14.7, wall=43659
pred_new.size(): torch.Size([1581, 42808])
ter_threshold: 0.352533
num_accepted / total 12 72
loss token level: tensor(8922.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3704., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5642, 42808])
2023-09-20 22:50:42 | INFO | train_inner | epoch 006:   7314 / 9060 loss=6.114, nll_loss=3.144, ppl=8.84, wps=7404.2, ups=0.57, wpb=13039, bsz=447.8, num_updates=52600, lr=0.000137882, gnorm=0.767, loss_scale=4, train_wall=176, gb_free=14.7, wall=43835
pred_new.size(): torch.Size([735, 42808])
2023-09-20 22:53:33 | INFO | train_inner | epoch 006:   7414 / 9060 loss=6.124, nll_loss=3.137, ppl=8.79, wps=7611.5, ups=0.58, wpb=13023.4, bsz=434.9, num_updates=52700, lr=0.000137751, gnorm=0.766, loss_scale=4, train_wall=171, gb_free=14.6, wall=44007
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2100, 42808])
2023-09-20 22:56:22 | INFO | train_inner | epoch 006:   7514 / 9060 loss=6.097, nll_loss=3.165, ppl=8.97, wps=7623.5, ups=0.59, wpb=12848.6, bsz=425.8, num_updates=52800, lr=0.00013762, gnorm=0.75, loss_scale=4, train_wall=168, gb_free=14.4, wall=44175
2023-09-20 22:59:20 | INFO | train_inner | epoch 006:   7614 / 9060 loss=6.087, nll_loss=3.135, ppl=8.79, wps=7245.8, ups=0.56, wpb=12916.6, bsz=420.6, num_updates=52900, lr=0.00013749, gnorm=0.781, loss_scale=4, train_wall=178, gb_free=16, wall=44353
2023-09-20 23:02:21 | INFO | train_inner | epoch 006:   7714 / 9060 loss=6.197, nll_loss=3.209, ppl=9.25, wps=7227.2, ups=0.55, wpb=13058.1, bsz=435.7, num_updates=53000, lr=0.000137361, gnorm=0.841, loss_scale=4, train_wall=180, gb_free=14.9, wall=44534
pred_new.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1452, 42808])
2023-09-20 23:05:26 | INFO | train_inner | epoch 006:   7814 / 9060 loss=6.196, nll_loss=3.197, ppl=9.17, wps=6966.8, ups=0.54, wpb=12921.7, bsz=426.1, num_updates=53100, lr=0.000137231, gnorm=0.799, loss_scale=4, train_wall=185, gb_free=15.9, wall=44719
ter_threshold: 0.353116
num_accepted / total 21 96
loss token level: tensor(10850.4248, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5756., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.353135
num_accepted / total 10 48
loss token level: tensor(9071.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5192., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-20 23:08:27 | INFO | train_inner | epoch 006:   7914 / 9060 loss=6.171, nll_loss=3.203, ppl=9.21, wps=7170.9, ups=0.55, wpb=12972.6, bsz=448.5, num_updates=53200, lr=0.000137102, gnorm=0.766, loss_scale=4, train_wall=181, gb_free=14.5, wall=44900
2023-09-20 23:11:31 | INFO | train_inner | epoch 006:   8014 / 9060 loss=6.206, nll_loss=3.173, ppl=9.02, wps=7048.6, ups=0.54, wpb=12976.5, bsz=452.8, num_updates=53300, lr=0.000136973, gnorm=0.799, loss_scale=4, train_wall=184, gb_free=13.1, wall=45084
tensor(1168., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([1188, 42808])
pred_new.size(): torch.Size([1088, 42808])
pred_new.size(): torch.Size([2232, 42808])
ter_threshold: 0.344615
num_accepted / total 2 72
loss token level: tensor(10196.4473, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(429., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([720, 42808])
ter_threshold: 0.344751
num_accepted / total 40 152
loss token level: tensor(10464.4062, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3910., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.344858
num_accepted / total 21 96
loss token level: tensor(9430.2070, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5828., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3108, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3280, 42808])
ter_threshold: 0.34549399999999997
num_accepted / total 30 136
loss token level: tensor(9596.3926, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5628., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([1440, 42808])
pred_new.size(): torch.Size([3686, 42808])
pred_new.size(): torch.Size([1890, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([2508, 42808])
ter_threshold: 0.346346
num_accepted / total 1 32
loss token level: tensor(8123.2573, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(322.2500, device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.34642
num_accepted / total 40 128
loss token level: tensor(9571.1270, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4516., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.346421
num_accepted / total 22 112
loss token level: tensor(8779.0371, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2238., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([836, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([2484, 42808])
pred_new.size(): torch.Size([891, 42808])
pred_new.size(): torch.Size([5858, 42808])
pred_new.size(): torch.Size([182, 42808])
pred_new.size(): torch.Size([3201, 42808])
ter_threshold: 0.346813
num_accepted / total 43 136
loss token level: tensor(9676.5508, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8216., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2016, 42808])
ter_threshold: 0.347009
num_accepted / total 38 136
loss token level: tensor(9296.9824, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6920., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2680, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([390, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([355, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([2208, 42808])
pred_new.size(): torch.Size([868, 42808])
pred_new.size(): torch.Size([4130, 42808])
pred_new.size(): torch.Size([462, 42808])
pred_new.size(): torch.Size([495, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.348444
num_accepted / total 32 184
loss token level: tensor(8556.1025, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3118., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1450, 42808])
pred_new.size(): torch.Size([1425, 42808])
pred_new.size(): torch.Size([228, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([3174, 42808])
pred_new.size(): torch.Size([3680, 42808])
lprobs.size(): torch.Size([3288, 42808])
ter_threshold: 0.34948599999999996
num_accepted / total 5 48
loss token level: tensor(9220.6885, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1510., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.349522
num_accepted / total 9 56
loss token level: tensor(9362.1309, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1697., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2920, 42808])
ter_threshold: 0.34954599999999997
num_accepted / total 20 80
loss token level: tensor(8881.5078, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3578., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1350, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.349997
num_accepted / total 9 64
loss token level: tensor(9572.7354, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2120., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4293, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1988, 42808])
ter_threshold: 0.350637
num_accepted / total 8 64
loss token level: tensor(10338.9395, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3500., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.350691
num_accepted / total 19 88
loss token level: tensor(8940.9600, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3074., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2106, 42808])
pred_new.size(): torch.Size([2628, 42808])
pred_new.size(): torch.Size([592, 42808])
pred_new.size(): torch.Size([1250, 42808])
pred_new.size(): torch.Size([2948, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.351005
num_accepted / total 15 72
loss token level: tensor(9780.2695, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5856., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1176, 42808])
pred_new.size(): torch.Size([2574, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([3507, 42808])
pred_new.size(): torch.Size([700, 42808])
pred_new.size(): torch.Size([3354, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([2800, 42808])
ter_threshold: 0.351657
num_accepted / total 28 104
loss token level: tensor(9757.3584, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4216., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1410, 42808])
pred_new.size(): torch.Size([2904, 42808])
ter_threshold: 0.351942
num_accepted / total 63 160
loss token level: tensor(9355.6396, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5720., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2170, 42808])
pred_new.size(): torch.Size([945, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6258, 42808])
pred_new.size(): torch.Size([1968, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([1320, 42808])
pred_new.size(): torch.Size([1674, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3320, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.353361
num_accepted / total 10 48
loss token level: lprobs.size(): torch.Size([3416, 42808])
2023-09-20 23:14:24 | INFO | train_inner | epoch 006:   8114 / 9060 loss=6.211, nll_loss=3.166, ppl=8.98, wps=7493.6, ups=0.58, wpb=12975.3, bsz=427.6, num_updates=53400, lr=0.000136845, gnorm=0.804, loss_scale=4, train_wall=173, gb_free=15.2, wall=45258
lprobs.size(): torch.Size([3456, 42808])
2023-09-20 23:17:16 | INFO | train_inner | epoch 006:   8214 / 9060 loss=6.035, nll_loss=3.121, ppl=8.7, wps=7471.4, ups=0.58, wpb=12863.8, bsz=431.8, num_updates=53500, lr=0.000136717, gnorm=0.76, loss_scale=4, train_wall=172, gb_free=14.4, wall=45430
2023-09-20 23:20:14 | INFO | train_inner | epoch 006:   8314 / 9060 loss=6.189, nll_loss=3.182, ppl=9.08, wps=7276.2, ups=0.56, wpb=12944.7, bsz=417.1, num_updates=53600, lr=0.00013659, gnorm=0.765, loss_scale=4, train_wall=178, gb_free=15, wall=45608
lprobs.size(): torch.Size([3128, 42808])
2023-09-20 23:23:10 | INFO | train_inner | epoch 006:   8414 / 9060 loss=6.227, nll_loss=3.195, ppl=9.16, wps=7370, ups=0.57, wpb=12926.2, bsz=440.7, num_updates=53700, lr=0.000136462, gnorm=0.77, loss_scale=4, train_wall=175, gb_free=13.6, wall=45783
pred_new.size(): torch.Size([2112, 42808])
2023-09-20 23:26:06 | INFO | train_inner | epoch 006:   8514 / 9060 loss=6.179, nll_loss=3.172, ppl=9.01, wps=7364.1, ups=0.57, wpb=13022.3, bsz=443.6, num_updates=53800, lr=0.000136335, gnorm=0.818, loss_scale=4, train_wall=177, gb_free=14.6, wall=45960
2023-09-20 23:28:56 | INFO | train_inner | epoch 006:   8614 / 9060 loss=6.113, nll_loss=3.159, ppl=8.93, wps=7581.7, ups=0.59, wpb=12850.4, bsz=428.3, num_updates=53900, lr=0.000136209, gnorm=0.766, loss_scale=4, train_wall=169, gb_free=14.2, wall=46129
2023-09-20 23:31:56 | INFO | train_inner | epoch 006:   8714 / 9060 loss=6.132, nll_loss=3.173, ppl=9.02, wps=7219.3, ups=0.55, wpb=13020.1, bsz=409.8, num_updates=54000, lr=0.000136083, gnorm=0.842, loss_scale=4, train_wall=180, gb_free=14.9, wall=46310
2023-09-20 23:34:43 | INFO | train_inner | epoch 006:   8814 / 9060 loss=6.179, nll_loss=3.183, ppl=9.08, wps=7784.6, ups=0.6, wpb=12973.9, bsz=440, num_updates=54100, lr=0.000135957, gnorm=0.783, loss_scale=4, train_wall=166, gb_free=14.2, wall=46476
ter_threshold: 0.354133
num_accepted / total 6 96
loss token level: tensor(8696.5449, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(602., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([2944, 42808])
2023-09-20 23:37:29 | INFO | train_inner | epoch 006:   8914 / 9060 loss=6.068, nll_loss=3.128, ppl=8.74, wps=7761.2, ups=0.6, wpb=12895.6, bsz=452.1, num_updates=54200, lr=0.000135831, gnorm=0.745, loss_scale=4, train_wall=166, gb_free=13.9, wall=46643
pred_new.size(): torch.Size([4318, 42808])
2023-09-20 23:40:16 | INFO | train_inner | epoch 006:   9014 / 9060 loss=6.024, nll_loss=3.116, ppl=8.67, wps=7791.7, ups=0.6, wpb=12998.4, bsz=429.4, num_updates=54300, lr=0.000135706, gnorm=0.739, loss_scale=4, train_wall=167, gb_free=14.7, wall=46809
lprobs.size(): torch.Size([3280, 42808])
2023-09-20 23:41:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-20 23:41:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 23:41:40 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-20 23:41:40 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-20 23:41:41 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-20 23:41:41 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-20 23:41:41 | INFO | fairseq.tasks.translation | example hypothesis: Danach gibt es keinen Anspruch auf Unterkunft.
2023-09-20 23:41:41 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-20 23:41:42 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-20 23:41:42 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-20 23:41:42 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-20 23:41:42 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-20 23:41:43 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein regnerischer Erfolg.
2023-09-20 23:41:43 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-20 23:41:44 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Happy New Year für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-20 23:41:44 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-20 23:41:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das respektieren wir.
2023-09-20 23:41:44 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-20 23:41:45 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatgesprächen.
2023-09-20 23:41:45 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-20 23:41:45 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales Fernsehen und Internetzugang, die sowohl für Geschäfts- als auch für Urlaubsgäste geeignet sind.
2023-09-20 23:41:45 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-20 23:41:46 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-20 23:41:46 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-20 23:41:46 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 23:41:46 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-20 23:41:47 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU riesige Mengen an Energie verschwendet.
2023-09-20 23:41:47 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-20 23:41:47 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel von Gentoo-Entwickler Michael Kohl in seiner neuesten Nummer.
2023-09-20 23:41:47 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-20 23:41:48 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Haltungen auch bald im Haushalt der Union widerspiegeln.
2023-09-20 23:41:48 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-20 23:41:48 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-20 23:41:48 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-20 23:41:49 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die allgemein bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-20 23:41:49 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-20 23:41:49 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der Hauptziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-20 23:41:49 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-20 23:41:50 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, ihrem Berufsleben mehr Zeit zu widmen, als sie sich gewünscht hätten?
2023-09-20 23:41:50 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-20 23:41:51 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-20 23:41:51 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-20 23:41:51 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-20 23:41:51 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-20 23:41:52 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-20 23:41:52 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-20 23:41:52 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-20 23:41:52 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-20 23:41:53 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu veranlassen, Eindrücke über die Qualität Ihrer Dienstleistungen und Produkte zu machen.
2023-09-20 23:41:53 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-20 23:41:53 | INFO | fairseq.tasks.translation | example hypothesis: Während sich die Zentralbanken weiter in ungecharterte Gebiete wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-20 23:41:53 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-20 23:41:54 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gibt, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-20 23:41:54 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-20 23:41:54 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die mir diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-20 23:41:54 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-20 23:41:55 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in ungefähr 5 km (8 km) Radius des Strip.
2023-09-20 23:41:55 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-20 23:41:55 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-20 23:41:55 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-20 23:41:56 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! akustisch, interaktiv oder in schriftlicher Form die Realisierung von Klanghandbüchern an.
2023-09-20 23:41:56 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-20 23:41:57 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-20 23:41:57 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-20 23:41:57 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer nationalen Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu schützen.
2023-09-20 23:41:57 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-20 23:41:58 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu den von ihnen gezahlten Mitteln in die europäischen Sozialversicherungssysteme haben.
2023-09-20 23:41:58 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-20 23:41:58 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-20 23:41:58 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-20 23:41:59 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-20 23:41:59 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-20 23:41:59 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird Ihnen auch helfen, qualifizierte Fachkräfte zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-20 23:41:59 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-20 23:42:00 | INFO | fairseq.tasks.translation | example hypothesis: Trotzdem sind Thatcherische Vorstellungen von niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-20 23:42:00 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-20 23:42:01 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen Splashutils neu emergen, damit es korrekt funktioniert.
2023-09-20 23:42:01 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-20 23:42:01 | INFO | fairseq.tasks.translation | example hypothesis: Spieler von Horde und Allianz können Gegenstände nicht kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-20 23:42:01 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-20 23:42:02 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum sich diese Kriterien darauf beschränken sollten, nur innerhalb der Grenzen Europas anzuwenden.
2023-09-20 23:42:02 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-20 23:42:02 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-20 23:42:02 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-20 23:42:03 | INFO | fairseq.tasks.translation | example hypothesis: Dem Vorschlag der Kommission zufolge wird der Rat formelle Standpunkte zu bestimmten Einzelheiten des Abkommens im Prinzip mit den Vereinigten Staaten vorlegen müssen.
2023-09-20 23:42:03 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-20 23:42:04 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderauflagen - unser breites Sortiment an Plastik-Babyartikeln ist beeindruckend, nicht zuletzt wegen seiner herausragenden Verarbeitung.
2023-09-20 23:42:04 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-20 23:42:04 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 23:42:04 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-20 23:42:05 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Bekanntwerden dieser AGB über Sachsituationen zu informieren, die mit diesen nicht vereinbar sind.
2023-09-20 23:42:05 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-20 23:42:05 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung erfordert.
2023-09-20 23:42:05 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-20 23:42:06 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen erstellt.
2023-09-20 23:42:06 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-20 23:42:07 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte anerkennen, die bei der Betrachtung aller Fragen erzielt wurden, die jetzt diskutiert werden und die etwas betreffen, das kaum zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-20 23:42:07 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-20 23:42:07 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-20 23:42:07 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-20 23:42:08 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal konnte der Berichterstatter die bisweilen unterschiedlichen Meinungen und Beiträge zusammenstellen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenfassen.
2023-09-20 23:42:08 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-20 23:42:09 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm der trockenen elektrostatischen Niederschläge mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-20 23:42:09 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-20 23:42:09 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-20 23:42:09 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-20 23:42:10 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-20 23:42:10 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-20 23:42:11 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und sich auf unseren Commonwealth of Nations beziehen.
2023-09-20 23:42:11 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-20 23:42:11 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-20 23:42:11 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-20 23:42:12 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-20 23:42:12 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-20 23:42:12 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Anzahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-20 23:42:12 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-20 23:42:13 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch einen weiteren: den Notfall, an dem die Kinder, der schwächste Bevölkerungsgruppe, ohne Familie, ohne Schutz und ohne Staat geblieben sind.
2023-09-20 23:42:13 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-20 23:42:14 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis der Flossen seit 2003 von der EU geregelt ist, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-20 23:42:14 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-20 23:42:14 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei gesetzt wird, erst erst nicht verwirklicht wird, bleiben alle äußeren Beziehungen durch diesen Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man das eigene wahre Selbst kennt.
2023-09-20 23:42:14 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-20 23:42:15 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Wählerregistrierung wieder zu eröffnen.
2023-09-20 23:42:15 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-20 23:42:16 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgerinnen und Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit geben, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-20 23:42:16 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-20 23:42:16 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java Programmiersprache mit J2EE-Techniken implementiert, die die Plattform- und Betriebssystem-Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-20 23:42:16 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-20 23:42:17 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab, und deshalb stimmen wir für die Klärung des Anhangs.
2023-09-20 23:42:17 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-20 23:42:18 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen betrachtet werden.
2023-09-20 23:42:18 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-20 23:42:18 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Aussprache über das irische öffentlich-rechtliche Rundfunk RTÉ mit einer Frau teilgenommen, die sehr besorgt war, dass wir die Gesundheitsausgaben senken und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-20 23:42:18 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-20 23:42:19 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird und möchte der Kommission nochmals zu ihrer besonnenen Haltung gratulieren.
2023-09-20 23:42:19 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-20 23:42:20 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie nach Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas wie die Verringerung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-20 23:42:20 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-20 23:42:20 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.
2023-09-20 23:42:20 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-20 23:42:21 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-20 23:42:21 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-20 23:42:22 | INFO | fairseq.tasks.translation | example hypothesis: Andersherum zu denken heißt, eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen zu erfinden und zu mystifizieren (unter ihnen ist oft die tatsächliche oder wahrgenommene Gefahr, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-20 23:42:22 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-20 23:42:22 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das die personenbezogenen Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn zum Beispiel Bürger Ansprüche stellen oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-20 23:42:22 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-20 23:42:23 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Fahrzeuge unter 50.000 Dollar, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-20 23:42:23 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-20 23:42:24 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für seinen ausgezeichneten Bericht danken, und dasselbe gilt für den Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für seine realistische Präsentation der Angelegenheit.
2023-09-20 23:42:24 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
lprobs.size(): torch.Size([3360, 42808])
2023-09-20 23:42:25 | INFO | fairseq.tasks.translation | example hypothesis: Sie müssen Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt (Stew) und die ausgezeichneten Frischwasserfische probieren: gegrillter Schweinefleisch, Forelle mit Mandeln.
2023-09-20 23:42:25 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-20 23:42:25 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt daran zu erinnern, was eine politische Aktion bedeutet, eine Gesamtsicht zu bieten, die es uns ermöglicht, die verschiedenen Fragen näher zu behandeln und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-20 23:42:25 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-20 23:42:26 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-20 23:42:26 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-20 23:42:27 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wenn es Arbeitslosigkeit gibt, wo die bestehenden Arbeitsplätze unmittelbar gefährdet werden und die Wettbewerbsfähigkeit durch makroökonomische Maßnahmen, steuerliche Maßnahmen und Zwänge, die sich nicht an die bestehende Situation vor Ort anpassen, schrittweise untergraben wird.
2023-09-20 23:42:27 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-20 23:42:28 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament mit einem ausgezeichneten Beispiel für die Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text übernommen hat.
2023-09-20 23:42:28 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-20 23:42:28 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den rechtlichen und justiziellen Bereich, wodurch Norwegen und Island Länder werden, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden.
2023-09-20 23:42:28 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-20 23:42:29 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schichtboot hinunter zum Mississippi fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein.
2023-09-20 23:42:29 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-20 23:42:30 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Meeresverschmutzung, den Umfang der Reaktion und den Strafcharakter der Sanktionen, die bei solchen von Einzelpersonen begangenen Verletzungen angewendet werden können.
2023-09-20 23:42:30 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-20 23:42:31 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Fse und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner verrichten und eine Gruppe von Bergreisenden filmen, die seit Jahren von einem autoritären Regime gejagt wurden, das jeden Grundsatz der Demokratie missachtet.
2023-09-20 23:42:31 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-20 23:42:31 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, Transport- und Sightseeingservice, Wechselstube, kostenloser Schuhputzservice und WLAN-Internetzugang. Die Omni Royal Orleans bietet 346 Gästezimmer und Suiten mit Blick auf den Innenhof und das französische Quartier.
2023-09-20 23:42:31 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-20 23:42:32 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen dem Thermalquellen verdankt, den Königin D. Leonor, Frau von König D. João II, und bekannt durch ihre Keramik, die international für ihre bildlichen und satirischen Werke bekannt ist, ist es auch einen Besuch wert.
2023-09-20 23:42:32 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-20 23:42:33 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um einen Fall guter Befürworter des Westens auf der einen Seite und Befürworter des früheren Regimes auf der anderen Seite handelt - auch das ist verwerflich, da die Rolle aller jetzt und davor bekannt ist.
2023-09-20 23:42:33 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-20 23:42:34 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-20 23:42:34 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-20 23:42:35 | INFO | fairseq.tasks.translation | example hypothesis: (4) Soweit Informationen aus Gründen seines Status als Aktionär außerhalb einer Aktionärsversammlung an einen Aktionär übermittelt wurden, werden diese Informationen auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn solche Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines auf der Tagesordnung stehenden Punktes zu ermöglichen.
2023-09-20 23:42:35 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-20 23:42:36 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme fließen, die in der Regel in die Taschen verschiedener Diktatoren fließen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr verabscheuungswürdiges Leben führen.
2023-09-20 23:42:36 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-20 23:42:36 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder die NATO hätten an diesem Kriegsakt beteiligt sein können -, bei Informationen zu helfen, die es nicht mehr gibt, geheim, geheim oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-20 23:42:36 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-20 23:42:37 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Bezirk Reinickendorf liegt nur 5 Gehminuten vom Bahnhof Waidmannslust S-Bahn und 30 Fahrminuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind in einem charmanten Landhausstil eingerichtet.
2023-09-20 23:42:37 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-20 23:42:38 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird der Advanced UAV die modernste, modulare Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die modernen Off-the-Regf-Plattformen nie erreichen können.
2023-09-20 23:42:38 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-20 23:42:39 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen unmissverständlich klarstellen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte aus dem Markt zu nehmen, die eine ernste Gefahr darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, denn solche Produkte können leicht recycelt werden, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-20 23:42:39 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-20 23:42:40 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Komplott von Modernität und Postmoderne oder der klar umrissenen Opposition von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung jener beiden Ästhetik-Politik erkennen, die in eben den Formen der Sichtbarkeit und Verständlichkeit verstrickt sind, die die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-20 23:42:40 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-20 23:42:41 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werden wir angesichts der Bedeutung der Aussprachen und angesichts der Meinungen, die Sie mir übermittelt haben und die eindeutig weitgehend das unterstützen, was ich gerade gesagt habe, und auf der Grundlage der vorangegangenen Entscheidungen unsere Debatten führen, und wenn es zur Abstimmung kommt, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht darum bitten, die Beschlussfähigkeit zu überprüfen.
2023-09-20 23:42:41 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-20 23:42:42 | INFO | fairseq.tasks.translation | example hypothesis: In Anbetracht der Tatsache, dass diese Völker die Einschränkung des nationalstaatlichen Grundsatzes nie akzeptiert haben, sind es paradoxerweise gerade sie, die, kaum jemandem bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen aufgehoben wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.
2023-09-20 23:42:42 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-20 23:42:43 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Weise als Hybridform veröffentlicht, die Rezensionen und Artikel der vierteljährlichen Zeitschrift für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Teilnehmer verteilt.
2023-09-20 23:42:43 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-20 23:42:44 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone ihre Federn nicht nur deutlich verfeinert, sondern auch von einst gewellten Taschenlampen über polyphonen Tootern von Game Boy bis hin zu schrägen Mini-PCs mit knackigem CD-Qualität Stereo-Sound: Zukünftig könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-wannabes bis hin zu Trailblazern neuer technologischer Entwicklungen absolvieren.
2023-09-20 23:42:44 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-20 23:42:46 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dirigide la defensa de la base humana en Pandora, conence a Jake para que le proportionoubinformación sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen.. En un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se cuenta de éstos renás unciarás, a su tierra, a unausweichlich haciendo a, a un contra arrollo de maquero; en un dequado de dequé está dequé.
2023-09-20 23:42:46 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-20 23:42:47 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 4.264 | nll_loss 2.276 | ppl 4.84 | bleu 28.76 | wps 17741.6 | wpb 12011.9 | bsz 398.1 | num_updates 54346 | best_bleu 28.76
2023-09-20 23:42:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 54346 updates
2023-09-20 23:42:47 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint6.pt
2023-09-20 23:42:52 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint6.pt
2023-09-20 23:43:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint6.pt (epoch 6 @ 54346 updates, score 28.76) (writing took 14.376646915014135 seconds)
2023-09-20 23:43:01 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2023-09-20 23:43:01 | INFO | train | epoch 006 | loss 6.103 | nll_loss 3.142 | ppl 8.83 | wps 7362.6 | ups 0.57 | wpb 12977.1 | bsz 430.4 | num_updates 54346 | lr 0.000135649 | gnorm 0.78 | loss_scale 4 | train_wall 15860 | gb_free 13.2 | wall 46974
2023-09-20 23:43:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-20 23:43:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-20 23:43:01 | INFO | fairseq.trainer | begin training epoch 7
2023-09-20 23:43:01 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-20 23:44:37 | INFO | train_inner | epoch 007:     54 / 9060 loss=5.981, nll_loss=3.084, ppl=8.48, wps=4992, ups=0.38, wpb=13019, bsz=432.5, num_updates=54400, lr=0.000135582, gnorm=0.735, loss_scale=4, train_wall=179, gb_free=16.2, wall=47070
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2520, 42808])
2023-09-20 23:47:30 | INFO | train_inner | epoch 007:    154 / 9060 loss=6.196, nll_loss=3.134, ppl=8.78, wps=7455.2, ups=0.58, wpb=12910.5, bsz=412.8, num_updates=54500, lr=0.000135457, gnorm=0.776, loss_scale=4, train_wall=173, gb_free=14.5, wall=47243
num_accepted / total 23 112
loss token level: tensor(8903.7266, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4816., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([3354, 42808])
ter_threshold: 0.345861
num_accepted / total 3 56
loss token level: tensor(12261.0693, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(842., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1596, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1752, 42808])
ter_threshold: 0.34642
num_accepted / total 38 120
loss token level: tensor(8855.3789, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4588., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.346421
num_accepted / total 95 208
loss token level: tensor(8289.7686, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4744., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2565, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6272, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3648, 42808])
pred_new.size(): torch.Size([1656, 42808])
pred_new.size(): torch.Size([2868, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3008, 42808])
ter_threshold: 0.347009
num_accepted / total 19 96
loss token level: tensor(9964.7959, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4856., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1480, 42808])
pred_new.size(): torch.Size([1065, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2600, 42808])
pred_new.size(): torch.Size([288, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2916, 42808])
pred_new.size(): torch.Size([1287, 42808])
pred_new.size(): torch.Size([1518, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.34803
num_accepted / total 6 72
loss token level: tensor(12878.1816, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2016., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2048, 42808])
pred_new.size(): torch.Size([1044, 42808])
lprobs.size(): torch.Size([2920, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1662, 42808])
pred_new.size(): torch.Size([2682, 42808])
pred_new.size(): torch.Size([465, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1890, 42808])
ter_threshold: 0.34893399999999997
num_accepted / total 25 120
loss token level: tensor(9828.3105, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2614., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([6622, 42808])
ter_threshold: 0.34954599999999997
num_accepted / total 271 392
loss token level: tensor(7309.0068, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7036., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2728, 42808])
pred_new.size(): torch.Size([2200, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([1365, 42808])
ter_threshold: 0.350029
num_accepted / total 18 104
loss token level: tensor(8808.5508, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3610., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3102, 42808])
pred_new.size(): torch.Size([2070, 42808])
pred_new.size(): torch.Size([876, 42808])
pred_new.size(): torch.Size([1326, 42808])
pred_new.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([1860, 42808])
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([840, 42808])
pred_new.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([5700, 42808])
pred_new.size(): torch.Size([1392, 42808])
ter_threshold: 0.351362
num_accepted / total 18 80
loss token level: tensor(9461.7363, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5752., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6400, 42808])
ter_threshold: 0.351485
num_accepted / total 15 64
loss token level: tensor(9516.7217, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3464., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2451, 42808])
ter_threshold: 0.351657
num_accepted / total 17 80
loss token level: tensor(8956.3350, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2916., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.351704
num_accepted / total 62 152
loss token level: tensor(8873.4004, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5448., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2672, 42808])
ter_threshold: 0.35189499999999996
num_accepted / total 17 88
loss token level: tensor(9796.7305, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5112., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([351, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([812, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.352338
num_accepted / total 2 48
loss token level: tensor(9858.2578, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(567.5000, device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([4266, 42808])
pred_new.size(): torch.Size([2080, 42808])
pred_new.size(): torch.Size([4672, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([885, 42808])
pred_new.size(): torch.Size([564, 42808])
pred_new.size(): torch.Size([1534, 42808])
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.353116
num_accepted / total 8 88
loss token level: tensor(8629.1504, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2058., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4165, 42808])
pred_new.size(): torch.Size([4717, 42808])
pred_new.size(): torch.Size([4015, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([2944, 42808])
ter_threshold: 0.35403399999999996
num_accepted / total 30 104
loss token level: tensor(10013.2637, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4356., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([378, 42808])
ter_threshold: 0.35407299999999997
num_accepted / total 0 32
loss token level: tensor(12031.0166, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: 0
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3424, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([884, 42808])
pred_new.size(): ter_threshold: 0.354525
num_accepted / total 3 64
loss token level: tensor(11760.3408, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(760.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1798, 42808])
lprobs.size(): torch.Size([3000, 42808])
2023-09-20 23:50:34 | INFO | train_inner | epoch 007:    254 / 9060 loss=6.166, nll_loss=3.119, ppl=8.69, wps=7068.1, ups=0.54, wpb=12983.9, bsz=439, num_updates=54600, lr=0.000135333, gnorm=0.786, loss_scale=4, train_wall=183, gb_free=14, wall=47427
pred_new.size(): torch.Size([4700, 42808])
lprobs.size(): torch.Size([3024, 42808])
2023-09-20 23:53:28 | INFO | train_inner | epoch 007:    354 / 9060 loss=6.172, nll_loss=3.139, ppl=8.81, wps=7475, ups=0.57, wpb=13003, bsz=421.9, num_updates=54700, lr=0.000135209, gnorm=0.771, loss_scale=4, train_wall=174, gb_free=15.7, wall=47601
pred_new.size(): torch.Size([822, 42808])
2023-09-20 23:56:27 | INFO | train_inner | epoch 007:    454 / 9060 loss=6.243, nll_loss=3.179, ppl=9.06, wps=7191.6, ups=0.56, wpb=12890, bsz=431.6, num_updates=54800, lr=0.000135086, gnorm=0.794, loss_scale=4, train_wall=179, gb_free=16.1, wall=47780
2023-09-20 23:59:19 | INFO | train_inner | epoch 007:    554 / 9060 loss=6.154, nll_loss=3.096, ppl=8.55, wps=7545.8, ups=0.58, wpb=13025.1, bsz=446.3, num_updates=54900, lr=0.000134963, gnorm=0.768, loss_scale=4, train_wall=172, gb_free=14.4, wall=47953
2023-09-21 00:02:14 | INFO | train_inner | epoch 007:    654 / 9060 loss=6.116, nll_loss=3.126, ppl=8.73, wps=7412.4, ups=0.57, wpb=12948.7, bsz=428.5, num_updates=55000, lr=0.00013484, gnorm=0.778, loss_scale=4, train_wall=174, gb_free=14.7, wall=48128
pred_new.size(): torch.Size([348, 42808])
2023-09-21 00:05:14 | INFO | train_inner | epoch 007:    754 / 9060 loss=6.171, nll_loss=3.127, ppl=8.74, wps=7226.2, ups=0.56, wpb=12968.2, bsz=421.9, num_updates=55100, lr=0.000134718, gnorm=0.8, loss_scale=4, train_wall=179, gb_free=14.9, wall=48307
2023-09-21 00:08:15 | INFO | train_inner | epoch 007:    854 / 9060 loss=6.158, nll_loss=3.153, ppl=8.9, wps=7075.2, ups=0.55, wpb=12857, bsz=422.1, num_updates=55200, lr=0.000134595, gnorm=0.826, loss_scale=4, train_wall=181, gb_free=15.8, wall=48489
lprobs.size(): torch.Size([2320, 42808])
lprobs.size(): torch.Size([2944, 42808])
2023-09-21 00:11:14 | INFO | train_inner | epoch 007:    954 / 9060 loss=6.123, nll_loss=3.101, ppl=8.58, wps=7272.7, ups=0.56, wpb=12983.9, bsz=426.8, num_updates=55300, lr=0.000134474, gnorm=0.783, loss_scale=4, train_wall=178, gb_free=14.9, wall=48667
lprobs.size(): torch.Size([3584, 42808])
2023-09-21 00:14:14 | INFO | train_inner | epoch 007:   1054 / 9060 loss=6.242, nll_loss=3.194, ppl=9.15, wps=7215.7, ups=0.56, wpb=12968.3, bsz=420.2, num_updates=55400, lr=0.000134352, gnorm=0.803, loss_scale=4, train_wall=179, gb_free=14.4, wall=48847
pred_new.size(): torch.Size([1036, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3080, 42808])
2023-09-21 00:17:11 | INFO | train_inner | epoch 007:   1154 / 9060 loss=6.297, nll_loss=3.209, ppl=9.25, wps=7361.4, ups=0.56, wpb=13064.2, bsz=425.4, num_updates=55500, lr=0.000134231, gnorm=0.823, loss_scale=4, train_wall=177, gb_free=14.6, wall=49025
lprobs.size(): torch.Size([3024, 42808])
2023-09-21 00:20:17 | INFO | train_inner | epoch 007:   1254 / 9060 loss=6.194, nll_loss=3.148, ppl=8.86, wps=6936.7, ups=0.54, wpb=12886.2, bsz=425.4, num_updates=55600, lr=0.00013411, gnorm=0.791, loss_scale=4, train_wall=186, gb_free=15.5, wall=49210
pred_new.size(): torch.Size([3354, 42808])
pred_new.size(): torch.Size([536, 42808])
2023-09-21 00:23:09 | INFO | train_inner | epoch 007:   1354 / 9060 loss=6.16, nll_loss=3.142, ppl=8.83, wps=7481.3, ups=0.58, wpb=12909.8, bsz=419.7, num_updates=55700, lr=0.00013399, gnorm=0.785, loss_scale=4, train_wall=172, gb_free=14.4, wall=49383
pred_new.size(): torch.Size([715, 42808])
2023-09-21 00:26:12 | INFO | train_inner | epoch 007:   1454 / 9060 loss=6.167, nll_loss=3.138, ppl=8.8, wps=7141.6, ups=0.55, wpb=13032.6, bsz=456, num_updates=55800, lr=0.00013387, gnorm=0.784, loss_scale=4, train_wall=182, gb_free=14.4, wall=49565
pred_new.size(): torch.Size([2301, 42808])
pred_new.size(): torch.Size([912, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.355887
num_accepted / total 11 56
loss token level: tensor(8729.4297, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4840., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 00:29:11 | INFO | train_inner | epoch 007:   1554 / 9060 loss=6.159, nll_loss=3.104, ppl=8.6, wps=7317.6, ups=0.56, wpb=13084.1, bsz=425.4, num_updates=55900, lr=0.00013375, gnorm=0.782, loss_scale=8, train_wall=179, gb_free=14.1, wall=49744
pred_new.size(): torch.Size([945, 42808])
2023-09-21 00:32:20 | INFO | train_inner | epoch 007:   1654 / 9060 loss=6.251, nll_loss=3.187, ppl=9.11, wps=6797.3, ups=0.53, wpb=12885.6, bsz=431.5, num_updates=56000, lr=0.000133631, gnorm=0.81, loss_scale=8, train_wall=189, gb_free=15, wall=49934
2023-09-21 00:35:16 | INFO | train_inner | epoch 007:   1754 / 9060 loss=6.305, nll_loss=3.169, ppl=9, wps=7406.2, ups=0.57, wpb=13051.6, bsz=435.1, num_updates=56100, lr=0.000133511, gnorm=0.775, loss_scale=8, train_wall=176, gb_free=14.2, wall=50110
ter_threshold: 0.356166
num_accepted / total 21 112
loss token level: tensor(10715.0596, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2732., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.35618299999999997
num_accepted / total 5 96
loss token level: tensor(9746.8467, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(574.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 00:38:25 | INFO | train_inner | epoch 007:   1854 / 9060 loss=6.27, nll_loss=3.176, ppl=9.04, wps=6890.3, ups=0.53, wpb=12977.3, bsz=444.1, num_updates=56200, lr=0.000133393, gnorm=0.788, loss_scale=8, train_wall=188, gb_free=15, wall=50298
2023-09-21 00:41:26 | INFO | train_inner | epoch 007:   1954 / 9060 loss=6.23, nll_loss=3.184, ppl=9.09, wps=7185.3, ups=0.55, wpb=13035.8, bsz=432.6, num_updates=56300, lr=0.000133274, gnorm=0.789, loss_scale=8, train_wall=181, gb_free=15.2, wall=50480
2023-09-21 00:44:29 | INFO | train_inner | epoch 007:   2054 / 9060 loss=6.233, nll_loss=3.178, ppl=9.05, wps=7159.2, ups=0.55, wpb=13070.5, bsz=438.1, num_updates=56400, lr=0.000133156, gnorm=0.789, loss_scale=8, train_wall=182, gb_free=14.8, wall=50662
lprobs.size(): torch.Size([2880, 42808])
2023-09-21 00:47:24 | INFO | train_inner | epoch 007:   2154 / 9060 loss=6.08, nll_loss=3.127, ppl=8.73, wps=7356.9, ups=0.57, wpb=12898.2, bsz=414.8, num_updates=56500, lr=0.000133038, gnorm=0.81, loss_scale=8, train_wall=175, gb_free=14.4, wall=50838
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3384, 42808])
2023-09-21 00:50:37 | INFO | train_inner | epoch 007:   2254 / 9060 loss=6.243, nll_loss=3.195, ppl=9.16, wps=6705.9, ups=0.52, wpb=12944.7, bsz=425.6, num_updates=56600, lr=0.00013292, gnorm=0.825, loss_scale=8, train_wall=193, gb_free=15.3, wall=51031
ter_threshold: 0.35662499999999997
num_accepted / total 3 72
loss token level: tensor(9644.9082, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(476.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([5670, 42808])
2023-09-21 00:53:38 | INFO | train_inner | epoch 007:   2354 / 9060 loss=6.215, nll_loss=3.177, ppl=9.05, wps=7091.6, ups=0.55, wpb=12844.5, bsz=429.1, num_updates=56700, lr=0.000132803, gnorm=0.827, loss_scale=8, train_wall=181, gb_free=13.5, wall=51212
pred_new.size(): torch.Size([3723, 42808])
2023-09-21 00:56:42 | INFO | train_inner | epoch 007:   2454 / 9060 loss=6.198, nll_loss=3.129, ppl=8.75, wps=7055.6, ups=0.54, wpb=12969.3, bsz=435, num_updates=56800, lr=0.000132686, gnorm=0.777, loss_scale=8, train_wall=184, gb_free=13.4, wall=51396
2023-09-21 00:59:37 | INFO | train_inner | epoch 007:   2554 / 9060 loss=6.174, nll_loss=3.155, ppl=8.9, wps=7473.2, ups=0.57, wpb=13032.6, bsz=421.7, num_updates=56900, lr=0.00013257, gnorm=0.788, loss_scale=8, train_wall=174, gb_free=15.2, wall=51570
lprobs.size(): torch.Size([2904, 42808])
2023-09-21 01:02:31 | INFO | train_inner | epoch 007:   2654 / 9060 loss=6.193, nll_loss=3.152, ppl=8.89, wps=7427.4, ups=0.57, wpb=12994.9, bsz=429, num_updates=57000, lr=0.000132453, gnorm=0.784, loss_scale=8, train_wall=175, gb_free=15.3, wall=51745
ter_threshold: 0.35702
num_accepted / total 12 48
loss token level: tensor(8630.8164, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3252., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.357079
num_accepted / total 72 160
loss token level: tensor(8827.2324, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10112., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 01:05:35 | INFO | train_inner | epoch 007:   2754 / 9060 loss=6.07, nll_loss=3.105, ppl=8.6, wps=7026.6, ups=0.54, wpb=12914.6, bsz=422.3, num_updates=57100, lr=0.000132337, gnorm=0.782, loss_scale=8, train_wall=184, gb_free=15.2, wall=51929
pred_new.size(): torch.Size([1974, 42808])
2023-09-21 01:08:28 | INFO | train_inner | epoch 007:   2854 / 9060 loss=6.094, nll_loss=3.102, ppl=8.59, wps=7555.3, ups=0.58, wpb=13024.4, bsz=409.8, num_updates=57200, lr=0.000132221, gnorm=0.767, loss_scale=8, train_wall=172, gb_free=14, wall=52101
ter_threshold: 0.357202
num_accepted / total 2 48
loss token level: tensor(10216.4512, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(737., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 01:11:27 | INFO | train_inner | epoch 007:   2954 / 9060 loss=6.192, nll_loss=3.17, ppl=9, wps=7195.8, ups=0.56, wpb=12915.3, bsz=410.3, num_updates=57300, lr=0.000132106, gnorm=0.802, loss_scale=8, train_wall=179, gb_free=15, wall=52281
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([2432, 42808])
lprobs.size(): torch.Size([3384, 42808])
2023-09-21 01:14:28 | INFO | train_inner | epoch 007:   3054 / 9060 loss=6.203, nll_loss=3.157, ppl=8.92, wps=7224.2, ups=0.55, wpb=13047.7, bsz=427.2, num_updates=57400, lr=0.000131991, gnorm=0.804, loss_scale=8, train_wall=180, gb_free=14.2, wall=52461
2023-09-21 01:17:16 | INFO | train_inner | epoch 007:   3154 / 9060 loss=6.095, nll_loss=3.128, ppl=8.74, wps=7667, ups=0.59, wpb=12902.1, bsz=407.8, num_updates=57500, lr=0.000131876, gnorm=0.778, loss_scale=8, train_wall=168, gb_free=14.9, wall=52629
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([5913, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 01:20:23 | INFO | train_inner | epoch 007:   3254 / 9060 loss=6.299, nll_loss=3.189, ppl=9.12, wps=6925.7, ups=0.53, wpb=12968.7, bsz=434.6, num_updates=57600, lr=0.000131762, gnorm=0.802, loss_scale=8, train_wall=187, gb_free=14.1, wall=52817
pred_new.size(): torch.Size([5822, 42808])
2023-09-21 01:23:19 | INFO | train_inner | epoch 007:   3354 / 9060 loss=6.257, nll_loss=3.202, ppl=9.2, wps=7422.4, ups=0.57, wpb=13023.9, bsz=448.3, num_updates=57700, lr=0.000131647, gnorm=0.798, loss_scale=8, train_wall=175, gb_free=14.6, wall=52992
lprobs.size(): torch.Size([3080, 42808])
2023-09-21 01:26:17 | INFO | train_inner | epoch 007:   3454 / 9060 loss=6.228, nll_loss=3.167, ppl=8.98, wps=7361.9, ups=0.56, wpb=13143.9, bsz=477.3, num_updates=57800, lr=0.000131533, gnorm=0.76, loss_scale=8, train_wall=178, gb_free=14.7, wall=53171
pred_new.size(): torch.Size([1320, 42808])
2023-09-21 01:29:24 | INFO | train_inner | epoch 007:   3554 / 9060 loss=6.27, nll_loss=3.226, ppl=9.36, wps=6869.7, ups=0.54, wpb=12833.3, bsz=412.8, num_updates=57900, lr=0.00013142, gnorm=0.835, loss_scale=8, train_wall=187, gb_free=14.2, wall=53358
lprobs.size(): torch.Size([3552, 42808])
2023-09-21 01:32:27 | INFO | train_inner | epoch 007:   3654 / 9060 loss=6.176, nll_loss=3.154, ppl=8.9, wps=7092.1, ups=0.55, wpb=12995, bsz=442.6, num_updates=58000, lr=0.000131306, gnorm=0.791, loss_scale=8, train_wall=183, gb_free=15.7, wall=53541
2023-09-21 01:35:30 | INFO | train_inner | epoch 007:   3754 / 9060 loss=6.149, nll_loss=3.147, ppl=8.86, wps=7047.2, ups=0.55, wpb=12879, bsz=415.4, num_updates=58100, lr=0.000131193, gnorm=0.809, loss_scale=8, train_wall=182, gb_free=15.1, wall=53724
2023-09-21 01:38:37 | INFO | train_inner | epoch 007:   3854 / 9060 loss=6.235, nll_loss=3.14, ppl=8.81, wps=6925.5, ups=0.53, wpb=12962.6, bsz=418.6, num_updates=58200, lr=0.000131081, gnorm=0.817, loss_scale=8, train_wall=187, gb_free=15, wall=53911
2023-09-21 01:40:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-21 01:41:38 | INFO | train_inner | epoch 007:   3955 / 9060 loss=6.185, nll_loss=3.154, ppl=8.9, wps=7141.2, ups=0.55, wpb=12921.7, bsz=458.7, num_updates=58300, lr=0.000130968, gnorm=0.78, loss_scale=4, train_wall=181, gb_free=14.9, wall=54092
2023-09-21 01:44:41 | INFO | train_inner | epoch 007:   4055 / 9060 loss=6.19, nll_loss=3.166, ppl=8.97, wps=7101.3, ups=0.55, wpb=12989.6, bsz=420.5, num_updates=58400, lr=0.000130856, gnorm=0.792, loss_scale=4, train_wall=183, gb_free=14.6, wall=54275
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([1536, 42808])
2023-09-21 01:47:51 | INFO | train_inner | epoch 007:   4155 / 9060 loss=6.267, nll_loss=3.176, ppl=9.03, wps=6801.7, ups=0.53, wpb=12910, bsz=428.3, num_updates=58500, lr=0.000130744, gnorm=0.818, loss_scale=4, train_wall=190, gb_free=14.9, wall=54464
pred_new.size(): torch.Size([1980, 42808])
2023-09-21 01:50:55 | INFO | train_inner | epoch 007:   4255 / 9060 loss=6.236, nll_loss=3.168, ppl=8.99, wps=7076.5, ups=0.54, wpb=13035.5, bsz=431, num_updates=58600, lr=0.000130632, gnorm=0.803, loss_scale=4, train_wall=184, gb_free=15.2, wall=54649
pred_new.size(): torch.Size([1806, 42808])
2023-09-21 01:54:01 | INFO | train_inner | epoch 007:   4355 / 9060 loss=6.131, nll_loss=3.143, ppl=8.83, wps=6961.2, ups=0.54, wpb=12932.8, bsz=449.4, num_updates=58700, lr=0.000130521, gnorm=0.765, loss_scale=4, train_wall=186, gb_free=15.3, wall=54834
2023-09-21 01:57:00 | INFO | train_inner | epoch 007:   4455 / 9060 loss=6.162, nll_loss=3.156, ppl=8.91, wps=7214.7, ups=0.56, wpb=12911.2, bsz=415.8, num_updates=58800, lr=0.00013041, gnorm=0.796, loss_scale=4, train_wall=179, gb_free=14.3, wall=55013
ter_threshold: 0.358886
num_accepted / total 0 24
loss token level: tensor(10724.7715, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: 0
2023-09-21 01:59:56 | INFO | train_inner | epoch 007:   4555 / 9060 loss=6.159, nll_loss=3.145, ppl=8.85, wps=7351.5, ups=0.57, wpb=12953, bsz=449.9, num_updates=58900, lr=0.000130299, gnorm=0.775, loss_scale=4, train_wall=176, gb_free=14.4, wall=55190
2023-09-21 02:02:53 | INFO | train_inner | epoch 007:   4655 / 9060 loss=6.18, nll_loss=3.172, ppl=9.01, wps=7336.3, ups=0.57, wpb=12984, bsz=435.9, num_updates=59000, lr=0.000130189, gnorm=0.788, loss_scale=4, train_wall=177, gb_free=14.5, wall=55367
pred_new.size(): torch.Size([3483, 42808])
2023-09-21 02:05:59 | INFO | train_inner | epoch 007:   4755 / 9060 loss=6.278, nll_loss=3.197, ppl=9.17, wps=6918.9, ups=0.54, wpb=12867.2, bsz=428.2, num_updates=59100, lr=0.000130079, gnorm=0.806, loss_scale=4, train_wall=186, gb_free=13.7, wall=55552
2023-09-21 02:08:51 | INFO | train_inner | epoch 007:   4855 / 9060 loss=6.15, nll_loss=3.154, ppl=8.9, wps=7566, ups=0.58, wpb=13048.4, bsz=414.7, num_updates=59200, lr=0.000129969, gnorm=0.771, loss_scale=4, train_wall=172, gb_free=14.3, wall=55725
pred_new.size(): torch.Size([3120, 42808])
2023-09-21 02:11:51 | INFO | train_inner | epoch 007:   4955 / 9060 loss=6.195, nll_loss=3.174, ppl=9.03, wps=7212.5, ups=0.56, wpb=12973.6, bsz=424.4, num_updates=59300, lr=0.000129859, gnorm=0.799, loss_scale=4, train_wall=180, gb_free=13.6, wall=55905
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 02:14:56 | INFO | train_inner | epoch 007:   5055 / 9060 loss=6.213, nll_loss=3.188, ppl=9.11, wps=7034.4, ups=0.54, wpb=12973.2, bsz=429.4, num_updates=59400, lr=0.00012975, gnorm=0.793, loss_scale=4, train_wall=184, gb_free=15, wall=56089
2023-09-21 02:17:59 | INFO | train_inner | epoch 007:   5155 / 9060 loss=6.254, nll_loss=3.199, ppl=9.18, wps=7118.8, ups=0.55, wpb=13048.8, bsz=437.8, num_updates=59500, lr=0.000129641, gnorm=0.947, loss_scale=4, train_wall=183, gb_free=14.8, wall=56273
2023-09-21 02:21:01 | INFO | train_inner | epoch 007:   5255 / 9060 loss=6.23, nll_loss=3.192, ppl=9.14, wps=7150.5, ups=0.55, wpb=12989.9, bsz=426.2, num_updates=59600, lr=0.000129532, gnorm=0.811, loss_scale=4, train_wall=181, gb_free=14.5, wall=56454
ter_threshold: 0.359627
num_accepted / total 12 64
loss token level: tensor(9797.4766, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5536., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 02:24:03 | INFO | train_inner | epoch 007:   5355 / 9060 loss=6.149, nll_loss=3.144, ppl=8.84, wps=7158.9, ups=0.55, wpb=13021.7, bsz=428.6, num_updates=59700, lr=0.000129423, gnorm=0.788, loss_scale=4, train_wall=182, gb_free=14.1, wall=56636
ter_threshold: 0.359705
num_accepted / total 4 56
loss token level: tensor(9803.7812, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1900., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
2023-09-21 02:27:00 | INFO | train_inner | epoch 007:   5455 / 9060 loss=6.181, nll_loss=3.155, ppl=8.91, wps=7343.6, ups=0.57, wpb=12997.2, bsz=429, num_updates=59800, lr=0.000129315, gnorm=0.781, loss_scale=4, train_wall=177, gb_free=14.1, wall=56813
ter_threshold: 0.359813
num_accepted / total 8 40
loss token level: tensor(8222.8984, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2730., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 02:30:07 | INFO | train_inner | epoch 007:   5555 / 9060 loss=6.194, nll_loss=3.121, ppl=8.7, wps=6935.3, ups=0.53, wpb=13019.3, bsz=450.5, num_updates=59900, lr=0.000129207, gnorm=0.777, loss_scale=4, train_wall=187, gb_free=14.8, wall=57001
ter_threshold: 0.359913
num_accepted / total 22 136
loss token level: tensor(10697.5938, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4120., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([3468, 42808])
2023-09-21 02:33:20 | INFO | train_inner | epoch 007:   5655 / 9060 loss=6.218, nll_loss=3.173, ppl=9.02, wps=6743.5, ups=0.52, wpb=12960.5, bsz=413.6, num_updates=60000, lr=0.000129099, gnorm=0.801, loss_scale=4, train_wall=192, gb_free=14.6, wall=57193
lprobs.size(): torch.Size([2312, 42808])
ter_threshold: 0.360078
num_accepted / total 60 176
loss token level: tensor(9063.7988, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4112., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36008799999999996
num_accepted / total 27 128
loss token level: tensor(8599.5830, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2440., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5100, 42808])
2023-09-21 02:36:17 | INFO | train_inner | epoch 007:   5755 / 9060 loss=6.381, nll_loss=3.215, ppl=9.29, wps=7361.9, ups=0.56, wpb=13048.5, bsz=461.4, num_updates=60100, lr=0.000128992, gnorm=0.813, loss_scale=4, train_wall=177, gb_free=14.8, wall=57370
2023-09-21 02:39:23 | INFO | train_inner | epoch 007:   5855 / 9060 loss=6.288, nll_loss=3.195, ppl=9.16, wps=6928.8, ups=0.54, wpb=12923.6, bsz=435.7, num_updates=60200, lr=0.000128885, gnorm=0.814, loss_scale=4, train_wall=186, gb_free=15.1, wall=57557
lprobs.size(): torch.Size([3008, 42808])
2023-09-21 02:42:27 | INFO | train_inner | epoch 007:   5955 / 9060 loss=6.239, nll_loss=3.188, ppl=9.11, wps=7092.9, ups=0.54, wpb=13020.5, bsz=430.5, num_updates=60300, lr=0.000128778, gnorm=0.805, loss_scale=4, train_wall=183, gb_free=14.6, wall=57740
pred_new.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-21 02:45:27 | INFO | train_inner | epoch 007:   6055 / 9060 loss=6.201, nll_loss=3.205, ppl=9.22, wps=7220.3, ups=0.56, wpb=12992.6, bsz=428.6, num_updates=60400, lr=0.000128671, gnorm=0.771, loss_scale=4, train_wall=180, gb_free=14.4, wall=57920
pred_new.size(): torch.Size([4914, 42808])
2023-09-21 02:48:24 | INFO | train_inner | epoch 007:   6155 / 9060 loss=6.214, nll_loss=3.187, ppl=9.1, wps=7336.6, ups=0.56, wpb=12992.6, bsz=428.2, num_updates=60500, lr=0.000128565, gnorm=0.795, loss_scale=4, train_wall=177, gb_free=14.9, wall=58097
pred_new.size(): torch.Size([300, 42808])
2023-09-21 02:51:25 | INFO | train_inner | epoch 007:   6255 / 9060 loss=6.182, nll_loss=3.175, ppl=9.03, wps=7166.6, ups=0.55, wpb=12990.4, bsz=444.6, num_updates=60600, lr=0.000128459, gnorm=0.824, loss_scale=4, train_wall=181, gb_free=14.1, wall=58279
2023-09-21 02:54:34 | INFO | train_inner | epoch 007:   6355 / 9060 loss=6.14, nll_loss=3.139, ppl=8.81, wps=6888, ups=0.53, wpb=12992.1, bsz=432.4, num_updates=60700, lr=0.000128353, gnorm=0.776, loss_scale=4, train_wall=188, gb_free=14.6, wall=58467
2023-09-21 02:57:38 | INFO | train_inner | epoch 007:   6455 / 9060 loss=6.224, nll_loss=3.16, ppl=8.94, wps=7065.4, ups=0.54, wpb=12991, bsz=433.9, num_updates=60800, lr=0.000128247, gnorm=0.811, loss_scale=4, train_wall=184, gb_free=15.4, wall=58651
pred_new.size(): torch.Size([5680, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3240, 42808])
2023-09-21 03:00:43 | INFO | train_inner | epoch 007:   6555 / 9060 loss=6.169, nll_loss=3.149, ppl=8.87, wps=7050.9, ups=0.54, wpb=13044.8, bsz=425.8, num_updates=60900, lr=0.000128142, gnorm=0.787, loss_scale=4, train_wall=185, gb_free=14.2, wall=58836
2023-09-21 03:03:43 | INFO | train_inner | epoch 007:   6655 / 9060 loss=6.353, nll_loss=3.263, ppl=9.6, wps=7219.3, ups=0.55, wpb=13008.6, bsz=424.9, num_updates=61000, lr=0.000128037, gnorm=0.807, loss_scale=4, train_wall=180, gb_free=14.9, wall=59016
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([440, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2960, 42808])
2023-09-21 03:06:40 | INFO | train_inner | epoch 007:   6755 / 9060 loss=6.123, nll_loss=3.132, ppl=8.77, wps=7276.3, ups=0.56, wpb=12895.5, bsz=408.1, num_updates=61100, lr=0.000127932, gnorm=0.768, loss_scale=4, train_wall=177, gb_free=14.5, wall=59194
2023-09-21 03:09:39 | INFO | train_inner | epoch 007:   6855 / 9060 loss=6.233, nll_loss=3.19, ppl=9.13, wps=7247.1, ups=0.56, wpb=12967.2, bsz=430.8, num_updates=61200, lr=0.000127827, gnorm=0.785, loss_scale=4, train_wall=179, gb_free=14.9, wall=59373
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 03:12:40 | INFO | train_inner | epoch 007:   6955 / 9060 loss=6.173, nll_loss=3.139, ppl=8.81, wps=7239.8, ups=0.55, wpb=13099.1, bsz=443.1, num_updates=61300, lr=0.000127723, gnorm=0.783, loss_scale=4, train_wall=181, gb_free=14.9, wall=59553
num_accepted / total 14 96
loss token level: tensor(10649.2969, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2382., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3465, 42808])
pred_new.size(): torch.Size([1716, 42808])
ter_threshold: 0.351657
num_accepted / total 58 176
loss token level: tensor(8684.0840, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4160., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.351704
num_accepted / total 18 112
loss token level: tensor(11316.6309, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2296., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2544, 42808])
pred_new.size(): torch.Size([2484, 42808])
ter_threshold: 0.351942
num_accepted / total 3 88
loss token level: tensor(10834.2012, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(502.5000, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.352063
num_accepted / total 6 80
loss token level: tensor(8064.7764, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(784., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([123, 42808])
pred_new.size(): torch.Size([1530, 42808])
pred_new.size(): torch.Size([4290, 42808])
pred_new.size(): torch.Size([1326, 42808])
pred_new.size(): torch.Size([368, 42808])
pred_new.size(): torch.Size([2392, 42808])
pred_new.size(): torch.Size([1694, 42808])
lprobs.size(): torch.Size([3256, 42808])
ter_threshold: 0.353116
num_accepted / total 67 168
loss token level: tensor(9011.1406, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8688., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2530, 42808])
ter_threshold: 0.353124
num_accepted / total 13 64
loss token level: tensor(9587.7471, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2902., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1836, 42808])
pred_new.size(): torch.Size([5061, 42808])
pred_new.size(): torch.Size([4056, 42808])
pred_new.size(): torch.Size([1728, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([728, 42808])
ter_threshold: 0.354133
num_accepted / total 65 168
loss token level: tensor(10047.1699, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5472., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([255, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2064, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([4848, 42808])
pred_new.size(): torch.Size([4536, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3096, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([585, 42808])
pred_new.size(): torch.Size([4399, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([4482, 42808])
pred_new.size(): torch.Size([1890, 42808])
pred_new.size(): torch.Size([3103, 42808])
pred_new.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([2664, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([320, 42808])
ter_threshold: 0.356166
num_accepted / total 110 224
loss token level: tensor(9336.7891, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7200., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([4658, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3744, 42808])
pred_new.size(): torch.Size([1728, 42808])
ter_threshold: 0.356896
num_accepted / total 100 232
loss token level: tensor(8722.7891, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4964., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.357079
num_accepted / total 25 136
loss token level: tensor(8333.1270, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3218., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1710, 42808])
pred_new.size(): torch.Size([2745, 42808])
pred_new.size(): torch.Size([1040, 42808])
ter_threshold: 0.35776399999999997
num_accepted / total 7 40
loss token level: tensor(9701.4668, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4604., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2088, 42808])
pred_new.size(): torch.Size([2167, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4050, 42808])
pred_new.size(): torch.Size([1188, 42808])
pred_new.size(): torch.Size([528, 42808])
lprobs.size(): torch.Size([3296, 42808])
pred_new.size(): torch.Size([6939, 42808])
pred_new.size(): torch.Size([1972, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.359742
num_accepted / total 9 48
loss token level: tensor(10680.3945, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5736., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.359913
num_accepted / total 15 96
loss token level: tensor(9658.8184, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3692., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1920, 42808])
ter_threshold: 0.36008799999999996
num_accepted / total 14 80
loss token level: tensor(9156.7314, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2236., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4030, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([159, 42808])
pred_new.size(): torch.Size([2016, 42808])
pred_new.size(): torch.Size([2322, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1720, 42808])
pred_new.size(): torch.Size([1440, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.360678
num_accepted / total 229 392
loss token level: tensor(7260.1416, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6764., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1980, 42808])
pred_new.size(): torch.Size([1372, 42808])
lprobs.size(): torch.Size([3280, 42808])
ter_threshold: 0.361178
num_accepted / total 3 40
loss token level: tensor(10587.2109, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2026., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36120599999999997
num_accepted / total 20 80
loss token level: tensor(9603.0977, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6748., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.361269
num_accepted / total 6 32
loss token level: tensor(9387.1172, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4920., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 03:15:35 | INFO | train_inner | epoch 007:   7055 / 9060 loss=6.204, nll_loss=3.206, ppl=9.23, wps=7436.4, ups=0.57, wpb=13000, bsz=414.7, num_updates=61400, lr=0.000127619, gnorm=0.795, loss_scale=4, train_wall=175, gb_free=14.6, wall=59728
lprobs.size(): torch.Size([3496, 42808])
2023-09-21 03:18:44 | INFO | train_inner | epoch 007:   7155 / 9060 loss=6.146, nll_loss=3.145, ppl=8.85, wps=6884.3, ups=0.53, wpb=13037, bsz=424.2, num_updates=61500, lr=0.000127515, gnorm=0.808, loss_scale=4, train_wall=189, gb_free=13.9, wall=59918
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 03:21:48 | INFO | train_inner | epoch 007:   7255 / 9060 loss=6.187, nll_loss=3.193, ppl=9.15, wps=7066, ups=0.55, wpb=12953.3, bsz=413, num_updates=61600, lr=0.000127412, gnorm=0.787, loss_scale=4, train_wall=183, gb_free=14.7, wall=60101
2023-09-21 03:24:50 | INFO | train_inner | epoch 007:   7355 / 9060 loss=6.221, nll_loss=3.213, ppl=9.27, wps=7132.3, ups=0.55, wpb=12992.9, bsz=420.6, num_updates=61700, lr=0.000127309, gnorm=0.79, loss_scale=4, train_wall=182, gb_free=15.1, wall=60283
2023-09-21 03:27:51 | INFO | train_inner | epoch 007:   7455 / 9060 loss=6.172, nll_loss=3.13, ppl=8.75, wps=7119, ups=0.55, wpb=12917.3, bsz=435.7, num_updates=61800, lr=0.000127205, gnorm=0.781, loss_scale=4, train_wall=181, gb_free=14.3, wall=60465
2023-09-21 03:30:51 | INFO | train_inner | epoch 007:   7555 / 9060 loss=6.209, nll_loss=3.176, ppl=9.04, wps=7176.1, ups=0.56, wpb=12923.8, bsz=429, num_updates=61900, lr=0.000127103, gnorm=0.783, loss_scale=4, train_wall=180, gb_free=14.4, wall=60645
lprobs.size(): torch.Size([2996, 42808])
pred_new.size(): torch.Size([1860, 42808])
lprobs.size(): torch.Size([3128, 42808])
2023-09-21 03:33:56 | INFO | train_inner | epoch 007:   7655 / 9060 loss=6.271, nll_loss=3.223, ppl=9.34, wps=6971, ups=0.54, wpb=12901.1, bsz=435.6, num_updates=62000, lr=0.000127, gnorm=0.819, loss_scale=4, train_wall=185, gb_free=14, wall=60830
2023-09-21 03:36:54 | INFO | train_inner | epoch 007:   7755 / 9060 loss=6.196, nll_loss=3.188, ppl=9.11, wps=7254.8, ups=0.56, wpb=12928.6, bsz=427.3, num_updates=62100, lr=0.000126898, gnorm=0.761, loss_scale=4, train_wall=178, gb_free=14.7, wall=61008
pred_new.size(): torch.Size([936, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([960, 42808])
2023-09-21 03:40:01 | INFO | train_inner | epoch 007:   7855 / 9060 loss=6.204, nll_loss=3.137, ppl=8.79, wps=7017.1, ups=0.53, wpb=13117.9, bsz=469.4, num_updates=62200, lr=0.000126796, gnorm=0.779, loss_scale=4, train_wall=187, gb_free=14.8, wall=61195
pred_new.size(): torch.Size([3672, 42808])
2023-09-21 03:43:07 | INFO | train_inner | epoch 007:   7955 / 9060 loss=6.233, nll_loss=3.167, ppl=8.98, wps=7011.9, ups=0.54, wpb=12986.2, bsz=429.4, num_updates=62300, lr=0.000126694, gnorm=0.787, loss_scale=4, train_wall=185, gb_free=14.9, wall=61380
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3432, 42808])
2023-09-21 03:46:02 | INFO | train_inner | epoch 007:   8055 / 9060 loss=6.155, nll_loss=3.141, ppl=8.82, wps=7427.7, ups=0.57, wpb=13041.1, bsz=424.5, num_updates=62400, lr=0.000126592, gnorm=0.79, loss_scale=8, train_wall=175, gb_free=15.8, wall=61556
2023-09-21 03:48:59 | INFO | train_inner | epoch 007:   8155 / 9060 loss=6.258, nll_loss=3.198, ppl=9.18, wps=7354.5, ups=0.56, wpb=13024.1, bsz=414.4, num_updates=62500, lr=0.000126491, gnorm=0.79, loss_scale=8, train_wall=177, gb_free=14.7, wall=61733
ter_threshold: 0.362544
num_accepted / total 49 128
loss token level: tensor(8710.8574, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5572., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1110, 42808])
2023-09-21 03:52:10 | INFO | train_inner | epoch 007:   8255 / 9060 loss=6.25, nll_loss=3.178, ppl=9.05, wps=6760.2, ups=0.52, wpb=12909.6, bsz=427, num_updates=62600, lr=0.00012639, gnorm=0.802, loss_scale=8, train_wall=191, gb_free=14.4, wall=61924
2023-09-21 03:55:16 | INFO | train_inner | epoch 007:   8355 / 9060 loss=6.202, nll_loss=3.171, ppl=9.01, wps=6965.6, ups=0.54, wpb=12962, bsz=440.2, num_updates=62700, lr=0.000126289, gnorm=0.804, loss_scale=8, train_wall=186, gb_free=15.4, wall=62110
pred_new.size(): torch.Size([3975, 42808])
2023-09-21 03:58:15 | INFO | train_inner | epoch 007:   8455 / 9060 loss=6.25, nll_loss=3.206, ppl=9.23, wps=7240.7, ups=0.56, wpb=12942.8, bsz=435.7, num_updates=62800, lr=0.000126189, gnorm=0.824, loss_scale=8, train_wall=179, gb_free=14.9, wall=62289
pred_new.size(): torch.Size([6554, 42808])
ter_threshold: 0.362822
num_accepted / total 5 64
loss token level: tensor(9587.8066, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1954., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.362834
num_accepted / total 44 136
loss token level: tensor(8869.1738, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4136., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36284299999999997
num_accepted / total 21 104
loss token level: tensor(9411.6562, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2778., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 04:01:25 | INFO | train_inner | epoch 007:   8555 / 9060 loss=6.286, nll_loss=3.19, ppl=9.12, wps=6849, ups=0.53, wpb=13001, bsz=429.9, num_updates=62900, lr=0.000126088, gnorm=0.789, loss_scale=8, train_wall=190, gb_free=14.9, wall=62478
2023-09-21 04:04:24 | INFO | train_inner | epoch 007:   8655 / 9060 loss=6.206, nll_loss=3.185, ppl=9.09, wps=7256.5, ups=0.56, wpb=13022.1, bsz=414.6, num_updates=63000, lr=0.000125988, gnorm=0.805, loss_scale=8, train_wall=179, gb_free=15.7, wall=62658
2023-09-21 04:07:29 | INFO | train_inner | epoch 007:   8755 / 9060 loss=6.188, nll_loss=3.128, ppl=8.74, wps=6979.2, ups=0.54, wpb=12908, bsz=457.2, num_updates=63100, lr=0.000125888, gnorm=0.791, loss_scale=8, train_wall=185, gb_free=14.4, wall=62843
2023-09-21 04:10:26 | INFO | train_inner | epoch 007:   8855 / 9060 loss=6.135, nll_loss=3.16, ppl=8.94, wps=7331.8, ups=0.57, wpb=12973.5, bsz=437.7, num_updates=63200, lr=0.000125789, gnorm=0.757, loss_scale=8, train_wall=177, gb_free=15.5, wall=63020
lprobs.size(): torch.Size([2688, 42808])
2023-09-21 04:13:28 | INFO | train_inner | epoch 007:   8955 / 9060 loss=6.244, nll_loss=3.17, ppl=9, wps=7199, ups=0.55, wpb=13058.4, bsz=444.8, num_updates=63300, lr=0.000125689, gnorm=0.786, loss_scale=8, train_wall=181, gb_free=14.4, wall=63201
pred_new.size(): torch.Size([3838, 42808])
lprobs.size(): torch.Size([3240, 42808])
2023-09-21 04:16:38 | INFO | train_inner | epoch 007:   9055 / 9060 loss=6.255, nll_loss=3.175, ppl=9.03, wps=6850.8, ups=0.53, wpb=13008.2, bsz=438.4, num_updates=63400, lr=0.00012559, gnorm=0.788, loss_scale=8, train_wall=190, gb_free=14.2, wall=63391
2023-09-21 04:16:53 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-21 04:16:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 04:16:54 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-21 04:16:54 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-21 04:16:54 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-21 04:16:54 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-21 04:16:55 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-21 04:16:55 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-21 04:16:55 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-21 04:16:55 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-21 04:16:56 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-21 04:16:56 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-21 04:16:57 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein bewegender Erfolg.
2023-09-21 04:16:57 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-21 04:16:57 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein gutes Neues Jahr für alle und Glückwünsche an unseren Präsidenten.
2023-09-21 04:16:57 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-21 04:16:58 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, und das respektieren wir.
2023-09-21 04:16:58 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-21 04:16:58 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatgesprächen.
2023-09-21 04:16:58 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-21 04:16:59 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende geeignet sind.
2023-09-21 04:16:59 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-21 04:16:59 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-21 04:16:59 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-21 04:17:00 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 04:17:00 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 04:17:00 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU enorme Mengen an Energie verschwendet.
2023-09-21 04:17:00 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-21 04:17:01 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin trägt einen Artikel des Gentoo Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-21 04:17:01 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-21 04:17:01 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Haltung auch in Kürze im Haushalt der Union widerspiegeln.
2023-09-21 04:17:01 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-21 04:17:02 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-21 04:17:02 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-21 04:17:03 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-21 04:17:03 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-21 04:17:03 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-21 04:17:03 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-21 04:17:03 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen wurden gezwungen, sich mehr Zeit auf ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-21 04:17:03 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-21 04:17:04 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-21 04:17:04 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-21 04:17:05 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-21 04:17:05 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-21 04:17:05 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer spezifischen politischen Kraft.
2023-09-21 04:17:05 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-21 04:17:06 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-21 04:17:06 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-21 04:17:06 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu bringen, Einblicke in die Qualität Ihrer Dienstleistung und Produkte zu machen.
2023-09-21 04:17:06 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-21 04:17:07 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken noch weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-21 04:17:07 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-21 04:17:07 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-21 04:17:07 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-21 04:17:08 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-21 04:17:08 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-21 04:17:09 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in ungefähr einem Umkreis von 8 Kilometern von The Strip.
2023-09-21 04:17:09 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-21 04:17:09 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Webportal-System basiert.
2023-09-21 04:17:09 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-21 04:17:10 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! akustisch, interaktiv oder schriftlich die Realisierung von Sound-Handbüchern an.
2023-09-21 04:17:10 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-21 04:17:10 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-21 04:17:10 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-21 04:17:11 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu sichern.
2023-09-21 04:17:11 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-21 04:17:11 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu dem Geld erhalten, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-21 04:17:11 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-21 04:17:12 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti Modell als Basis.
2023-09-21 04:17:12 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-21 04:17:12 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf Computerplattformen läuft.
2023-09-21 04:17:12 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-21 04:17:13 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie Sie Ihnen helfen können, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-21 04:17:13 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-21 04:17:14 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-21 04:17:14 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-21 04:17:14 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es korrekt funktionieren kann.
2023-09-21 04:17:14 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-21 04:17:15 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht kaufen oder an einander verkaufen, wenn sie die unten aufgeführten neutralen Auktionshäuser nicht nutzen.
2023-09-21 04:17:15 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-21 04:17:16 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-21 04:17:16 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-21 04:17:16 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt der Kommission auf der Grundlage eines Berichts von Herrn Wynn die Entlastung des Gesamthaushaltsplans der Gemeinschaft für 1994.
2023-09-21 04:17:16 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-21 04:17:17 | INFO | fairseq.tasks.translation | example hypothesis: Dem Vorschlag der Kommission zufolge muss der Rat formelle Standpunkte zu bestimmten Details des Abkommens im Prinzip mit den Vereinigten Staaten einreichen.
2023-09-21 04:17:17 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-21 04:17:17 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unser breites Sortiment an PlastikBabyartikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-21 04:17:17 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-21 04:17:18 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourismus"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 04:17:18 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 04:17:19 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis dieser AGB über Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-21 04:17:19 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-21 04:17:19 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die die Notwendigkeit institutioneller Änderungen vorangeschritten und erkannt hat, die sie eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung erfordert.
2023-09-21 04:17:19 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-21 04:17:20 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen erstellt.
2023-09-21 04:17:20 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-21 04:17:20 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte anerkennen, die bei all den Themen erzielt wurden, die jetzt zur Diskussion stehen, was etwas betrifft, das knapp zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-21 04:17:20 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-21 04:17:21 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-21 04:17:21 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-21 04:17:22 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es dem Berichterstatter gelungen, zuweilen unterschiedliche Meinungen und Beiträge zu erarbeiten und in einem äußerst ausgewogenen Text zusammenzufassen - ich würde sagen -.
2023-09-21 04:17:22 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-21 04:17:22 | INFO | fairseq.tasks.translation | example hypothesis: Unser COMPACT-Modell ergänzt mit der gleichen hochwertigen Technologie unser Programm von trocken elektrostatischen Niederrichtern mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-21 04:17:22 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-21 04:17:23 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-21 04:17:23 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-21 04:17:24 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-21 04:17:24 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-21 04:17:24 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und beruht auf Verhandlungen mit Drittländern, von denen viele seit Jahren in Kraft sind und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-21 04:17:24 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-21 04:17:25 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-21 04:17:25 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-21 04:17:25 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht der Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-21 04:17:25 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-21 04:17:26 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-21 04:17:26 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-21 04:17:27 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch einen anderen: die Notsituation, an der die Kinder, der schwächste Teil der Bevölkerung beteiligt sind, die ohne Familie, ohne Schutz und ohne Staat geblieben sind.
2023-09-21 04:17:27 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-21 04:17:27 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis der Fasterung von der EU seit 2003 reguliert wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-21 04:17:27 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-21 04:17:28 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei gesetzt ist, erst nicht erst realisiert ist, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-21 04:17:28 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-21 04:17:29 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb ist es von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in ihrer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Wählerregistrierung wieder zu öffnen.
2023-09-21 04:17:29 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-21 04:17:29 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit deutlich gemacht werden, dass niemand über dem Gesetz steht.
2023-09-21 04:17:29 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-21 04:17:30 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit garantieren (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-21 04:17:30 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-21 04:17:31 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur deutlicheren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab, und deshalb stimmen wir für eine Klarstellung des Anhangs.
2023-09-21 04:17:31 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-21 04:17:32 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist auch der Ansicht, dass die WTO-Mitgliedsländer eine besondere Verantwortung haben, grundlegende Arbeitsnormen einzuhalten, und fordert die WTO auf, eindeutig zu erklären, dass die von der IAO verhängten Sanktionen nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-21 04:17:32 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-21 04:17:32 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich habe ich an einer Debatte über das irische öffentlich-rechtliche Rundfunk RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben senken und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-21 04:17:32 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-21 04:17:33 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer sachlichen Haltung gratulieren.
2023-09-21 04:17:33 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-21 04:17:34 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie nach Inspiration für Ihre Lektionen oder konkreten Informationen über die europäische Geschichte, Unionsbürgerschaft oder so etwas Konkretes wie die Senkung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Studenten zugeschnitten ist.
2023-09-21 04:17:34 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-21 04:17:34 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.
2023-09-21 04:17:34 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-21 04:17:35 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-21 04:17:35 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-21 04:17:36 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, bedeutet, zu naturalisieren und zu mystifizieren, was eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Gefahr, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-21 04:17:36 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-21 04:17:36 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-21 04:17:36 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-21 04:17:37 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist einer der lustigsten Autos, die unter 50.000 Dollar fahren, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-21 04:17:37 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-21 04:17:38 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für ihre realistische Darstellung der Angelegenheit.
2023-09-21 04:17:38 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-21 04:17:38 | INFO | fairseq.tasks.translation | example hypothesis: Sie müssen Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt (Stew) und den ausgezeichneten Süßwasserfisch probieren: gegrillter Pike-Perch, Forelle mit Mandeln.
2023-09-21 04:17:38 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-21 04:17:39 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, eine Gesamtsicht zu geben, die es uns ermöglicht, näher auf die verschiedenen Fragen einzugehen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-21 04:17:39 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-21 04:17:40 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-21 04:17:40 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-21 04:17:41 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Strategien, steuerliche Maßnahmen und Beschränkungen, die nicht an die derzeitige Situation vor Ort angepasst sind, allmählich untergraben wird.
2023-09-21 04:17:41 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-21 04:17:41 | INFO | fairseq.tasks.translation | example hypothesis: Der uns von der Kommission vorgelegte Verordnungsvorschlag geht in dieselbe Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel für die Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-21 04:17:41 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-21 04:17:42 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den rechtlichen und justiziellen Bereich, wodurch Norwegen und Island Länder, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen gelten werden, gelten.
2023-09-21 04:17:42 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-21 04:17:43 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Make-Shift-Boot hinunter den Mississippi gehen, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir großartige Freunde sein.
2023-09-21 04:17:43 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-21 04:17:44 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Meeresverschmutzung durch Schiffe, den Umfang der Reaktion und den Strafcharakter der Sanktionen, die bei solchen von Einzelpersonen begangenen Verletzungen angewendet werden können.
2023-09-21 04:17:44 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-21 04:17:44 | INFO | fairseq.tasks.translation | example hypothesis: Tatsächlich wurden Thierry Fse und Vincent Reynaud einfach dafür verurteilt, dass sie ihre Arbeit als Journalisten und Kameramänner geleistet und eine Gruppe von Bergregionen gefilmt wurden, die seit Jahren von einem autoritären Regime verfolgt wurden, das jedes Prinzip der Demokratie missachtet.
2023-09-21 04:17:44 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-21 04:17:45 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels gehören Concierge-Service, ein Friseur- und Schönheitsgeschäft, ein Transport- und Sightseeing-Schalter, ein Menü- und Presseservice, Wechselstube, kostenloser Schuhputzservice und kabelloses Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-21 04:17:45 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-21 04:17:46 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, die Frau von König D. João II, geliebte, und bekannt durch ihre Keramik, die international für ihre bildlichen und satirischen Werke bekannt ist, ist es auch einen Besuch wert.
2023-09-21 04:17:46 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-21 04:17:47 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute Befürworter des Westens auf der einen Seite und Anhänger des ehemaligen Regimes auf der anderen Seite handelt - auch das ist verwerflich, da die Rollen aller von heute und früher bekannt sind.
2023-09-21 04:17:47 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-21 04:17:47 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und dem Meer fahren, nicht auf diese Weise abgedeckt werden, und sicherlich ist dies ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-21 04:17:47 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-21 04:17:48 | INFO | fairseq.tasks.translation | example hypothesis: (4) Soweit Informationen außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär an einen Aktionär übermittelt wurden, werden diese Informationen auf Antrag an jeden anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn solche Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Punktes auf der Tagesordnung zu ermöglichen.
2023-09-21 04:17:48 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-21 04:17:49 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme gesteckt werden, die normalerweise in den Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Millionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.
2023-09-21 04:17:49 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-21 04:17:50 | INFO | fairseq.tasks.translation | example hypothesis: Wir bitten die Mitgliedstaaten - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder die NATO an diesem Kriegsakt beteiligt gewesen wären -, bei Informationen zu helfen, die es keinen Grund mehr gibt, geheim, geheim oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-21 04:17:50 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-21 04:17:51 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Minuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 04:17:51 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 04:17:52 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar, angeführt von Thales in Frankreich, zusammen mit unserer Geschäftseinheit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularen Sensor- und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die modernen Offsetplattformen nie erreichen können.
2023-09-21 04:17:52 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-21 04:17:53 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen absolut klarstellen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte vom Markt zu nehmen, die eine ernste Gefahr darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, denn solche Produkte können leicht recycelt werden, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 feststellt.
2023-09-21 04:17:53 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-21 04:17:53 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Plot von Modernität und Postmoderne oder der klaren Opposition von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung dieser beiden ästhetischen Politik erkennen, die in genau den Formen der Sichtbarkeit und Verständlichkeit verwurzelt sind, die Kunst als solche für uns identifizierbar machen - jener beiden Politik, die letztendlich zu ihrer eigenen Selbstunterdrückung führt.
2023-09-21 04:17:53 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-21 04:17:54 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Aussprachen und angesichts der Meinungen, die Sie mir gegeben haben, die eindeutig weitgehend das unterstützen, was ich gerade gesagt habe, und auf der Grundlage der vorangegangenen Beschlüsse unsere Debatten führen, und wenn es um die Abstimmung geht, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht beantragen, dass die Beschlussfähigkeit überprüft wird.
2023-09-21 04:17:54 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-21 04:17:55 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker die Einschränkung des Prinzips des Nationalstaates nie akzeptiert haben, sind es paradoxerweise gerade sie, die, kaum jemandem bekannt, nicht nur Zeugen eines alten, vergessenen Europa sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.
2023-09-21 04:17:55 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-21 04:17:56 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Hinsicht als Hybridform veröffentlicht, die Rezensionen und Artikel der Quartalszeitschrift sind für H-Soz-u-Kult verfasst und über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an ihre Abonnenten verteilt.
2023-09-21 04:17:56 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-21 04:17:58 | INFO | fairseq.tasks.translation | example hypothesis: Es ist nicht nur mit der Ankunft der neuen Smartphone-Generation, dass Handys nicht nur ihre Federn deutlich verfeinert haben, von einstmals blutigen Taschenlampen über polyphonisch Rootling Game Boy-Ambitionen bis hin zu regelrechten Mini-PCs mit knackigem CD-Qualität Stereosound: Von nun an könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazers neuer technologischer Entwicklungen absteigen.
2023-09-21 04:17:58 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-21 04:17:59 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dirige la defensa de la base humana en Pandora, contrence a Jake para que le proportionalmente información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se marchen.
2023-09-21 04:17:59 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-21 04:18:00 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 4.25 | nll_loss 2.266 | ppl 4.81 | bleu 29.05 | wps 17819.1 | wpb 12011.9 | bsz 398.1 | num_updates 63405 | best_bleu 29.05
2023-09-21 04:18:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 63405 updates
2023-09-21 04:18:00 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint7.pt
2023-09-21 04:18:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint7.pt
2023-09-21 04:18:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint7.pt (epoch 7 @ 63405 updates, score 29.05) (writing took 13.972043793008197 seconds)
2023-09-21 04:18:14 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2023-09-21 04:18:14 | INFO | train | epoch 007 | loss 6.202 | nll_loss 3.164 | ppl 8.96 | wps 7119.3 | ups 0.55 | wpb 12977.3 | bsz 430.6 | num_updates 63405 | lr 0.000125585 | gnorm 0.794 | loss_scale 8 | train_wall 16409 | gb_free 15.3 | wall 63488
2023-09-21 04:18:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 04:18:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-21 04:18:14 | INFO | fairseq.trainer | begin training epoch 8
2023-09-21 04:18:14 | INFO | fairseq_cli.train | Start iterating over samples
pred_new.size(): torch.Size([5145, 42808])
pred_new.size(): torch.Size([4032, 42808])
2023-09-21 04:21:05 | INFO | train_inner | epoch 008:     95 / 9060 loss=6.385, nll_loss=3.196, ppl=9.16, wps=4786.6, ups=0.37, wpb=12813.9, bsz=458.7, num_updates=63500, lr=0.000125491, gnorm=0.806, loss_scale=8, train_wall=187, gb_free=14.2, wall=63659
lprobs.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([1463, 42808])
2023-09-21 04:24:10 | INFO | train_inner | epoch 008:    195 / 9060 loss=6.275, nll_loss=3.14, ppl=8.82, wps=7045.5, ups=0.54, wpb=13004.5, bsz=415.8, num_updates=63600, lr=0.000125392, gnorm=0.799, loss_scale=8, train_wall=184, gb_free=14.4, wall=63843
pred_new.size(): torch.Size([2240, 42808])
2023-09-21 04:27:20 | INFO | train_inner | epoch 008:    295 / 9060 loss=6.251, nll_loss=3.143, ppl=8.83, wps=6867.6, ups=0.53, wpb=13067.6, bsz=422.9, num_updates=63700, lr=0.000125294, gnorm=0.787, loss_scale=8, train_wall=190, gb_free=15.1, wall=64034
pred_new.size(): torch.Size([620, 42808])
2023-09-21 04:30:26 | INFO | train_inner | epoch 008:    395 / 9060 loss=6.3, nll_loss=3.187, ppl=9.11, wps=7022.4, ups=0.54, wpb=13036.2, bsz=440.1, num_updates=63800, lr=0.000125196, gnorm=0.791, loss_scale=8, train_wall=185, gb_free=13.5, wall=64219
lprobs.size(): torch.Size([3104, 42808])
2023-09-21 04:33:39 | INFO | train_inner | epoch 008:    495 / 9060 loss=6.283, nll_loss=3.176, ppl=9.04, wps=6751.6, ups=0.52, wpb=13060.3, bsz=420.3, num_updates=63900, lr=0.000125098, gnorm=0.809, loss_scale=8, train_wall=193, gb_free=14.7, wall=64413
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.363987
num_accepted / total 12 64
loss token level: tensor(10346.9570, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4968., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 04:36:40 | INFO | train_inner | epoch 008:    595 / 9060 loss=6.222, nll_loss=3.167, ppl=8.98, wps=7198.3, ups=0.55, wpb=12985.5, bsz=401, num_updates=64000, lr=0.000125, gnorm=0.811, loss_scale=8, train_wall=180, gb_free=14.1, wall=64593
pred_new.size(): torch.Size([1476, 42808])
2023-09-21 04:39:46 | INFO | train_inner | epoch 008:    695 / 9060 loss=6.283, nll_loss=3.161, ppl=8.94, wps=7032.8, ups=0.54, wpb=13113, bsz=424.5, num_updates=64100, lr=0.000124902, gnorm=0.8, loss_scale=8, train_wall=186, gb_free=14.3, wall=64780
2023-09-21 04:42:49 | INFO | train_inner | epoch 008:    795 / 9060 loss=6.205, nll_loss=3.174, ppl=9.03, wps=7113.9, ups=0.55, wpb=13019.8, bsz=420, num_updates=64200, lr=0.000124805, gnorm=0.855, loss_scale=8, train_wall=183, gb_free=14.2, wall=64963
2023-09-21 04:45:49 | INFO | train_inner | epoch 008:    895 / 9060 loss=6.265, nll_loss=3.181, ppl=9.07, wps=7203.6, ups=0.56, wpb=12953.7, bsz=413.1, num_updates=64300, lr=0.000124708, gnorm=0.829, loss_scale=8, train_wall=180, gb_free=15.5, wall=65142
2023-09-21 04:48:57 | INFO | train_inner | epoch 008:    995 / 9060 loss=6.289, nll_loss=3.192, ppl=9.14, wps=6887.9, ups=0.53, wpb=12940.1, bsz=445.6, num_updates=64400, lr=0.000124611, gnorm=0.807, loss_scale=8, train_wall=188, gb_free=14.8, wall=65330
tensor(8683.2959, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2952., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([3388, 42808])
pred_new.size(): torch.Size([1683, 42808])
ter_threshold: 0.354133
num_accepted / total 49 152
loss token level: tensor(8845.4160, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4200., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1485, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3504, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4480, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([2272, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2910, 42808])
pred_new.size(): torch.Size([1360, 42808])
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([300, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([735, 42808])
pred_new.size(): torch.Size([2508, 42808])
pred_new.size(): torch.Size([2730, 42808])
pred_new.size(): torch.Size([2349, 42808])
ter_threshold: 0.355887
num_accepted / total 20 64
loss token level: tensor(8751.5684, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7864., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3596, 42808])
pred_new.size(): torch.Size([2904, 42808])
ter_threshold: 0.356166
num_accepted / total 27 96
loss token level: tensor(9632.7900, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4252., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.35618299999999997
num_accepted / total 86 208
loss token level: tensor(9452.0176, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5980., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.356406
num_accepted / total 19 80
loss token level: tensor(8903.2324, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5704., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2672, 42808])
lprobs.size(): torch.Size([3072, 42808])
ter_threshold: 0.356541
num_accepted / total 58 144
loss token level: tensor(10055.2285, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5796., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([2040, 42808])
pred_new.size(): torch.Size([2790, 42808])
lprobs.size(): torch.Size([2352, 42808])
ter_threshold: 0.35670399999999997
num_accepted / total 10 48
loss token level: tensor(7998.5708, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2670., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([972, 42808])
lprobs.size(): torch.Size([2800, 42808])
ter_threshold: 0.357079
num_accepted / total 7 72
loss token level: tensor(9196.2920, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1734., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([1628, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([1800, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([486, 42808])
ter_threshold: 0.358906
num_accepted / total 17 72
loss token level: tensor(9410.0459, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3510., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1978, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1452, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([590, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.359373
num_accepted / total 2 56
loss token level: tensor(12807.7539, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(571.5000, device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.359913
num_accepted / total 27 112
loss token level: tensor(9149.9502, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6060., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1610, 42808])
pred_new.size(): torch.Size([1932, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3024, 42808])
ter_threshold: 0.360078
num_accepted / total 13 104
loss token level: tensor(9555.1289, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1556., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([165, 42808])
lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.360307
num_accepted / total 22 80
loss token level: tensor(8740.4512, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3968., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2016, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([312, 42808])
ter_threshold: 0.360678
num_accepted / total 50 152
loss token level: tensor(9826.7324, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8080., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([5162, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([2856, 42808])
ter_threshold: 0.361116
num_accepted / total 20 88
loss token level: tensor(10385.7881, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3400., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4508, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1392, 42808])
lprobs.size(): torch.Size([2576, 42808])
lprobs.size(): torch.Size([3560, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.36197599999999996
num_accepted / total 7 56
loss token level: tensor(8456.7363, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1330., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5760, 42808])
pred_new.size(): torch.Size([2590, 42808])
pred_new.size(): torch.Size([1230, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.362544
num_accepted / total 17 112
loss token level: tensor(11255.6309, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2280., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([980, 42808])
pred_new.size(): torch.Size([3575, 42808])
pred_new.size(): torch.Size([3087, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2167, 42808])
pred_new.size(): torch.Size([1292, 42808])
pred_new.size(): torch.Size([1215, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([5405, 42808])
pred_new.size(): torch.Size([2425, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2035, 42808])
pred_new.size(): torch.Size([2166, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): lprobs.size(): torch.Size([3400, 42808])
2023-09-21 04:51:51 | INFO | train_inner | epoch 008:   1095 / 9060 loss=6.257, nll_loss=3.186, ppl=9.1, wps=7438.7, ups=0.57, wpb=12997.5, bsz=421, num_updates=64500, lr=0.000124515, gnorm=0.799, loss_scale=8, train_wall=174, gb_free=14.9, wall=65505
pred_new.size(): torch.Size([2660, 42808])
2023-09-21 04:54:53 | INFO | train_inner | epoch 008:   1195 / 9060 loss=6.229, nll_loss=3.14, ppl=8.82, wps=7190.3, ups=0.55, wpb=13059.6, bsz=436.6, num_updates=64600, lr=0.000124418, gnorm=0.793, loss_scale=8, train_wall=181, gb_free=15, wall=65687
pred_new.size(): torch.Size([1188, 42808])
2023-09-21 04:57:57 | INFO | train_inner | epoch 008:   1295 / 9060 loss=6.355, nll_loss=3.236, ppl=9.42, wps=6972, ups=0.54, wpb=12833.3, bsz=431.9, num_updates=64700, lr=0.000124322, gnorm=0.808, loss_scale=8, train_wall=184, gb_free=14.7, wall=65871
pred_new.size(): torch.Size([6545, 42808])
2023-09-21 05:01:07 | INFO | train_inner | epoch 008:   1395 / 9060 loss=6.279, nll_loss=3.151, ppl=8.88, wps=6876.8, ups=0.53, wpb=13021.5, bsz=436.3, num_updates=64800, lr=0.000124226, gnorm=0.798, loss_scale=8, train_wall=189, gb_free=14.8, wall=66060
lprobs.size(): torch.Size([3280, 42808])
2023-09-21 05:04:09 | INFO | train_inner | epoch 008:   1495 / 9060 loss=6.306, nll_loss=3.198, ppl=9.18, wps=7109.7, ups=0.55, wpb=12949.9, bsz=457.4, num_updates=64900, lr=0.00012413, gnorm=0.812, loss_scale=8, train_wall=182, gb_free=14.8, wall=66242
lprobs.size(): torch.Size([3584, 42808])
2023-09-21 05:07:27 | INFO | train_inner | epoch 008:   1595 / 9060 loss=6.347, nll_loss=3.197, ppl=9.17, wps=6530.5, ups=0.5, wpb=12954, bsz=421.4, num_updates=65000, lr=0.000124035, gnorm=0.831, loss_scale=8, train_wall=198, gb_free=15.2, wall=66441
2023-09-21 05:10:29 | INFO | train_inner | epoch 008:   1695 / 9060 loss=6.356, nll_loss=3.234, ppl=9.41, wps=7109.9, ups=0.55, wpb=12935, bsz=426.6, num_updates=65100, lr=0.000123939, gnorm=0.825, loss_scale=8, train_wall=182, gb_free=14.1, wall=66622
ter_threshold: 0.36511899999999997
num_accepted / total 31 112
loss token level: tensor(9555.0957, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3824., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36516099999999996
num_accepted / total 7 32
loss token level: tensor(8751.4238, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5276., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 05:13:43 | INFO | train_inner | epoch 008:   1795 / 9060 loss=6.364, nll_loss=3.214, ppl=9.28, wps=6706.6, ups=0.51, wpb=13025.8, bsz=440.1, num_updates=65200, lr=0.000123844, gnorm=0.849, loss_scale=8, train_wall=194, gb_free=14.9, wall=66817
pred_new.size(): torch.Size([1548, 42808])
2023-09-21 05:16:58 | INFO | train_inner | epoch 008:   1895 / 9060 loss=6.277, nll_loss=3.188, ppl=9.11, wps=6666, ups=0.51, wpb=12956.7, bsz=416.4, num_updates=65300, lr=0.000123749, gnorm=0.812, loss_scale=8, train_wall=194, gb_free=14.8, wall=67011
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([2938, 42808])
2023-09-21 05:20:07 | INFO | train_inner | epoch 008:   1995 / 9060 loss=6.207, nll_loss=3.147, ppl=8.86, wps=6850.2, ups=0.53, wpb=12943.3, bsz=410.9, num_updates=65400, lr=0.000123655, gnorm=0.817, loss_scale=8, train_wall=189, gb_free=14.6, wall=67200
2023-09-21 05:23:16 | INFO | train_inner | epoch 008:   2095 / 9060 loss=6.301, nll_loss=3.219, ppl=9.31, wps=6791.1, ups=0.53, wpb=12870.7, bsz=423.7, num_updates=65500, lr=0.00012356, gnorm=0.831, loss_scale=8, train_wall=189, gb_free=13.9, wall=67390
pred_new.size(): torch.Size([1638, 42808])
2023-09-21 05:26:28 | INFO | train_inner | epoch 008:   2195 / 9060 loss=6.298, nll_loss=3.165, ppl=8.97, wps=6758.2, ups=0.52, wpb=12956.8, bsz=458.6, num_updates=65600, lr=0.000123466, gnorm=0.793, loss_scale=8, train_wall=191, gb_free=14.9, wall=67581
lprobs.size(): torch.Size([3472, 42808])
2023-09-21 05:29:29 | INFO | train_inner | epoch 008:   2295 / 9060 loss=6.182, nll_loss=3.135, ppl=8.78, wps=7155.1, ups=0.55, wpb=12952.9, bsz=428.6, num_updates=65700, lr=0.000123372, gnorm=0.771, loss_scale=8, train_wall=181, gb_free=13.7, wall=67762
torch.Size([2562, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([420, 42808])
pred_new.size(): torch.Size([1533, 42808])
pred_new.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([432, 42808])
ter_threshold: 0.355041
num_accepted / total 5 48
loss token level: tensor(9894.5918, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2722., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([4032, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([792, 42808])
pred_new.size(): torch.Size([1672, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([4347, 42808])
pred_new.size(): torch.Size([1386, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([2100, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.356166
num_accepted / total 93 184
loss token level: tensor(8953.9619, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7080., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3696, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2838, 42808])
ter_threshold: 0.35662499999999997
num_accepted / total 25 88
loss token level: tensor(9408.0801, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4116., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1216, 42808])
ter_threshold: 0.356896
num_accepted / total 47 160
loss token level: tensor(10453.1006, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3944., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.35702
num_accepted / total 8 48
loss token level: tensor(8406.8965, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2298., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.357079
num_accepted / total 31 112
loss token level: tensor(8616.6006, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6264., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.357132
num_accepted / total 9 56
loss token level: tensor(9602.5469, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4464., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1458, 42808])
pred_new.size(): torch.Size([432, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2730, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3096, 42808])
pred_new.size(): torch.Size([280, 42808])
lprobs.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([3050, 42808])
lprobs.size(): torch.Size([3320, 42808])
ter_threshold: 0.35784099999999996
num_accepted / total 9 72
loss token level: tensor(11199.5322, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1814., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([1632, 42808])
pred_new.size(): torch.Size([2136, 42808])
pred_new.size(): torch.Size([1950, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1290, 42808])
pred_new.size(): torch.Size([1680, 42808])
pred_new.size(): torch.Size([4620, 42808])
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([576, 42808])
pred_new.size(): torch.Size([3111, 42808])
ter_threshold: 0.36008799999999996
num_accepted / total 25 168
loss token level: tensor(11465.3418, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1899., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([2814, 42808])
pred_new.size(): torch.Size([264, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([324, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2120, 42808])
pred_new.size(): torch.Size([1400, 42808])
pred_new.size(): torch.Size([130, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2064, 42808])
ter_threshold: 0.360851
num_accepted / total 7 48
loss token level: tensor(8970.6484, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3792., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3304, 42808])
ter_threshold: 0.36120599999999997
num_accepted / total 22 80
loss token level: tensor(9964.5273, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7568., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([1080, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.361494
num_accepted / total 13 96
loss token level: tensor(9151.6377, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3326., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1564, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2912, 42808])
ter_threshold: 0.361761
num_accepted / total 60 168
loss token level: tensor(10014.3613, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8552., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2132, 42808])
pred_new.size(): torch.Size([1782, 42808])
pred_new.size(): torch.Size([5871, 42808])
ter_threshold: 0.362834
num_accepted / total 77 168
loss token level: tensor(8629.2861, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5848., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36284299999999997
num_accepted / total 58 176
loss token level: tensor(9024.3486, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3956., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3216, 42808])
ter_threshold: 0.363262
num_accepted / total 53 192
loss token level: tensor(8393.1133, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4696., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2835, 42808])
pred_new.size(): torch.Size([4600, 42808])
pred_new.size(): torch.Size([1800, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([188, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([3728, 42808])
pred_new.size(): torch.Size([2064, 42808])
lprobs.size(): torch.Size([3320, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([432, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([1125, 42808])
pred_new.size(): torch.Size([1250, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2232, 42808])
lprobs.size(): torch.Size([2640, 42808])
ter_threshold: 0.365166
num_accepted / total 10 40
loss token level: tensor(8410.5586, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3708., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1617, 42808])
pred_new.size(): torch.Size([1128, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: ter_threshold: 0.36575199999999997
num_accepted / total 29 96
loss token level: tensor(9430.9688, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4640., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 05:32:39 | INFO | train_inner | epoch 008:   2395 / 9060 loss=6.205, nll_loss=3.155, ppl=8.91, wps=6817.6, ups=0.52, wpb=12988, bsz=444.6, num_updates=65800, lr=0.000123278, gnorm=0.83, loss_scale=8, train_wall=190, gb_free=14.2, wall=67953
lprobs.size(): torch.Size([3120, 42808])
ter_threshold: 0.365865
num_accepted / total 36 128
loss token level: tensor(9794.6621, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6776., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 05:35:55 | INFO | train_inner | epoch 008:   2495 / 9060 loss=6.431, nll_loss=3.224, ppl=9.34, wps=6622.1, ups=0.51, wpb=12958.1, bsz=444.6, num_updates=65900, lr=0.000123185, gnorm=0.845, loss_scale=8, train_wall=195, gb_free=14.5, wall=68148
pred_new.size(): torch.Size([3081, 42808])
2023-09-21 05:39:04 | INFO | train_inner | epoch 008:   2595 / 9060 loss=6.252, nll_loss=3.152, ppl=8.89, wps=6907.8, ups=0.53, wpb=13037.6, bsz=427.9, num_updates=66000, lr=0.000123091, gnorm=0.817, loss_scale=8, train_wall=188, gb_free=13.9, wall=68337
pred_new.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([2592, 42808])
2023-09-21 05:42:04 | INFO | train_inner | epoch 008:   2695 / 9060 loss=6.39, nll_loss=3.241, ppl=9.45, wps=7182.3, ups=0.56, wpb=12938.2, bsz=444.5, num_updates=66100, lr=0.000122998, gnorm=0.793, loss_scale=8, train_wall=180, gb_free=15.4, wall=68517
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1500, 42808])
2023-09-21 05:45:11 | INFO | train_inner | epoch 008:   2795 / 9060 loss=6.225, nll_loss=3.157, ppl=8.92, wps=6893.9, ups=0.53, wpb=12900.4, bsz=436.2, num_updates=66200, lr=0.000122905, gnorm=0.834, loss_scale=8, train_wall=187, gb_free=14.8, wall=68704
pred_new.size(): torch.Size([1428, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-21 05:48:16 | INFO | train_inner | epoch 008:   2895 / 9060 loss=6.244, nll_loss=3.178, ppl=9.05, wps=7014.1, ups=0.54, wpb=12950, bsz=411.8, num_updates=66300, lr=0.000122813, gnorm=0.844, loss_scale=8, train_wall=184, gb_free=13.8, wall=68889
pred_new.size(): torch.Size([5184, 42808])
2023-09-21 05:51:27 | INFO | train_inner | epoch 008:   2995 / 9060 loss=6.278, nll_loss=3.145, ppl=8.85, wps=6807, ups=0.52, wpb=13026.5, bsz=425.8, num_updates=66400, lr=0.00012272, gnorm=0.805, loss_scale=8, train_wall=191, gb_free=14.7, wall=69080
2023-09-21 05:54:35 | INFO | train_inner | epoch 008:   3095 / 9060 loss=6.272, nll_loss=3.187, ppl=9.11, wps=6946, ups=0.53, wpb=13042.6, bsz=424.1, num_updates=66500, lr=0.000122628, gnorm=0.794, loss_scale=16, train_wall=188, gb_free=15.2, wall=69268
lprobs.size(): torch.Size([3480, 42808])
2023-09-21 05:56:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-21 05:57:47 | INFO | train_inner | epoch 008:   3196 / 9060 loss=6.33, nll_loss=3.211, ppl=9.26, wps=6810.2, ups=0.52, wpb=13091.4, bsz=436.5, num_updates=66600, lr=0.000122536, gnorm=0.781, loss_scale=8, train_wall=192, gb_free=14.6, wall=69460
lprobs.size(): torch.Size([3248, 42808])
2023-09-21 06:00:44 | INFO | train_inner | epoch 008:   3296 / 9060 loss=6.169, nll_loss=3.129, ppl=8.75, wps=7354.1, ups=0.57, wpb=12986, bsz=408.6, num_updates=66700, lr=0.000122444, gnorm=0.791, loss_scale=8, train_wall=176, gb_free=14.3, wall=69637
2023-09-21 06:03:53 | INFO | train_inner | epoch 008:   3396 / 9060 loss=6.364, nll_loss=3.188, ppl=9.11, wps=6888, ups=0.53, wpb=13047.1, bsz=451.8, num_updates=66800, lr=0.000122352, gnorm=0.796, loss_scale=8, train_wall=189, gb_free=14.7, wall=69826
2023-09-21 06:07:10 | INFO | train_inner | epoch 008:   3496 / 9060 loss=6.265, nll_loss=3.19, ppl=9.13, wps=6555.3, ups=0.51, wpb=12909, bsz=410.3, num_updates=66900, lr=0.000122261, gnorm=0.843, loss_scale=8, train_wall=197, gb_free=14.4, wall=70023
2023-09-21 06:10:11 | INFO | train_inner | epoch 008:   3596 / 9060 loss=6.307, nll_loss=3.184, ppl=9.09, wps=7188, ups=0.55, wpb=13040.1, bsz=425.8, num_updates=67000, lr=0.000122169, gnorm=0.835, loss_scale=8, train_wall=181, gb_free=15.2, wall=70205
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6156, 42808])
2023-09-21 06:13:22 | INFO | train_inner | epoch 008:   3696 / 9060 loss=6.224, nll_loss=3.168, ppl=8.99, wps=6758.5, ups=0.52, wpb=12878.4, bsz=415.8, num_updates=67100, lr=0.000122078, gnorm=0.81, loss_scale=8, train_wall=190, gb_free=14.1, wall=70395
pred_new.size(): torch.Size([306, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 06:16:30 | INFO | train_inner | epoch 008:   3796 / 9060 loss=6.4, nll_loss=3.244, ppl=9.48, wps=6878.3, ups=0.53, wpb=12935.7, bsz=427.4, num_updates=67200, lr=0.000121988, gnorm=0.803, loss_scale=8, train_wall=188, gb_free=14.9, wall=70583
lprobs.size(): torch.Size([3280, 42808])
2023-09-21 06:19:54 | INFO | train_inner | epoch 008:   3896 / 9060 loss=6.367, nll_loss=3.196, ppl=9.16, wps=6390.1, ups=0.49, wpb=13024.1, bsz=463, num_updates=67300, lr=0.000121897, gnorm=0.825, loss_scale=8, train_wall=204, gb_free=14.1, wall=70787
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4361, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 06:22:59 | INFO | train_inner | epoch 008:   3996 / 9060 loss=6.392, nll_loss=3.24, ppl=9.45, wps=6995.8, ups=0.54, wpb=12987.4, bsz=448.8, num_updates=67400, lr=0.000121806, gnorm=0.807, loss_scale=8, train_wall=185, gb_free=15.6, wall=70973
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 06:26:08 | INFO | train_inner | epoch 008:   4096 / 9060 loss=6.299, nll_loss=3.181, ppl=9.07, wps=6921.1, ups=0.53, wpb=13036.9, bsz=448.4, num_updates=67500, lr=0.000121716, gnorm=0.826, loss_scale=8, train_wall=188, gb_free=15.2, wall=71161
pred_new.size(): torch.Size([3599, 42808])
2023-09-21 06:29:08 | INFO | train_inner | epoch 008:   4196 / 9060 loss=6.292, nll_loss=3.216, ppl=9.29, wps=7159, ups=0.56, wpb=12898.8, bsz=417.2, num_updates=67600, lr=0.000121626, gnorm=0.814, loss_scale=8, train_wall=180, gb_free=15.4, wall=71341
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2688, 42808])
2023-09-21 06:32:15 | INFO | train_inner | epoch 008:   4296 / 9060 loss=6.289, nll_loss=3.193, ppl=9.14, wps=6914.1, ups=0.54, wpb=12917, bsz=418.2, num_updates=67700, lr=0.000121536, gnorm=0.807, loss_scale=8, train_wall=187, gb_free=14.1, wall=71528
lprobs.size(): torch.Size([3120, 42808])
2023-09-21 06:35:21 | INFO | train_inner | epoch 008:   4396 / 9060 loss=6.284, nll_loss=3.163, ppl=8.95, wps=7001.8, ups=0.54, wpb=13026.9, bsz=433.5, num_updates=67800, lr=0.000121447, gnorm=0.804, loss_scale=8, train_wall=186, gb_free=14.8, wall=71714
2023-09-21 06:38:30 | INFO | train_inner | epoch 008:   4496 / 9060 loss=6.275, nll_loss=3.186, ppl=9.1, wps=6884.5, ups=0.53, wpb=13005.5, bsz=414, num_updates=67900, lr=0.000121357, gnorm=0.782, loss_scale=8, train_wall=189, gb_free=14.5, wall=71903
pred_new.size(): torch.Size([2808, 42808])
2023-09-21 06:41:39 | INFO | train_inner | epoch 008:   4596 / 9060 loss=6.357, nll_loss=3.203, ppl=9.21, wps=6911.7, ups=0.53, wpb=13089.4, bsz=431.4, num_updates=68000, lr=0.000121268, gnorm=0.825, loss_scale=8, train_wall=189, gb_free=14.4, wall=72093
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([2576, 42808])
2023-09-21 06:44:45 | INFO | train_inner | epoch 008:   4696 / 9060 loss=6.289, nll_loss=3.208, ppl=9.24, wps=6974.3, ups=0.54, wpb=12975.2, bsz=429, num_updates=68100, lr=0.000121179, gnorm=0.809, loss_scale=8, train_wall=186, gb_free=14.7, wall=72279
pred_new.size(): torch.Size([3276, 42808])
2023-09-21 06:47:59 | INFO | train_inner | epoch 008:   4796 / 9060 loss=6.323, nll_loss=3.18, ppl=9.07, wps=6645, ups=0.51, wpb=12909.1, bsz=427.8, num_updates=68200, lr=0.00012109, gnorm=0.813, loss_scale=8, train_wall=194, gb_free=15.3, wall=72473
lprobs.size(): torch.Size([2520, 42808])
ter_threshold: 0.36823
num_accepted / total 10 56
loss token level: tensor(8731.5762, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2816., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4386, 42808])
lprobs.size(): torch.Size([2880, 42808])
2023-09-21 06:51:13 | INFO | train_inner | epoch 008:   4896 / 9060 loss=6.251, nll_loss=3.162, ppl=8.95, wps=6725.4, ups=0.52, wpb=13010.2, bsz=432.6, num_updates=68300, lr=0.000121001, gnorm=0.79, loss_scale=8, train_wall=193, gb_free=14.7, wall=72666
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.368329
num_accepted / total 49 152
loss token level: tensor(9941.6260, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4452., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 06:54:21 | INFO | train_inner | epoch 008:   4996 / 9060 loss=6.427, nll_loss=3.244, ppl=9.47, wps=6880.6, ups=0.53, wpb=12943.4, bsz=432.9, num_updates=68400, lr=0.000120913, gnorm=0.822, loss_scale=8, train_wall=188, gb_free=14.6, wall=72854
lprobs.size(): torch.Size([3360, 42808])
2023-09-21 06:57:28 | INFO | train_inner | epoch 008:   5096 / 9060 loss=6.225, nll_loss=3.185, ppl=9.09, wps=6945.3, ups=0.54, wpb=12957, bsz=419.4, num_updates=68500, lr=0.000120824, gnorm=0.802, loss_scale=8, train_wall=186, gb_free=15.4, wall=73041
ter_threshold: 0.368581
num_accepted / total 46 112
loss token level: tensor(9095.6025, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9960., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 07:00:42 | INFO | train_inner | epoch 008:   5196 / 9060 loss=6.272, nll_loss=3.168, ppl=8.99, wps=6662.9, ups=0.52, wpb=12925.3, bsz=429.3, num_updates=68600, lr=0.000120736, gnorm=0.84, loss_scale=8, train_wall=194, gb_free=15.4, wall=73235
ter_threshold: 0.36863999999999997
num_accepted / total 80 176
loss token level: tensor(9473.1846, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10784., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.368649
num_accepted / total 113 232
loss token level: tensor(7499.3730, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6712., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5070, 42808])
2023-09-21 07:03:48 | INFO | train_inner | epoch 008:   5296 / 9060 loss=6.303, nll_loss=3.205, ppl=9.22, wps=6945.7, ups=0.54, wpb=12970.2, bsz=428.6, num_updates=68700, lr=0.000120648, gnorm=0.801, loss_scale=8, train_wall=186, gb_free=14.6, wall=73422
pred_new.size(): torch.Size([1900, 42808])
2023-09-21 07:07:02 | INFO | train_inner | epoch 008:   5396 / 9060 loss=6.377, nll_loss=3.217, ppl=9.3, wps=6708.7, ups=0.52, wpb=12965.5, bsz=425.4, num_updates=68800, lr=0.000120561, gnorm=0.831, loss_scale=8, train_wall=193, gb_free=13.2, wall=73615
2023-09-21 07:10:07 | INFO | train_inner | epoch 008:   5496 / 9060 loss=6.245, nll_loss=3.195, ppl=9.16, wps=6979, ups=0.54, wpb=12943.2, bsz=431, num_updates=68900, lr=0.000120473, gnorm=0.831, loss_scale=8, train_wall=185, gb_free=13.6, wall=73800
pred_new.size(): torch.Size([1440, 42808])
pred_new.size(): torch.Size([516, 42808])
pred_new.size(): torch.Size([336, 42808])
2023-09-21 07:13:16 | INFO | train_inner | epoch 008:   5596 / 9060 loss=6.337, nll_loss=3.227, ppl=9.37, wps=6835.7, ups=0.53, wpb=12933.7, bsz=432.6, num_updates=69000, lr=0.000120386, gnorm=0.813, loss_scale=8, train_wall=189, gb_free=13.5, wall=73990
2023-09-21 07:16:23 | INFO | train_inner | epoch 008:   5696 / 9060 loss=6.345, nll_loss=3.208, ppl=9.24, wps=6987.5, ups=0.53, wpb=13072.4, bsz=429.2, num_updates=69100, lr=0.000120299, gnorm=0.827, loss_scale=8, train_wall=187, gb_free=14.3, wall=74177
2023-09-21 07:19:41 | INFO | train_inner | epoch 008:   5796 / 9060 loss=6.306, nll_loss=3.199, ppl=9.19, wps=6543.8, ups=0.51, wpb=12954.9, bsz=430.9, num_updates=69200, lr=0.000120212, gnorm=0.813, loss_scale=8, train_wall=198, gb_free=14.8, wall=74375
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 07:22:49 | INFO | train_inner | epoch 008:   5896 / 9060 loss=6.412, nll_loss=3.227, ppl=9.37, wps=6889.9, ups=0.53, wpb=12941.5, bsz=433.1, num_updates=69300, lr=0.000120125, gnorm=0.819, loss_scale=8, train_wall=188, gb_free=14.4, wall=74563
lprobs.size(): torch.Size([2920, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([5841, 42808])
pred_new.size(): torch.Size([972, 42808])
ter_threshold: 0.361761
num_accepted / total 67 168
loss token level: tensor(8795.3574, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8320., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2392, 42808])
pred_new.size(): torch.Size([1230, 42808])
pred_new.size(): torch.Size([2970, 42808])
pred_new.size(): torch.Size([1768, 42808])
lprobs.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.362544
num_accepted / total 16 96
loss token level: tensor(11042.5273, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2330., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([3640, 42808])
ter_threshold: 0.362834
num_accepted / total 16 112
loss token level: tensor(9632.2100, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1952., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36284299999999997
num_accepted / total 35 112
loss token level: tensor(8863.5938, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4014., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2752, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3072, 42808])
ter_threshold: 0.363262
num_accepted / total 18 104
loss token level: tensor(10230.9912, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4480., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2100, 42808])
pred_new.size(): torch.Size([4680, 42808])
pred_new.size(): torch.Size([5353, 42808])
pred_new.size(): torch.Size([1600, 42808])
ter_threshold: 0.363686
num_accepted / total 2 56
loss token level: tensor(10038.9756, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(859.5000, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4725, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.363987
num_accepted / total 15 64
loss token level: tensor(8962.3672, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6236., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([861, 42808])
lprobs.size(): torch.Size([2920, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3392, 42808])
ter_threshold: 0.36439499999999997
num_accepted / total 0 80
loss token level: tensor(13999.1377, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: 0
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1539, 42808])
pred_new.size(): torch.Size([4221, 42808])
ter_threshold: 0.364813
num_accepted / total 10 64
loss token level: tensor(9323.5605, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4456., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1860, 42808])
ter_threshold: 0.36511899999999997
num_accepted / total 4 128
loss token level: tensor(9310.1318, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(322., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1410, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.36550499999999997
num_accepted / total 20 80
loss token level: tensor(9235.3623, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3590., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2940, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3072, 42808])
ter_threshold: 0.365865
num_accepted / total 15 88
loss token level: tensor(8693.6289, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3752., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1683, 42808])
pred_new.size(): torch.Size([2106, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1056, 42808])
pred_new.size(): torch.Size([176, 42808])
pred_new.size(): torch.Size([3335, 42808])
ter_threshold: 0.366311
num_accepted / total 4 56
loss token level: tensor(9825.5918, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1756., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([396, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2002, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([4025, 42808])
ter_threshold: 0.367139
num_accepted / total 23 64
loss token level: tensor(8635.2324, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9280., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.367153
num_accepted / total 19 128
loss token level: tensor(8322.0352, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2424., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1338, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([444, 42808])
pred_new.size(): torch.Size([2700, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.367401
num_accepted / total 80 208
loss token level: tensor(9196.2979, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8520., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.36744299999999996
num_accepted / total 10 56
loss token level: tensor(10832.8848, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5080., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4674, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([1690, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([1938, 42808])
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([2871, 42808])
pred_new.size(): torch.Size([1496, 42808])
ter_threshold: 0.367923
num_accepted / total 22 64
loss token level: tensor(9593.5605, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8656., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1530, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2928, 42808])
pred_new.size(): torch.Size([4088, 42808])
pred_new.size(): torch.Size([4921, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.368581
num_accepted / total 32 96
loss token level: tensor(10167.2959, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8680., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36863999999999997
num_accepted / total 40 136
loss token level: tensor(8106.7163, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5660., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.368649
num_accepted / total 116 256
loss token level: tensor(9093.1699, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9280., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1260, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([5200, 42808])
pred_new.size(): torch.Size([2295, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.369302
num_accepted / total pred_new.size(): torch.Size([1206, 42808])
2023-09-21 07:25:58 | INFO | train_inner | epoch 008:   5996 / 9060 loss=6.321, nll_loss=3.223, ppl=9.33, wps=6852.5, ups=0.53, wpb=12944.5, bsz=446.6, num_updates=69400, lr=0.000120038, gnorm=0.812, loss_scale=8, train_wall=189, gb_free=14.3, wall=74751
2023-09-21 07:28:59 | INFO | train_inner | epoch 008:   6096 / 9060 loss=6.335, nll_loss=3.188, ppl=9.11, wps=7170, ups=0.55, wpb=12954.3, bsz=441.2, num_updates=69500, lr=0.000119952, gnorm=0.79, loss_scale=8, train_wall=180, gb_free=15, wall=74932
2023-09-21 07:32:07 | INFO | train_inner | epoch 008:   6196 / 9060 loss=6.284, nll_loss=3.175, ppl=9.03, wps=6831, ups=0.53, wpb=12886.4, bsz=444, num_updates=69600, lr=0.000119866, gnorm=0.82, loss_scale=8, train_wall=188, gb_free=14.7, wall=75121
2023-09-21 07:35:21 | INFO | train_inner | epoch 008:   6296 / 9060 loss=6.339, nll_loss=3.222, ppl=9.33, wps=6752.7, ups=0.52, wpb=13103, bsz=415.4, num_updates=69700, lr=0.00011978, gnorm=0.823, loss_scale=8, train_wall=194, gb_free=14.4, wall=75315
lprobs.size(): torch.Size([2400, 42808])
2023-09-21 07:38:32 | INFO | train_inner | epoch 008:   6396 / 9060 loss=6.212, nll_loss=3.166, ppl=8.98, wps=6751.2, ups=0.52, wpb=12891.2, bsz=445.3, num_updates=69800, lr=0.000119694, gnorm=0.784, loss_scale=8, train_wall=191, gb_free=14.8, wall=75506
ter_threshold: 0.36988699999999997
num_accepted / total 48 136
loss token level: tensor(8459.2148, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7448., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 07:41:49 | INFO | train_inner | epoch 008:   6496 / 9060 loss=6.314, nll_loss=3.175, ppl=9.03, wps=6643.3, ups=0.51, wpb=13033.2, bsz=422.1, num_updates=69900, lr=0.000119608, gnorm=0.796, loss_scale=8, train_wall=196, gb_free=14.3, wall=75702
pred_new.size(): torch.Size([774, 42808])
lprobs.size(): torch.Size([3432, 42808])
2023-09-21 07:45:00 | INFO | train_inner | epoch 008:   6596 / 9060 loss=6.319, nll_loss=3.179, ppl=9.05, wps=6744.2, ups=0.52, wpb=12938.4, bsz=407.8, num_updates=70000, lr=0.000119523, gnorm=0.805, loss_scale=8, train_wall=192, gb_free=13.8, wall=75894
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2304, 42808])
2023-09-21 07:48:09 | INFO | train_inner | epoch 008:   6696 / 9060 loss=6.289, nll_loss=3.194, ppl=9.15, wps=6918.1, ups=0.53, wpb=13018.4, bsz=416, num_updates=70100, lr=0.000119438, gnorm=0.789, loss_scale=8, train_wall=188, gb_free=14.8, wall=76082
pred_new.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([5226, 42808])
2023-09-21 07:51:13 | INFO | train_inner | epoch 008:   6796 / 9060 loss=6.392, nll_loss=3.251, ppl=9.52, wps=6983.9, ups=0.54, wpb=12906.1, bsz=452.2, num_updates=70200, lr=0.000119352, gnorm=0.812, loss_scale=8, train_wall=185, gb_free=15.6, wall=76267
2023-09-21 07:54:21 | INFO | train_inner | epoch 008:   6896 / 9060 loss=6.379, nll_loss=3.243, ppl=9.47, wps=6947.5, ups=0.53, wpb=13013.1, bsz=425.2, num_updates=70300, lr=0.000119268, gnorm=0.823, loss_scale=8, train_wall=187, gb_free=13.3, wall=76454
pred_new.size(): torch.Size([1075, 42808])
2023-09-21 07:57:32 | INFO | train_inner | epoch 008:   6996 / 9060 loss=6.299, nll_loss=3.186, ppl=9.1, wps=6758.4, ups=0.52, wpb=12948.6, bsz=406.6, num_updates=70400, lr=0.000119183, gnorm=0.819, loss_scale=8, train_wall=191, gb_free=14.7, wall=76646
2023-09-21 08:00:45 | INFO | train_inner | epoch 008:   7096 / 9060 loss=6.387, nll_loss=3.247, ppl=9.49, wps=6768.8, ups=0.52, wpb=13029.5, bsz=438.2, num_updates=70500, lr=0.000119098, gnorm=0.808, loss_scale=8, train_wall=192, gb_free=13.8, wall=76838
pred_new.size(): torch.Size([3220, 42808])
pred_new.size(): torch.Size([1740, 42808])
2023-09-21 08:04:00 | INFO | train_inner | epoch 008:   7196 / 9060 loss=6.426, nll_loss=3.251, ppl=9.52, wps=6638.3, ups=0.51, wpb=12954.6, bsz=450.9, num_updates=70600, lr=0.000119014, gnorm=0.826, loss_scale=8, train_wall=195, gb_free=14.4, wall=77033
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 08:07:15 | INFO | train_inner | epoch 008:   7296 / 9060 loss=6.276, nll_loss=3.163, ppl=8.96, wps=6642, ups=0.51, wpb=12958, bsz=423, num_updates=70700, lr=0.00011893, gnorm=0.81, loss_scale=16, train_wall=195, gb_free=14.8, wall=77228
2023-09-21 08:10:19 | INFO | train_inner | epoch 008:   7396 / 9060 loss=6.37, nll_loss=3.23, ppl=9.38, wps=7032.3, ups=0.54, wpb=12962.8, bsz=426.7, num_updates=70800, lr=0.000118846, gnorm=0.81, loss_scale=16, train_wall=184, gb_free=13.5, wall=77413
2023-09-21 08:13:27 | INFO | train_inner | epoch 008:   7496 / 9060 loss=6.31, nll_loss=3.217, ppl=9.3, wps=6856.5, ups=0.53, wpb=12890, bsz=439.8, num_updates=70900, lr=0.000118762, gnorm=0.837, loss_scale=16, train_wall=188, gb_free=14.4, wall=77601
2023-09-21 08:16:43 | INFO | train_inner | epoch 008:   7596 / 9060 loss=6.301, nll_loss=3.188, ppl=9.11, wps=6650.5, ups=0.51, wpb=13031, bsz=423.6, num_updates=71000, lr=0.000118678, gnorm=0.817, loss_scale=16, train_wall=196, gb_free=14.6, wall=77797
lprobs.size(): torch.Size([3312, 42808])
2023-09-21 08:19:45 | INFO | train_inner | epoch 008:   7696 / 9060 loss=6.341, nll_loss=3.235, ppl=9.42, wps=7079.1, ups=0.55, wpb=12889, bsz=422.1, num_updates=71100, lr=0.000118595, gnorm=0.81, loss_scale=16, train_wall=182, gb_free=14.3, wall=77979
ter_threshold: 0.371116
num_accepted / total 13 48
loss token level: tensor(9137.0889, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6792., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([774, 42808])
ter_threshold: 0.37116099999999996
num_accepted / total 22 104
loss token level: tensor(9832.4209, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3208., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 08:23:02 | INFO | train_inner | epoch 008:   7796 / 9060 loss=6.404, nll_loss=3.214, ppl=9.28, wps=6590.1, ups=0.51, wpb=12980.6, bsz=445.1, num_updates=71200, lr=0.000118511, gnorm=0.801, loss_scale=16, train_wall=197, gb_free=14.5, wall=78176
ter_threshold: 0.371202
num_accepted / total 29 104
loss token level: tensor(9903.2051, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4040., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 08:26:08 | INFO | train_inner | epoch 008:   7896 / 9060 loss=6.261, nll_loss=3.199, ppl=9.18, wps=7049.5, ups=0.54, wpb=13057.4, bsz=430.6, num_updates=71300, lr=0.000118428, gnorm=0.78, loss_scale=16, train_wall=185, gb_free=14.3, wall=78361
2023-09-21 08:26:39 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3312, 42808])
2023-09-21 08:29:14 | INFO | train_inner | epoch 008:   7997 / 9060 loss=6.311, nll_loss=3.211, ppl=9.26, wps=6947.8, ups=0.54, wpb=12943.8, bsz=425.1, num_updates=71400, lr=0.000118345, gnorm=0.822, loss_scale=8, train_wall=186, gb_free=14.3, wall=78547
pred_new.size(): torch.Size([2028, 42808])
lprobs.size(): torch.Size([3240, 42808])
2023-09-21 08:32:17 | INFO | train_inner | epoch 008:   8097 / 9060 loss=6.308, nll_loss=3.2, ppl=9.19, wps=7096.5, ups=0.55, wpb=13011.6, bsz=441.9, num_updates=71500, lr=0.000118262, gnorm=0.805, loss_scale=8, train_wall=183, gb_free=14.3, wall=78731
pred_new.size(): torch.Size([1302, 42808])
2023-09-21 08:35:23 | INFO | train_inner | epoch 008:   8197 / 9060 loss=6.352, nll_loss=3.204, ppl=9.22, wps=6948.2, ups=0.54, wpb=12938.6, bsz=435, num_updates=71600, lr=0.00011818, gnorm=0.804, loss_scale=8, train_wall=186, gb_free=15.8, wall=78917
2023-09-21 08:38:38 | INFO | train_inner | epoch 008:   8297 / 9060 loss=6.32, nll_loss=3.209, ppl=9.25, wps=6609.4, ups=0.51, wpb=12895.1, bsz=440.6, num_updates=71700, lr=0.000118097, gnorm=0.827, loss_scale=8, train_wall=195, gb_free=14.8, wall=79112
ter_threshold: 0.371749
num_accepted / total 10 104
loss token level: tensor(12529.8867, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2300., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 08:41:41 | INFO | train_inner | epoch 008:   8397 / 9060 loss=6.327, nll_loss=3.216, ppl=9.29, wps=7179.4, ups=0.55, wpb=13078.4, bsz=416.9, num_updates=71800, lr=0.000118015, gnorm=0.808, loss_scale=8, train_wall=182, gb_free=14.5, wall=79294
lprobs.size(): torch.Size([3384, 42808])
2023-09-21 08:44:49 | INFO | train_inner | epoch 008:   8497 / 9060 loss=6.372, nll_loss=3.203, ppl=9.21, wps=6871.6, ups=0.53, wpb=12968.6, bsz=440.3, num_updates=71900, lr=0.000117933, gnorm=0.82, loss_scale=8, train_wall=188, gb_free=14.8, wall=79483
lprobs.size(): torch.Size([2736, 42808])
2023-09-21 08:47:58 | INFO | train_inner | epoch 008:   8597 / 9060 loss=6.296, nll_loss=3.195, ppl=9.16, wps=6851.3, ups=0.53, wpb=12918.8, bsz=423.4, num_updates=72000, lr=0.000117851, gnorm=0.816, loss_scale=8, train_wall=188, gb_free=14.4, wall=79671
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 08:49:03 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
ter_threshold: 0.372054
num_accepted / total 29 104
loss token level: tensor(10612.5586, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6976., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1440, 42808])
ter_threshold: 0.372085
num_accepted / total 14 112
loss token level: tensor(8167.2241, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1304., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3216, 42808])
2023-09-21 08:51:12 | INFO | train_inner | epoch 008:   8698 / 9060 loss=6.411, nll_loss=3.227, ppl=9.36, wps=6748.3, ups=0.51, wpb=13108.4, bsz=447, num_updates=72100, lr=0.000117769, gnorm=0.826, loss_scale=4, train_wall=194, gb_free=13.8, wall=79866
ter_threshold: 0.372112
num_accepted / total 38 112
loss token level: tensor(9579.5674, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8776., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 08:54:26 | INFO | train_inner | epoch 008:   8798 / 9060 loss=6.357, nll_loss=3.215, ppl=9.28, wps=6732.7, ups=0.52, wpb=13065.1, bsz=441.4, num_updates=72200, lr=0.000117688, gnorm=0.797, loss_scale=4, train_wall=194, gb_free=14.7, wall=80060
2023-09-21 08:57:40 | INFO | train_inner | epoch 008:   8898 / 9060 loss=6.328, nll_loss=3.176, ppl=9.04, wps=6671.7, ups=0.52, wpb=12933.1, bsz=427.2, num_updates=72300, lr=0.000117606, gnorm=0.787, loss_scale=4, train_wall=194, gb_free=14.4, wall=80254
2023-09-21 09:00:52 | INFO | train_inner | epoch 008:   8998 / 9060 loss=6.434, nll_loss=3.232, ppl=9.4, wps=6777.9, ups=0.52, wpb=12983, bsz=446.1, num_updates=72400, lr=0.000117525, gnorm=0.855, loss_scale=4, train_wall=191, gb_free=14.5, wall=80445
2023-09-21 09:02:59 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-21 09:02:59 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 09:03:00 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-21 09:03:00 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-21 09:03:00 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-21 09:03:00 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-21 09:03:01 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-21 09:03:01 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-21 09:03:01 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-21 09:03:01 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-21 09:03:02 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-21 09:03:02 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-21 09:03:02 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein bewegender Erfolg.
2023-09-21 09:03:02 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-21 09:03:03 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-21 09:03:03 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-21 09:03:03 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-21 09:03:03 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-21 09:03:04 | INFO | fairseq.tasks.translation | example hypothesis: Das Chatmodul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatgesprächen.
2023-09-21 09:03:04 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-21 09:03:05 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten digitales Fernsehen und Internetzugang, die sowohl für Geschäfts- als auch für Privatreisende geeignet sind.
2023-09-21 09:03:05 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-21 09:03:05 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-21 09:03:05 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-21 09:03:06 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 09:03:06 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 09:03:06 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU als Ganzes riesige Mengen an Energie verschwendet.
2023-09-21 09:03:06 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-21 09:03:07 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin trägt einen Artikel des Gentoo Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-21 09:03:07 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-21 09:03:07 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich auch die Änderung der Haltung bald im Haushalt der Union widerspiegeln.
2023-09-21 09:03:07 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-21 09:03:08 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-21 09:03:08 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-21 09:03:08 | INFO | fairseq.tasks.translation | example hypothesis: Hier ist ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-21 09:03:08 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-21 09:03:09 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der Hauptziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-21 09:03:09 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-21 09:03:10 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie sich gewünscht hätten?
2023-09-21 09:03:10 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-21 09:03:10 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionsräume in Stans.
2023-09-21 09:03:10 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-21 09:03:11 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-21 09:03:11 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-21 09:03:11 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-21 09:03:11 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-21 09:03:12 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-21 09:03:12 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-21 09:03:12 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potenzielle Käufer dazu bringen, über die Qualität Ihres Services und Ihrer Produkte zu informieren.
2023-09-21 09:03:12 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-21 09:03:13 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in ungecharterte Gebiete wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-21 09:03:13 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-21 09:03:14 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-21 09:03:14 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-21 09:03:14 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-21 09:03:14 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-21 09:03:15 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Orte in etwa einem Umkreis von 8 km von The Strip.
2023-09-21 09:03:15 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-21 09:03:15 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web-legale Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-21 09:03:15 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-21 09:03:16 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die Umsetzung von Klanghandbüchern akustisch, interaktiv oder in schriftlicher Form an.
2023-09-21 09:03:16 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-21 09:03:16 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-21 09:03:16 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-21 09:03:17 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer internen Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und SicherheitsZusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu gewährleisten.
2023-09-21 09:03:17 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-21 09:03:18 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Ausreise Zugang zu dem Geld erhalten, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-21 09:03:18 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-21 09:03:18 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendeten das Ascent Ti-Modell als Basis.
2023-09-21 09:03:18 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-21 09:03:19 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf Computerplattformen läuft.
2023-09-21 09:03:19 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-21 09:03:19 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachkräfte zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-21 09:03:19 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-21 09:03:20 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherische Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselbereiche seiner Agenda.
2023-09-21 09:03:20 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-21 09:03:20 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen Splashutils neu emergen, damit sie korrekt funktionieren.
2023-09-21 09:03:20 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-21 09:03:21 | INFO | fairseq.tasks.translation | example hypothesis: Spieler von Horde und Allianz können Gegenstände nicht kaufen oder verkaufen, wenn sie die unten aufgeführten neutralen Auktionshäuser nicht nutzen.
2023-09-21 09:03:21 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-21 09:03:22 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-21 09:03:22 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-21 09:03:22 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn die Entlastung der Kommission für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-21 09:03:22 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-21 09:03:23 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Einzelheiten des Abkommens im Prinzip mit den Vereinigten Staaten vorlegen müssen.
2023-09-21 09:03:23 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-21 09:03:24 | INFO | fairseq.tasks.translation | example hypothesis: Ob trendige oder klassische Farben, zeitloses Design oder besondere Edition - unser breites Sortiment an Plastik-Babyartikeln ist beeindruckend, nicht zuletzt aufgrund seiner hervorragenden Verarbeitung.
2023-09-21 09:03:24 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-21 09:03:24 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 09:03:24 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 09:03:25 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis dieser AGB über Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-21 09:03:25 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-21 09:03:25 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht hat und erkannt hat, dass institutionelle Veränderungen notwendig sind, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung erfordert.
2023-09-21 09:03:25 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-21 09:03:26 | INFO | fairseq.tasks.translation | example hypothesis: Neben unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden mit Produktnachrichten und Informationen aus allen Kategorien in zwei Sprachen erstellt.
2023-09-21 09:03:26 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-21 09:03:27 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die erheblichen Fortschritte erkennen, die bei all den Themen erzielt wurden, die jetzt zur Diskussion stehen, nämlich etwas, das gerade einmal zwei Jahre alt ist, nämlich die neue transatlantische Agenda.
2023-09-21 09:03:27 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-21 09:03:27 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-21 09:03:27 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-21 09:03:28 | INFO | fairseq.tasks.translation | example hypothesis: Einmal mehr war der Berichterstatter in der Lage, gelegentlich unterschiedliche Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-21 09:03:28 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-21 09:03:29 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm der trockenen elektrostatischen Niederschläge mit einem trockenen ESP für den niedrigeren Leistungsbereich.
2023-09-21 09:03:29 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-21 09:03:29 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-21 09:03:29 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-21 09:03:30 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-21 09:03:30 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-21 09:03:30 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und stützt sich auf Verhandlungen mit Drittländern, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-21 09:03:30 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-21 09:03:31 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 000 $.
2023-09-21 09:03:31 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-21 09:03:32 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-21 09:03:32 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-21 09:03:32 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-21 09:03:32 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-21 09:03:33 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch einen weiteren: den Notfall, an dem die Kinder, der schwächste Sektor der Bevölkerung, betroffen sind, der keine Familie, keinen Schutz und keinen Staat mehr hat.
2023-09-21 09:03:33 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-21 09:03:34 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis der Flossen seit 2003 von der EU reguliert wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-21 09:03:34 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-21 09:03:34 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei und erst gar nicht erst verwirklicht ist, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis befleckt, denn man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-21 09:03:34 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-21 09:03:35 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in ihrer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren zur Wählerregistrierung wieder zu eröffnen.
2023-09-21 09:03:35 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-21 09:03:36 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgerinnen und Bürgern freie Meinungsäußerung, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-21 09:03:36 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-21 09:03:36 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java-Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystemunabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-21 09:03:36 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-21 09:03:37 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für eine Klärung des Anhangs.
2023-09-21 09:03:37 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-21 09:03:38 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen betrachtet werden.
2023-09-21 09:03:38 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-21 09:03:38 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische öffentlich-rechtliche Radio RTE teilgenommen, mit einer Frau, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-21 09:03:38 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-21 09:03:39 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-21 09:03:39 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-21 09:03:40 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihre Lektionen oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas wie die Verringerung des individuellen Energieverbrauchs suchen, sollten Sie etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-21 09:03:40 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-21 09:03:40 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.
2023-09-21 09:03:40 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-21 09:03:41 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, abgesehen von diesen wenigen Vorbehalten, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-21 09:03:41 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-21 09:03:42 | INFO | fairseq.tasks.translation | example hypothesis: Anderes zu denken, heißt, zu naturalisieren und zu mystifizieren, was eine bestimmte Art von Vertragsbeziehung zwischen Menschen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Drohung, von der institutionellen Hegemonie zerschlagen zu werden)!
2023-09-21 09:03:42 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-21 09:03:42 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft bei einem Thema, das personenbezogene Daten betrifft, sollte der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-21 09:03:42 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-21 09:03:43 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er Serie ist eines der lustigsten Autos, das unter 50.000 Dollar fährt, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos für Sie ausprobieren.
2023-09-21 09:03:43 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-21 09:03:44 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte und gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-21 09:03:44 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-21 09:03:44 | INFO | fairseq.tasks.translation | example hypothesis: Sie müssen Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt (stew) und den ausgezeichneten Süßwasserfisch: gegrillte Taube, Forelle mit Mandeln.
2023-09-21 09:03:44 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-21 09:03:45 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt daran zu erinnern, was eine politische Aktion bedeutet, eine Gesamtsicht zu bieten, die es uns ermöglicht, näher auf die verschiedenen Fragen einzugehen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-21 09:03:45 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-21 09:03:46 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-21 09:03:46 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-21 09:03:47 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht werden und die Wettbewerbsfähigkeit durch makroökonomische Strategien, steuerliche Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, schrittweise untergraben wird.
2023-09-21 09:03:47 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-21 09:03:47 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament mit einem ausgezeichneten Beispiel für die Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-21 09:03:47 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-21 09:03:48 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus um die entsprechenden Folgen für den rechtlichen und juristischen Bereich hinaus, wodurch Norwegen und Island Länder, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden, gelten werden.
2023-09-21 09:03:48 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-21 09:03:49 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schichtboot den Mississippi hinunterfahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein.
2023-09-21 09:03:49 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-21 09:03:50 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion und die Strafbarkeit der Sanktionen, die bei solchen von Personen begangenen Verletzungen verhängt werden können.
2023-09-21 09:03:50 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-21 09:03:50 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat dafür verurteilt, dass sie ihre Arbeit als Journalisten und Kameramänner verrichtet und eine Gruppe von Bergbewohnern gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das jedes Prinzip der Demokratie missachtet.
2023-09-21 09:03:50 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-21 09:03:51 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, Transport und Sightseeing-Service, ein Menue und Pressservice, ein Wechselstube, kostenloser Schuhputzservice und WLAN-Internetzugang. Die Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-21 09:03:51 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-21 09:03:52 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen dem Thermalquelle verdankt, den Königin D. Leonor, die Frau von König D. João II, und bekannt durch ihre Keramik international berühmt für ihre bildlichen und satirischen Werke bekannt ist, ist es auch einen Besuch wert.
2023-09-21 09:03:52 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-21 09:03:53 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute pro-Westler auf der einen Seite und um Anhänger des früheren Regimes auf der anderen Seite handelt - das ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-21 09:03:53 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-21 09:03:54 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, aber ich muss darauf hinweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer reisen, nicht auf diese Weise erfasst werden, und das ist sicherlich ein Punkt, der irgendwie irgendwie abgedeckt werden sollte.
2023-09-21 09:03:54 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-21 09:03:54 | INFO | fairseq.tasks.translation | example hypothesis: (4) Sofern Informationen außerhalb einer Aktionärsversammlung einem Aktionär aufgrund seines Status als Aktionär zur Verfügung gestellt wurden, werden diese Informationen auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn solche Informationen nicht notwendig sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-21 09:03:54 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-21 09:03:55 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch die nachfolgende Kontrolle haben, weil Milliarden und Milliarden von Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren gelangen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Millionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.
2023-09-21 09:03:55 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-21 09:03:56 | INFO | fairseq.tasks.translation | example hypothesis: Wir bitten die Mitgliedstaaten - weil sie sagen, Flugzeuge aus einem Mitgliedstaat oder die NATO hätten in diesen Kriegsakt verwickelt sein können -, bei Informationen zu helfen, die es keinen Grund mehr gibt, geheim, verschwiegen oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-21 09:03:56 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-21 09:03:57 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Bezirk Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und eine 30-minütige Zugfahrt vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 09:03:57 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 09:03:58 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien wird der Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen entscheidend sind, die die heutigen Off-the-Regf-Plattformen nie erreichen können.
2023-09-21 09:03:58 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-21 09:03:59 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar machen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit jene Produkte vom Markt zu nehmen, die eine ernste Gefahr darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-21 09:03:59 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-21 09:04:00 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Komplott von Modernität und Postmoderne oder der klaren Opposition reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung jener beiden ästhetischen Politik anerkennen, die in eben den Formen der Sichtbarkeit und Verständlichkeit verstrickt sind, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-21 09:04:00 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-21 09:04:01 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werden wir angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir abgegeben haben, die eindeutig weitgehend das unterstützen, was ich gerade gesagt habe, und auf der Grundlage der vorangegangenen Beschlüsse, werden wir unsere Debatten führen, und wenn die vierzig Petenten nicht anwesend sind, werde ich bei der Abstimmung nicht beantragen, dass die Beschlußfähigkeit überprüft wird.
2023-09-21 09:04:01 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-21 09:04:02 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker niemals die Begrenzung des nationalstaatlichen Prinzips akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum niemandem bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.
2023-09-21 09:04:02 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-21 09:04:03 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Hinsicht als Hybridform veröffentlicht, die Rezensionen und Artikel der Quartalszeitschrift sind für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an ihre Abonnenten verteilt.
2023-09-21 09:04:03 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-21 09:04:04 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit dem Eintreffen der neuen Smartphone-Generation haben Handys nicht nur ihre Federn deutlich verfeinert, sondern auch von einst blutigen Taschenlampen über polyphonisch tootende Game Boy-Ambitionen bis hin zu schlichten Mini-PCs mit knackigem CD-Qualität Stereo-Sound: Von nun an könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-wannabes zu Trailblazers neuer technologischer Entwicklungen übergehen.
2023-09-21 09:04:04 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-21 09:04:06 | INFO | fairseq.tasks.translation | example hypothesis: En un principio, Jake cumple profesionalmente su misión, pero se enamora de una de una de las nativas, Neytiri, y se cuenta de éque están stás renunciarán a su tierra, hacira, haciendo un unausweichlich hacira, haciendo un qué deará en la mada de la dequesta de dequé.
2023-09-21 09:04:06 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-21 09:04:06 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 4.241 | nll_loss 2.257 | ppl 4.78 | bleu 29.19 | wps 17672.6 | wpb 12011.9 | bsz 398.1 | num_updates 72462 | best_bleu 29.19
2023-09-21 09:04:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 72462 updates
2023-09-21 09:04:06 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint8.pt
2023-09-21 09:04:12 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint8.pt
2023-09-21 09:04:20 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint8.pt (epoch 8 @ 72462 updates, score 29.19) (writing took 13.102413613989484 seconds)
2023-09-21 09:04:20 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2023-09-21 09:04:20 | INFO | train | epoch 008 | loss 6.31 | nll_loss 3.195 | ppl 9.16 | wps 6847.2 | ups 0.53 | wpb 12977.3 | bsz 430.6 | num_updates 72462 | lr 0.000117475 | gnorm 0.812 | loss_scale 4 | train_wall 17061 | gb_free 14.7 | wall 80653
2023-09-21 09:04:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 09:04:20 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-21 09:04:20 | INFO | fairseq.trainer | begin training epoch 9
2023-09-21 09:04:20 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-21 09:05:31 | INFO | train_inner | epoch 009:     38 / 9060 loss=6.358, nll_loss=3.212, ppl=9.27, wps=4676.9, ups=0.36, wpb=13050.8, bsz=417.8, num_updates=72500, lr=0.000117444, gnorm=0.825, loss_scale=4, train_wall=198, gb_free=14.3, wall=80724
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1056, 42808])
lprobs.size(): torch.Size([3136, 42808])
2023-09-21 09:08:36 | INFO | train_inner | epoch 009:    138 / 9060 loss=6.236, nll_loss=3.138, ppl=8.8, wps=7032.7, ups=0.54, wpb=13037.9, bsz=410.5, num_updates=72600, lr=0.000117363, gnorm=0.825, loss_scale=4, train_wall=185, gb_free=14.9, wall=80910
pred_new.size(): torch.Size([2600, 42808])
2023-09-21 09:12:02 | INFO | train_inner | epoch 009:    238 / 9060 loss=6.247, nll_loss=3.12, ppl=8.69, wps=6304.9, ups=0.49, wpb=12976.8, bsz=444.2, num_updates=72700, lr=0.000117282, gnorm=0.814, loss_scale=4, train_wall=206, gb_free=15.8, wall=81115
2023-09-21 09:15:12 | INFO | train_inner | epoch 009:    338 / 9060 loss=6.42, nll_loss=3.225, ppl=9.35, wps=6862.2, ups=0.53, wpb=13033.3, bsz=453.8, num_updates=72800, lr=0.000117202, gnorm=0.821, loss_scale=4, train_wall=190, gb_free=15.1, wall=81305
2023-09-21 09:18:33 | INFO | train_inner | epoch 009:    438 / 9060 loss=6.396, nll_loss=3.198, ppl=9.18, wps=6412.3, ups=0.5, wpb=12914.6, bsz=405.4, num_updates=72900, lr=0.000117121, gnorm=0.835, loss_scale=4, train_wall=201, gb_free=14.5, wall=81507
lprobs.size(): torch.Size([3264, 42808])
2023-09-21 09:21:45 | INFO | train_inner | epoch 009:    538 / 9060 loss=6.318, nll_loss=3.157, ppl=8.92, wps=6796.8, ups=0.52, wpb=13044.1, bsz=419.6, num_updates=73000, lr=0.000117041, gnorm=0.826, loss_scale=4, train_wall=192, gb_free=14.4, wall=81699
lprobs.size(): torch.Size([3440, 42808])
2023-09-21 09:25:08 | INFO | train_inner | epoch 009:    638 / 9060 loss=6.358, nll_loss=3.213, ppl=9.27, wps=6364.5, ups=0.49, wpb=12918.9, bsz=410.6, num_updates=73100, lr=0.000116961, gnorm=0.856, loss_scale=4, train_wall=203, gb_free=14, wall=81902
ter_threshold: 0.373112
num_accepted / total 34 128
loss token level: tensor(8084.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5520., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.373124
num_accepted / total 14 64
loss token level: tensor(8434.9375, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4476., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 09:28:16 | INFO | train_inner | epoch 009:    738 / 9060 loss=6.395, nll_loss=3.23, ppl=9.38, wps=6885.4, ups=0.53, wpb=12965.3, bsz=429.4, num_updates=73200, lr=0.000116881, gnorm=0.817, loss_scale=4, train_wall=188, gb_free=13.9, wall=82090
2023-09-21 09:31:28 | INFO | train_inner | epoch 009:    838 / 9060 loss=6.449, nll_loss=3.234, ppl=9.41, wps=6775.8, ups=0.52, wpb=12968.6, bsz=424.7, num_updates=73300, lr=0.000116801, gnorm=0.831, loss_scale=4, train_wall=191, gb_free=14, wall=82281
ter_threshold: 0.373351
num_accepted / total 29 104
loss token level: tensor(8894.0391, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6732., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
2023-09-21 09:34:37 | INFO | train_inner | epoch 009:    938 / 9060 loss=6.259, nll_loss=3.171, ppl=9, wps=6825.3, ups=0.53, wpb=12936.3, bsz=435.7, num_updates=73400, lr=0.000116722, gnorm=0.817, loss_scale=4, train_wall=189, gb_free=14.1, wall=82471
pred_new.size(): torch.Size([440, 42808])
lprobs.size(): torch.Size([2632, 42808])
2023-09-21 09:37:46 | INFO | train_inner | epoch 009:   1038 / 9060 loss=6.297, nll_loss=3.166, ppl=8.97, wps=6875.1, ups=0.53, wpb=12965.6, bsz=427.7, num_updates=73500, lr=0.000116642, gnorm=0.819, loss_scale=4, train_wall=188, gb_free=14.3, wall=82659
2023-09-21 09:40:56 | INFO | train_inner | epoch 009:   1138 / 9060 loss=6.375, nll_loss=3.171, ppl=9.01, wps=6827.8, ups=0.53, wpb=12991.7, bsz=439.4, num_updates=73600, lr=0.000116563, gnorm=0.859, loss_scale=4, train_wall=190, gb_free=15.9, wall=82850
2023-09-21 09:44:18 | INFO | train_inner | epoch 009:   1238 / 9060 loss=6.376, nll_loss=3.19, ppl=9.13, wps=6443.6, ups=0.5, wpb=13001.2, bsz=413.4, num_updates=73700, lr=0.000116484, gnorm=0.855, loss_scale=4, train_wall=202, gb_free=15.2, wall=83051
pred_new.size(): torch.Size([3267, 42808])
lprobs.size(): torch.Size([3312, 42808])
2023-09-21 09:47:25 | INFO | train_inner | epoch 009:   1338 / 9060 loss=6.382, nll_loss=3.206, ppl=9.23, wps=6913.4, ups=0.54, wpb=12916.6, bsz=417.9, num_updates=73800, lr=0.000116405, gnorm=0.831, loss_scale=4, train_wall=187, gb_free=14.1, wall=83238
pred_new.size(): torch.Size([2875, 42808])
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([5670, 42808])
2023-09-21 09:50:52 | INFO | train_inner | epoch 009:   1438 / 9060 loss=6.362, nll_loss=3.197, ppl=9.17, wps=6230.8, ups=0.48, wpb=12906.9, bsz=425, num_updates=73900, lr=0.000116326, gnorm=0.925, loss_scale=4, train_wall=207, gb_free=15.8, wall=83445
2023-09-21 09:54:02 | INFO | train_inner | epoch 009:   1538 / 9060 loss=6.339, nll_loss=3.207, ppl=9.23, wps=6826.6, ups=0.53, wpb=12948.8, bsz=423.5, num_updates=74000, lr=0.000116248, gnorm=0.831, loss_scale=4, train_wall=189, gb_free=14.5, wall=83635
ter_threshold: 0.374057
num_accepted / total 23 80
loss token level: tensor(10005.6719, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7496., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.37407199999999996
num_accepted / total 7 56
loss token level: tensor(9551.8379, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1909., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 09:57:10 | INFO | train_inner | epoch 009:   1638 / 9060 loss=6.35, nll_loss=3.186, ppl=9.1, wps=6868.1, ups=0.53, wpb=12937.9, bsz=432, num_updates=74100, lr=0.000116169, gnorm=0.82, loss_scale=4, train_wall=188, gb_free=14.4, wall=83824
torch.Size([2960, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3562, 42808])
pred_new.size(): torch.Size([3234, 42808])
pred_new.size(): torch.Size([1827, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([216, 42808])
lprobs.size(): torch.Size([2528, 42808])
pred_new.size(): torch.Size([840, 42808])
ter_threshold: 0.36511899999999997
num_accepted / total 49 136
loss token level: tensor(9059.2383, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5368., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([936, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.36575199999999997
num_accepted / total 49 224
loss token level: tensor(7932.7222, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2012., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1242, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2680, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3530, 42808])
pred_new.size(): torch.Size([5168, 42808])
pred_new.size(): torch.Size([1974, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([774, 42808])
pred_new.size(): torch.Size([510, 42808])
pred_new.size(): torch.Size([2480, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.367024
num_accepted / total 7 64
loss token level: tensor(10330.3281, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2888., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.367153
num_accepted / total 84 184
loss token level: tensor(9333.3242, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10304., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([3995, 42808])
pred_new.size(): torch.Size([1482, 42808])
pred_new.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2990, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([4686, 42808])
pred_new.size(): torch.Size([1530, 42808])
pred_new.size(): torch.Size([1924, 42808])
pred_new.size(): torch.Size([3366, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([3600, 42808])
pred_new.size(): torch.Size([510, 42808])
pred_new.size(): torch.Size([4068, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.368581
num_accepted / total 62 144
loss token level: tensor(8748.1758, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9760., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.36863999999999997
num_accepted / total 20 104
loss token level: tensor(10654.9102, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5132., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5103, 42808])
pred_new.size(): torch.Size([902, 42808])
pred_new.size(): torch.Size([1350, 42808])
ter_threshold: 0.369133
num_accepted / total 20 88
loss token level: tensor(9534.0693, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5944., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3157, 42808])
ter_threshold: 0.36937699999999996
num_accepted / total 79 176
loss token level: tensor(9074.3350, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5864., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.369624
num_accepted / total 1 48
loss token level: tensor(14133.2236, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(599., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([960, 42808])
ter_threshold: 0.369875
num_accepted / total 0 64
loss token level: tensor(10111.7812, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: 0
pred_new.size(): torch.Size([1485, 42808])
pred_new.size(): torch.Size([1344, 42808])
pred_new.size(): torch.Size([1980, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3500, 42808])
pred_new.size(): torch.Size([2240, 42808])
lprobs.size(): torch.Size([2808, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([1395, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.37107
num_accepted / total 9 40
loss token level: tensor(8020.8184, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5292., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([3192, 42808])
ter_threshold: 0.371202
num_accepted / total 43 128
loss token level: tensor(9261.3525, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4804., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1215, 42808])
lprobs.size(): torch.Size([2304, 42808])
pred_new.size(): torch.Size([6858, 42808])
pred_new.size(): torch.Size([1980, 42808])
pred_new.size(): torch.Size([1980, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2430, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.372085
num_accepted / total 42 112
loss token level: tensor(10031.0625, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5232., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.372112
num_accepted / total 32 144
loss token level: tensor(8700.9346, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4244., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4355, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2610, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2744, 42808])
ter_threshold: 0.372627
num_accepted / total 19 80
loss token level: tensor(9718.4082, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6528., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.37262799999999996
num_accepted / total 12 72
loss token level: tensor(8323.7422, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1952., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3060, 42808])
pred_new.size(): torch.Size([1620, 42808])
pred_new.size(): torch.Size([2250, 42808])
ter_threshold: 0.373112
num_accepted / total 35 96
loss token level: tensor(9399.9648, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9440., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.373135
num_accepted / total 17 72
loss token level: tensor(8417.8457, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2962., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.373351
num_accepted / total 30 112
loss token level: tensor(9515.3213, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6136., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([4554, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4060, 42808])
pred_new.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([3944, 42808])
2023-09-21 10:00:15 | INFO | train_inner | epoch 009:   1738 / 9060 loss=6.421, nll_loss=3.205, ppl=9.22, wps=6953.6, ups=0.54, wpb=12863.9, bsz=443.8, num_updates=74200, lr=0.000116091, gnorm=0.837, loss_scale=4, train_wall=185, gb_free=15.6, wall=84008
lprobs.size(): torch.Size([3400, 42808])
2023-09-21 10:03:34 | INFO | train_inner | epoch 009:   1838 / 9060 loss=6.468, nll_loss=3.226, ppl=9.36, wps=6530.7, ups=0.5, wpb=12984.8, bsz=451.3, num_updates=74300, lr=0.000116013, gnorm=0.823, loss_scale=4, train_wall=199, gb_free=14.7, wall=84207
2023-09-21 10:06:49 | INFO | train_inner | epoch 009:   1938 / 9060 loss=6.448, nll_loss=3.245, ppl=9.48, wps=6722.1, ups=0.51, wpb=13123.4, bsz=421, num_updates=74400, lr=0.000115935, gnorm=0.839, loss_scale=4, train_wall=195, gb_free=14, wall=84403
pred_new.size(): torch.Size([4495, 42808])
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.374482
num_accepted / total 4 64
loss token level: tensor(10391.9238, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1532., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 10:09:59 | INFO | train_inner | epoch 009:   2038 / 9060 loss=6.219, nll_loss=3.121, ppl=8.7, wps=6832.9, ups=0.53, wpb=12964, bsz=436.1, num_updates=74500, lr=0.000115857, gnorm=0.844, loss_scale=4, train_wall=189, gb_free=15.1, wall=84592
pred_new.size(): torch.Size([1470, 42808])
2023-09-21 10:13:02 | INFO | train_inner | epoch 009:   2138 / 9060 loss=6.329, nll_loss=3.212, ppl=9.26, wps=7038.1, ups=0.55, wpb=12894.9, bsz=412.2, num_updates=74600, lr=0.000115779, gnorm=0.814, loss_scale=4, train_wall=183, gb_free=14.4, wall=84776
pred_new.size(): torch.Size([1302, 42808])
2023-09-21 10:16:13 | INFO | train_inner | epoch 009:   2238 / 9060 loss=6.324, nll_loss=3.162, ppl=8.95, wps=6794.1, ups=0.52, wpb=13001.4, bsz=454.5, num_updates=74700, lr=0.000115702, gnorm=0.805, loss_scale=4, train_wall=191, gb_free=14.1, wall=84967
lprobs.size(): torch.Size([3040, 42808])
2023-09-21 10:19:32 | INFO | train_inner | epoch 009:   2338 / 9060 loss=6.42, nll_loss=3.23, ppl=9.38, wps=6501.2, ups=0.5, wpb=12902.3, bsz=417.4, num_updates=74800, lr=0.000115624, gnorm=0.841, loss_scale=4, train_wall=198, gb_free=13.8, wall=85165
2023-09-21 10:22:40 | INFO | train_inner | epoch 009:   2438 / 9060 loss=6.37, nll_loss=3.183, ppl=9.08, wps=6861.9, ups=0.53, wpb=12932.5, bsz=421, num_updates=74900, lr=0.000115547, gnorm=0.82, loss_scale=4, train_wall=188, gb_free=15.6, wall=85354
2023-09-21 10:25:46 | INFO | train_inner | epoch 009:   2538 / 9060 loss=6.27, nll_loss=3.145, ppl=8.85, wps=7027.3, ups=0.54, wpb=13034.5, bsz=446, num_updates=75000, lr=0.00011547, gnorm=0.801, loss_scale=4, train_wall=185, gb_free=14.7, wall=85539
2023-09-21 10:28:58 | INFO | train_inner | epoch 009:   2638 / 9060 loss=6.39, nll_loss=3.19, ppl=9.13, wps=6737.4, ups=0.52, wpb=12968.9, bsz=438.8, num_updates=75100, lr=0.000115393, gnorm=0.835, loss_scale=4, train_wall=192, gb_free=15.1, wall=85732
lprobs.size(): torch.Size([3360, 42808])
2023-09-21 10:32:24 | INFO | train_inner | epoch 009:   2738 / 9060 loss=6.476, nll_loss=3.254, ppl=9.54, wps=6358.2, ups=0.49, wpb=13047.7, bsz=446.4, num_updates=75200, lr=0.000115316, gnorm=0.826, loss_scale=4, train_wall=205, gb_free=14.2, wall=85937
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([3243, 42808])
2023-09-21 10:35:35 | INFO | train_inner | epoch 009:   2838 / 9060 loss=6.381, nll_loss=3.235, ppl=9.41, wps=6748.6, ups=0.52, wpb=12892.3, bsz=438.4, num_updates=75300, lr=0.00011524, gnorm=0.821, loss_scale=4, train_wall=191, gb_free=15.9, wall=86128
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2958, 42808])
pred_new.size(): torch.Size([2205, 42808])
lprobs.size(): torch.Size([3192, 42808])
2023-09-21 10:38:49 | INFO | train_inner | epoch 009:   2938 / 9060 loss=6.363, nll_loss=3.202, ppl=9.2, wps=6739.7, ups=0.52, wpb=13081, bsz=436.6, num_updates=75400, lr=0.000115163, gnorm=0.817, loss_scale=4, train_wall=194, gb_free=15, wall=86322
0.36575199999999997
num_accepted / total 7 104
loss token level: tensor(12779.7773, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(933., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1782, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3008, 42808])
pred_new.size(): torch.Size([6370, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1512, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([210, 42808])
ter_threshold: 0.367153
num_accepted / total 95 168
loss token level: tensor(9072.0557, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13336., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([2109, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([1980, 42808])
pred_new.size(): torch.Size([2790, 42808])
pred_new.size(): torch.Size([3250, 42808])
pred_new.size(): torch.Size([5895, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.368581
num_accepted / total 29 88
loss token level: tensor(9428.8203, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8528., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1230, 42808])
lprobs.size(): torch.Size([3504, 42808])
pred_new.size(): torch.Size([1974, 42808])
lprobs.size(): torch.Size([3216, 42808])
pred_new.size(): torch.Size([770, 42808])
pred_new.size(): torch.Size([6678, 42808])
pred_new.size(): torch.Size([2816, 42808])
ter_threshold: 0.369133
num_accepted / total 23 152
loss token level: tensor(8563.4492, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2852., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5100, 42808])
ter_threshold: 0.36937699999999996
num_accepted / total 29 96
loss token level: tensor(9539.6465, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4568., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.369579
num_accepted / total 39 128
loss token level: tensor(8572.3105, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3854., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4851, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2240, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([3861, 42808])
pred_new.size(): torch.Size([2805, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3439, 42808])
lprobs.size(): torch.Size([3408, 42808])
pred_new.size(): torch.Size([5616, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1404, 42808])
ter_threshold: 0.37123799999999996
num_accepted / total 71 176
loss token level: tensor(9475.5918, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5440., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3336, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.371749
num_accepted / total 61 152
loss token level: tensor(9038.1494, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9544., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.372085
num_accepted / total 65 160
loss token level: tensor(9167.9092, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5296., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.372112
num_accepted / total 38 144
loss token level: tensor(9847.1826, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6464., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2616, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3990, 42808])
pred_new.size(): torch.Size([960, 42808])
ter_threshold: 0.37262799999999996
num_accepted / total 53 160
loss token level: tensor(9582.8320, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4404., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.373112
num_accepted / total 40 120
loss token level: tensor(9757.5195, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8560., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.373124
num_accepted / total 3 64
loss token level: tensor(9239.0146, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1047., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1404, 42808])
lprobs.size(): torch.Size([3400, 42808])
ter_threshold: 0.373351
num_accepted / total 31 128
loss token level: tensor(9289.7080, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6008., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([201, 42808])
pred_new.size(): torch.Size([2002, 42808])
pred_new.size(): torch.Size([2700, 42808])
pred_new.size(): torch.Size([3885, 42808])
pred_new.size(): torch.Size([2244, 42808])
ter_threshold: 0.373864
num_accepted / total 4 56
loss token level: tensor(10496.0781, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(802.5000, device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.373867
num_accepted / total 29 88
loss token level: tensor(9551.6270, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5108., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.37407199999999996
num_accepted / total 11 64
loss token level: tensor(9335.5195, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2282., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1170, 42808])
ter_threshold: 0.37411
num_accepted / total 25 88
loss token level: tensor(9160.9990, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3772., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([888, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([2304, 42808])
ter_threshold: 0.374646
num_accepted / total 23 72
loss token level: tensor(8684.9102, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4976., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1760, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([770, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1953, 42808])
pred_new.size(): torch.Size([696, 42808])
ter_threshold: 0.375403
num_accepted / total 36 112
loss token level: tensor(8835.3125, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4388., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([430, 42808])
ter_threshold: ter_threshold: 0.375403
num_accepted / total 55 160
loss token level: tensor(9141.5830, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4868., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.37549899999999997
num_accepted / total 41 128
loss token level: tensor(9702.8135, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4496., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 10:41:56 | INFO | train_inner | epoch 009:   3038 / 9060 loss=6.528, nll_loss=3.25, ppl=9.51, wps=6928.9, ups=0.53, wpb=13015.3, bsz=458.2, num_updates=75500, lr=0.000115087, gnorm=0.832, loss_scale=4, train_wall=188, gb_free=14.3, wall=86510
pred_new.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([1463, 42808])
2023-09-21 10:45:20 | INFO | train_inner | epoch 009:   3138 / 9060 loss=6.393, nll_loss=3.236, ppl=9.42, wps=6347.9, ups=0.49, wpb=12891.6, bsz=424.6, num_updates=75600, lr=0.000115011, gnorm=0.836, loss_scale=4, train_wall=203, gb_free=14.9, wall=86713
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 10:48:39 | INFO | train_inner | epoch 009:   3238 / 9060 loss=6.51, nll_loss=3.262, ppl=9.59, wps=6507.9, ups=0.5, wpb=13002.3, bsz=436.2, num_updates=75700, lr=0.000114935, gnorm=0.852, loss_scale=4, train_wall=200, gb_free=14.2, wall=86913
2023-09-21 10:51:45 | INFO | train_inner | epoch 009:   3338 / 9060 loss=6.491, nll_loss=3.297, ppl=9.83, wps=7029.8, ups=0.54, wpb=13069.8, bsz=427.7, num_updates=75800, lr=0.000114859, gnorm=0.821, loss_scale=4, train_wall=186, gb_free=14.3, wall=87099
2023-09-21 10:54:56 | INFO | train_inner | epoch 009:   3438 / 9060 loss=6.371, nll_loss=3.197, ppl=9.17, wps=6830.2, ups=0.53, wpb=12996.7, bsz=444.4, num_updates=75900, lr=0.000114783, gnorm=0.822, loss_scale=4, train_wall=190, gb_free=14.1, wall=87289
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3432, 42808])
2023-09-21 10:58:13 | INFO | train_inner | epoch 009:   3538 / 9060 loss=6.443, nll_loss=3.266, ppl=9.62, wps=6574.8, ups=0.51, wpb=12973.4, bsz=430.4, num_updates=76000, lr=0.000114708, gnorm=0.843, loss_scale=4, train_wall=197, gb_free=14, wall=87486
pred_new.size(): torch.Size([6837, 42808])
ter_threshold: 0.376061
num_accepted / total 46 160
loss token level: tensor(7878.0615, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4320., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 11:01:29 | INFO | train_inner | epoch 009:   3638 / 9060 loss=6.429, nll_loss=3.216, ppl=9.29, wps=6672.1, ups=0.51, wpb=13076.1, bsz=445.8, num_updates=76100, lr=0.000114632, gnorm=0.822, loss_scale=4, train_wall=196, gb_free=14.1, wall=87682
2023-09-21 11:04:39 | INFO | train_inner | epoch 009:   3738 / 9060 loss=6.437, nll_loss=3.262, ppl=9.59, wps=6791.6, ups=0.53, wpb=12920.6, bsz=431, num_updates=76200, lr=0.000114557, gnorm=0.839, loss_scale=8, train_wall=190, gb_free=14.7, wall=87873
pred_new.size(): torch.Size([2560, 42808])
ter_threshold: 0.37629
num_accepted / total 22 72
loss token level: tensor(9042.5293, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7856., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 11:07:51 | INFO | train_inner | epoch 009:   3838 / 9060 loss=6.558, nll_loss=3.303, ppl=9.87, wps=6753.6, ups=0.52, wpb=12977.9, bsz=442.5, num_updates=76300, lr=0.000114482, gnorm=0.842, loss_scale=8, train_wall=192, gb_free=14.3, wall=88065
lprobs.size(): torch.Size([3480, 42808])
2023-09-21 11:11:05 | INFO | train_inner | epoch 009:   3938 / 9060 loss=6.42, nll_loss=3.217, ppl=9.3, wps=6757.2, ups=0.52, wpb=13064.4, bsz=461.3, num_updates=76400, lr=0.000114407, gnorm=0.808, loss_scale=8, train_wall=193, gb_free=14.8, wall=88258
2023-09-21 11:14:24 | INFO | train_inner | epoch 009:   4038 / 9060 loss=6.372, nll_loss=3.223, ppl=9.34, wps=6472.4, ups=0.5, wpb=12898.2, bsz=424.9, num_updates=76500, lr=0.000114332, gnorm=0.827, loss_scale=8, train_wall=199, gb_free=14.2, wall=88457
pred_new.size(): torch.Size([1376, 42808])
2023-09-21 11:17:32 | INFO | train_inner | epoch 009:   4138 / 9060 loss=6.431, nll_loss=3.25, ppl=9.51, wps=6915.7, ups=0.53, wpb=13020.8, bsz=419.9, num_updates=76600, lr=0.000114258, gnorm=0.809, loss_scale=8, train_wall=188, gb_free=14.7, wall=88646
2023-09-21 11:20:47 | INFO | train_inner | epoch 009:   4238 / 9060 loss=6.335, nll_loss=3.186, ppl=9.1, wps=6628.4, ups=0.51, wpb=12942.4, bsz=416.4, num_updates=76700, lr=0.000114183, gnorm=0.827, loss_scale=8, train_wall=195, gb_free=14.2, wall=88841
pred_new.size(): torch.Size([3312, 42808])
2023-09-21 11:24:02 | INFO | train_inner | epoch 009:   4338 / 9060 loss=6.329, nll_loss=3.19, ppl=9.12, wps=6588.5, ups=0.51, wpb=12799.5, bsz=434.4, num_updates=76800, lr=0.000114109, gnorm=0.814, loss_scale=8, train_wall=194, gb_free=14.7, wall=89035
pred_new.size(): torch.Size([1240, 42808])
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([2368, 42808])
pred_new.size(): torch.Size([2040, 42808])
2023-09-21 11:27:04 | INFO | train_inner | epoch 009:   4438 / 9060 loss=6.403, nll_loss=3.22, ppl=9.32, wps=7120.3, ups=0.55, wpb=12970.7, bsz=440.1, num_updates=76900, lr=0.000114035, gnorm=0.815, loss_scale=8, train_wall=182, gb_free=14.3, wall=89217
15 64
loss token level: tensor(8978.9775, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5552., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.369441
num_accepted / total 14 48
loss token level: tensor(9002.8340, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7940., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2920, 42808])
ter_threshold: 0.369579
num_accepted / total 22 128
loss token level: tensor(9253.2646, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2294., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.369774
num_accepted / total 3 56
loss token level: tensor(12234.0430, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1292., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1245, 42808])
ter_threshold: 0.36988699999999997
num_accepted / total 81 160
loss token level: tensor(9240.9121, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12496., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5070, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2100, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.370063
num_accepted / total 21 72
loss token level: tensor(8846.7559, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6640., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1496, 42808])
pred_new.size(): torch.Size([1120, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2697, 42808])
pred_new.size(): torch.Size([3838, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2560, 42808])
pred_new.size(): torch.Size([2970, 42808])
pred_new.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([1272, 42808])
ter_threshold: 0.371202
num_accepted / total 16 104
loss token level: tensor(8932.7871, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1956., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([800, 42808])
ter_threshold: 0.37123799999999996
num_accepted / total 3 88
loss token level: tensor(12604.7861, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(539., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2397, 42808])
pred_new.size(): torch.Size([1955, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([1816, 42808])
pred_new.size(): torch.Size([1280, 42808])
pred_new.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.371749
num_accepted / total 120 224
loss token level: tensor(9155.1064, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11920., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([2448, 42808])
ter_threshold: 0.372085
num_accepted / total 39 128
loss token level: tensor(9619.6396, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4288., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.372112
num_accepted / total 48 152
loss token level: tensor(8710.2256, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6700., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([192, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2884, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([2790, 42808])
pred_new.size(): torch.Size([1696, 42808])
lprobs.size(): torch.Size([2992, 42808])
ter_threshold: 0.372627
num_accepted / total 7 72
loss token level: tensor(12247.2812, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2372., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.37263
num_accepted / total 5 56
loss token level: tensor(9062.4531, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(770., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2432, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1620, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1119, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3280, 42808])
ter_threshold: 0.373701
num_accepted / total 8 72
loss token level: tensor(8925.3623, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1332., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4884, 42808])
ter_threshold: 0.373864
num_accepted / total 19 80
loss token level: tensor(9528.9727, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3460., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2952, 42808])
pred_new.size(): torch.Size([1974, 42808])
ter_threshold: 0.37404099999999996
num_accepted / total 2 48
loss token level: tensor(11943.9004, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.374057
num_accepted / total 11 72
loss token level: tensor(10363.1523, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4296., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3720, 42808])
ter_threshold: 0.37411
num_accepted / total 14 88
loss token level: tensor(8606.6973, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2002., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2310, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1950, 42808])
lprobs.size(): torch.Size([2832, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([1320, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3144, 42808])
pred_new.size(): torch.Size([5350, 42808])
pred_new.size(): torch.Size([1722, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([4130, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([216, 42808])
lprobs.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([1725, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.37549899999999997
num_accepted / total 32 96
loss token level: tensor(8981.3740, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4520., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([306, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([1584, 42808])
pred_new.size(): torch.Size([4224, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.376061
num_accepted / total 21 144
loss token level: tensor(12165.1504, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3560., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3612, 42808])
pred_new.size(): torch.Size([3051, 42808])
pred_new.size(): torch.Size([2436, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([240, 42808])
pred_new.size(): torch.Size([1392, 42808])
pred_new.size(): torch.Size([2412, 42808])
pred_new.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([2790, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([6555, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3552, 42808])
2023-09-21 11:30:20 | INFO | train_inner | epoch 009:   4538 / 9060 loss=6.464, nll_loss=3.235, ppl=9.42, wps=6621.8, ups=0.51, wpb=12976.2, bsz=442, num_updates=77000, lr=0.000113961, gnorm=0.838, loss_scale=8, train_wall=196, gb_free=14.4, wall=89413
ter_threshold: 0.377047
num_accepted / total 15 72
loss token level: tensor(8584.9062, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5036., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 11:33:33 | INFO | train_inner | epoch 009:   4638 / 9060 loss=6.462, nll_loss=3.259, ppl=9.57, wps=6727.1, ups=0.52, wpb=12998.8, bsz=421, num_updates=77100, lr=0.000113887, gnorm=0.825, loss_scale=8, train_wall=193, gb_free=14.2, wall=89607
2023-09-21 11:36:48 | INFO | train_inner | epoch 009:   4738 / 9060 loss=6.48, nll_loss=3.258, ppl=9.56, wps=6617.4, ups=0.51, wpb=12931.1, bsz=430.9, num_updates=77200, lr=0.000113813, gnorm=0.83, loss_scale=8, train_wall=195, gb_free=14.6, wall=89802
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1950, 42808])
lprobs.size(): torch.Size([3264, 42808])
2023-09-21 11:40:00 | INFO | train_inner | epoch 009:   4838 / 9060 loss=6.38, nll_loss=3.22, ppl=9.32, wps=6758.7, ups=0.52, wpb=12975.6, bsz=421, num_updates=77300, lr=0.000113739, gnorm=0.809, loss_scale=8, train_wall=192, gb_free=14.4, wall=89994
2023-09-21 11:43:10 | INFO | train_inner | epoch 009:   4938 / 9060 loss=6.337, nll_loss=3.186, ppl=9.1, wps=6852.6, ups=0.53, wpb=13020.6, bsz=405.9, num_updates=77400, lr=0.000113666, gnorm=0.812, loss_scale=8, train_wall=190, gb_free=14, wall=90184
pred_new.size(): torch.Size([3546, 42808])
2023-09-21 11:46:21 | INFO | train_inner | epoch 009:   5038 / 9060 loss=6.364, nll_loss=3.191, ppl=9.13, wps=6861.6, ups=0.53, wpb=13061.6, bsz=422.7, num_updates=77500, lr=0.000113592, gnorm=0.863, loss_scale=8, train_wall=190, gb_free=14.6, wall=90374
2023-09-21 11:49:38 | INFO | train_inner | epoch 009:   5138 / 9060 loss=6.356, nll_loss=3.188, ppl=9.11, wps=6556.9, ups=0.51, wpb=12934, bsz=421.9, num_updates=77600, lr=0.000113519, gnorm=0.833, loss_scale=8, train_wall=197, gb_free=15, wall=90572
2023-09-21 11:50:08 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
lprobs.size(): torch.Size([3280, 42808])
2023-09-21 11:52:54 | INFO | train_inner | epoch 009:   5239 / 9060 loss=6.41, nll_loss=3.241, ppl=9.45, wps=6594.3, ups=0.51, wpb=12910.7, bsz=423.8, num_updates=77700, lr=0.000113446, gnorm=0.825, loss_scale=4, train_wall=196, gb_free=14.3, wall=90767
pred_new.size(): torch.Size([2970, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-21 11:56:10 | INFO | train_inner | epoch 009:   5339 / 9060 loss=6.399, nll_loss=3.21, ppl=9.25, wps=6660, ups=0.51, wpb=13069.9, bsz=441.5, num_updates=77800, lr=0.000113373, gnorm=0.826, loss_scale=4, train_wall=196, gb_free=14.2, wall=90964
2023-09-21 11:59:24 | INFO | train_inner | epoch 009:   5439 / 9060 loss=6.424, nll_loss=3.206, ppl=9.23, wps=6673.1, ups=0.52, wpb=12952.1, bsz=447.8, num_updates=77900, lr=0.0001133, gnorm=0.846, loss_scale=4, train_wall=194, gb_free=14.5, wall=91158
ter_threshold: 0.377965
num_accepted / total 6 56
loss token level: tensor(9365.7656, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2890., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
2023-09-21 12:02:38 | INFO | train_inner | epoch 009:   5539 / 9060 loss=6.49, nll_loss=3.27, ppl=9.65, wps=6679.3, ups=0.52, wpb=12919.5, bsz=426.2, num_updates=78000, lr=0.000113228, gnorm=0.848, loss_scale=4, train_wall=193, gb_free=15.1, wall=91351
lprobs.size(): torch.Size([3472, 42808])
2023-09-21 12:05:58 | INFO | train_inner | epoch 009:   5639 / 9060 loss=6.379, nll_loss=3.208, ppl=9.24, wps=6457.3, ups=0.5, wpb=12956.9, bsz=433.4, num_updates=78100, lr=0.000113155, gnorm=0.888, loss_scale=4, train_wall=200, gb_free=13.3, wall=91552
2023-09-21 12:09:14 | INFO | train_inner | epoch 009:   5739 / 9060 loss=6.432, nll_loss=3.239, ppl=9.44, wps=6669.8, ups=0.51, wpb=13084.3, bsz=439.2, num_updates=78200, lr=0.000113083, gnorm=0.83, loss_scale=4, train_wall=196, gb_free=14.7, wall=91748
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2784, 42808])
2023-09-21 12:12:28 | INFO | train_inner | epoch 009:   5839 / 9060 loss=6.437, nll_loss=3.251, ppl=9.52, wps=6724.9, ups=0.52, wpb=13031.2, bsz=447.3, num_updates=78300, lr=0.000113011, gnorm=0.812, loss_scale=4, train_wall=194, gb_free=16.1, wall=91942
pred_new.size(): torch.Size([1344, 42808])
2023-09-21 12:15:49 | INFO | train_inner | epoch 009:   5939 / 9060 loss=6.418, nll_loss=3.264, ppl=9.61, wps=6477.4, ups=0.5, wpb=12983.3, bsz=438.1, num_updates=78400, lr=0.000112938, gnorm=0.81, loss_scale=4, train_wall=200, gb_free=15.5, wall=92142
2023-09-21 12:18:53 | INFO | train_inner | epoch 009:   6039 / 9060 loss=6.376, nll_loss=3.233, ppl=9.4, wps=7016.9, ups=0.54, wpb=12953.2, bsz=401.4, num_updates=78500, lr=0.000112867, gnorm=0.834, loss_scale=4, train_wall=184, gb_free=14.2, wall=92327
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 12:22:10 | INFO | train_inner | epoch 009:   6139 / 9060 loss=6.401, nll_loss=3.191, ppl=9.13, wps=6628.1, ups=0.51, wpb=13039.1, bsz=424.3, num_updates=78600, lr=0.000112795, gnorm=0.81, loss_scale=4, train_wall=196, gb_free=13.9, wall=92523
pred_new.size(): torch.Size([5874, 42808])
2023-09-21 12:25:24 | INFO | train_inner | epoch 009:   6239 / 9060 loss=6.322, nll_loss=3.191, ppl=9.13, wps=6690.4, ups=0.51, wpb=13004.4, bsz=412.9, num_updates=78700, lr=0.000112723, gnorm=0.807, loss_scale=4, train_wall=194, gb_free=15.2, wall=92718
pred_new.size(): torch.Size([576, 42808])
2023-09-21 12:28:43 | INFO | train_inner | epoch 009:   6339 / 9060 loss=6.509, nll_loss=3.281, ppl=9.72, wps=6524.9, ups=0.5, wpb=12951.2, bsz=431.7, num_updates=78800, lr=0.000112651, gnorm=0.837, loss_scale=4, train_wall=198, gb_free=14.1, wall=92916
ter_threshold: 0.37883999999999995
num_accepted / total 60 128
loss token level: tensor(9316.8574, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12456., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 12:32:01 | INFO | train_inner | epoch 009:   6439 / 9060 loss=6.498, nll_loss=3.22, ppl=9.32, wps=6591.6, ups=0.5, wpb=13087.3, bsz=466, num_updates=78900, lr=0.00011258, gnorm=0.826, loss_scale=4, train_wall=198, gb_free=14.6, wall=93115
2023-09-21 12:35:04 | INFO | train_inner | epoch 009:   6539 / 9060 loss=6.41, nll_loss=3.216, ppl=9.29, wps=7079.4, ups=0.55, wpb=12957.4, bsz=436.2, num_updates=79000, lr=0.000112509, gnorm=0.811, loss_scale=4, train_wall=183, gb_free=14.6, wall=93298
2023-09-21 12:38:21 | INFO | train_inner | epoch 009:   6639 / 9060 loss=6.321, nll_loss=3.177, ppl=9.05, wps=6671.3, ups=0.51, wpb=13080.4, bsz=431.4, num_updates=79100, lr=0.000112438, gnorm=0.816, loss_scale=4, train_wall=196, gb_free=15.5, wall=93494
pred_new.size(): torch.Size([5550, 42808])
ter_threshold: 0.379198
num_accepted / total 27 96
loss token level: tensor(8790.4541, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7040., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 12:41:34 | INFO | train_inner | epoch 009:   6739 / 9060 loss=6.461, nll_loss=3.235, ppl=9.42, wps=6751.8, ups=0.52, wpb=13037.6, bsz=440.9, num_updates=79200, lr=0.000112367, gnorm=0.829, loss_scale=4, train_wall=193, gb_free=14.4, wall=93687
lprobs.size(): torch.Size([3120, 42808])
2023-09-21 12:44:41 | INFO | train_inner | epoch 009:   6839 / 9060 loss=6.366, nll_loss=3.199, ppl=9.18, wps=6947.6, ups=0.53, wpb=13049.4, bsz=420.6, num_updates=79300, lr=0.000112296, gnorm=0.8, loss_scale=4, train_wall=188, gb_free=16.1, wall=93875
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.379368
num_accepted / total 27 128
loss token level: tensor(10829.3633, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3052., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4032, 42808])
2023-09-21 12:47:51 | INFO | train_inner | epoch 009:   6939 / 9060 loss=6.43, nll_loss=3.227, ppl=9.36, wps=6838.6, ups=0.53, wpb=12989, bsz=447.4, num_updates=79400, lr=0.000112225, gnorm=0.821, loss_scale=4, train_wall=190, gb_free=14.5, wall=94065
pred_new.size(): torch.Size([2548, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([3102, 42808])
2023-09-21 12:51:16 | INFO | train_inner | epoch 009:   7039 / 9060 loss=6.497, nll_loss=3.272, ppl=9.66, wps=6353.1, ups=0.49, wpb=12989.9, bsz=451.8, num_updates=79500, lr=0.000112154, gnorm=0.852, loss_scale=4, train_wall=204, gb_free=14.6, wall=94269
2023-09-21 12:54:29 | INFO | train_inner | epoch 009:   7139 / 9060 loss=6.402, nll_loss=3.205, ppl=9.22, wps=6693.2, ups=0.52, wpb=12936.5, bsz=448.2, num_updates=79600, lr=0.000112084, gnorm=0.824, loss_scale=4, train_wall=193, gb_free=14, wall=94463
lprobs.size(): torch.Size([3192, 42808])
2023-09-21 12:57:36 | INFO | train_inner | epoch 009:   7239 / 9060 loss=6.286, nll_loss=3.196, ppl=9.16, wps=6911.9, ups=0.54, wpb=12897.4, bsz=403.9, num_updates=79700, lr=0.000112014, gnorm=0.843, loss_scale=4, train_wall=186, gb_free=14.9, wall=94649
pred_new.size(): torch.Size([4095, 42808])
2023-09-21 13:00:53 | INFO | train_inner | epoch 009:   7339 / 9060 loss=6.396, nll_loss=3.202, ppl=9.2, wps=6541.1, ups=0.51, wpb=12899.6, bsz=419.8, num_updates=79800, lr=0.000111943, gnorm=0.835, loss_scale=4, train_wall=197, gb_free=14.5, wall=94846
pred_new.size(): torch.Size([2000, 42808])
2023-09-21 13:04:11 | INFO | train_inner | epoch 009:   7439 / 9060 loss=6.471, nll_loss=3.234, ppl=9.41, wps=6562.7, ups=0.51, wpb=12968.5, bsz=434, num_updates=79900, lr=0.000111873, gnorm=0.875, loss_scale=4, train_wall=197, gb_free=14.4, wall=95044
2023-09-21 13:07:31 | INFO | train_inner | epoch 009:   7539 / 9060 loss=6.429, nll_loss=3.274, ppl=9.67, wps=6476.3, ups=0.5, wpb=12973.8, bsz=418.8, num_updates=80000, lr=0.000111803, gnorm=0.825, loss_scale=4, train_wall=200, gb_free=14.8, wall=95244
ter_threshold: 0.380043
num_accepted / total 7 72
loss token level: tensor(9023.3965, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1888., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 13:10:38 | INFO | train_inner | epoch 009:   7639 / 9060 loss=6.458, nll_loss=3.265, ppl=9.62, wps=6940.2, ups=0.54, wpb=12971.6, bsz=429.2, num_updates=80100, lr=0.000111734, gnorm=0.83, loss_scale=4, train_wall=187, gb_free=15.9, wall=95431
lprobs.size(): torch.Size([3496, 42808])
2023-09-21 13:13:59 | INFO | train_inner | epoch 009:   7739 / 9060 loss=6.374, nll_loss=3.214, ppl=9.28, wps=6469.9, ups=0.5, wpb=13010.4, bsz=421.5, num_updates=80200, lr=0.000111664, gnorm=0.823, loss_scale=4, train_wall=201, gb_free=13.6, wall=95632
lprobs.size(): torch.Size([2632, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([1710, 42808])
2023-09-21 13:17:12 | INFO | train_inner | epoch 009:   7839 / 9060 loss=6.5, nll_loss=3.263, ppl=9.6, wps=6730.5, ups=0.52, wpb=13015.3, bsz=453, num_updates=80300, lr=0.000111594, gnorm=0.842, loss_scale=4, train_wall=193, gb_free=14.1, wall=95826
2023-09-21 13:20:23 | INFO | train_inner | epoch 009:   7939 / 9060 loss=6.553, nll_loss=3.314, ppl=9.94, wps=6802.7, ups=0.52, wpb=13001.2, bsz=446.7, num_updates=80400, lr=0.000111525, gnorm=0.837, loss_scale=4, train_wall=191, gb_free=14.4, wall=96017
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 13:23:37 | INFO | train_inner | epoch 009:   8039 / 9060 loss=6.426, nll_loss=3.243, ppl=9.47, wps=6733.3, ups=0.52, wpb=13058.9, bsz=420.4, num_updates=80500, lr=0.000111456, gnorm=0.817, loss_scale=4, train_wall=194, gb_free=15.9, wall=96211
lprobs.size(): torch.Size([3216, 42808])
2023-09-21 13:26:44 | INFO | train_inner | epoch 009:   8139 / 9060 loss=6.34, nll_loss=3.203, ppl=9.21, wps=6910.6, ups=0.54, wpb=12892.9, bsz=426.6, num_updates=80600, lr=0.000111386, gnorm=0.805, loss_scale=4, train_wall=186, gb_free=14.6, wall=96397
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([2912, 42808])
2023-09-21 13:29:49 | INFO | train_inner | epoch 009:   8239 / 9060 loss=6.403, nll_loss=3.265, ppl=9.61, wps=6946.4, ups=0.54, wpb=12870.3, bsz=406.4, num_updates=80700, lr=0.000111317, gnorm=0.831, loss_scale=4, train_wall=185, gb_free=14.3, wall=96583
pred_new.size(): torch.Size([4446, 42808])
2023-09-21 13:33:03 | INFO | train_inner | epoch 009:   8339 / 9060 loss=6.457, nll_loss=3.265, ppl=9.61, wps=6675, ups=0.52, wpb=12928.7, bsz=430.9, num_updates=80800, lr=0.000111249, gnorm=0.847, loss_scale=4, train_wall=193, gb_free=15.2, wall=96776
lprobs.size(): torch.Size([2856, 42808])
2023-09-21 13:36:22 | INFO | train_inner | epoch 009:   8439 / 9060 loss=6.395, nll_loss=3.191, ppl=9.13, wps=6540.4, ups=0.5, wpb=13012, bsz=444, num_updates=80900, lr=0.00011118, gnorm=0.815, loss_scale=4, train_wall=199, gb_free=14.7, wall=96975
ter_threshold: 0.38094
num_accepted / total 32 96
loss token level: tensor(9267.1045, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8124., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 13:39:44 | INFO | train_inner | epoch 009:   8539 / 9060 loss=6.398, nll_loss=3.222, ppl=9.33, wps=6441.1, ups=0.5, wpb=12992.1, bsz=402.2, num_updates=81000, lr=0.000111111, gnorm=0.829, loss_scale=4, train_wall=201, gb_free=15.1, wall=97177
2023-09-21 13:43:12 | INFO | train_inner | epoch 009:   8639 / 9060 loss=6.431, nll_loss=3.251, ppl=9.52, wps=6182.8, ups=0.48, wpb=12905, bsz=419.7, num_updates=81100, lr=0.000111043, gnorm=0.829, loss_scale=4, train_wall=208, gb_free=15.6, wall=97386
2023-09-21 13:46:32 | INFO | train_inner | epoch 009:   8739 / 9060 loss=6.408, nll_loss=3.229, ppl=9.38, wps=6491.4, ups=0.5, wpb=12972, bsz=436.2, num_updates=81200, lr=0.000110974, gnorm=0.82, loss_scale=4, train_wall=200, gb_free=14.8, wall=97586
pred_new.size(): torch.Size([3267, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 13:49:44 | INFO | train_inner | epoch 009:   8839 / 9060 loss=6.425, nll_loss=3.258, ppl=9.57, wps=6760.8, ups=0.52, wpb=12949.1, bsz=407.5, num_updates=81300, lr=0.000110906, gnorm=0.824, loss_scale=4, train_wall=191, gb_free=14.8, wall=97777
lprobs.size(): torch.Size([3432, 42808])
2023-09-21 13:52:51 | INFO | train_inner | epoch 009:   8939 / 9060 loss=6.402, nll_loss=3.259, ppl=9.58, wps=6909, ups=0.53, wpb=12961.7, bsz=423.2, num_updates=81400, lr=0.000110838, gnorm=0.853, loss_scale=4, train_wall=187, gb_free=13.5, wall=97965
lprobs.size(): torch.Size([2880, 42808])
2023-09-21 13:56:04 | INFO | train_inner | epoch 009:   9039 / 9060 loss=6.373, nll_loss=3.23, ppl=9.38, wps=6761.4, ups=0.52, wpb=13008.7, bsz=418.3, num_updates=81500, lr=0.00011077, gnorm=0.827, loss_scale=4, train_wall=192, gb_free=14.3, wall=98157
2023-09-21 13:56:52 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-21 13:56:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 13:56:52 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-21 13:56:52 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-21 13:56:53 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-21 13:56:53 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-21 13:56:53 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-21 13:56:53 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-21 13:56:54 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-21 13:56:54 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-21 13:56:54 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-21 13:56:54 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-21 13:56:55 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu, und es war ein rabender Erfolg.
2023-09-21 13:56:55 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-21 13:56:55 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches Neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-21 13:56:55 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-21 13:56:56 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, und das respektieren wir.
2023-09-21 13:56:56 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-21 13:56:56 | INFO | fairseq.tasks.translation | example hypothesis: Das Chatmodul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-21 13:56:56 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-21 13:56:57 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Firmen- als auch für Privaturlauber geeignet sind.
2023-09-21 13:56:57 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-21 13:56:57 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-21 13:56:57 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-21 13:56:58 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 13:56:58 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 13:56:59 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU als Ganzes große Mengen an Energie verschwendet.
2023-09-21 13:56:59 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-21 13:56:59 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin enthält einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-21 13:56:59 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-21 13:57:00 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellungen auch in Kürze im Haushalt der Union widerspiegeln.
2023-09-21 13:57:00 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-21 13:57:00 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-21 13:57:00 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-21 13:57:01 | INFO | fairseq.tasks.translation | example hypothesis: Hier ist ein konkretes Beispiel: die bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-21 13:57:01 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-21 13:57:02 | INFO | fairseq.tasks.translation | example hypothesis: Ich darf Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-21 13:57:02 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-21 13:57:02 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie sich gewünscht hätten?
2023-09-21 13:57:02 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-21 13:57:03 | INFO | fairseq.tasks.translation | example hypothesis: Der größte Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-21 13:57:03 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-21 13:57:03 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-21 13:57:03 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-21 13:57:04 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jede von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-21 13:57:04 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-21 13:57:04 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionale Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-21 13:57:04 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-21 13:57:05 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlgeschlagene Anzeige kann potentielle Käufer dazu bringen, über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-21 13:57:05 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-21 13:57:06 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in ungecharterte Gebiete wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-21 13:57:06 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-21 13:57:06 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-21 13:57:06 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-21 13:57:07 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-21 13:57:07 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-21 13:57:07 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in ungefähr einem Umkreis von 8 Kilometern vom Strip.
2023-09-21 13:57:07 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-21 13:57:08 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web-legale Portal, das auf dem berühmten Open Source Php-Nuke Webportal-System basiert.
2023-09-21 13:57:08 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-21 13:57:08 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! akustisch, interaktiv oder schriftlich die Realisierung von Klanghandbüchern an.
2023-09-21 13:57:08 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-21 13:57:09 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-21 13:57:09 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-21 13:57:09 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer inneren Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu schützen.
2023-09-21 13:57:09 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-21 13:57:10 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Abflug Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme gezahlt haben.
2023-09-21 13:57:10 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-21 13:57:11 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten die Ascent Ti Modell als Basis.
2023-09-21 13:57:11 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-21 13:57:11 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf Computerplattformen läuft.
2023-09-21 13:57:11 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-21 13:57:12 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie Sie helfen, qualifizierte Fachleute zu finden, die die beste Lösung finden, wenn es Ihre Bedürfnisse und Wünsche ist.
2023-09-21 13:57:12 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-21 13:57:12 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherische Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-21 13:57:12 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-21 13:57:13 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils-Benutzer müssen Splashutils neu emergen, damit sie korrekt funktionieren.
2023-09-21 13:57:13 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-21 13:57:13 | INFO | fairseq.tasks.translation | example hypothesis: Spieler von Horde und Allianz können Gegenstände nicht kaufen oder verkaufen, wenn sie die unten aufgeführten neutralen Auktionshäuser nicht nutzen.
2023-09-21 13:57:13 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-21 13:57:14 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien sich auf die Anwendung nur innerhalb der Grenzen Europas beschränken sollten.
2023-09-21 13:57:14 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 13:57:15 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-21 13:57:15 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-21 13:57:15 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formale Ansichten zu bestimmten Einzelheiten des Abkommens im Prinzip mit den Vereinigten Staaten vorlegen müssen.
2023-09-21 13:57:15 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-21 13:57:16 | INFO | fairseq.tasks.translation | example hypothesis: Elegante oder klassische Farben, zeitloses Design oder spezielle Edition - unsere große Auswahl an KunststoffBabyartikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-21 13:57:16 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-21 13:57:16 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 13:57:16 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 13:57:17 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis über Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-21 13:57:17 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-21 13:57:18 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und erkannt hat, dass institutionelle Veränderungen notwendig sind, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung erfordert.
2023-09-21 13:57:18 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-21 13:57:18 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktnachrichten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-21 13:57:18 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-21 13:57:19 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte anerkennen, die bei der Prüfung aller Fragen erzielt wurden, die jetzt im Zusammenhang mit etwas stehen, das knapp zwei Jahre alt ist, nämlich der neuen transatlantischen Agenda.
2023-09-21 13:57:19 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-21 13:57:19 | INFO | fairseq.tasks.translation | example hypothesis: BILSTEIN B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-21 13:57:19 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-21 13:57:20 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal konnte der Berichterstatter zuweilen unterschiedliche Meinungen und Beiträge zusammenstellen und sie - ich würde sagen - in einem äußerst ausgewogenen Text zusammenfassen.
2023-09-21 13:57:20 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-21 13:57:21 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niedersetzern mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-21 13:57:21 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-21 13:57:21 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-21 13:57:21 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-21 13:57:22 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-21 13:57:22 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-21 13:57:23 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und ist auf Verhandlungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-21 13:57:23 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-21 13:57:23 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-21 13:57:23 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-21 13:57:24 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren wollen und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-21 13:57:24 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-21 13:57:24 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-21 13:57:24 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-21 13:57:25 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Notfall gibt es jedoch noch einen anderen: die Notsituation der Kinder, des schwächsten Bevölkerungssektors, der ohne Familie, ohne Schutz und ohne Staat geblieben ist.
2023-09-21 13:57:25 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-21 13:57:26 | INFO | fairseq.tasks.translation | example hypothesis: Zunächst sollte klargestellt und hervorgehoben werden, dass die Praxis der Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht allein für ihre Flossen gefangen werden können.
2023-09-21 13:57:26 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-21 13:57:26 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, erst erst nicht verwirklicht, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis befleckt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-21 13:57:26 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-21 13:57:27 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, um alles in unserer Macht Stehende zu tun, um vor den Wahlen einen gewaltfreien Zeitraum zu schaffen und das Verfahren für die Wählerregistrierung wieder zu öffnen.
2023-09-21 13:57:27 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-21 13:57:28 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit verleihen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-21 13:57:28 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-21 13:57:28 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java-Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit gewährleisten (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-21 13:57:28 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-21 13:57:29 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für eine Klärung des Anhangs.
2023-09-21 13:57:29 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-21 13:57:30 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist auch der Ansicht, dass die WTO-Mitgliedsländer eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass die von der IAO verhängten Sanktionen nicht als unvereinbar mit den WTO-Übereinkommen angesehen werden.
2023-09-21 13:57:30 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-21 13:57:30 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich nahm ich an einer Aussprache über das irische öffentlich-rechtliche Rundfunk RTÉ mit einer Frau teil, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-21 13:57:30 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-21 13:57:31 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-21 13:57:31 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-21 13:57:32 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie Inspiration für Ihre Lektionen oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas wie die Reduktion des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-21 13:57:32 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-21 13:57:32 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.
2023-09-21 13:57:32 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-21 13:57:33 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-21 13:57:33 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-21 13:57:34 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, heißt, zu naturalisieren und zu mystifizieren, was eine bestimmte Art von Vertragsverhältnis zwischen Individuen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Drohung, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-21 13:57:34 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-21 13:57:35 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollte der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-21 13:57:35 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-21 13:57:35 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er Serie ist eines der lustigsten Automobile für unter 50.000 US $, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-21 13:57:35 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-21 13:57:36 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte und gemeinsame Sicherheit und Verteidigungspolitik für seine realistische Darstellung der Angelegenheit.
2023-09-21 13:57:36 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-21 13:57:37 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den hervorragenden Süßwasserfisch: gegrillter Schweinefleisch, Forelle mit Mandeln.
2023-09-21 13:57:37 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-21 13:57:37 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt daran zu erinnern, was ein politisches Handeln bedeutet, einen Gesamtüberblick zu geben, der es uns ermöglicht, tiefer in die verschiedenen Fragen zu gehen und zu sehen, welche Impulse die Europäische Union mit Blick auf die Zukunft geben kann.
2023-09-21 13:57:37 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-21 13:57:38 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-21 13:57:38 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-21 13:57:39 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen echten Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit aufgrund der makroökonomischen Politik, der steuerlichen Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-21 13:57:39 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-21 13:57:40 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-21 13:57:40 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-21 13:57:40 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus um die entsprechenden Konsequenzen für den Rechts- und Rechtsraum, wodurch Norwegen und Island Länder werden, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden.
2023-09-21 13:57:40 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-21 13:57:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir gehen mit voller Geschwindigkeit in einem Schichtboot hinunter den Mississippi, suchen nach dem großen verborgenen Schatz, verlieben sich in den schönen Becky Thatcher, der rein dynamisch ist, und vor allem werden wir große Freunde sein.
2023-09-21 13:57:41 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-21 13:57:42 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die im Falle von Verletzungen durch Einzelpersonen verhängt werden können.
2023-09-21 13:57:42 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-21 13:57:43 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falisund Vincent Reynaud wurden in der Tat einfach verurteilt, weil sie ihre Arbeit als Journalisten und Kameramänner geleistet und eine Gruppe von Bergregionen gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das jeden Grundsatz der Demokratie missachtet.
2023-09-21 13:57:43 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-21 13:57:43 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Conciergeservice, ein Friseur- und Schönheitssalon, Transport- und Sightseeing-Rezeption, Menü- und Presseservice, Wechselwechsel, kostenfreies Schuhwerk und WLAN. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-21 13:57:43 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-21 13:57:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha verdankt ihren Namen der Thermalquelle, die Königin D. Leonor, Ehefrau von König D. João II, und bekannt durch ihre Keramiken international bekannt für ihre figurativen und satirischen Werke ist es auch einen Besuch wert.
2023-09-21 13:57:44 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-21 13:57:45 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um einen Fall guter Pro-Westler auf der einen Seite und Anhänger des ehemaligen Regimes auf der anderen Seite handelt - auch das ist verwerflich, da die Rolle aller jetzt und vor der Realität bekannt ist.
2023-09-21 13:57:45 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-21 13:57:46 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich muss darauf hinweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer reisen, auf diese Weise nicht abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie behandelt werden sollte.
2023-09-21 13:57:46 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-21 13:57:47 | INFO | fairseq.tasks.translation | example hypothesis: (4) Soweit einem Aktionär aus Gründen seines Status als Aktionär Informationen außerhalb einer Hauptversammlung zur Verfügung gestellt wurden, sind diese auf Verlangen an einen anderen Aktionär in der Hauptversammlung weiterzugeben, auch wenn diese Informationen nicht notwendig sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-21 13:57:47 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-21 13:57:48 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Abermillionen Euro in einige Programme gesteckt werden, die normalerweise in die Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr miserable Leben führen.
2023-09-21 13:57:48 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-21 13:57:48 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem Mitgliedstaat oder die NATO an diesem Kriegsakt beteiligt gewesen sein könnten -, bei Informationen zu helfen, die nicht mehr Grund haben, vertraulich, versteckt oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-21 13:57:48 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-21 13:57:49 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 13:57:49 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 13:57:50 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird der Advanced UAV die modernsten, modularsten Sensorsuite und Datenlinks enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen von entscheidender Bedeutung sind, die moderne Offset-Plattformen nie erreichen können.
2023-09-21 13:57:50 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-21 13:57:51 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen deutlich machen, dass wir auch in der Lage sein werden, diese Produkte, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt eine ernste Gefahr darstellen, nicht nur für uns, sondern weltweit aus dem Markt zu nehmen, weil sie leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 feststellt.
2023-09-21 13:57:51 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-21 13:57:52 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Komplott von Moderne und Postmoderne oder der klaren Opposition reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung dieser beiden ästhetischen Politik erkennen, die in genau den Formen der Sichtbarkeit und Verständlichkeit steckt, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-21 13:57:52 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-21 13:57:53 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch den heutigen Tag betrifft, so werden wir angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir gegeben haben, die eindeutig weitgehend das unterstützen, was ich gerade gesagt habe, und auf der Grundlage der vorangegangenen Entscheidungen unsere Debatten führen, und wenn die 40 Petenten nicht anwesend sind, werde ich bei der Abstimmung nicht beantragen, dass die Beschlussfähigkeit überprüft wird.
2023-09-21 13:57:53 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-21 13:57:54 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker niemals die Einschränkung des nationalstaatlichen Prinzips akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum jemandem bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern die ethnische, religiöse, sprachliche und kulturelle Vielfalt sich entwickeln zu lassen.
2023-09-21 13:57:54 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-21 13:57:55 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Weise als hybride Form veröffentlicht, die Rezensionen und Artikel der vierteljährlichen Zeitschrift für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt.
2023-09-21 13:57:55 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-21 13:57:56 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone ihre Federn deutlich verwischt, von einst düsteren Taschenlampen über polyphonisch tootling Game Boy-Ambitionen bis hin zu schlichten Mini-PCs mit scharfen CD-Qualität Stereo-Sound: Von nun an könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazers neuer technologischer Entwicklungen übergehen.
2023-09-21 13:57:56 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-21 13:57:58 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dienerla defensa de la base humana en Pandora, conence a Jake para que le proportionenamora de una de las nativas, Neytiri, y se cuenta de que éstos jamás renunciarán a su tierra, hun aciendo a la fuerza para que se marchen.
2023-09-21 13:57:58 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-21 13:57:58 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 4.21 | nll_loss 2.232 | ppl 4.7 | bleu 29.41 | wps 17791.7 | wpb 12011.9 | bsz 398.1 | num_updates 81521 | best_bleu 29.41
2023-09-21 13:57:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 81521 updates
2023-09-21 13:57:58 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint9.pt
2023-09-21 13:58:04 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint9.pt
2023-09-21 13:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint9.pt (epoch 9 @ 81521 updates, score 29.41) (writing took 13.105685078015085 seconds)
2023-09-21 13:58:12 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2023-09-21 13:58:12 | INFO | train | epoch 009 | loss 6.401 | nll_loss 3.22 | ppl 9.32 | wps 6667.4 | ups 0.51 | wpb 12977.2 | bsz 430.6 | num_updates 81521 | lr 0.000110755 | gnorm 0.83 | loss_scale 4 | train_wall 17528 | gb_free 14.2 | wall 98285
2023-09-21 13:58:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 13:58:12 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-21 13:58:12 | INFO | fairseq.trainer | begin training epoch 10
2023-09-21 13:58:12 | INFO | fairseq_cli.train | Start iterating over samples
lprobs.size(): torch.Size([3480, 42808])
2023-09-21 14:00:50 | INFO | train_inner | epoch 010:     79 / 9060 loss=6.511, nll_loss=3.259, ppl=9.58, wps=4535.7, ups=0.35, wpb=12973.5, bsz=420.8, num_updates=81600, lr=0.000110702, gnorm=0.846, loss_scale=4, train_wall=206, gb_free=14.9, wall=98443
pred_new.size(): torch.Size([5978, 42808])
pred_new.size(): torch.Size([3168, 42808])
2023-09-21 14:04:17 | INFO | train_inner | epoch 010:    179 / 9060 loss=6.475, nll_loss=3.211, ppl=9.26, wps=6232.4, ups=0.48, wpb=12947, bsz=422.5, num_updates=81700, lr=0.000110634, gnorm=0.849, loss_scale=4, train_wall=207, gb_free=14.9, wall=98651
2023-09-21 14:07:34 | INFO | train_inner | epoch 010:    279 / 9060 loss=6.355, nll_loss=3.17, ppl=9, wps=6594.7, ups=0.51, wpb=12940.2, bsz=427.8, num_updates=81800, lr=0.000110566, gnorm=0.82, loss_scale=8, train_wall=196, gb_free=14.9, wall=98847
pred_new.size(): torch.Size([5040, 42808])
2023-09-21 14:11:06 | INFO | train_inner | epoch 010:    379 / 9060 loss=6.513, nll_loss=3.219, ppl=9.31, wps=6131.7, ups=0.47, wpb=13029.7, bsz=437.5, num_updates=81900, lr=0.000110499, gnorm=0.841, loss_scale=8, train_wall=212, gb_free=16, wall=99060
2023-09-21 14:14:38 | INFO | train_inner | epoch 010:    479 / 9060 loss=6.474, nll_loss=3.21, ppl=9.25, wps=6150.2, ups=0.47, wpb=13010.9, bsz=417, num_updates=82000, lr=0.000110432, gnorm=0.826, loss_scale=8, train_wall=211, gb_free=14.9, wall=99271
ter_threshold: 0.38201799999999997
num_accepted / total 29 88
loss token level: tensor(8413.1816, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4596., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 14:17:56 | INFO | train_inner | epoch 010:    579 / 9060 loss=6.458, nll_loss=3.219, ppl=9.31, wps=6566.1, ups=0.5, wpb=13036.5, bsz=411.3, num_updates=82100, lr=0.000110364, gnorm=0.843, loss_scale=8, train_wall=198, gb_free=14.4, wall=99470
pred_new.size(): torch.Size([1287, 42808])
pred_new.size(): torch.Size([4508, 42808])
2023-09-21 14:21:15 | INFO | train_inner | epoch 010:    679 / 9060 loss=6.402, nll_loss=3.167, ppl=8.98, wps=6514.5, ups=0.5, wpb=12921, bsz=431.4, num_updates=82200, lr=0.000110297, gnorm=0.839, loss_scale=8, train_wall=198, gb_free=15.1, wall=99668
2023-09-21 14:24:42 | INFO | train_inner | epoch 010:    779 / 9060 loss=6.499, nll_loss=3.247, ppl=9.5, wps=6285.9, ups=0.48, wpb=13028, bsz=433, num_updates=82300, lr=0.00011023, gnorm=0.839, loss_scale=8, train_wall=207, gb_free=15.2, wall=99875
pred_new.size(): torch.Size([606, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-21 14:28:01 | INFO | train_inner | epoch 010:    879 / 9060 loss=6.435, nll_loss=3.237, ppl=9.43, wps=6506.7, ups=0.5, wpb=12982.7, bsz=435, num_updates=82400, lr=0.000110163, gnorm=0.86, loss_scale=8, train_wall=199, gb_free=14.9, wall=100075
lprobs.size(): torch.Size([3136, 42808])
2023-09-21 14:31:20 | INFO | train_inner | epoch 010:    979 / 9060 loss=6.44, nll_loss=3.225, ppl=9.35, wps=6556.6, ups=0.5, wpb=12996.6, bsz=421.6, num_updates=82500, lr=0.000110096, gnorm=0.835, loss_scale=8, train_wall=198, gb_free=14.4, wall=100273
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3264, 42808])
2023-09-21 14:34:38 | INFO | train_inner | epoch 010:   1079 / 9060 loss=6.622, nll_loss=3.3, ppl=9.85, wps=6573.3, ups=0.5, wpb=13030.4, bsz=443.2, num_updates=82600, lr=0.00011003, gnorm=0.847, loss_scale=8, train_wall=198, gb_free=15, wall=100471
2023-09-21 14:36:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-21 14:37:59 | INFO | train_inner | epoch 010:   1180 / 9060 loss=6.512, nll_loss=3.186, ppl=9.1, wps=6497, ups=0.5, wpb=13045.4, bsz=455.1, num_updates=82700, lr=0.000109963, gnorm=0.83, loss_scale=4, train_wall=201, gb_free=14.6, wall=100672
pred_new.size(): torch.Size([450, 42808])
2023-09-21 14:41:18 | INFO | train_inner | epoch 010:   1280 / 9060 loss=6.486, nll_loss=3.228, ppl=9.37, wps=6481.4, ups=0.5, wpb=12931.6, bsz=439.8, num_updates=82800, lr=0.000109897, gnorm=0.854, loss_scale=4, train_wall=199, gb_free=13.7, wall=100872
2023-09-21 14:44:37 | INFO | train_inner | epoch 010:   1380 / 9060 loss=6.503, nll_loss=3.251, ppl=9.52, wps=6508.8, ups=0.5, wpb=12942.6, bsz=446, num_updates=82900, lr=0.00010983, gnorm=0.826, loss_scale=4, train_wall=199, gb_free=15.2, wall=101070
pred_new.size(): torch.Size([184, 42808])
2023-09-21 14:47:58 | INFO | train_inner | epoch 010:   1480 / 9060 loss=6.419, nll_loss=3.218, ppl=9.31, wps=6482.3, ups=0.5, wpb=13040.6, bsz=424.7, num_updates=83000, lr=0.000109764, gnorm=0.817, loss_scale=4, train_wall=201, gb_free=14.2, wall=101272
pred_new.size(): torch.Size([3900, 42808])
2023-09-21 14:51:20 | INFO | train_inner | epoch 010:   1580 / 9060 loss=6.514, nll_loss=3.262, ppl=9.59, wps=6470.8, ups=0.5, wpb=13039.6, bsz=444.6, num_updates=83100, lr=0.000109698, gnorm=0.879, loss_scale=4, train_wall=201, gb_free=13.6, wall=101473
2023-09-21 14:54:50 | INFO | train_inner | epoch 010:   1680 / 9060 loss=6.54, nll_loss=3.244, ppl=9.47, wps=6170.2, ups=0.48, wpb=12989.8, bsz=431.6, num_updates=83200, lr=0.000109632, gnorm=0.834, loss_scale=4, train_wall=210, gb_free=13.4, wall=101684
lprobs.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([1440, 42808])
ter_threshold: 0.383232
num_accepted / total 0 56
loss token level: tensor(14436.1465, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: 0
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.383275
num_accepted / total 15 64
loss token level: tensor(8675.1875, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3388., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 14:58:18 | INFO | train_inner | epoch 010:   1780 / 9060 loss=6.411, nll_loss=3.177, ppl=9.04, wps=6222.5, ups=0.48, wpb=12922.6, bsz=426.2, num_updates=83300, lr=0.000109566, gnorm=0.835, loss_scale=4, train_wall=207, gb_free=15, wall=101891
ter_threshold: 0.383345
num_accepted / total 62 136
loss token level: tensor(8026.9307, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5712., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.383395
num_accepted / total 14 120
loss token level: tensor(11808.9229, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3006., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 15:01:44 | INFO | train_inner | epoch 010:   1880 / 9060 loss=6.495, nll_loss=3.188, ppl=9.12, wps=6283.2, ups=0.48, wpb=12963.1, bsz=444.3, num_updates=83400, lr=0.000109501, gnorm=0.862, loss_scale=4, train_wall=206, gb_free=16, wall=102098
pred_new.size(): torch.Size([3612, 42808])
pred_new.size(): torch.Size([2124, 42808])
2023-09-21 15:05:11 | INFO | train_inner | epoch 010:   1980 / 9060 loss=6.525, nll_loss=3.256, ppl=9.55, wps=6298.6, ups=0.48, wpb=13022.6, bsz=429, num_updates=83500, lr=0.000109435, gnorm=0.857, loss_scale=4, train_wall=206, gb_free=14.4, wall=102304
2023-09-21 15:08:24 | INFO | train_inner | epoch 010:   2080 / 9060 loss=6.273, nll_loss=3.167, ppl=8.98, wps=6727.2, ups=0.52, wpb=12975.1, bsz=415.4, num_updates=83600, lr=0.00010937, gnorm=0.815, loss_scale=4, train_wall=193, gb_free=14.1, wall=102497
2023-09-21 15:11:41 | INFO | train_inner | epoch 010:   2180 / 9060 loss=6.472, nll_loss=3.22, ppl=9.32, wps=6622.2, ups=0.51, wpb=13048.1, bsz=442.7, num_updates=83700, lr=0.000109304, gnorm=0.81, loss_scale=4, train_wall=197, gb_free=15.5, wall=102694
ter_threshold: 0.383765
num_accepted / total 20 112
loss token level: tensor(8890.7969, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2548., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 15:15:05 | INFO | train_inner | epoch 010:   2280 / 9060 loss=6.487, nll_loss=3.225, ppl=9.35, wps=6360.1, ups=0.49, wpb=13015.9, bsz=427.4, num_updates=83800, lr=0.000109239, gnorm=0.866, loss_scale=4, train_wall=204, gb_free=14.2, wall=102899
ter_threshold: 0.383886
num_accepted / total 5 48
loss token level: tensor(8554.7891, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1478., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 15:18:27 | INFO | train_inner | epoch 010:   2380 / 9060 loss=6.419, nll_loss=3.226, ppl=9.36, wps=6418.6, ups=0.5, wpb=12940.5, bsz=453.2, num_updates=83900, lr=0.000109174, gnorm=0.835, loss_scale=4, train_wall=201, gb_free=14.2, wall=103101
pred_new.size(): torch.Size([5562, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([800, 42808])
pred_new.size(): torch.Size([2040, 42808])
ter_threshold: 0.37422099999999997
num_accepted / total 7 40
loss token level: tensor(9300.6318, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2468., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2904, 42808])
lprobs.size(): torch.Size([2136, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([936, 42808])
ter_threshold: 0.37493
num_accepted / total 13 72
loss token level: tensor(10135.1113, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4436., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1728, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([2472, 42808])
pred_new.size(): torch.Size([1820, 42808])
pred_new.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([2673, 42808])
ter_threshold: 0.375403
num_accepted / total 35 112
loss token level: tensor(9375.2344, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4624., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2394, 42808])
pred_new.size(): torch.Size([3600, 42808])
pred_new.size(): torch.Size([2937, 42808])
pred_new.size(): torch.Size([4692, 42808])
lprobs.size(): torch.Size([3560, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4224, 42808])
pred_new.size(): torch.Size([5548, 42808])
pred_new.size(): torch.Size([2580, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([2145, 42808])
pred_new.size(): torch.Size([4590, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([408, 42808])
pred_new.size(): torch.Size([344, 42808])
pred_new.size(): torch.Size([88, 42808])
pred_new.size(): torch.Size([2156, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([2943, 42808])
pred_new.size(): torch.Size([544, 42808])
pred_new.size(): torch.Size([3960, 42808])
lprobs.size(): torch.Size([3008, 42808])
ter_threshold: 0.377047
num_accepted / total 2 80
loss token level: tensor(11325.3770, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(633.5000, device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([324, 42808])
pred_new.size(): torch.Size([3380, 42808])
pred_new.size(): torch.Size([3180, 42808])
pred_new.size(): torch.Size([3780, 42808])
ter_threshold: 0.377596
num_accepted / total 4 72
loss token level: tensor(11796.7109, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(775., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([297, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([2574, 42808])
pred_new.size(): torch.Size([2646, 42808])
pred_new.size(): torch.Size([2340, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([2626, 42808])
pred_new.size(): torch.Size([1476, 42808])
pred_new.size(): torch.Size([1020, 42808])
pred_new.size(): torch.Size([1596, 42808])
pred_new.size(): torch.Size([1824, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2450, 42808])
ter_threshold: 0.379198
num_accepted / total 48 128
loss token level: tensor(9158.2275, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8920., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1612, 42808])
pred_new.size(): torch.Size([2340, 42808])
pred_new.size(): torch.Size([1768, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1980, 42808])
ter_threshold: 0.379931
num_accepted / total 148 272
loss token level: tensor(8650.5410, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10768., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.38057599999999997
num_accepted / total 16 80
loss token level: tensor(8037.9658, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3740., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2000, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([1216, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.38094
num_accepted / total 21 160
loss token level: tensor(12549.9014, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3094., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3320, 42808])
ter_threshold: 0.38099299999999997
num_accepted / total 2 40
loss token level: tensor(13533.3584, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1072., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([6300, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([4536, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([1880, 42808])
pred_new.size(): torch.Size([2288, 42808])
pred_new.size(): torch.Size([2480, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3320, 42808])
pred_new.size(): torch.Size([4522, 42808])
ter_threshold: 0.38201799999999997
num_accepted / total 76 152
loss token level: tensor(9358.4551, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6940., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1246, 42808])
pred_new.size(): torch.Size([5445, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([2322, 42808])
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([4953, 42808])
lprobs.size(): torch.Size([2704, 42808])
pred_new.size(): torch.Size([2510, 42808])
lprobs.size(): torch.Size([2544, 42808])
pred_new.size(): torch.Size([3900, 42808])
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([3933, 42808])
pred_new.size(): torch.Size([4032, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2400, 42808])
ter_threshold: 0.383244
num_accepted / total 7 32
loss token level: tensor(9139.8867, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5748., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.383395
num_accepted / total 53 152
loss token level: tensor(8437.5527, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7608., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3036, 42808])
ter_threshold: 0.383588
num_accepted / total 53 136
loss token level: tensor(9171.6211, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5648., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.383765
num_accepted / total 86 208
loss token level: tensor(9719.0146, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5576., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): lprobs.size(): torch.Size([3472, 42808])
2023-09-21 15:21:38 | INFO | train_inner | epoch 010:   2480 / 9060 loss=6.395, nll_loss=3.239, ppl=9.44, wps=6774.8, ups=0.52, wpb=12955.3, bsz=413.3, num_updates=84000, lr=0.000109109, gnorm=0.828, loss_scale=4, train_wall=191, gb_free=14.3, wall=103292
pred_new.size(): torch.Size([920, 42808])
pred_new.size(): torch.Size([1596, 42808])
2023-09-21 15:25:01 | INFO | train_inner | epoch 010:   2580 / 9060 loss=6.62, nll_loss=3.285, ppl=9.75, wps=6414.9, ups=0.49, wpb=13002.6, bsz=440, num_updates=84100, lr=0.000109044, gnorm=0.876, loss_scale=4, train_wall=202, gb_free=14.7, wall=103494
lprobs.size(): torch.Size([3168, 42808])
2023-09-21 15:28:19 | INFO | train_inner | epoch 010:   2680 / 9060 loss=6.506, nll_loss=3.26, ppl=9.58, wps=6582.4, ups=0.51, wpb=13033, bsz=439.9, num_updates=84200, lr=0.000108979, gnorm=0.842, loss_scale=4, train_wall=198, gb_free=15.2, wall=103692
pred_new.size(): torch.Size([1176, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2850, 42808])
2023-09-21 15:31:40 | INFO | train_inner | epoch 010:   2780 / 9060 loss=6.344, nll_loss=3.176, ppl=9.04, wps=6484.7, ups=0.5, wpb=13061.1, bsz=429.5, num_updates=84300, lr=0.000108915, gnorm=0.825, loss_scale=4, train_wall=201, gb_free=15.3, wall=103894
ter_threshold: 0.384371
num_accepted / total 12 96
loss token level: tensor(8854.8145, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2324., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 15:34:55 | INFO | train_inner | epoch 010:   2880 / 9060 loss=6.48, nll_loss=3.264, ppl=9.61, wps=6661.5, ups=0.51, wpb=12951.1, bsz=436.2, num_updates=84400, lr=0.00010885, gnorm=0.845, loss_scale=4, train_wall=194, gb_free=14.3, wall=104088
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3016, 42808])
2023-09-21 15:38:10 | INFO | train_inner | epoch 010:   2980 / 9060 loss=6.484, nll_loss=3.254, ppl=9.54, wps=6621.4, ups=0.51, wpb=12947.6, bsz=410.6, num_updates=84500, lr=0.000108786, gnorm=0.917, loss_scale=4, train_wall=195, gb_free=14.7, wall=104284
ter_threshold: 0.384519
num_accepted / total 20 72
loss token level: tensor(8732.7012, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4010., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1920, 42808])
2023-09-21 15:41:28 | INFO | train_inner | epoch 010:   3080 / 9060 loss=6.5, nll_loss=3.244, ppl=9.47, wps=6574.8, ups=0.51, wpb=13009.6, bsz=429.2, num_updates=84600, lr=0.000108721, gnorm=0.822, loss_scale=4, train_wall=198, gb_free=14.5, wall=104482
lprobs.size(): torch.Size([3400, 42808])
2023-09-21 15:44:55 | INFO | train_inner | epoch 010:   3180 / 9060 loss=6.584, nll_loss=3.282, ppl=9.73, wps=6294.5, ups=0.48, wpb=12992.4, bsz=420.6, num_updates=84700, lr=0.000108657, gnorm=0.857, loss_scale=4, train_wall=206, gb_free=13.5, wall=104688
pred_new.size(): torch.Size([1080, 42808])
pred_new.size(): torch.Size([4540, 42808])
2023-09-21 15:48:21 | INFO | train_inner | epoch 010:   3280 / 9060 loss=6.482, nll_loss=3.24, ppl=9.44, wps=6305.4, ups=0.49, wpb=12994.3, bsz=448.4, num_updates=84800, lr=0.000108593, gnorm=0.856, loss_scale=4, train_wall=206, gb_free=14.8, wall=104894
pred_new.size(): torch.Size([5612, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 15:51:31 | INFO | train_inner | epoch 010:   3380 / 9060 loss=6.487, nll_loss=3.246, ppl=9.49, wps=6806.2, ups=0.53, wpb=12926.1, bsz=423.7, num_updates=84900, lr=0.000108529, gnorm=0.842, loss_scale=4, train_wall=190, gb_free=15.1, wall=105084
2023-09-21 15:54:42 | INFO | train_inner | epoch 010:   3480 / 9060 loss=6.478, nll_loss=3.251, ppl=9.52, wps=6797.2, ups=0.52, wpb=13038.7, bsz=434.6, num_updates=85000, lr=0.000108465, gnorm=0.829, loss_scale=4, train_wall=192, gb_free=15, wall=105276
0.375456
num_accepted / total 0 24
loss token level: tensor(10931.7285, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: 0
pred_new.size(): torch.Size([2834, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1914, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.376061
num_accepted / total 66 176
loss token level: tensor(10504.3477, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8608., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1104, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.37637299999999996
num_accepted / total 10 56
loss token level: tensor(9337.1504, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2710., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2280, 42808])
pred_new.size(): torch.Size([4760, 42808])
pred_new.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([3483, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.377047
num_accepted / total 14 72
loss token level: tensor(9030.6973, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4280., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3036, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([3485, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([2652, 42808])
lprobs.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([2700, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([4953, 42808])
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([1776, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.37816299999999997
num_accepted / total 15 96
loss token level: tensor(11585.7031, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4424., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([2964, 42808])
pred_new.size(): torch.Size([2717, 42808])
pred_new.size(): torch.Size([700, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([3300, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4730, 42808])
pred_new.size(): torch.Size([4396, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([896, 42808])
ter_threshold: 0.379198
num_accepted / total 52 144
loss token level: tensor(9948.1172, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8688., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.379368
num_accepted / total 64 168
loss token level: tensor(9123.9658, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4984., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([480, 42808])
pred_new.size(): torch.Size([960, 42808])
pred_new.size(): torch.Size([3720, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([1824, 42808])
pred_new.size(): torch.Size([2553, 42808])
pred_new.size(): torch.Size([1452, 42808])
lprobs.size(): torch.Size([2912, 42808])
ter_threshold: 0.379931
num_accepted / total 25 112
loss token level: tensor(9900.4219, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5792., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.380043
num_accepted / total 23 88
loss token level: tensor(9960.0186, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6112., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([400, 42808])
ter_threshold: 0.38057599999999997
num_accepted / total 41 128
loss token level: tensor(9737.8633, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7964., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1419, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([496, 42808])
lprobs.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([2970, 42808])
lprobs.size(): torch.Size([3096, 42808])
pred_new.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([5085, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6222, 42808])
pred_new.size(): torch.Size([2070, 42808])
pred_new.size(): torch.Size([3366, 42808])
pred_new.size(): torch.Size([688, 42808])
pred_new.size(): torch.Size([3358, 42808])
pred_new.size(): torch.Size([4094, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([2625, 42808])
pred_new.size(): torch.Size([4060, 42808])
lprobs.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([1800, 42808])
pred_new.size(): torch.Size([2250, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([2401, 42808])
pred_new.size(): torch.Size([480, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([3575, 42808])
ter_threshold: 0.383345
num_accepted / total 20 88
loss token level: tensor(8979.3096, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2568., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.383395
num_accepted / total 44 120
loss token level: tensor(9254.4727, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8736., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1782, 42808])
pred_new.size(): torch.Size([1728, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.383588
num_accepted / total 42 112
loss token level: tensor(8877.7090, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5308., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([1512, 42808])
pred_new.size(): torch.Size([1750, 42808])
pred_new.size(): torch.Size([1092, 42808])
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([3920, 42808])
pred_new.size(): torch.Size([2509, 42808])
pred_new.size(): torch.Size([2652, 42808])
ter_threshold: 0.384371
num_accepted / total 52 136
loss token level: tensor(9884.6855, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9488., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2100, 42808])
pred_new.size(): torch.Size([5100, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): lprobs.size(): torch.Size([3528, 42808])
2023-09-21 15:57:59 | INFO | train_inner | epoch 010:   3580 / 9060 loss=6.447, nll_loss=3.244, ppl=9.47, wps=6647.6, ups=0.51, wpb=13043.6, bsz=408.6, num_updates=85100, lr=0.000108401, gnorm=0.827, loss_scale=4, train_wall=196, gb_free=13, wall=105472
pred_new.size(): torch.Size([4224, 42808])
ter_threshold: 0.385147
num_accepted / total 54 144
loss token level: tensor(9491.9785, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9216., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 16:01:13 | INFO | train_inner | epoch 010:   3680 / 9060 loss=6.436, nll_loss=3.251, ppl=9.52, wps=6700.9, ups=0.51, wpb=13016.5, bsz=405.5, num_updates=85200, lr=0.000108338, gnorm=0.836, loss_scale=4, train_wall=194, gb_free=14.9, wall=105666
2023-09-21 16:04:34 | INFO | train_inner | epoch 010:   3780 / 9060 loss=6.522, nll_loss=3.285, ppl=9.75, wps=6416.1, ups=0.5, wpb=12870.2, bsz=439.8, num_updates=85300, lr=0.000108274, gnorm=0.875, loss_scale=4, train_wall=200, gb_free=15.4, wall=105867
2023-09-21 16:07:57 | INFO | train_inner | epoch 010:   3880 / 9060 loss=6.496, nll_loss=3.24, ppl=9.45, wps=6341, ups=0.49, wpb=12922.2, bsz=419, num_updates=85400, lr=0.000108211, gnorm=0.864, loss_scale=4, train_wall=204, gb_free=15.7, wall=106071
pred_new.size(): torch.Size([4446, 42808])
pred_new.size(): torch.Size([4389, 42808])
ter_threshold: 0.385456
num_accepted / total 59 120
loss token level: tensor(9293.2080, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11888., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 16:11:13 | INFO | train_inner | epoch 010:   3980 / 9060 loss=6.518, nll_loss=3.254, ppl=9.54, wps=6593.2, ups=0.51, wpb=12877, bsz=445, num_updates=85500, lr=0.000108148, gnorm=0.85, loss_scale=4, train_wall=195, gb_free=14.3, wall=106266
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 16:14:40 | INFO | train_inner | epoch 010:   4080 / 9060 loss=6.577, nll_loss=3.273, ppl=9.66, wps=6260, ups=0.48, wpb=12963, bsz=428.9, num_updates=85600, lr=0.000108084, gnorm=0.876, loss_scale=4, train_wall=207, gb_free=14.8, wall=106473
ter_threshold: 0.385604
num_accepted / total 111 208
loss token level: tensor(8837.4258, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7132., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
2023-09-21 16:17:55 | INFO | train_inner | epoch 010:   4180 / 9060 loss=6.477, nll_loss=3.231, ppl=9.39, wps=6650.6, ups=0.51, wpb=12983.1, bsz=429.3, num_updates=85700, lr=0.000108021, gnorm=0.822, loss_scale=4, train_wall=195, gb_free=14.7, wall=106668
pred_new.size(): torch.Size([1792, 42808])
2023-09-21 16:21:10 | INFO | train_inner | epoch 010:   4280 / 9060 loss=6.525, nll_loss=3.267, ppl=9.63, wps=6619.8, ups=0.51, wpb=12922.7, bsz=425.8, num_updates=85800, lr=0.000107958, gnorm=0.863, loss_scale=4, train_wall=195, gb_free=14.3, wall=106864
lprobs.size(): torch.Size([2240, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 16:24:27 | INFO | train_inner | epoch 010:   4380 / 9060 loss=6.585, nll_loss=3.335, ppl=10.09, wps=6576.3, ups=0.51, wpb=12945.3, bsz=435.7, num_updates=85900, lr=0.000107896, gnorm=0.866, loss_scale=4, train_wall=197, gb_free=14.5, wall=107060
pred_new.size(): torch.Size([4369, 42808])
pred_new.size(): torch.Size([1824, 42808])
2023-09-21 16:27:47 | INFO | train_inner | epoch 010:   4480 / 9060 loss=6.469, nll_loss=3.249, ppl=9.51, wps=6497.8, ups=0.5, wpb=12991.8, bsz=409.2, num_updates=86000, lr=0.000107833, gnorm=0.844, loss_scale=4, train_wall=200, gb_free=14.4, wall=107260
2023-09-21 16:31:11 | INFO | train_inner | epoch 010:   4580 / 9060 loss=6.411, nll_loss=3.22, ppl=9.32, wps=6289.8, ups=0.49, wpb=12831.6, bsz=419.1, num_updates=86100, lr=0.00010777, gnorm=0.833, loss_scale=4, train_wall=204, gb_free=15.2, wall=107464
2023-09-21 16:34:36 | INFO | train_inner | epoch 010:   4680 / 9060 loss=6.526, nll_loss=3.236, ppl=9.42, wps=6294.9, ups=0.49, wpb=12939.7, bsz=431.8, num_updates=86200, lr=0.000107708, gnorm=0.861, loss_scale=4, train_wall=205, gb_free=14.3, wall=107670
pred_new.size(): torch.Size([3084, 42808])
2023-09-21 16:37:51 | INFO | train_inner | epoch 010:   4780 / 9060 loss=6.401, nll_loss=3.22, ppl=9.32, wps=6700.8, ups=0.52, wpb=13006.1, bsz=408.2, num_updates=86300, lr=0.000107645, gnorm=0.847, loss_scale=4, train_wall=194, gb_free=14.8, wall=107864
lprobs.size(): torch.Size([3240, 42808])
2023-09-21 16:41:15 | INFO | train_inner | epoch 010:   4880 / 9060 loss=6.475, nll_loss=3.212, ppl=9.27, wps=6363.3, ups=0.49, wpb=13002.4, bsz=455.2, num_updates=86400, lr=0.000107583, gnorm=0.821, loss_scale=4, train_wall=204, gb_free=14.7, wall=108068
lprobs.size(): torch.Size([2520, 42808])
2023-09-21 16:44:40 | INFO | train_inner | epoch 010:   4980 / 9060 loss=6.587, nll_loss=3.289, ppl=9.77, wps=6317.2, ups=0.49, wpb=12978.4, bsz=438.6, num_updates=86500, lr=0.000107521, gnorm=0.868, loss_scale=4, train_wall=205, gb_free=15.1, wall=108274
lprobs.size(): torch.Size([2544, 42808])
pred_new.size(): torch.Size([5000, 42808])
2023-09-21 16:47:54 | INFO | train_inner | epoch 010:   5080 / 9060 loss=6.513, nll_loss=3.268, ppl=9.63, wps=6702.7, ups=0.52, wpb=12966.7, bsz=444.2, num_updates=86600, lr=0.000107459, gnorm=0.841, loss_scale=4, train_wall=193, gb_free=14.9, wall=108467
ter_threshold: 0.386619
num_accepted / total 30 88
loss token level: tensor(9438.2656, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9520., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.38669699999999996
num_accepted / total 88 160
loss token level: tensor(9173.6055, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13096., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 16:51:20 | INFO | train_inner | epoch 010:   5180 / 9060 loss=6.514, nll_loss=3.264, ppl=9.6, wps=6303.9, ups=0.48, wpb=12999.6, bsz=422.6, num_updates=86700, lr=0.000107397, gnorm=0.879, loss_scale=4, train_wall=206, gb_free=14.7, wall=108673
lprobs.size(): torch.Size([3040, 42808])
2023-09-21 16:54:39 | INFO | train_inner | epoch 010:   5280 / 9060 loss=6.625, nll_loss=3.323, ppl=10.01, wps=6510.4, ups=0.5, wpb=12925.3, bsz=424.6, num_updates=86800, lr=0.000107335, gnorm=0.875, loss_scale=8, train_wall=198, gb_free=15.6, wall=108872
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2856, 42808])
2023-09-21 16:58:00 | INFO | train_inner | epoch 010:   5380 / 9060 loss=6.459, nll_loss=3.231, ppl=9.39, wps=6511.1, ups=0.5, wpb=13094.3, bsz=427.4, num_updates=86900, lr=0.000107273, gnorm=0.837, loss_scale=8, train_wall=201, gb_free=14.6, wall=109073
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2624, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1288, 42808])
pred_new.size(): torch.Size([1785, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([600, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.37816299999999997
num_accepted / total 27 104
loss token level: tensor(9631.1699, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7016., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1920, 42808])
pred_new.size(): torch.Size([1440, 42808])
ter_threshold: 0.379137
num_accepted / total 8 64
loss token level: tensor(11371.7549, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1998., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([152, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.379368
num_accepted / total 37 144
loss token level: tensor(9675.3047, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3596., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3780, 42808])
pred_new.size(): torch.Size([3045, 42808])
pred_new.size(): torch.Size([2747, 42808])
pred_new.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3652, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([4368, 42808])
pred_new.size(): torch.Size([1944, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.379931
num_accepted / total 27 112
loss token level: tensor(9183.9160, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5696., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.380043
num_accepted / total 50 136
loss token level: tensor(9967.0479, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9424., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.380541
num_accepted / total 1 16
loss token level: tensor(7481.0811, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(407.2500, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.380909
num_accepted / total 10 48
loss token level: tensor(8864.3525, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5232., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.38094
num_accepted / total 168 272
loss token level: tensor(8627.9707, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12496., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6435, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([3834, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([5063, 42808])
pred_new.size(): torch.Size([2134, 42808])
pred_new.size(): torch.Size([5846, 42808])
pred_new.size(): torch.Size([2530, 42808])
pred_new.size(): torch.Size([2088, 42808])
pred_new.size(): torch.Size([988, 42808])
pred_new.size(): torch.Size([984, 42808])
ter_threshold: 0.38206399999999996
num_accepted / total 20 72
loss token level: tensor(9881.2549, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4136., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([702, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2184, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3430, 42808])
pred_new.size(): torch.Size([2940, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([136, 42808])
ter_threshold: 0.382541
num_accepted / total 0 80
loss token level: tensor(9103.1572, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: 0
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([4320, 42808])
lprobs.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1566, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1953, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.383588
num_accepted / total 9 80
loss token level: tensor(8438.0059, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1336., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([588, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([392, 42808])
pred_new.size(): torch.Size([1320, 42808])
pred_new.size(): torch.Size([2244, 42808])
pred_new.size(): torch.Size([1900, 42808])
pred_new.size(): torch.Size([968, 42808])
pred_new.size(): torch.Size([1914, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([3995, 42808])
pred_new.size(): torch.Size([2475, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([1612, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([7200, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([2050, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([6875, 42808])
ter_threshold: 0.385147
num_accepted / total 33 176
loss token level: tensor(12211.4395, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3948., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.385165
num_accepted / total 6 48
loss token level: tensor(10753.5371, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2074., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4960, 42808])
ter_threshold: 0.385287
num_accepted / total 18 72
loss token level: tensor(8611.9355, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6404., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2256, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3875, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2800, 42808])
ter_threshold: 0.385753
num_accepted / total 16 80
loss token level: tensor(8963.6475, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2934., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2070, 42808])
pred_new.size(): torch.Size([496, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([2904, 42808])
lprobs.size(): torch.Size([2688, 42808])
ter_threshold: 0.386619
num_accepted / total 58 128
loss token level: tensor(9385.7520, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11312., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.386762
num_accepted / total 5 8
loss token level: tensor(5317.9287, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5476., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): pred_new.size(): torch.Size([2759, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 17:01:24 | INFO | train_inner | epoch 010:   5480 / 9060 loss=6.51, nll_loss=3.263, ppl=9.6, wps=6349.4, ups=0.49, wpb=12958.1, bsz=432.6, num_updates=87000, lr=0.000107211, gnorm=0.859, loss_scale=8, train_wall=204, gb_free=14.4, wall=109277
pred_new.size(): torch.Size([2432, 42808])
2023-09-21 17:04:29 | INFO | train_inner | epoch 010:   5580 / 9060 loss=6.493, nll_loss=3.282, ppl=9.73, wps=6943.6, ups=0.54, wpb=12876, bsz=441.4, num_updates=87100, lr=0.00010715, gnorm=0.847, loss_scale=8, train_wall=185, gb_free=15.2, wall=109463
lprobs.size(): torch.Size([3248, 42808])
2023-09-21 17:07:45 | INFO | train_inner | epoch 010:   5680 / 9060 loss=6.432, nll_loss=3.228, ppl=9.37, wps=6624.9, ups=0.51, wpb=12972.9, bsz=439.8, num_updates=87200, lr=0.000107088, gnorm=0.833, loss_scale=8, train_wall=196, gb_free=14.3, wall=109658
pred_new.size(): torch.Size([7410, 42808])
ter_threshold: 0.387245
num_accepted / total 33 112
loss token level: tensor(9171.2627, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7512., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 17:11:04 | INFO | train_inner | epoch 010:   5780 / 9060 loss=6.457, nll_loss=3.258, ppl=9.57, wps=6570.8, ups=0.5, wpb=13048, bsz=405.4, num_updates=87300, lr=0.000107027, gnorm=0.838, loss_scale=8, train_wall=198, gb_free=15, wall=109857
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([430, 42808])
2023-09-21 17:14:11 | INFO | train_inner | epoch 010:   5880 / 9060 loss=6.512, nll_loss=3.277, ppl=9.69, wps=6961.8, ups=0.53, wpb=13067.2, bsz=432, num_updates=87400, lr=0.000106966, gnorm=0.843, loss_scale=8, train_wall=187, gb_free=14.4, wall=110045
lprobs.size(): torch.Size([3360, 42808])
2023-09-21 17:17:42 | INFO | train_inner | epoch 010:   5980 / 9060 loss=6.559, nll_loss=3.297, ppl=9.83, wps=6099.5, ups=0.47, wpb=12869.1, bsz=425, num_updates=87500, lr=0.000106904, gnorm=0.882, loss_scale=8, train_wall=211, gb_free=14.6, wall=110256
pred_new.size(): torch.Size([1510, 42808])
pred_new.size(): torch.Size([258, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-21 17:21:05 | INFO | train_inner | epoch 010:   6080 / 9060 loss=6.464, nll_loss=3.269, ppl=9.64, wps=6334.4, ups=0.49, wpb=12854, bsz=405.1, num_updates=87600, lr=0.000106843, gnorm=0.854, loss_scale=8, train_wall=203, gb_free=14.6, wall=110459
2023-09-21 17:24:18 | INFO | train_inner | epoch 010:   6180 / 9060 loss=6.503, nll_loss=3.271, ppl=9.65, wps=6770.6, ups=0.52, wpb=13030.7, bsz=434.8, num_updates=87700, lr=0.000106783, gnorm=0.843, loss_scale=8, train_wall=192, gb_free=14.2, wall=110651
pred_new.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 17:27:38 | INFO | train_inner | epoch 010:   6280 / 9060 loss=6.596, nll_loss=3.299, ppl=9.84, wps=6434, ups=0.5, wpb=12918.8, bsz=435, num_updates=87800, lr=0.000106722, gnorm=0.868, loss_scale=8, train_wall=201, gb_free=14.1, wall=110852
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6120, 42808])
2023-09-21 17:31:00 | INFO | train_inner | epoch 010:   6380 / 9060 loss=6.414, nll_loss=3.211, ppl=9.26, wps=6466.5, ups=0.5, wpb=13016.3, bsz=430.5, num_updates=87900, lr=0.000106661, gnorm=0.842, loss_scale=8, train_wall=201, gb_free=14.6, wall=111053
2023-09-21 17:34:19 | INFO | train_inner | epoch 010:   6480 / 9060 loss=6.543, nll_loss=3.284, ppl=9.74, wps=6505.9, ups=0.5, wpb=12956.7, bsz=427.7, num_updates=88000, lr=0.0001066, gnorm=0.874, loss_scale=8, train_wall=199, gb_free=14.6, wall=111252
2023-09-21 17:34:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-21 17:37:37 | INFO | train_inner | epoch 010:   6581 / 9060 loss=6.507, nll_loss=3.265, ppl=9.61, wps=6540.9, ups=0.5, wpb=12975.7, bsz=423, num_updates=88100, lr=0.00010654, gnorm=0.846, loss_scale=4, train_wall=198, gb_free=13.8, wall=111451
lprobs.size(): torch.Size([3248, 42808])
2023-09-21 17:41:00 | INFO | train_inner | epoch 010:   6681 / 9060 loss=6.449, nll_loss=3.223, ppl=9.34, wps=6364.7, ups=0.49, wpb=12902.4, bsz=401.7, num_updates=88200, lr=0.000106479, gnorm=0.888, loss_scale=4, train_wall=202, gb_free=14.1, wall=111653
2023-09-21 17:44:25 | INFO | train_inner | epoch 010:   6781 / 9060 loss=6.401, nll_loss=3.226, ppl=9.35, wps=6290.5, ups=0.49, wpb=12884.6, bsz=412.2, num_updates=88300, lr=0.000106419, gnorm=0.829, loss_scale=4, train_wall=205, gb_free=13.6, wall=111858
ter_threshold: 0.388335
num_accepted / total 29 112
loss token level: tensor(9180.0322, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3588., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 17:47:47 | INFO | train_inner | epoch 010:   6881 / 9060 loss=6.507, nll_loss=3.281, ppl=9.72, wps=6424.5, ups=0.49, wpb=13007, bsz=438.2, num_updates=88400, lr=0.000106359, gnorm=0.888, loss_scale=4, train_wall=202, gb_free=15.2, wall=112061
ter_threshold: 0.38841499999999995
num_accepted / total 58 160
loss token level: tensor(8039.5132, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3074., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 17:51:10 | INFO | train_inner | epoch 010:   6981 / 9060 loss=6.512, nll_loss=3.275, ppl=9.68, wps=6398.4, ups=0.49, wpb=12976.9, bsz=410.5, num_updates=88500, lr=0.000106299, gnorm=0.867, loss_scale=4, train_wall=203, gb_free=14.4, wall=112264
pred_new.size(): torch.Size([4216, 42808])
pred_new.size(): torch.Size([2250, 42808])
lprobs.size(): torch.Size([2760, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.38858099999999995
num_accepted / total 51 160
loss token level: tensor(10900.8848, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7928., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 17:54:31 | INFO | train_inner | epoch 010:   7081 / 9060 loss=6.538, nll_loss=3.27, ppl=9.65, wps=6505.9, ups=0.5, wpb=13086, bsz=439.1, num_updates=88600, lr=0.000106239, gnorm=0.842, loss_scale=4, train_wall=201, gb_free=15.4, wall=112465
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1980, 42808])
2023-09-21 17:57:55 | INFO | train_inner | epoch 010:   7181 / 9060 loss=6.573, nll_loss=3.261, ppl=9.59, wps=6417.6, ups=0.49, wpb=13060.8, bsz=440.9, num_updates=88700, lr=0.000106179, gnorm=0.932, loss_scale=4, train_wall=203, gb_free=14.6, wall=112668
ter_threshold: 0.388761
num_accepted / total 5 88
loss token level: tensor(11287.2363, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(806., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 18:01:16 | INFO | train_inner | epoch 010:   7281 / 9060 loss=6.532, nll_loss=3.286, ppl=9.75, wps=6501.4, ups=0.5, wpb=13090.6, bsz=453, num_updates=88800, lr=0.000106119, gnorm=0.831, loss_scale=4, train_wall=201, gb_free=14.7, wall=112870
2023-09-21 18:04:42 | INFO | train_inner | epoch 010:   7381 / 9060 loss=6.555, nll_loss=3.265, ppl=9.61, wps=6312.3, ups=0.49, wpb=12990.5, bsz=464.2, num_updates=88900, lr=0.000106059, gnorm=0.867, loss_scale=4, train_wall=206, gb_free=14.1, wall=113075
2023-09-21 18:07:57 | INFO | train_inner | epoch 010:   7481 / 9060 loss=6.571, nll_loss=3.313, ppl=9.94, wps=6630.2, ups=0.51, wpb=12927, bsz=428.6, num_updates=89000, lr=0.000106, gnorm=0.86, loss_scale=4, train_wall=195, gb_free=15, wall=113270
2023-09-21 18:11:15 | INFO | train_inner | epoch 010:   7581 / 9060 loss=6.633, nll_loss=3.33, ppl=10.06, wps=6544.3, ups=0.5, wpb=12997.1, bsz=428.5, num_updates=89100, lr=0.00010594, gnorm=0.876, loss_scale=4, train_wall=198, gb_free=14.7, wall=113469
pred_new.size(): torch.Size([2112, 42808])
2023-09-21 18:14:27 | INFO | train_inner | epoch 010:   7681 / 9060 loss=6.517, nll_loss=3.292, ppl=9.8, wps=6717.4, ups=0.52, wpb=12864.8, bsz=438.2, num_updates=89200, lr=0.000105881, gnorm=0.838, loss_scale=4, train_wall=191, gb_free=13.7, wall=113660
lprobs.size(): torch.Size([2744, 42808])
2023-09-21 18:17:49 | INFO | train_inner | epoch 010:   7781 / 9060 loss=6.507, nll_loss=3.247, ppl=9.49, wps=6383.6, ups=0.49, wpb=12904.5, bsz=438.1, num_updates=89300, lr=0.000105822, gnorm=0.844, loss_scale=4, train_wall=202, gb_free=14.5, wall=113863
pred_new.size(): torch.Size([4828, 42808])
pred_new.size(): torch.Size([1824, 42808])
2023-09-21 18:21:13 | INFO | train_inner | epoch 010:   7881 / 9060 loss=6.677, nll_loss=3.316, ppl=9.96, wps=6376.6, ups=0.49, wpb=13000.5, bsz=443.8, num_updates=89400, lr=0.000105762, gnorm=0.881, loss_scale=4, train_wall=204, gb_free=14.8, wall=114066
lprobs.size(): torch.Size([2928, 42808])
2023-09-21 18:24:30 | INFO | train_inner | epoch 010:   7981 / 9060 loss=6.52, nll_loss=3.291, ppl=9.79, wps=6554.5, ups=0.51, wpb=12936.7, bsz=424.6, num_updates=89500, lr=0.000105703, gnorm=0.846, loss_scale=4, train_wall=197, gb_free=14.6, wall=114264
pred_new.size(): torch.Size([4125, 42808])
2023-09-21 18:27:52 | INFO | train_inner | epoch 010:   8081 / 9060 loss=6.61, nll_loss=3.321, ppl=9.99, wps=6410.4, ups=0.5, wpb=12934, bsz=429.2, num_updates=89600, lr=0.000105644, gnorm=0.86, loss_scale=4, train_wall=202, gb_free=14.8, wall=114466
2023-09-21 18:31:22 | INFO | train_inner | epoch 010:   8181 / 9060 loss=6.645, nll_loss=3.33, ppl=10.06, wps=6201.2, ups=0.48, wpb=13002.4, bsz=463.1, num_updates=89700, lr=0.000105585, gnorm=0.879, loss_scale=4, train_wall=209, gb_free=14.9, wall=114675
lprobs.size(): torch.Size([3136, 42808])
2023-09-21 18:34:39 | INFO | train_inner | epoch 010:   8281 / 9060 loss=6.602, nll_loss=3.324, ppl=10.01, wps=6525.2, ups=0.51, wpb=12897.7, bsz=419.7, num_updates=89800, lr=0.000105527, gnorm=0.861, loss_scale=4, train_wall=197, gb_free=15.5, wall=114873
lprobs.size(): torch.Size([3392, 42808])
2023-09-21 18:37:58 | INFO | train_inner | epoch 010:   8381 / 9060 loss=6.547, nll_loss=3.296, ppl=9.82, wps=6579.3, ups=0.5, wpb=13033.3, bsz=414.6, num_updates=89900, lr=0.000105468, gnorm=0.86, loss_scale=4, train_wall=198, gb_free=13.9, wall=115071
2023-09-21 18:41:19 | INFO | train_inner | epoch 010:   8481 / 9060 loss=6.579, nll_loss=3.299, ppl=9.84, wps=6456.2, ups=0.5, wpb=12998.8, bsz=425.1, num_updates=90000, lr=0.000105409, gnorm=0.858, loss_scale=4, train_wall=201, gb_free=15.1, wall=115272
pred_new.size(): torch.Size([4242, 42808])
pred_new.size(): torch.Size([2324, 42808])
2023-09-21 18:44:35 | INFO | train_inner | epoch 010:   8581 / 9060 loss=6.616, nll_loss=3.324, ppl=10.02, wps=6601.8, ups=0.51, wpb=12964.1, bsz=425.8, num_updates=90100, lr=0.000105351, gnorm=0.848, loss_scale=4, train_wall=196, gb_free=14.1, wall=115469
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3344, 42808])
2023-09-21 18:47:56 | INFO | train_inner | epoch 010:   8681 / 9060 loss=6.549, nll_loss=3.288, ppl=9.77, wps=6481.8, ups=0.5, wpb=12993.7, bsz=431.6, num_updates=90200, lr=0.000105292, gnorm=0.84, loss_scale=4, train_wall=200, gb_free=14.3, wall=115669
ter_threshold: 0.39023599999999997
num_accepted / total 8 48
loss token level: tensor(8685.5137, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4312., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 18:51:19 | INFO | train_inner | epoch 010:   8781 / 9060 loss=6.568, nll_loss=3.304, ppl=9.88, wps=6397.7, ups=0.49, wpb=13013.3, bsz=435.2, num_updates=90300, lr=0.000105234, gnorm=0.866, loss_scale=4, train_wall=203, gb_free=13.6, wall=115873
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2590, 42808])
lprobs.size(): torch.Size([3472, 42808])
2023-09-21 18:54:44 | INFO | train_inner | epoch 010:   8881 / 9060 loss=6.63, nll_loss=3.302, ppl=9.87, wps=6327.8, ups=0.49, wpb=12981.8, bsz=444.1, num_updates=90400, lr=0.000105176, gnorm=0.852, loss_scale=4, train_wall=205, gb_free=14.3, wall=116078
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([2040, 42808])
2023-09-21 18:58:19 | INFO | train_inner | epoch 010:   8981 / 9060 loss=6.513, nll_loss=3.276, ppl=9.68, wps=6050.1, ups=0.47, wpb=12973.4, bsz=439.8, num_updates=90500, lr=0.000105118, gnorm=0.852, loss_scale=4, train_wall=214, gb_free=13.6, wall=116292
2023-09-21 19:01:07 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-21 19:01:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 19:01:08 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident!
2023-09-21 19:01:08 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-21 19:01:08 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-21 19:01:08 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-21 19:01:09 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-21 19:01:09 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-21 19:01:09 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente vertraulich behandelt.
2023-09-21 19:01:09 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-21 19:01:10 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-21 19:01:10 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-21 19:01:10 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und war ein großer Erfolg.
2023-09-21 19:01:10 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-21 19:01:11 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein frohes neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-21 19:01:11 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-21 19:01:11 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, was wir respektieren.
2023-09-21 19:01:11 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-21 19:01:12 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Features zur Verwaltung und Überprüfung von Chat-Diskussionen.
2023-09-21 19:01:12 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-21 19:01:12 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Geschäftsreisende als auch für Urlauber geeignet sind.
2023-09-21 19:01:12 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-21 19:01:13 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-21 19:01:13 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-21 19:01:14 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 19:01:14 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-21 19:01:14 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU riesige Mengen Energie verschwendet.
2023-09-21 19:01:14 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-21 19:01:15 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin trägt einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-21 19:01:15 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-21 19:01:15 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellung auch in Kürze im Haushalt der Union widerspiegeln.
2023-09-21 19:01:15 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-21 19:01:16 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-21 19:01:16 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-21 19:01:16 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die allgemein bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-21 19:01:16 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-21 19:01:17 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der Hauptziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-21 19:01:17 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-21 19:01:17 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-21 19:01:17 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-21 19:01:18 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionsräume in Stans.
2023-09-21 19:01:18 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-21 19:01:18 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-21 19:01:18 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-21 19:01:19 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-21 19:01:19 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-21 19:01:20 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionale Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-21 19:01:20 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-21 19:01:20 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu bringen, sich über die Qualität Ihrer Dienstleistung und Produkte zu informieren.
2023-09-21 19:01:20 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-21 19:01:21 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in ungecharterten Gebieten wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-21 19:01:21 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-21 19:01:21 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-21 19:01:21 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-21 19:01:22 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze diese Aussprache auch, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-21 19:01:22 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-21 19:01:22 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in etwa einem Umkreis von 8 km vom Strip entfernt.
2023-09-21 19:01:22 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-21 19:01:23 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-21 19:01:23 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-21 19:01:24 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! akustisch, interaktiv oder in schriftlicher Form die Realisierung von Tonbüchern an.
2023-09-21 19:01:24 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-21 19:01:24 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-21 19:01:24 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-21 19:01:25 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich zur Wahrung der Stabilität des Landes auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen.
2023-09-21 19:01:25 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-21 19:01:25 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu dem von ihnen in die europäischen Sozialversicherungssysteme gezahlten Geld haben.
2023-09-21 19:01:25 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-21 19:01:26 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-21 19:01:26 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-21 19:01:26 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf allen Computerplattformen läuft.
2023-09-21 19:01:26 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-21 19:01:27 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-21 19:01:27 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-21 19:01:28 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Vorstellungen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-21 19:01:28 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-21 19:01:28 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-21 19:01:28 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-21 19:01:29 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht kaufen oder verkaufen, es sei denn, sie verwenden die unten aufgeführten neutralen Auktionshäuser.
2023-09-21 19:01:29 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-21 19:01:29 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien sich darauf beschränken sollten, nur innerhalb der Grenzen Europas anzuwenden.
2023-09-21 19:01:29 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-21 19:01:30 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn die Entlastung der Kommission für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-21 19:01:30 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-21 19:01:31 | INFO | fairseq.tasks.translation | example hypothesis: Dem Vorschlag der Kommission zufolge wird der Rat formelle Standpunkte zu bestimmten Einzelheiten des Abkommens mit den Vereinigten Staaten im Prinzip vorlegen müssen.
2023-09-21 19:01:31 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-21 19:01:31 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unser breites Sortiment an Plastikbabyleartikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-21 19:01:31 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-21 19:01:32 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 19:01:32 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-21 19:01:32 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach deren Kenntnis über Sachsituationen zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-21 19:01:32 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-21 19:01:33 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die ihrer Ansicht nach eine stärkere Präsenz im Bereich der Außen- und Verteidigungspolitik und der Verteidigung braucht.
2023-09-21 19:01:33 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-21 19:01:34 | INFO | fairseq.tasks.translation | example hypothesis: Neben unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-21 19:01:34 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-21 19:01:35 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte anerkennen, die bei der Behandlung aller Fragen erzielt wurden, die derzeit diskutiert werden, und zwar in Bezug auf etwas, das knapp zwei Jahre alt ist, nämlich die neue transatlantische Agenda.
2023-09-21 19:01:35 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-21 19:01:35 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus gesenkten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-21 19:01:35 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-21 19:01:36 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal konnte der Berichterstatter die bisweilen unterschiedlichen Meinungen und Beiträge zusammenfassen und sie - ich würde sagen - in einem äußerst ausgewogenen Text zusammenfassen.
2023-09-21 19:01:36 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-21 19:01:37 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlagsgeräten mit einem trockenen ESP für den niedrigeren Leistungsbereich.
2023-09-21 19:01:37 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-21 19:01:37 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-21 19:01:37 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-21 19:01:38 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und Fernost abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-21 19:01:38 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-21 19:01:38 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und die sich auf unsere Völkergemeinschaft beziehen.
2023-09-21 19:01:38 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-21 19:01:39 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-21 19:01:39 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-21 19:01:40 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-21 19:01:40 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-21 19:01:40 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Anzahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-21 19:01:40 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-21 19:01:41 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine weitere: die Notsituation der Kinder, den schwächsten Teil der Bevölkerung, die ohne Familie, keinen Schutz und keinen Staat zurückgelassen wurden.
2023-09-21 19:01:41 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-21 19:01:42 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und betont werden, dass die Praxis der Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-21 19:01:42 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
lprobs.size(): torch.Size([3256, 42808])
2023-09-21 19:01:42 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht befreit, nicht erst verwirklicht ist, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, bis man sein wahres Selbst kennt.
2023-09-21 19:01:42 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-21 19:01:43 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Periode zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen.
2023-09-21 19:01:43 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-21 19:01:44 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern freie Meinungsäußerung, freie und unabhängige Wahlen und Vereinigungsfreiheit geben, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-21 19:01:44 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-21 19:01:45 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java-Programmiersprache mit J2EE-Techniken implementiert, die Plattform und Betriebssystem Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-21 19:01:45 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-21 19:01:45 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Sehr geehrte Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für eine Klarstellung des Anhangs.
2023-09-21 19:01:45 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-21 19:01:46 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass die von der IAO verhängten Sanktionen nicht als unvereinbar mit den WTO-Abkommen angesehen werden.
2023-09-21 19:01:46 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-21 19:01:47 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich habe ich an einer Aussprache über das irische öffentlich-rechtliche Radio RTÉ, mit einer Frau teilgenommen, die sehr besorgt war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-21 19:01:47 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-21 19:01:47 | INFO | fairseq.tasks.translation | example hypothesis: Vor diesem Hintergrund hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-21 19:01:47 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-21 19:01:48 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen zur europäischen Geschichte, Staatsbürgerschaft oder etwas so Spezielles wie die Verringerung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-21 19:01:48 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-21 19:01:49 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Jahreszeit der griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und steht Spielern aller Nationalitäten offen.
2023-09-21 19:01:49 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-21 19:01:49 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, abgesehen von diesen wenigen Vorbehalten, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-21 19:01:49 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-21 19:01:50 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, hieße, zu naturalisieren und zu mystifizieren, was eine bestimmte Art von Vertragsbeziehung zwischen Personen mit gemeinsamen Anliegen ist (unter ihnen oft die tatsächliche oder wahrgenommene Drohung, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-21 19:01:50 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-21 19:01:51 | INFO | fairseq.tasks.translation | example hypothesis: In der Rechtsprechung der Gemeinschaft zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-21 19:01:51 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-21 19:01:52 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Automobile für unter 50.000 Dollar und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos ausprobieren.
2023-09-21 19:01:52 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-21 19:01:52 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, und das gilt auch für den Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-21 19:01:52 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-21 19:01:53 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den ausgezeichneten Süßwasserfisch: gegrillter Hecht, Forelle mit Mandeln.
2023-09-21 19:01:53 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-21 19:01:54 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt daran zu erinnern, was eine politische Aktion bedeutet, eine Gesamtsicht zu geben, die es uns ermöglicht, näher auf die verschiedenen Fragen einzugehen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-21 19:01:54 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-21 19:01:55 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, stimmten der Veröffentlichung eines Live-Albums "Bodulska balada 2009" zu.
2023-09-21 19:01:55 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-21 19:01:55 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit aufgrund von makroökonomischen Strategien, Steuermaßnahmen und Zwängen, die nicht an die bestehende Situation vor Ort angepasst sind, schrittweise abgebaut wird.
2023-09-21 19:01:55 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-21 19:01:56 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text übernommen hat.
2023-09-21 19:01:56 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-21 19:01:57 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus, was die entsprechenden Konsequenzen für den Rechts- und Rechtsbereich hat, wodurch Norwegen und Island, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden, zu den Ländern gehören.
2023-09-21 19:01:57 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-21 19:01:58 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schwenkboot hinunter den Mississippi fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein.
2023-09-21 19:01:58 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-21 19:01:59 | INFO | fairseq.tasks.translation | example hypothesis: In der Praxis harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die bei solchen von Personen begangenen Verletzungen angewendet werden können.
2023-09-21 19:01:59 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-21 19:01:59 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falization und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner geleistet und eine Gruppe von Bergern gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das jedes Prinzip der Demokratie missachtet.
2023-09-21 19:01:59 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-21 19:02:00 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Menü- und Presseservice, ein Wechselstube, kostenfreie Schuhputzmaschine und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-21 19:02:00 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-21 19:02:01 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, Frau von König D. João II, und bekannt durch ihre Keramik international bekannt für ihre bildhaften und satirischen Werke ist es auch einen Besuch wert.
2023-09-21 19:02:01 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-21 19:02:02 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um einen Fall guter Pro-Westler auf der einen Seite und Verfechter des früheren Regimes auf der anderen handelt - das ist ebenfalls verwerflich, da die Rolle aller immer wieder bekannt ist.
2023-09-21 19:02:02 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-21 19:02:03 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer verkehren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-21 19:02:03 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-21 19:02:04 | INFO | fairseq.tasks.translation | example hypothesis: (4) Soweit Informationen außerhalb einer Aktionärsversammlung einem Aktionär aufgrund seines Status als Aktionär zur Verfügung gestellt wurden, sind diese auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung zu übermitteln, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-21 19:02:04 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-21 19:02:05 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme fließen, die in der Regel in die Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.
2023-09-21 19:02:05 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-21 19:02:05 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem Mitgliedstaat oder die NATO an diesem Kriegshandlungen beteiligt gewesen sein könnten -, bei Informationen zu helfen, die es keinen Grund mehr gibt, geheim, verschwiegen oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-21 19:02:05 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-21 19:02:06 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30-minütige Zugfahrt vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 19:02:06 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-21 19:02:07 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radargerät unter der Führung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die moderne Offset-Plattformen nie erreichen können.
2023-09-21 19:02:07 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-21 19:02:08 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen unmissverständlich klarstellen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte vom Markt zu nehmen, die eine ernste Gefahr darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, denn solche Produkte können leicht recycelt werden, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-21 19:02:08 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-21 19:02:09 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Plan der Moderne und Postmoderne oder dem klaren Widerstand reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und anhaltende Spannung jener beiden ästhetischen Politik anerkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die Kunst als solche für uns identifizierbar machen - jene beiden Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-21 19:02:09 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-21 19:02:10 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir gegeben haben, die das, was ich gerade gesagt habe, im Wesentlichen unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen werden wir unsere Debatten führen, und wenn es zur Abstimmung kommt, wenn die 40 Petenten nicht anwesend sind, werde ich nicht verlangen, dass die Beschlussfähigkeit überprüft wird. Wenn die 40 Petenten nicht anwesend sind, werde ich nicht beantragen, dass die Beschlussfähigkeit überprüft wird.
2023-09-21 19:02:10 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-21 19:02:11 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips niemals akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum jemand weiß, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, wenn auch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.
2023-09-21 19:02:11 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-21 19:02:12 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Weise als hybride Form veröffentlicht, die Rezensionen und Artikel des vierteljährlichen Magazins für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Websites der Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an ihre Abonnenten verteilt.
2023-09-21 19:02:12 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-21 19:02:13 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone ihre Federn erheblich verfeinert, von einstmals blutenden Taschenlampen über polyphonisch tootling Game Boy-Bestrebungen bis hin zu schlichten Mini-PCs mit knackigem CD-Qualität Stereo-Sound: Von nun an können sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-wannabes bis hin zu Trailblazers neuer technischer Entwicklungen absolvieren.
2023-09-21 19:02:13 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-21 19:02:15 | INFO | fairseq.tasks.translation | example hypothesis: En la pandora de Jake para que le proportionalmente información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen, en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se cuenta de que éstos jamás renunciarán a su tierra, hendo a su tierra, hendo a unausweichaciendo a un konflito; en un mado de deberá de deberado.
2023-09-21 19:02:15 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-21 19:02:16 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 4.198 | nll_loss 2.213 | ppl 4.64 | bleu 29.46 | wps 17193.3 | wpb 12011.9 | bsz 398.1 | num_updates 90579 | best_bleu 29.46
2023-09-21 19:02:16 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 90579 updates
2023-09-21 19:02:16 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint10.pt
2023-09-21 19:02:22 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint10.pt
2023-09-21 19:02:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint10.pt (epoch 10 @ 90579 updates, score 29.46) (writing took 15.733532177982852 seconds)
2023-09-21 19:02:32 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2023-09-21 19:02:32 | INFO | train | epoch 010 | loss 6.507 | nll_loss 3.257 | ppl 9.56 | wps 6437.3 | ups 0.5 | wpb 12977.1 | bsz 430.6 | num_updates 90579 | lr 0.000105072 | gnorm 0.851 | loss_scale 4 | train_wall 18151 | gb_free 14.2 | wall 116545
2023-09-21 19:02:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-21 19:02:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-21 19:02:32 | INFO | fairseq.trainer | begin training epoch 11
2023-09-21 19:02:32 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-21 19:03:10 | INFO | train_inner | epoch 011:     21 / 9060 loss=6.533, nll_loss=3.27, ppl=9.64, wps=4414.7, ups=0.34, wpb=12878.2, bsz=427.9, num_updates=90600, lr=0.00010506, gnorm=0.86, loss_scale=4, train_wall=206, gb_free=13.5, wall=116584
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 19:06:46 | INFO | train_inner | epoch 011:    121 / 9060 loss=6.529, nll_loss=3.22, ppl=9.32, wps=6024.5, ups=0.46, wpb=12966.4, bsz=427, num_updates=90700, lr=0.000105002, gnorm=0.898, loss_scale=4, train_wall=215, gb_free=16, wall=116799
ter_threshold: 0.390767
num_accepted / total 29 88
loss token level: tensor(9188.4395, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4792., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 19:10:17 | INFO | train_inner | epoch 011:    221 / 9060 loss=6.662, nll_loss=3.306, ppl=9.89, wps=6117.5, ups=0.47, wpb=12911.8, bsz=421.4, num_updates=90800, lr=0.000104944, gnorm=0.873, loss_scale=4, train_wall=211, gb_free=14.3, wall=117010
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 19:13:35 | INFO | train_inner | epoch 011:    321 / 9060 loss=6.549, nll_loss=3.244, ppl=9.47, wps=6577.9, ups=0.5, wpb=13052.9, bsz=410.3, num_updates=90900, lr=0.000104886, gnorm=0.894, loss_scale=4, train_wall=198, gb_free=14.9, wall=117209
2023-09-21 19:17:08 | INFO | train_inner | epoch 011:    421 / 9060 loss=6.626, nll_loss=3.264, ppl=9.6, wps=6172.5, ups=0.47, wpb=13108.2, bsz=456.7, num_updates=91000, lr=0.000104828, gnorm=0.862, loss_scale=4, train_wall=212, gb_free=14.4, wall=117421
pred_new.size(): torch.Size([1755, 42808])
2023-09-21 19:20:26 | INFO | train_inner | epoch 011:    521 / 9060 loss=6.516, nll_loss=3.232, ppl=9.4, wps=6546, ups=0.5, wpb=13002.9, bsz=426.3, num_updates=91100, lr=0.000104771, gnorm=0.835, loss_scale=4, train_wall=198, gb_free=14.5, wall=117620
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 19:23:51 | INFO | train_inner | epoch 011:    621 / 9060 loss=6.519, nll_loss=3.213, ppl=9.27, wps=6321.6, ups=0.49, wpb=12957.3, bsz=428.6, num_updates=91200, lr=0.000104713, gnorm=0.862, loss_scale=4, train_wall=205, gb_free=15.4, wall=117825
pred_new.size(): torch.Size([222, 42808])
ter_threshold: 0.39120499999999997
num_accepted / total 21 88
loss token level: tensor(8954.8125, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3290., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
2023-09-21 19:27:13 | INFO | train_inner | epoch 011:    721 / 9060 loss=6.583, nll_loss=3.273, ppl=9.67, wps=6400.5, ups=0.5, wpb=12925, bsz=421.5, num_updates=91300, lr=0.000104656, gnorm=0.858, loss_scale=4, train_wall=202, gb_free=15.1, wall=118027
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.391313
num_accepted / total 17 80
loss token level: tensor(8717.5977, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2510., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 19:30:40 | INFO | train_inner | epoch 011:    821 / 9060 loss=6.433, nll_loss=3.245, ppl=9.48, wps=6228.1, ups=0.48, wpb=12909.5, bsz=428.7, num_updates=91400, lr=0.000104599, gnorm=0.911, loss_scale=4, train_wall=207, gb_free=15.3, wall=118234
ter_threshold: 0.391455
num_accepted / total 82 192
loss token level: tensor(9661.8271, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9696., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 19:34:01 | INFO | train_inner | epoch 011:    921 / 9060 loss=6.543, nll_loss=3.233, ppl=9.4, wps=6534.9, ups=0.5, wpb=13090.5, bsz=415.5, num_updates=91500, lr=0.000104542, gnorm=0.878, loss_scale=4, train_wall=200, gb_free=14.5, wall=118434
2023-09-21 19:37:35 | INFO | train_inner | epoch 011:   1021 / 9060 loss=6.634, nll_loss=3.273, ppl=9.67, wps=6002.7, ups=0.47, wpb=12890.5, bsz=441.8, num_updates=91600, lr=0.000104485, gnorm=0.924, loss_scale=4, train_wall=214, gb_free=14.9, wall=118649
2023-09-21 19:37:58 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
lprobs.size(): torch.Size([3192, 42808])
2023-09-21 19:41:04 | INFO | train_inner | epoch 011:   1122 / 9060 loss=6.724, nll_loss=3.335, ppl=10.09, wps=6273.9, ups=0.48, wpb=13059.6, bsz=417, num_updates=91700, lr=0.000104428, gnorm=0.882, loss_scale=2, train_wall=208, gb_free=14.9, wall=118857
2023-09-21 19:44:30 | INFO | train_inner | epoch 011:   1222 / 9060 loss=6.633, nll_loss=3.28, ppl=9.71, wps=6317.9, ups=0.48, wpb=13030.3, bsz=456.7, num_updates=91800, lr=0.000104371, gnorm=0.855, loss_scale=2, train_wall=206, gb_free=14.9, wall=119063
ter_threshold: 0.391804
num_accepted / total 6 40
loss token level: tensor(9921.6191, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2424., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 19:47:34 | INFO | train_inner | epoch 011:   1322 / 9060 loss=6.456, nll_loss=3.203, ppl=9.21, wps=7034, ups=0.54, wpb=12921, bsz=422, num_updates=91900, lr=0.000104314, gnorm=0.849, loss_scale=2, train_wall=183, gb_free=14.8, wall=119247
2023-09-21 19:51:00 | INFO | train_inner | epoch 011:   1422 / 9060 loss=6.614, nll_loss=3.268, ppl=9.63, wps=6272.8, ups=0.48, wpb=12946.7, bsz=420.9, num_updates=92000, lr=0.000104257, gnorm=0.864, loss_scale=2, train_wall=206, gb_free=14.1, wall=119453
pred_new.size(): torch.Size([1104, 42808])
pred_new.size(): torch.Size([5518, 42808])
2023-09-21 19:54:34 | INFO | train_inner | epoch 011:   1522 / 9060 loss=6.735, nll_loss=3.332, ppl=10.07, wps=6099.2, ups=0.47, wpb=13029.9, bsz=465.2, num_updates=92100, lr=0.000104201, gnorm=0.881, loss_scale=2, train_wall=213, gb_free=14.3, wall=119667
2023-09-21 19:57:49 | INFO | train_inner | epoch 011:   1622 / 9060 loss=6.658, nll_loss=3.314, ppl=9.95, wps=6732.6, ups=0.51, wpb=13133.5, bsz=431.8, num_updates=92200, lr=0.000104144, gnorm=0.876, loss_scale=2, train_wall=195, gb_free=13.7, wall=119862
pred_new.size(): torch.Size([1416, 42808])
2023-09-21 20:01:16 | INFO | train_inner | epoch 011:   1722 / 9060 loss=6.478, nll_loss=3.21, ppl=9.25, wps=6282, ups=0.48, wpb=13023.7, bsz=439.3, num_updates=92300, lr=0.000104088, gnorm=0.845, loss_scale=2, train_wall=207, gb_free=14.6, wall=120069
2023-09-21 20:04:46 | INFO | train_inner | epoch 011:   1822 / 9060 loss=6.662, nll_loss=3.335, ppl=10.09, wps=6179.2, ups=0.48, wpb=12993.4, bsz=432.3, num_updates=92400, lr=0.000104031, gnorm=0.885, loss_scale=2, train_wall=210, gb_free=14.3, wall=120280
pred_new.size(): torch.Size([7670, 42808])
2023-09-21 20:08:10 | INFO | train_inner | epoch 011:   1922 / 9060 loss=6.594, nll_loss=3.281, ppl=9.72, wps=6384.8, ups=0.49, wpb=13028, bsz=436.8, num_updates=92500, lr=0.000103975, gnorm=0.877, loss_scale=2, train_wall=204, gb_free=13.4, wall=120484
2023-09-21 20:11:44 | INFO | train_inner | epoch 011:   2022 / 9060 loss=6.579, nll_loss=3.248, ppl=9.5, wps=6078.9, ups=0.47, wpb=12972, bsz=427.2, num_updates=92600, lr=0.000103919, gnorm=0.899, loss_scale=2, train_wall=213, gb_free=14.7, wall=120697
pred_new.size(): torch.Size([204, 42808])
2023-09-21 20:15:13 | INFO | train_inner | epoch 011:   2122 / 9060 loss=6.625, nll_loss=3.295, ppl=9.82, wps=6216.1, ups=0.48, wpb=13025.8, bsz=459.4, num_updates=92700, lr=0.000103863, gnorm=0.878, loss_scale=2, train_wall=209, gb_free=15.3, wall=120907
2023-09-21 20:18:44 | INFO | train_inner | epoch 011:   2222 / 9060 loss=6.753, nll_loss=3.342, ppl=10.14, wps=6135.2, ups=0.47, wpb=12932.4, bsz=442.1, num_updates=92800, lr=0.000103807, gnorm=0.902, loss_scale=2, train_wall=211, gb_free=15.3, wall=121117
ter_threshold: 0.392827
num_accepted / total 2 64
loss token level: tensor(13701.1855, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(698., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2992, 42808])
2023-09-21 20:22:09 | INFO | train_inner | epoch 011:   2322 / 9060 loss=6.601, nll_loss=3.253, ppl=9.53, wps=6324.2, ups=0.49, wpb=12972.5, bsz=444.3, num_updates=92900, lr=0.000103751, gnorm=0.858, loss_scale=2, train_wall=205, gb_free=14.7, wall=121323
2023-09-21 20:25:34 | INFO | train_inner | epoch 011:   2422 / 9060 loss=6.673, nll_loss=3.319, ppl=9.98, wps=6367.1, ups=0.49, wpb=13017.3, bsz=432.2, num_updates=93000, lr=0.000103695, gnorm=0.864, loss_scale=2, train_wall=204, gb_free=14.2, wall=121527
lprobs.size(): torch.Size([3136, 42808])
2023-09-21 20:28:57 | INFO | train_inner | epoch 011:   2522 / 9060 loss=6.551, nll_loss=3.274, ppl=9.68, wps=6395.1, ups=0.49, wpb=13006.3, bsz=445.7, num_updates=93100, lr=0.000103639, gnorm=0.878, loss_scale=2, train_wall=203, gb_free=13.7, wall=121730
pred_new.size(): torch.Size([3132, 42808])
2023-09-21 20:32:20 | INFO | train_inner | epoch 011:   2622 / 9060 loss=6.572, nll_loss=3.266, ppl=9.62, wps=6392.4, ups=0.49, wpb=13004.1, bsz=422.6, num_updates=93200, lr=0.000103584, gnorm=0.874, loss_scale=2, train_wall=203, gb_free=14.8, wall=121934
lprobs.size(): torch.Size([3520, 42808])
2023-09-21 20:35:55 | INFO | train_inner | epoch 011:   2722 / 9060 loss=6.626, nll_loss=3.293, ppl=9.8, wps=6026.8, ups=0.47, wpb=12934.3, bsz=420, num_updates=93300, lr=0.000103528, gnorm=0.9, loss_scale=2, train_wall=214, gb_free=14.8, wall=122148
pred_new.size(): torch.Size([4825, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([1720, 42808])
pred_new.size(): torch.Size([3160, 42808])
2023-09-21 20:39:25 | INFO | train_inner | epoch 011:   2822 / 9060 loss=6.68, nll_loss=3.299, ppl=9.84, wps=6187.6, ups=0.48, wpb=13005.2, bsz=428.7, num_updates=93400, lr=0.000103473, gnorm=0.869, loss_scale=2, train_wall=210, gb_free=15.4, wall=122359
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([5082, 42808])
pred_new.size(): torch.Size([282, 42808])
2023-09-21 20:43:00 | INFO | train_inner | epoch 011:   2922 / 9060 loss=6.733, nll_loss=3.332, ppl=10.07, wps=6015.3, ups=0.46, wpb=12938.2, bsz=425.8, num_updates=93500, lr=0.000103418, gnorm=0.924, loss_scale=2, train_wall=215, gb_free=14.7, wall=122574
lprobs.size(): torch.Size([3328, 42808])
2023-09-21 20:46:18 | INFO | train_inner | epoch 011:   3022 / 9060 loss=6.578, nll_loss=3.276, ppl=9.69, wps=6566.1, ups=0.5, wpb=13012.2, bsz=439.8, num_updates=93600, lr=0.000103362, gnorm=0.844, loss_scale=2, train_wall=198, gb_free=14.6, wall=122772
2023-09-21 20:49:48 | INFO | train_inner | epoch 011:   3122 / 9060 loss=6.628, nll_loss=3.323, ppl=10.01, wps=6163.1, ups=0.48, wpb=12900.4, bsz=416.2, num_updates=93700, lr=0.000103307, gnorm=0.876, loss_scale=2, train_wall=209, gb_free=13.8, wall=122981
2023-09-21 20:53:10 | INFO | train_inner | epoch 011:   3222 / 9060 loss=6.6, nll_loss=3.305, ppl=9.88, wps=6404.7, ups=0.49, wpb=12979.2, bsz=417.7, num_updates=93800, lr=0.000103252, gnorm=0.882, loss_scale=2, train_wall=202, gb_free=15, wall=123184
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([2320, 42808])
2023-09-21 20:56:38 | INFO | train_inner | epoch 011:   3322 / 9060 loss=6.649, nll_loss=3.293, ppl=9.8, wps=6258.2, ups=0.48, wpb=13004, bsz=419.8, num_updates=93900, lr=0.000103197, gnorm=0.887, loss_scale=2, train_wall=208, gb_free=14.1, wall=123392
2023-09-21 21:00:00 | INFO | train_inner | epoch 011:   3422 / 9060 loss=6.672, nll_loss=3.315, ppl=9.95, wps=6534.4, ups=0.5, wpb=13166.1, bsz=447.2, num_updates=94000, lr=0.000103142, gnorm=0.863, loss_scale=2, train_wall=201, gb_free=13.9, wall=123593
lprobs.size(): torch.Size([3384, 42808])
2023-09-21 21:03:18 | INFO | train_inner | epoch 011:   3522 / 9060 loss=6.475, nll_loss=3.231, ppl=9.39, wps=6511.5, ups=0.5, wpb=12939.4, bsz=412.6, num_updates=94100, lr=0.000103087, gnorm=0.86, loss_scale=2, train_wall=198, gb_free=14.8, wall=123792
ter_threshold: 0.39414
num_accepted / total 22 72
loss token level: tensor(9549.2227, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7920., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([711, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-21 21:06:53 | INFO | train_inner | epoch 011:   3622 / 9060 loss=6.511, nll_loss=3.242, ppl=9.46, wps=6001.8, ups=0.47, wpb=12880.9, bsz=418.8, num_updates=94200, lr=0.000103033, gnorm=0.884, loss_scale=2, train_wall=214, gb_free=13.9, wall=124007
2023-09-21 21:10:21 | INFO | train_inner | epoch 011:   3722 / 9060 loss=6.575, nll_loss=3.285, ppl=9.75, wps=6196.4, ups=0.48, wpb=12874.4, bsz=423.3, num_updates=94300, lr=0.000102978, gnorm=0.861, loss_scale=2, train_wall=208, gb_free=14.3, wall=124214
pred_new.size(): torch.Size([4860, 42808])
2023-09-21 21:13:41 | INFO | train_inner | epoch 011:   3822 / 9060 loss=6.599, nll_loss=3.278, ppl=9.7, wps=6527.8, ups=0.5, wpb=13050.1, bsz=433.8, num_updates=94400, lr=0.000102923, gnorm=0.859, loss_scale=2, train_wall=200, gb_free=15, wall=124414
pred_new.size(): torch.Size([3524, 42808])
2023-09-21 21:17:16 | INFO | train_inner | epoch 011:   3922 / 9060 loss=6.601, nll_loss=3.285, ppl=9.75, wps=6001.7, ups=0.47, wpb=12893.1, bsz=435.8, num_updates=94500, lr=0.000102869, gnorm=0.9, loss_scale=2, train_wall=215, gb_free=14.3, wall=124629
2023-09-21 21:20:39 | INFO | train_inner | epoch 011:   4022 / 9060 loss=6.56, nll_loss=3.261, ppl=9.59, wps=6416.4, ups=0.49, wpb=13058.9, bsz=417.8, num_updates=94600, lr=0.000102815, gnorm=0.879, loss_scale=2, train_wall=203, gb_free=14.3, wall=124833
2023-09-21 21:24:03 | INFO | train_inner | epoch 011:   4122 / 9060 loss=6.554, nll_loss=3.275, ppl=9.68, wps=6293.2, ups=0.49, wpb=12810.8, bsz=405.2, num_updates=94700, lr=0.00010276, gnorm=0.869, loss_scale=2, train_wall=203, gb_free=14, wall=125036
torch.Size([1845, 42808])
pred_new.size(): torch.Size([1462, 42808])
lprobs.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([720, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1584, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.385125
num_accepted / total 18 56
loss token level: tensor(8565.5586, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7888., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.385147
num_accepted / total 34 128
loss token level: tensor(9014.5186, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5816., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1980, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.385604
num_accepted / total 38 104
loss token level: tensor(9456.5811, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5240., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.385753
num_accepted / total 26 88
loss token level: tensor(9928.1816, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4472., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([702, 42808])
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2565, 42808])
lprobs.size(): torch.Size([2720, 42808])
ter_threshold: 0.386189
num_accepted / total 8 56
loss token level: tensor(10648.3086, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2248., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5029, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([2584, 42808])
ter_threshold: 0.38669699999999996
num_accepted / total 29 104
loss token level: tensor(10669.1895, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7152., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2340, 42808])
pred_new.size(): torch.Size([2938, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.38716
num_accepted / total 44 112
loss token level: tensor(8978.1719, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5912., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1296, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([5796, 42808])
ter_threshold: 0.387245
num_accepted / total 16 80
loss token level: tensor(9025.7012, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4940., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.38736899999999996
num_accepted / total 48 112
loss token level: tensor(9511.0488, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11392., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2576, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3564, 42808])
pred_new.size(): torch.Size([2149, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.38841499999999995
num_accepted / total 78 184
loss token level: tensor(10212.4619, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5696., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1664, 42808])
pred_new.size(): torch.Size([2730, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3296, 42808])
lprobs.size(): torch.Size([3128, 42808])
ter_threshold: 0.38858099999999995
num_accepted / total 23 88
loss token level: tensor(10424.6992, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6928., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.388621
num_accepted / total 161 296
loss token level: tensor(9920.1680, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9928., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1800, 42808])
pred_new.size(): torch.Size([2482, 42808])
pred_new.size(): torch.Size([1080, 42808])
pred_new.size(): torch.Size([3886, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.389281
num_accepted / total 8 56
loss token level: tensor(9548.3711, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3592., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2926, 42808])
pred_new.size(): torch.Size([3003, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([3588, 42808])
pred_new.size(): torch.Size([3364, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([684, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2728, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4860, 42808])
ter_threshold: 0.39120499999999997
num_accepted / total 39 104
loss token level: tensor(8578.8564, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5192., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.391455
num_accepted / total 37 104
loss token level: tensor(9674.0508, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8920., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.391689
num_accepted / total 28 88
loss token level: tensor(9366.2471, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4632., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1881, 42808])
pred_new.size(): torch.Size([2428, 42808])
ter_threshold: 0.39180899999999996
num_accepted / total 9 40
loss token level: tensor(9344.6074, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3136., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1650, 42808])
pred_new.size(): torch.Size([6480, 42808])
lprobs.size(): torch.Size([3444, 42808])
pred_new.size(): torch.Size([6713, 42808])
pred_new.size(): torch.Size([1480, 42808])
pred_new.size(): torch.Size([720, 42808])
pred_new.size(): torch.Size([1554, 42808])
pred_new.size(): torch.Size([1134, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([456, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([5456, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([3159, 42808])
pred_new.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2919, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([4104, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3392, 42808])
2023-09-21 21:27:29 | INFO | train_inner | epoch 011:   4222 / 9060 loss=6.608, nll_loss=3.294, ppl=9.81, wps=6279, ups=0.48, wpb=12965.4, bsz=433.4, num_updates=94800, lr=0.000102706, gnorm=0.863, loss_scale=2, train_wall=206, gb_free=15, wall=125243
2023-09-21 21:30:46 | INFO | train_inner | epoch 011:   4322 / 9060 loss=6.644, nll_loss=3.34, ppl=10.13, wps=6538.1, ups=0.51, wpb=12883.3, bsz=422.9, num_updates=94900, lr=0.000102652, gnorm=0.864, loss_scale=2, train_wall=197, gb_free=14, wall=125440
pred_new.size(): torch.Size([1680, 42808])
2023-09-21 21:34:15 | INFO | train_inner | epoch 011:   4422 / 9060 loss=6.603, nll_loss=3.275, ppl=9.68, wps=6266.1, ups=0.48, wpb=13063.8, bsz=415.9, num_updates=95000, lr=0.000102598, gnorm=0.899, loss_scale=2, train_wall=208, gb_free=13.9, wall=125648
pred_new.size(): torch.Size([1680, 42808])
2023-09-21 21:37:46 | INFO | train_inner | epoch 011:   4522 / 9060 loss=6.57, nll_loss=3.263, ppl=9.6, wps=6153.7, ups=0.47, wpb=13028.1, bsz=429.7, num_updates=95100, lr=0.000102544, gnorm=0.879, loss_scale=2, train_wall=211, gb_free=14.6, wall=125860
2023-09-21 21:41:13 | INFO | train_inner | epoch 011:   4622 / 9060 loss=6.56, nll_loss=3.29, ppl=9.78, wps=6264.6, ups=0.48, wpb=12970.4, bsz=424.9, num_updates=95200, lr=0.00010249, gnorm=0.865, loss_scale=2, train_wall=207, gb_free=14.9, wall=126067
lprobs.size(): torch.Size([3528, 42808])
2023-09-21 21:44:38 | INFO | train_inner | epoch 011:   4722 / 9060 loss=6.516, nll_loss=3.285, ppl=9.75, wps=6310.4, ups=0.49, wpb=12886, bsz=424.5, num_updates=95300, lr=0.000102436, gnorm=0.869, loss_scale=2, train_wall=204, gb_free=13.8, wall=126271
lprobs.size(): torch.Size([2912, 42808])
2023-09-21 21:47:58 | INFO | train_inner | epoch 011:   4822 / 9060 loss=6.592, nll_loss=3.325, ppl=10.02, wps=6428.5, ups=0.5, wpb=12894.1, bsz=422.6, num_updates=95400, lr=0.000102383, gnorm=0.868, loss_scale=2, train_wall=200, gb_free=15.9, wall=126472
lprobs.size(): torch.Size([3248, 42808])
2023-09-21 21:51:29 | INFO | train_inner | epoch 011:   4922 / 9060 loss=6.629, nll_loss=3.311, ppl=9.92, wps=6162.3, ups=0.47, wpb=12998.8, bsz=433.8, num_updates=95500, lr=0.000102329, gnorm=0.895, loss_scale=2, train_wall=211, gb_free=14.2, wall=126683
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([1722, 42808])
2023-09-21 21:55:01 | INFO | train_inner | epoch 011:   5022 / 9060 loss=6.547, nll_loss=3.277, ppl=9.69, wps=6090, ups=0.47, wpb=12870.9, bsz=415.6, num_updates=95600, lr=0.000102275, gnorm=0.889, loss_scale=2, train_wall=211, gb_free=13.6, wall=126894
2023-09-21 21:58:21 | INFO | train_inner | epoch 011:   5122 / 9060 loss=6.678, nll_loss=3.354, ppl=10.22, wps=6510.6, ups=0.5, wpb=13043.2, bsz=437.5, num_updates=95700, lr=0.000102222, gnorm=0.873, loss_scale=2, train_wall=200, gb_free=13.9, wall=127094
2023-09-21 22:01:51 | INFO | train_inner | epoch 011:   5222 / 9060 loss=6.659, nll_loss=3.338, ppl=10.11, wps=6189.1, ups=0.48, wpb=12979.6, bsz=429, num_updates=95800, lr=0.000102169, gnorm=0.913, loss_scale=4, train_wall=209, gb_free=13.5, wall=127304
torch.Size([3456, 42808])
ter_threshold: 0.385125
num_accepted / total 3 56
loss token level: tensor(12503.9600, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1524., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2340, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([2280, 42808])
pred_new.size(): torch.Size([6930, 42808])
ter_threshold: 0.385554
num_accepted / total 27 112
loss token level: tensor(10918.9619, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6552., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2989, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([4347, 42808])
pred_new.size(): torch.Size([1620, 42808])
pred_new.size(): torch.Size([2214, 42808])
lprobs.size(): torch.Size([2928, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6391, 42808])
pred_new.size(): torch.Size([2475, 42808])
ter_threshold: 0.386619
num_accepted / total 28 96
loss token level: tensor(8834.8799, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7584., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1128, 42808])
ter_threshold: 0.386787
num_accepted / total 10 64
loss token level: tensor(9124.2441, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3888., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([936, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([3255, 42808])
ter_threshold: 0.387245
num_accepted / total 95 192
loss token level: tensor(8480.2832, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10192., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.38736899999999996
num_accepted / total 21 136
loss token level: tensor(8392.3887, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2582., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2898, 42808])
pred_new.size(): torch.Size([792, 42808])
pred_new.size(): torch.Size([2472, 42808])
pred_new.size(): torch.Size([3870, 42808])
lprobs.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([5456, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2613, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([4104, 42808])
pred_new.size(): torch.Size([4050, 42808])
lprobs.size(): torch.Size([2960, 42808])
ter_threshold: 0.38858099999999995
num_accepted / total 65 152
loss token level: tensor(9195.6533, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10432., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3344, 42808])
ter_threshold: 0.388621
num_accepted / total 55 128
loss token level: tensor(9256.6680, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10944., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1932, 42808])
ter_threshold: 0.388761
num_accepted / total 52 176
loss token level: tensor(10035.5850, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4052., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([2666, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([1617, 42808])
pred_new.size(): torch.Size([3570, 42808])
lprobs.size(): torch.Size([2232, 42808])
ter_threshold: 0.39014099999999996
num_accepted / total 20 72
loss token level: tensor(9389.0283, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7064., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1855, 42808])
pred_new.size(): torch.Size([3633, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([2244, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.39120499999999997
num_accepted / total 44 104
loss token level: tensor(8977.8760, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6080., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2624, 42808])
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.391313
num_accepted / total 32 88
loss token level: tensor(9188.5098, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5280., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.391455
num_accepted / total 93 224
loss token level: tensor(10365.9395, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9232., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([1570, 42808])
pred_new.size(): torch.Size([4750, 42808])
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.391689
num_accepted / total 14 88
loss token level: tensor(11251.9922, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2434., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4719, 42808])
pred_new.size(): torch.Size([2088, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([920, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([2280, 42808])
pred_new.size(): torch.Size([3105, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4590, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3780, 42808])
pred_new.size(): torch.Size([1056, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3136, 42808])
ter_threshold: 0.394121
num_accepted / total 34 104
loss token level: tensor(8870.1426, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7988., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2408, 42808])
pred_new.size(): torch.Size([754, 42808])
pred_new.size(): torch.Size([740, 42808])
pred_new.size(): torch.Size([4293, 42808])
pred_new.size(): torch.Size([4284, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3216, 42808])
pred_new.size(): torch.Size([2132, 42808])
ter_threshold: 0.395122
num_accepted / total 42 112
loss token level: tensor(9035.6777, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5376., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1295, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2015, 42808])
ter_threshold: 0.39580099999999996
num_accepted / total 33 128
loss token level: lprobs.size(): torch.Size([2384, 42808])
2023-09-21 22:05:09 | INFO | train_inner | epoch 011:   5322 / 9060 loss=6.474, nll_loss=3.234, ppl=9.41, wps=6538.4, ups=0.5, wpb=13001.5, bsz=433.4, num_updates=95900, lr=0.000102115, gnorm=0.859, loss_scale=4, train_wall=199, gb_free=15.1, wall=127503
2023-09-21 22:08:42 | INFO | train_inner | epoch 011:   5422 / 9060 loss=6.68, nll_loss=3.335, ppl=10.09, wps=6099.5, ups=0.47, wpb=12948.2, bsz=437, num_updates=96000, lr=0.000102062, gnorm=0.89, loss_scale=4, train_wall=212, gb_free=13.9, wall=127715
ter_threshold: 0.396094
num_accepted / total 21 64
loss token level: tensor(9317.6260, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5344., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 22:12:08 | INFO | train_inner | epoch 011:   5522 / 9060 loss=6.61, nll_loss=3.314, ppl=9.94, wps=6297.9, ups=0.48, wpb=12997.9, bsz=430.2, num_updates=96100, lr=0.000102009, gnorm=0.872, loss_scale=4, train_wall=206, gb_free=14.7, wall=127922
lprobs.size(): torch.Size([2784, 42808])
2023-09-21 22:15:40 | INFO | train_inner | epoch 011:   5622 / 9060 loss=6.453, nll_loss=3.219, ppl=9.31, wps=6132.2, ups=0.47, wpb=12981.5, bsz=431.8, num_updates=96200, lr=0.000101956, gnorm=0.849, loss_scale=4, train_wall=211, gb_free=15.1, wall=128133
pred_new.size(): torch.Size([1974, 42808])
lprobs.size(): torch.Size([3344, 42808])
2023-09-21 22:19:15 | INFO | train_inner | epoch 011:   5722 / 9060 loss=6.602, nll_loss=3.278, ppl=9.7, wps=6024, ups=0.46, wpb=12969.3, bsz=429.4, num_updates=96300, lr=0.000101903, gnorm=0.875, loss_scale=4, train_wall=215, gb_free=14.3, wall=128349
ter_threshold: 0.396386
num_accepted / total 12 48
loss token level: tensor(10541.4160, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3724., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 22:22:45 | INFO | train_inner | epoch 011:   5822 / 9060 loss=6.559, nll_loss=3.297, ppl=9.83, wps=6197.9, ups=0.48, wpb=12997.2, bsz=447, num_updates=96400, lr=0.00010185, gnorm=0.866, loss_scale=4, train_wall=209, gb_free=14.1, wall=128558
pred_new.size(): torch.Size([2760, 42808])
lprobs.size(): torch.Size([2968, 42808])
2023-09-21 22:26:03 | INFO | train_inner | epoch 011:   5922 / 9060 loss=6.629, nll_loss=3.306, ppl=9.89, wps=6538.8, ups=0.5, wpb=12966.8, bsz=438.4, num_updates=96500, lr=0.000101797, gnorm=0.885, loss_scale=4, train_wall=198, gb_free=14.1, wall=128757
2023-09-21 22:29:30 | INFO | train_inner | epoch 011:   6022 / 9060 loss=6.577, nll_loss=3.335, ppl=10.09, wps=6190.4, ups=0.48, wpb=12787.1, bsz=423.4, num_updates=96600, lr=0.000101745, gnorm=0.915, loss_scale=4, train_wall=206, gb_free=13.8, wall=128963
ter_threshold: 0.396624
num_accepted / total 74 152
loss token level: tensor(9608.8594, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11024., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 22:32:46 | INFO | train_inner | epoch 011:   6122 / 9060 loss=6.677, nll_loss=3.357, ppl=10.25, wps=6615.6, ups=0.51, wpb=12967.7, bsz=443.6, num_updates=96700, lr=0.000101692, gnorm=0.887, loss_scale=4, train_wall=196, gb_free=14.7, wall=129159
2023-09-21 22:36:16 | INFO | train_inner | epoch 011:   6222 / 9060 loss=6.701, nll_loss=3.35, ppl=10.19, wps=6155.6, ups=0.48, wpb=12929.7, bsz=437.1, num_updates=96800, lr=0.000101639, gnorm=0.908, loss_scale=4, train_wall=210, gb_free=13.3, wall=129369
ter_threshold: 0.396806
num_accepted / total 2 48
loss token level: tensor(10852.0645, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(643., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4042, 42808])
pred_new.size(): torch.Size([3312, 42808])
2023-09-21 22:39:35 | INFO | train_inner | epoch 011:   6322 / 9060 loss=6.677, nll_loss=3.335, ppl=10.09, wps=6544.8, ups=0.5, wpb=13022.7, bsz=442.2, num_updates=96900, lr=0.000101587, gnorm=0.898, loss_scale=4, train_wall=199, gb_free=14.4, wall=129568
2023-09-21 22:42:58 | INFO | train_inner | epoch 011:   6422 / 9060 loss=6.613, nll_loss=3.293, ppl=9.8, wps=6394.7, ups=0.49, wpb=13029, bsz=454.1, num_updates=97000, lr=0.000101535, gnorm=0.887, loss_scale=4, train_wall=203, gb_free=14.1, wall=129772
pred_new.size(): torch.Size([4760, 42808])
pred_new.size(): torch.Size([2184, 42808])
2023-09-21 22:46:26 | INFO | train_inner | epoch 011:   6522 / 9060 loss=6.539, nll_loss=3.225, ppl=9.35, wps=6266, ups=0.48, wpb=13031.6, bsz=420.5, num_updates=97100, lr=0.000101482, gnorm=0.892, loss_scale=4, train_wall=208, gb_free=14.1, wall=129980
pred_new.size(): torch.Size([1620, 42808])
2023-09-21 22:50:07 | INFO | train_inner | epoch 011:   6622 / 9060 loss=6.703, nll_loss=3.34, ppl=10.13, wps=5899.7, ups=0.45, wpb=13033.9, bsz=434.2, num_updates=97200, lr=0.00010143, gnorm=0.894, loss_scale=4, train_wall=221, gb_free=14.4, wall=130201
lprobs.size(): torch.Size([3392, 42808])
2023-09-21 22:53:35 | INFO | train_inner | epoch 011:   6722 / 9060 loss=6.659, nll_loss=3.337, ppl=10.1, wps=6228.5, ups=0.48, wpb=12904.9, bsz=440.2, num_updates=97300, lr=0.000101378, gnorm=0.887, loss_scale=4, train_wall=207, gb_free=13.7, wall=130408
2023-09-21 22:57:06 | INFO | train_inner | epoch 011:   6822 / 9060 loss=6.602, nll_loss=3.285, ppl=9.75, wps=6121.8, ups=0.47, wpb=12970.9, bsz=429, num_updates=97400, lr=0.000101326, gnorm=0.872, loss_scale=4, train_wall=212, gb_free=14.1, wall=130620
lprobs.size(): torch.Size([2552, 42808])
pred_new.size(): torch.Size([2668, 42808])
2023-09-21 23:00:32 | INFO | train_inner | epoch 011:   6922 / 9060 loss=6.646, nll_loss=3.302, ppl=9.87, wps=6357.4, ups=0.49, wpb=13065.7, bsz=444.2, num_updates=97500, lr=0.000101274, gnorm=0.87, loss_scale=4, train_wall=205, gb_free=13.7, wall=130825
2023-09-21 23:04:01 | INFO | train_inner | epoch 011:   7022 / 9060 loss=6.603, nll_loss=3.276, ppl=9.69, wps=6173.4, ups=0.48, wpb=12926.2, bsz=424.3, num_updates=97600, lr=0.000101222, gnorm=0.869, loss_scale=4, train_wall=209, gb_free=15.2, wall=131035
lprobs.size(): torch.Size([3240, 42808])
2023-09-21 23:07:37 | INFO | train_inner | epoch 011:   7122 / 9060 loss=6.631, nll_loss=3.258, ppl=9.57, wps=6045.9, ups=0.46, wpb=13045.9, bsz=422.5, num_updates=97700, lr=0.00010117, gnorm=0.882, loss_scale=4, train_wall=216, gb_free=14.2, wall=131251
ter_threshold: 0.397737
num_accepted / total 0 48
loss token level: tensor(13907.9492, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: 0
2023-09-21 23:11:12 | INFO | train_inner | epoch 011:   7222 / 9060 loss=6.586, nll_loss=3.323, ppl=10.01, wps=6023.6, ups=0.47, wpb=12928.4, bsz=424, num_updates=97800, lr=0.000101118, gnorm=0.884, loss_scale=4, train_wall=214, gb_free=14.4, wall=131465
pred_new.size(): torch.Size([6500, 42808])
lprobs.size(): torch.Size([3136, 42808])
2023-09-21 23:14:41 | INFO | train_inner | epoch 011:   7322 / 9060 loss=6.625, nll_loss=3.304, ppl=9.87, wps=6224.4, ups=0.48, wpb=13003.9, bsz=422, num_updates=97900, lr=0.000101067, gnorm=0.884, loss_scale=4, train_wall=209, gb_free=14.4, wall=131674
pred_new.size(): torch.Size([3094, 42808])
2023-09-21 23:18:04 | INFO | train_inner | epoch 011:   7422 / 9060 loss=6.53, nll_loss=3.277, ppl=9.69, wps=6351, ups=0.49, wpb=12916.7, bsz=422.2, num_updates=98000, lr=0.000101015, gnorm=0.857, loss_scale=4, train_wall=203, gb_free=14.2, wall=131877
pred_new.size(): torch.Size([4225, 42808])
2023-09-21 23:21:25 | INFO | train_inner | epoch 011:   7522 / 9060 loss=6.548, nll_loss=3.307, ppl=9.9, wps=6460.9, ups=0.5, wpb=13002.7, bsz=420.3, num_updates=98100, lr=0.000100964, gnorm=0.873, loss_scale=4, train_wall=201, gb_free=14.2, wall=132079
pred_new.size(): torch.Size([3465, 42808])
2023-09-21 23:25:11 | INFO | train_inner | epoch 011:   7622 / 9060 loss=6.637, nll_loss=3.32, ppl=9.99, wps=5735.4, ups=0.44, wpb=12931.4, bsz=415.8, num_updates=98200, lr=0.000100912, gnorm=0.908, loss_scale=4, train_wall=225, gb_free=14.3, wall=132304
pred_new.size(): torch.Size([1472, 42808])
2023-09-21 23:28:39 | INFO | train_inner | epoch 011:   7722 / 9060 loss=6.594, nll_loss=3.307, ppl=9.9, wps=6211.2, ups=0.48, wpb=12912.5, bsz=422.5, num_updates=98300, lr=0.000100861, gnorm=0.866, loss_scale=4, train_wall=208, gb_free=14.3, wall=132512
ter_threshold: 0.398331
num_accepted / total 6 48
loss token level: tensor(10435.9287, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2914., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 23:31:54 | INFO | train_inner | epoch 011:   7822 / 9060 loss=6.619, nll_loss=3.315, ppl=9.95, wps=6667.3, ups=0.51, wpb=13019.9, bsz=431.5, num_updates=98400, lr=0.00010081, gnorm=0.897, loss_scale=4, train_wall=195, gb_free=13.8, wall=132707
pred_new.size(): torch.Size([4140, 42808])
2023-09-21 23:35:25 | INFO | train_inner | epoch 011:   7922 / 9060 loss=6.592, nll_loss=3.28, ppl=9.71, wps=6196.7, ups=0.47, wpb=13086.4, bsz=448.5, num_updates=98500, lr=0.000100759, gnorm=0.882, loss_scale=4, train_wall=211, gb_free=14.3, wall=132919
torch.Size([3456, 42808])
ter_threshold: 0.38716
num_accepted / total 62 128
loss token level: tensor(9264.4883, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6720., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2368, 42808])
pred_new.size(): torch.Size([5285, 42808])
pred_new.size(): torch.Size([3060, 42808])
pred_new.size(): torch.Size([1890, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([3320, 42808])
lprobs.size(): torch.Size([2480, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2888, 42808])
lprobs.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([312, 42808])
ter_threshold: 0.38841499999999995
num_accepted / total 95 168
loss token level: tensor(8975.0146, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7568., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([5767, 42808])
lprobs.size(): torch.Size([3280, 42808])
ter_threshold: 0.388621
num_accepted / total 61 136
loss token level: tensor(9125.2441, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10624., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([756, 42808])
pred_new.size(): torch.Size([6206, 42808])
pred_new.size(): torch.Size([4484, 42808])
pred_new.size(): torch.Size([4800, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([4042, 42808])
pred_new.size(): torch.Size([4370, 42808])
ter_threshold: 0.39014099999999996
num_accepted / total 16 72
loss token level: tensor(9658.5049, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6096., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([312, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.39075899999999997
num_accepted / total 16 72
loss token level: tensor(9521.9492, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3286., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.390767
num_accepted / total 45 128
loss token level: tensor(9178.5664, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5056., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3408, 42808])
pred_new.size(): torch.Size([2460, 42808])
pred_new.size(): torch.Size([988, 42808])
pred_new.size(): torch.Size([4599, 42808])
ter_threshold: 0.391313
num_accepted / total 71 144
loss token level: tensor(8297.2803, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6680., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3444, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([1947, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([9900, 42808])
pred_new.size(): torch.Size([1380, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([1680, 42808])
lprobs.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([1170, 42808])
pred_new.size(): torch.Size([3525, 42808])
pred_new.size(): torch.Size([3720, 42808])
ter_threshold: 0.393497
num_accepted / total 10 40
loss token level: tensor(10053.9521, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6944., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3150, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([3600, 42808])
ter_threshold: 0.394121
num_accepted / total 100 256
loss token level: tensor(7254.8784, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5160., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2583, 42808])
pred_new.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2856, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.39427199999999996
num_accepted / total 23 64
loss token level: tensor(8055.4717, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4736., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([216, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([3912, 42808])
pred_new.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([960, 42808])
pred_new.size(): torch.Size([3888, 42808])
pred_new.size(): torch.Size([756, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.395122
num_accepted / total 26 96
loss token level: tensor(10551.1641, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4064., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2646, 42808])
lprobs.size(): torch.Size([2224, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2432, 42808])
pred_new.size(): torch.Size([10725, 42808])
pred_new.size(): torch.Size([1584, 42808])
pred_new.size(): torch.Size([296, 42808])
lprobs.size(): torch.Size([3008, 42808])
pred_new.size(): torch.Size([4888, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.396386
num_accepted / total 14 56
loss token level: tensor(9987.9287, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3700., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([1722, 42808])
ter_threshold: 0.396624
num_accepted / total 25 112
loss token level: tensor(10950.2031, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4924., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([4340, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2862, 42808])
pred_new.size(): torch.Size([6480, 42808])
ter_threshold: 0.397189
num_accepted / total 16 64
loss token level: tensor(8479.7725, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3434., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([480, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.397509
num_accepted / total 93 192
loss token level: tensor(8468.0361, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5456., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2460, 42808])
pred_new.size(): torch.Size([9250, 42808])
pred_new.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([3150, 42808])
pred_new.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([2262, 42808])
ter_threshold: 0.398296
num_accepted / total 74 168
loss token level: tensor(9746.7969, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10904., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7399, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([5016, 42808])
pred_new.size(): torch.Size([3591, 42808])
pred_new.size(): torch.Size([3330, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5500, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([836, 42808])
ter_threshold: 0.398578
num_accepted / total 22 88
loss token level: tensor(8777.0547, device='cuda:2', grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4950, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3066, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.398578
num_accepted / total 3 88
loss token level: tensor(12940.1963, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(845., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1932, 42808])
2023-09-21 23:38:46 | INFO | train_inner | epoch 011:   8022 / 9060 loss=6.627, nll_loss=3.324, ppl=10.01, wps=6431.3, ups=0.5, wpb=12915.5, bsz=421.4, num_updates=98600, lr=0.000100707, gnorm=0.875, loss_scale=4, train_wall=201, gb_free=13.9, wall=133119
pred_new.size(): torch.Size([4560, 42808])
2023-09-21 23:42:16 | INFO | train_inner | epoch 011:   8122 / 9060 loss=6.537, nll_loss=3.255, ppl=9.55, wps=6211.7, ups=0.48, wpb=13023, bsz=421.8, num_updates=98700, lr=0.000100656, gnorm=0.881, loss_scale=4, train_wall=209, gb_free=12.7, wall=133329
ter_threshold: 0.398764
num_accepted / total 39 128
loss token level: tensor(9978.2295, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3932., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 23:45:42 | INFO | train_inner | epoch 011:   8222 / 9060 loss=6.586, nll_loss=3.29, ppl=9.78, wps=6316.7, ups=0.49, wpb=13008.4, bsz=425.4, num_updates=98800, lr=0.000100605, gnorm=0.877, loss_scale=4, train_wall=206, gb_free=14.6, wall=133535
lprobs.size(): torch.Size([3328, 42808])
2023-09-21 23:49:10 | INFO | train_inner | epoch 011:   8322 / 9060 loss=6.634, nll_loss=3.314, ppl=9.95, wps=6237, ups=0.48, wpb=13032.6, bsz=443.4, num_updates=98900, lr=0.000100555, gnorm=0.892, loss_scale=4, train_wall=209, gb_free=14.6, wall=133744
pred_new.size(): torch.Size([3700, 42808])
lprobs.size(): torch.Size([2496, 42808])
pred_new.size(): torch.Size([5300, 42808])
2023-09-21 23:52:43 | INFO | train_inner | epoch 011:   8422 / 9060 loss=6.639, nll_loss=3.3, ppl=9.85, wps=6079.2, ups=0.47, wpb=12917.6, bsz=433.4, num_updates=99000, lr=0.000100504, gnorm=0.908, loss_scale=4, train_wall=212, gb_free=14.8, wall=133956
pred_new.size(): torch.Size([3120, 42808])
2023-09-21 23:56:12 | INFO | train_inner | epoch 011:   8522 / 9060 loss=6.588, nll_loss=3.311, ppl=9.93, wps=6196.4, ups=0.48, wpb=12947.6, bsz=431.4, num_updates=99100, lr=0.000100453, gnorm=0.886, loss_scale=4, train_wall=209, gb_free=15.4, wall=134165
ter_threshold: 0.39919099999999996
num_accepted / total 7 56
loss token level: tensor(10524.0703, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2088., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-21 23:59:40 | INFO | train_inner | epoch 011:   8622 / 9060 loss=6.541, nll_loss=3.239, ppl=9.44, wps=6235.3, ups=0.48, wpb=12971, bsz=421.4, num_updates=99200, lr=0.000100402, gnorm=0.863, loss_scale=4, train_wall=208, gb_free=14.8, wall=134373
2023-09-22 00:03:12 | INFO | train_inner | epoch 011:   8722 / 9060 loss=6.599, nll_loss=3.264, ppl=9.61, wps=6136.1, ups=0.47, wpb=12993.9, bsz=457.2, num_updates=99300, lr=0.000100352, gnorm=0.897, loss_scale=4, train_wall=212, gb_free=14, wall=134585
2023-09-22 00:06:30 | INFO | train_inner | epoch 011:   8822 / 9060 loss=6.521, nll_loss=3.263, ppl=9.6, wps=6512.5, ups=0.5, wpb=12945.3, bsz=447.9, num_updates=99400, lr=0.000100301, gnorm=0.858, loss_scale=4, train_wall=199, gb_free=13.4, wall=134784
pred_new.size(): torch.Size([1798, 42808])
pred_new.size(): torch.Size([6860, 42808])
2023-09-22 00:09:50 | INFO | train_inner | epoch 011:   8922 / 9060 loss=6.596, nll_loss=3.297, ppl=9.83, wps=6517.8, ups=0.5, wpb=12999.6, bsz=420.8, num_updates=99500, lr=0.000100251, gnorm=0.906, loss_scale=4, train_wall=199, gb_free=14.3, wall=134983
pred_new.size(): torch.Size([5778, 42808])
pred_new.size(): torch.Size([5508, 42808])
2023-09-22 00:13:18 | INFO | train_inner | epoch 011:   9022 / 9060 loss=6.588, nll_loss=3.304, ppl=9.87, wps=6223.4, ups=0.48, wpb=12948.2, bsz=430.6, num_updates=99600, lr=0.000100201, gnorm=0.888, loss_scale=4, train_wall=208, gb_free=14.5, wall=135191
2023-09-22 00:14:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-22 00:14:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 00:14:48 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-22 00:14:48 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-22 00:14:49 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-22 00:14:49 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-22 00:14:49 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-22 00:14:49 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-22 00:14:50 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente vertraulich behandelt.
2023-09-22 00:14:50 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-22 00:14:50 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-22 00:14:50 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-22 00:14:51 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein regnerischer Erfolg.
2023-09-22 00:14:51 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-22 00:14:51 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Frohe Neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-22 00:14:51 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-22 00:14:52 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, was wir respektieren.
2023-09-22 00:14:52 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-22 00:14:52 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-22 00:14:52 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-22 00:14:53 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über einen digitalen Fernseher und Internetzugang, der sowohl für Geschäfts- als auch für Privatreisende geeignet ist.
2023-09-22 00:14:53 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-22 00:14:53 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-22 00:14:53 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-22 00:14:54 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 00:14:54 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 00:14:54 | INFO | fairseq.tasks.translation | example hypothesis: Generell wird in der gesamten EU riesige Menge Energie verschwendet.
2023-09-22 00:14:54 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-22 00:14:55 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-22 00:14:55 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-22 00:14:55 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Haltungsänderung auch in Kürze im Haushalt der Union niederschlagen.
2023-09-22 00:14:55 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-22 00:14:56 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für kleine Produzenten als auch für die Agrarindustrie ist inakzeptabel.
2023-09-22 00:14:56 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-22 00:14:57 | INFO | fairseq.tasks.translation | example hypothesis: Hier ist ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-22 00:14:57 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-22 00:14:57 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-22 00:14:57 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-22 00:14:58 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-22 00:14:58 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-22 00:14:58 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-22 00:14:58 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-22 00:14:59 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-22 00:14:59 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-22 00:14:59 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jede von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-22 00:14:59 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-22 00:15:00 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionale Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution erfolgen.
2023-09-22 00:15:00 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-22 00:15:00 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu machen.
2023-09-22 00:15:00 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-22 00:15:01 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-22 00:15:01 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-22 00:15:02 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-22 00:15:02 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-22 00:15:02 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze diese Aussprache auch, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-22 00:15:02 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-22 00:15:03 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in etwa einem (8 km) Radius von The Strip.
2023-09-22 00:15:03 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-22 00:15:04 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web-Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-22 00:15:04 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-22 00:15:04 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-22 00:15:04 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-22 00:15:05 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-22 00:15:05 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-22 00:15:05 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-22 00:15:05 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-22 00:15:06 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu dem von ihnen in die europäischen Sozialversicherungssysteme eingezahlten Geld haben.
2023-09-22 00:15:06 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-22 00:15:06 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-22 00:15:06 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-22 00:15:07 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf allen Computerplattformen läuft.
2023-09-22 00:15:07 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-22 00:15:08 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie Sie Ihnen helfen, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-22 00:15:08 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-22 00:15:08 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Vorstellungen von niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv Kernelemente seiner Agenda.
2023-09-22 00:15:08 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-22 00:15:09 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils neu emergen, damit es richtig funktioniert.
2023-09-22 00:15:09 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-22 00:15:09 | INFO | fairseq.tasks.translation | example hypothesis: Horde und Allianzspieler können Gegenstände nicht kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser benutzen.
2023-09-22 00:15:09 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-22 00:15:10 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-22 00:15:10 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-22 00:15:11 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt der Kommission auf der Grundlage eines Berichts von Herrn Wynn die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-22 00:15:11 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-22 00:15:11 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Einzelheiten des Abkommens im Prinzip mit den Vereinigten Staaten vorlegen müssen.
2023-09-22 00:15:11 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-22 00:15:12 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder spezielle Edition - unser breites Sortiment an Plastikbaby-Artikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-22 00:15:12 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-22 00:15:12 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... health tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 00:15:12 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 00:15:13 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis über Sachsituationen, die mit diesen AGB nicht vereinbar sind, zu informieren.
2023-09-22 00:15:13 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-22 00:15:14 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung für notwendig hält.
2023-09-22 00:15:14 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-22 00:15:14 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden mit Produktnachrichten und Informationen aus allen Kategorien in zwei Sprachen erstellt.
2023-09-22 00:15:14 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-22 00:15:15 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Prüfung aller Themen gemacht wurden, die jetzt diskutiert werden, um etwas zu erörtern, das kaum zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-22 00:15:15 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-22 00:15:15 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus gesenkten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-22 00:15:15 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-22 00:15:16 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es dem Berichterstatter gelungen, bisweilen unterschiedliche Meinungen und Beiträge zusammenzufassen und - wie ich sagen würde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 00:15:16 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 00:15:17 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlägen mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-22 00:15:17 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
lprobs.size(): torch.Size([3552, 42808])
2023-09-22 00:15:17 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-22 00:15:17 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-22 00:15:18 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und Fernost abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-22 00:15:18 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-22 00:15:19 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und beruht auf Verhandlungen mit Drittländern, von denen viele seit Jahren bestehen und sich auf unsere Völkergemeinschaft beziehen.
2023-09-22 00:15:19 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-22 00:15:19 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-22 00:15:19 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-22 00:15:20 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-22 00:15:20 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-22 00:15:20 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-22 00:15:20 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-22 00:15:21 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notlage gibt es jedoch noch einen weiteren: die Notlage der Kinder, des schwächsten BevölkerungsBevölkerung, die ohne Familie, keinen Schutz und keinen Staat.
2023-09-22 00:15:21 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-22 00:15:22 | INFO | fairseq.tasks.translation | example hypothesis: Zunächst sollte klargestellt und hervorgehoben werden, dass die Praxis der Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht ausschließlich für ihre Flossen gefangen werden können.
2023-09-22 00:15:22 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-22 00:15:22 | INFO | fairseq.tasks.translation | example hypothesis: Wenn sich das Selbst nicht befreit, erst innerhalb der ersten nicht verwirklicht wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-22 00:15:22 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-22 00:15:23 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in ihrer Macht Stehende unternimmt, um vor den Wahlen eine gewaltfreie Periode zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen.
2023-09-22 00:15:23 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-22 00:15:24 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern das Recht auf freie Meinungsäußerung, freie und unabhängige Wahlen und Vereinigungsfreiheit geben, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-22 00:15:24 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-22 00:15:24 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken implementiert, die Plattform und Betriebssystem Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-22 00:15:24 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-22 00:15:25 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für eine Präzisierung des Anhangs.
2023-09-22 00:15:25 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-22 00:15:26 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung von Kernarbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass die von der IAO verhängten Sanktionen nicht als unvereinbar mit den WTO-Abkommen betrachtet werden.
2023-09-22 00:15:26 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-22 00:15:26 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich nahm ich an einer Aussprache über das irische öffentlich-rechtliche Radio RTE mit einer Frau teil, die sehr besorgt war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-22 00:15:26 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-22 00:15:27 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer besonnenen Haltung gratulieren.
2023-09-22 00:15:27 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-22 00:15:28 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über europäische Geschichte, Bürgerschaft oder so etwas wie die Senkung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Studenten zugeschnitten ist.
2023-09-22 00:15:28 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-22 00:15:29 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen.
2023-09-22 00:15:29 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-22 00:15:29 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament dafür danken.
2023-09-22 00:15:29 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-22 00:15:30 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, bedeutet, zu naturalisieren und zu mystizieren, was eine spezifische Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Bedrohung, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-22 00:15:30 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-22 00:15:31 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-22 00:15:31 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-22 00:15:31 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Fahrzeuge unter 50.000 $und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-22 00:15:31 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-22 00:15:32 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für ihre realistische Darstellung der Angelegenheit.
2023-09-22 00:15:32 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-22 00:15:33 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den ausgezeichneten Süßwasserfisch: gegrillter Pike-perch, Forelle mit Mandeln.
2023-09-22 00:15:33 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-22 00:15:33 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was ein politisches Handeln bedeutet, einen Gesamtüberblick zu geben, der es uns ermöglicht, die verschiedenen Fragen zu vertiefen und zu prüfen, welche Impulse die Europäische Union mit Blick auf die Zukunft geben kann.
2023-09-22 00:15:33 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-22 00:15:34 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-22 00:15:34 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-22 00:15:35 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo es unmittelbare Gefahren für bestehende Arbeitsplätze gibt und die Wettbewerbsfähigkeit durch makroökonomische Politik, steuerliche Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-22 00:15:35 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-22 00:15:36 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament mit einem hervorragenden Beispiel für die Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-22 00:15:36 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-22 00:15:36 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus um die entsprechenden Konsequenzen für den Rechts- und Rechtsraum hinaus, wodurch Norwegen und Island Länder werden, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden.
2023-09-22 00:15:36 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-22 00:15:37 | INFO | fairseq.tasks.translation | example hypothesis: Wir gehen mit voller Geschwindigkeit mit einem Schalterboot hinunter den Mississippi, suchen nach dem großen versteckten Schatz, verlieben sich in den schönen Becky Thatcher, der rein dynamisch ist, und vor allem werden wir tolle Freunde sein.
2023-09-22 00:15:37 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-22 00:15:38 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion und die Strafbarkeit der Sanktionen, die im Falle solcher von Einzelpersonen begangenen Verletzungen angewendet werden können.
2023-09-22 00:15:38 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-22 00:15:39 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falization und Vincent Reynaud wurden in der Tat einfach dafür verurteilt, dass sie ihre Arbeit als Journalisten und Kameramänner verrichtet und eine Gruppe von Bergern gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wird, das jeden Grundsatz der Demokratie missachtet.
2023-09-22 00:15:39 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-22 00:15:40 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels gehören Concierge-Service, ein Friseur- und Schönheitssalon, Transport- und Sightseeingbar, Mengen- und Presseservice, Geldwechsel, kostenfreie Schuhputzmaschine und WLAN. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-22 00:15:40 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-22 00:15:40 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, die Frau von König D. João II., und bekannt durch ihre Keramik international bekannt für ihre figurativen und satirischen Werke, ist es auch einen Besuch wert.
2023-09-22 00:15:40 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-22 00:15:41 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um einen Fall guter Pro-Westler auf der einen Seite und Anhänger des ehemaligen Regimes auf der anderen handelt - das ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-22 00:15:41 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-22 00:15:42 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt sind, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-22 00:15:42 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-22 00:15:43 | INFO | fairseq.tasks.translation | example hypothesis: (4) Soweit Informationen außerhalb der Aktionärsversammlung einem Aktionär aufgrund seines Status als Aktionär zur Verfügung gestellt wurden, werden diese Informationen auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung weitergeleitet, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-22 00:15:43 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-22 00:15:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr elendes Leben führen.
2023-09-22 00:15:44 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-22 00:15:45 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem Mitgliedstaat oder die NATO in diesen Kriegsakt verwickelt gewesen sein könnten -, mit Informationen zu helfen, die es keinen Grund mehr gibt, geheim, versteckt oder geheim zu halten, damit wir die Fakten ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-22 00:15:45 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-22 00:15:45 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 00:15:45 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 00:15:46 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Führung von Thales in Frankreich sowie unserer Business Unit Defence Electronics und Indra in Spanien wird der Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die moderne Off-the-Regf-Plattformen nie erreichen können.
2023-09-22 00:15:46 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-22 00:15:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar machen, dass wir auch die Produkte, die ein ernstes Risiko darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-22 00:15:47 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-22 00:15:48 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Komplott von Modernität und Postmoderne oder dem klaren Widerstand von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung dieser beiden ästhetischen Politik anerkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die Kunst als solche für uns identifizierbar machen - jene beiden Politik, die schließlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-22 00:15:48 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-22 00:15:49 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werden wir angesichts der Bedeutung der Aussprachen und angesichts der Stellungnahmen, die Sie mir gegeben haben, die eindeutig weitgehend dem unterstützen, was ich gerade gesagt habe, und auf der Grundlage der vorangegangenen Beschlüsse unsere Debatten führen, und wenn es zur Abstimmung kommt, werde ich nicht beantragen, dass die Quorum überprüft wird, wenn die vierzig Petenten nicht anwesend sind.
2023-09-22 00:15:49 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-22 00:15:50 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips niemals akzeptiert haben, sind es paradoxerweise genau sie, die, kaum niemandem bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem nationale Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.
2023-09-22 00:15:50 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-22 00:15:51 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Weise als Hybridform veröffentlicht, die Rezensionen und Artikel der Quartalszeitschrift sind für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Webseiten des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt.
2023-09-22 00:15:51 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-22 00:15:52 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Einführung der neuen Smartphone-Generation haben Mobiltelefone ihre Federn erheblich verfeinert, von einstmals blutenden Taschenformat-Alarmuhren über polyphonisch tootling Game Boy-Ambitionen zu schlichten Mini-PCs mit scharfen CD-Qualität Stereo-Sound: Von nun an können sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazers neuer technologischer Entwicklungen entwickeln.
2023-09-22 00:15:52 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-22 00:15:54 | INFO | fairseq.tasks.translation | example hypothesis: En un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se cuenta de que éstos jamás renunciarán a su tierra, hendo un unausweichlich mado; en dedir de dedir.
2023-09-22 00:15:54 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-22 00:15:55 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 4.194 | nll_loss 2.221 | ppl 4.66 | bleu 29.44 | wps 17727.9 | wpb 12011.9 | bsz 398.1 | num_updates 99638 | best_bleu 29.46
2023-09-22 00:15:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 99638 updates
2023-09-22 00:15:55 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint11.pt
2023-09-22 00:16:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint11.pt
2023-09-22 00:16:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint11.pt (epoch 11 @ 99638 updates, score 29.44) (writing took 11.086094697995577 seconds)
2023-09-22 00:16:06 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2023-09-22 00:16:06 | INFO | train | epoch 011 | loss 6.599 | nll_loss 3.288 | ppl 9.77 | wps 6248.6 | ups 0.48 | wpb 12977.2 | bsz 430.6 | num_updates 99638 | lr 0.000100181 | gnorm 0.879 | loss_scale 4 | train_wall 18712 | gb_free 14.8 | wall 135359
2023-09-22 00:16:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 00:16:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-22 00:16:06 | INFO | fairseq.trainer | begin training epoch 12
2023-09-22 00:16:06 | INFO | fairseq_cli.train | Start iterating over samples
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-22 00:18:17 | INFO | train_inner | epoch 012:     62 / 9060 loss=6.608, nll_loss=3.249, ppl=9.51, wps=4334, ups=0.33, wpb=12938.4, bsz=428.8, num_updates=99700, lr=0.00010015, gnorm=0.893, loss_scale=4, train_wall=220, gb_free=14.1, wall=135490
2023-09-22 00:21:57 | INFO | train_inner | epoch 012:    162 / 9060 loss=6.609, nll_loss=3.276, ppl=9.68, wps=5863.2, ups=0.45, wpb=12942, bsz=419.2, num_updates=99800, lr=0.0001001, gnorm=0.873, loss_scale=4, train_wall=220, gb_free=14.1, wall=135711
pred_new.size(): torch.Size([164, 42808])
ter_threshold: 0.39987799999999996
num_accepted / total 19 88
loss token level: tensor(9910.7041, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3324., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 00:25:29 | INFO | train_inner | epoch 012:    262 / 9060 loss=6.676, nll_loss=3.277, ppl=9.69, wps=6140.5, ups=0.47, wpb=13031.5, bsz=438.9, num_updates=99900, lr=0.00010005, gnorm=0.861, loss_scale=8, train_wall=212, gb_free=15.4, wall=135923
lprobs.size(): torch.Size([2856, 42808])
lprobs.size(): torch.Size([3328, 42808])
2023-09-22 00:28:56 | INFO | train_inner | epoch 012:    362 / 9060 loss=6.642, nll_loss=3.263, ppl=9.6, wps=6313.7, ups=0.48, wpb=13058.8, bsz=435.8, num_updates=100000, lr=0.0001, gnorm=0.89, loss_scale=8, train_wall=207, gb_free=13.4, wall=136130
2023-09-22 00:32:33 | INFO | train_inner | epoch 012:    462 / 9060 loss=6.591, nll_loss=3.279, ppl=9.7, wps=5960.9, ups=0.46, wpb=12904.4, bsz=420.2, num_updates=100100, lr=9.995e-05, gnorm=0.885, loss_scale=8, train_wall=216, gb_free=13.7, wall=136346
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([1593, 42808])
2023-09-22 00:36:00 | INFO | train_inner | epoch 012:    562 / 9060 loss=6.676, nll_loss=3.316, ppl=9.96, wps=6281.9, ups=0.48, wpb=13031, bsz=431.8, num_updates=100200, lr=9.99001e-05, gnorm=0.891, loss_scale=8, train_wall=207, gb_free=13.8, wall=136554
ter_threshold: 0.400209
num_accepted / total 57 160
loss token level: tensor(8581.4375, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4680., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 00:39:32 | INFO | train_inner | epoch 012:    662 / 9060 loss=6.689, nll_loss=3.33, ppl=10.06, wps=6114.6, ups=0.47, wpb=12930.8, bsz=414.3, num_updates=100300, lr=9.98503e-05, gnorm=0.914, loss_scale=8, train_wall=211, gb_free=14.2, wall=136765
2023-09-22 00:43:17 | INFO | train_inner | epoch 012:    762 / 9060 loss=6.726, nll_loss=3.327, ppl=10.04, wps=5757.9, ups=0.44, wpb=12946, bsz=412.6, num_updates=100400, lr=9.98006e-05, gnorm=0.896, loss_scale=8, train_wall=225, gb_free=14.3, wall=136990
2023-09-22 00:46:51 | INFO | train_inner | epoch 012:    862 / 9060 loss=6.719, nll_loss=3.299, ppl=9.84, wps=6001.1, ups=0.47, wpb=12897.7, bsz=431.2, num_updates=100500, lr=9.97509e-05, gnorm=0.918, loss_scale=8, train_wall=215, gb_free=15.1, wall=137205
2023-09-22 00:50:24 | INFO | train_inner | epoch 012:    962 / 9060 loss=6.667, nll_loss=3.269, ppl=9.64, wps=6167.4, ups=0.47, wpb=13091, bsz=444.6, num_updates=100600, lr=9.97013e-05, gnorm=0.863, loss_scale=8, train_wall=212, gb_free=13.8, wall=137417
2023-09-22 00:53:52 | INFO | train_inner | epoch 012:   1062 / 9060 loss=6.716, nll_loss=3.304, ppl=9.88, wps=6252.1, ups=0.48, wpb=12992.8, bsz=449, num_updates=100700, lr=9.96518e-05, gnorm=0.905, loss_scale=8, train_wall=208, gb_free=14.4, wall=137625
ter_threshold: 0.400701
num_accepted / total 83 168
loss token level: tensor(8885.9316, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6136., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 00:57:17 | INFO | train_inner | epoch 012:   1162 / 9060 loss=6.656, nll_loss=3.305, ppl=9.89, wps=6327.3, ups=0.49, wpb=12995.5, bsz=430.3, num_updates=100800, lr=9.96024e-05, gnorm=0.878, loss_scale=8, train_wall=205, gb_free=13.6, wall=137830
pred_new.size(): torch.Size([3850, 42808])
2023-09-22 01:00:45 | INFO | train_inner | epoch 012:   1262 / 9060 loss=6.691, nll_loss=3.298, ppl=9.84, wps=6245.5, ups=0.48, wpb=13003.9, bsz=435.2, num_updates=100900, lr=9.9553e-05, gnorm=0.881, loss_scale=8, train_wall=208, gb_free=15.5, wall=138039
lprobs.size(): torch.Size([2688, 42808])
2023-09-22 01:04:17 | INFO | train_inner | epoch 012:   1362 / 9060 loss=6.691, nll_loss=3.341, ppl=10.13, wps=6146.7, ups=0.47, wpb=13000.5, bsz=429.1, num_updates=101000, lr=9.95037e-05, gnorm=0.895, loss_scale=8, train_wall=211, gb_free=14.9, wall=138250
lprobs.size(): torch.Size([3240, 42808])
2023-09-22 01:07:51 | INFO | train_inner | epoch 012:   1462 / 9060 loss=6.719, nll_loss=3.306, ppl=9.89, wps=6052.9, ups=0.47, wpb=12965, bsz=459, num_updates=101100, lr=9.94545e-05, gnorm=0.916, loss_scale=8, train_wall=214, gb_free=14.7, wall=138464
2023-09-22 01:11:36 | INFO | train_inner | epoch 012:   1562 / 9060 loss=6.665, nll_loss=3.285, ppl=9.75, wps=5713.2, ups=0.44, wpb=12870.3, bsz=408.1, num_updates=101200, lr=9.94053e-05, gnorm=0.904, loss_scale=8, train_wall=225, gb_free=14.2, wall=138690
lprobs.size(): torch.Size([2496, 42808])
2023-09-22 01:15:03 | INFO | train_inner | epoch 012:   1662 / 9060 loss=6.569, nll_loss=3.275, ppl=9.68, wps=6299.6, ups=0.48, wpb=13054.1, bsz=399.8, num_updates=101300, lr=9.93563e-05, gnorm=0.861, loss_scale=8, train_wall=207, gb_free=14.5, wall=138897
lprobs.size(): torch.Size([2392, 42808])
pred_new.size(): torch.Size([2146, 42808])
pred_new.size(): torch.Size([2232, 42808])
2023-09-22 01:18:36 | INFO | train_inner | epoch 012:   1762 / 9060 loss=6.743, nll_loss=3.321, ppl=9.99, wps=6081.5, ups=0.47, wpb=12944.4, bsz=445.3, num_updates=101400, lr=9.93073e-05, gnorm=0.912, loss_scale=8, train_wall=213, gb_free=15.3, wall=139110
ter_threshold: 0.401421
num_accepted / total 57 176
loss token level: tensor(10933.6416, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4424., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 01:22:08 | INFO | train_inner | epoch 012:   1862 / 9060 loss=6.789, nll_loss=3.374, ppl=10.37, wps=6180, ups=0.47, wpb=13104.2, bsz=439.2, num_updates=101500, lr=9.92583e-05, gnorm=0.896, loss_scale=8, train_wall=212, gb_free=13.8, wall=139322
ter_threshold: 0.401533
num_accepted / total 47 128
loss token level: tensor(9591.3916, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5272., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 01:25:35 | INFO | train_inner | epoch 012:   1962 / 9060 loss=6.682, nll_loss=3.312, ppl=9.93, wps=6242.2, ups=0.48, wpb=12903.2, bsz=432.9, num_updates=101600, lr=9.92095e-05, gnorm=0.913, loss_scale=8, train_wall=206, gb_free=14.2, wall=139528
lprobs.size(): torch.Size([2480, 42808])
pred_new.size(): torch.Size([4032, 42808])
2023-09-22 01:29:06 | INFO | train_inner | epoch 012:   2062 / 9060 loss=6.681, nll_loss=3.352, ppl=10.21, wps=6143.4, ups=0.47, wpb=12960.2, bsz=428.2, num_updates=101700, lr=9.91607e-05, gnorm=0.877, loss_scale=8, train_wall=211, gb_free=14.5, wall=139739
pred_new.size(): torch.Size([1485, 42808])
2023-09-22 01:32:46 | INFO | train_inner | epoch 012:   2162 / 9060 loss=6.601, nll_loss=3.317, ppl=9.97, wps=5843.7, ups=0.45, wpb=12867.3, bsz=410.7, num_updates=101800, lr=9.9112e-05, gnorm=0.881, loss_scale=8, train_wall=220, gb_free=14.7, wall=139960
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 01:36:14 | INFO | train_inner | epoch 012:   2262 / 9060 loss=6.599, nll_loss=3.265, ppl=9.61, wps=6193.2, ups=0.48, wpb=12903.8, bsz=433.2, num_updates=101900, lr=9.90633e-05, gnorm=0.883, loss_scale=8, train_wall=208, gb_free=15.5, wall=140168
ter_threshold: 0.401984
num_accepted / total 33 96
loss token level: tensor(9071.8701, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4816., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 01:39:59 | INFO | train_inner | epoch 012:   2362 / 9060 loss=6.705, nll_loss=3.317, ppl=9.96, wps=5771.1, ups=0.44, wpb=12981.1, bsz=407.4, num_updates=102000, lr=9.90148e-05, gnorm=0.913, loss_scale=8, train_wall=225, gb_free=14.4, wall=140393
pred_new.size(): torch.Size([6510, 42808])
2023-09-22 01:43:38 | INFO | train_inner | epoch 012:   2462 / 9060 loss=6.816, nll_loss=3.368, ppl=10.32, wps=5958.7, ups=0.46, wpb=13016, bsz=416.2, num_updates=102100, lr=9.89663e-05, gnorm=0.915, loss_scale=8, train_wall=218, gb_free=15.4, wall=140611
2023-09-22 01:47:11 | INFO | train_inner | epoch 012:   2562 / 9060 loss=6.636, nll_loss=3.3, ppl=9.85, wps=6130.8, ups=0.47, wpb=13061.8, bsz=422.1, num_updates=102200, lr=9.89178e-05, gnorm=0.882, loss_scale=8, train_wall=213, gb_free=13.9, wall=140824
2023-09-22 01:50:56 | INFO | train_inner | epoch 012:   2662 / 9060 loss=6.751, nll_loss=3.343, ppl=10.15, wps=5743.6, ups=0.44, wpb=12934.3, bsz=448.3, num_updates=102300, lr=9.88695e-05, gnorm=0.927, loss_scale=8, train_wall=225, gb_free=14.5, wall=141050
2023-09-22 01:54:25 | INFO | train_inner | epoch 012:   2762 / 9060 loss=6.621, nll_loss=3.309, ppl=9.91, wps=6176.8, ups=0.48, wpb=12882.3, bsz=412, num_updates=102400, lr=9.88212e-05, gnorm=0.892, loss_scale=8, train_wall=208, gb_free=14.1, wall=141258
lprobs.size(): torch.Size([3264, 42808])
2023-09-22 01:58:03 | INFO | train_inner | epoch 012:   2862 / 9060 loss=6.789, nll_loss=3.353, ppl=10.22, wps=5962.5, ups=0.46, wpb=13040.3, bsz=436.5, num_updates=102500, lr=9.8773e-05, gnorm=0.94, loss_scale=8, train_wall=218, gb_free=14.1, wall=141477
ter_threshold: 0.40255399999999997
num_accepted / total 16 72
loss token level: tensor(8549.4785, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2720., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
2023-09-22 02:01:39 | INFO | train_inner | epoch 012:   2962 / 9060 loss=6.751, nll_loss=3.34, ppl=10.12, wps=6055.6, ups=0.46, wpb=13054.9, bsz=438.9, num_updates=102600, lr=9.87248e-05, gnorm=0.908, loss_scale=8, train_wall=215, gb_free=14.5, wall=141692
lprobs.size(): torch.Size([3432, 42808])
2023-09-22 02:05:10 | INFO | train_inner | epoch 012:   3062 / 9060 loss=6.616, nll_loss=3.256, ppl=9.56, wps=6194.9, ups=0.47, wpb=13105.5, bsz=442.2, num_updates=102700, lr=9.86767e-05, gnorm=0.864, loss_scale=8, train_wall=211, gb_free=14.5, wall=141904
ter_threshold: 0.40271999999999997
num_accepted / total 12 64
loss token level: tensor(8785.8750, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2542., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4002, 42808])
2023-09-22 02:08:45 | INFO | train_inner | epoch 012:   3162 / 9060 loss=6.772, nll_loss=3.336, ppl=10.1, wps=5998.7, ups=0.47, wpb=12867.9, bsz=437, num_updates=102800, lr=9.86287e-05, gnorm=0.921, loss_scale=8, train_wall=214, gb_free=14, wall=142118
pred_new.size(): torch.Size([1196, 42808])
2023-09-22 02:12:12 | INFO | train_inner | epoch 012:   3262 / 9060 loss=6.685, nll_loss=3.354, ppl=10.22, wps=6265, ups=0.48, wpb=12957, bsz=430.9, num_updates=102900, lr=9.85808e-05, gnorm=0.902, loss_scale=8, train_wall=207, gb_free=14.3, wall=142325
ter_threshold: 0.402962
num_accepted / total 129 232
loss token level: tensor(8180.2598, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9552., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1296, 42808])
2023-09-22 02:15:45 | INFO | train_inner | epoch 012:   3362 / 9060 loss=6.688, nll_loss=3.29, ppl=9.78, wps=6078.6, ups=0.47, wpb=12973.6, bsz=466.5, num_updates=103000, lr=9.85329e-05, gnorm=0.903, loss_scale=8, train_wall=213, gb_free=14.6, wall=142539
pred_new.size(): torch.Size([7056, 42808])
2023-09-22 02:19:24 | INFO | train_inner | epoch 012:   3462 / 9060 loss=6.607, nll_loss=3.251, ppl=9.52, wps=5972.6, ups=0.46, wpb=13050.3, bsz=451, num_updates=103100, lr=9.84851e-05, gnorm=0.861, loss_scale=8, train_wall=218, gb_free=15.1, wall=142757
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4560, 42808])
lprobs.size(): torch.Size([2744, 42808])
2023-09-22 02:23:11 | INFO | train_inner | epoch 012:   3562 / 9060 loss=6.767, nll_loss=3.359, ppl=10.26, wps=5726.5, ups=0.44, wpb=12996.5, bsz=438.9, num_updates=103200, lr=9.84374e-05, gnorm=0.9, loss_scale=8, train_wall=227, gb_free=14.1, wall=142984
ter_threshold: 0.40322
num_accepted / total 27 96
loss token level: tensor(9731.1113, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7324., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.40327599999999997
num_accepted / total 8 72
loss token level: tensor(8335.2168, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2128., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 02:26:38 | INFO | train_inner | epoch 012:   3662 / 9060 loss=6.629, nll_loss=3.291, ppl=9.79, wps=6258.3, ups=0.48, wpb=12961.1, bsz=427.4, num_updates=103300, lr=9.83897e-05, gnorm=0.879, loss_scale=8, train_wall=207, gb_free=14.1, wall=143191
2023-09-22 02:30:23 | INFO | train_inner | epoch 012:   3762 / 9060 loss=6.788, nll_loss=3.369, ppl=10.33, wps=5757.3, ups=0.44, wpb=12990.5, bsz=440.2, num_updates=103400, lr=9.83422e-05, gnorm=0.915, loss_scale=8, train_wall=225, gb_free=14.1, wall=143417
2023-09-22 02:34:02 | INFO | train_inner | epoch 012:   3862 / 9060 loss=6.688, nll_loss=3.315, ppl=9.95, wps=5954.1, ups=0.46, wpb=13028.2, bsz=425, num_updates=103500, lr=9.82946e-05, gnorm=0.89, loss_scale=8, train_wall=219, gb_free=14.6, wall=143636
pred_new.size(): torch.Size([333, 42808])
ter_threshold: 0.40358
num_accepted / total 12 56
loss token level: tensor(9547.6133, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3524., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 02:37:44 | INFO | train_inner | epoch 012:   3962 / 9060 loss=6.648, nll_loss=3.277, ppl=9.69, wps=5864.2, ups=0.45, wpb=12981.6, bsz=434.6, num_updates=103600, lr=9.82472e-05, gnorm=0.882, loss_scale=8, train_wall=221, gb_free=14.6, wall=143857
2023-09-22 02:41:06 | INFO | train_inner | epoch 012:   4062 / 9060 loss=6.513, nll_loss=3.276, ppl=9.68, wps=6430.9, ups=0.49, wpb=13012.1, bsz=419.5, num_updates=103700, lr=9.81998e-05, gnorm=0.854, loss_scale=8, train_wall=202, gb_free=14.9, wall=144059
ter_threshold: 0.403738
num_accepted / total 42 128
loss token level: tensor(10107.1865, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7304., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 02:44:50 | INFO | train_inner | epoch 012:   4162 / 9060 loss=6.67, nll_loss=3.35, ppl=10.2, wps=5777.9, ups=0.45, wpb=12925.2, bsz=427, num_updates=103800, lr=9.81525e-05, gnorm=0.881, loss_scale=8, train_wall=223, gb_free=15.4, wall=144283
tensor(10793.7510, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6224., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.396152
num_accepted / total 3 32
loss token level: tensor(9762.7715, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2890., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([6345, 42808])
ter_threshold: 0.396624
num_accepted / total 148 272
loss token level: tensor(9458.8320, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10544., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1560, 42808])
ter_threshold: 0.397125
num_accepted / total 32 160
loss token level: tensor(11951.8730, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4664., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4592, 42808])
lprobs.size(): torch.Size([3024, 42808])
ter_threshold: 0.397417
num_accepted / total 44 112
loss token level: tensor(9540.3369, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10552., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([4446, 42808])
ter_threshold: 0.397509
num_accepted / total 56 128
loss token level: tensor(9340.4219, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6344., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([1950, 42808])
pred_new.size(): torch.Size([2160, 42808])
pred_new.size(): torch.Size([2160, 42808])
pred_new.size(): torch.Size([2340, 42808])
pred_new.size(): torch.Size([4725, 42808])
pred_new.size(): torch.Size([432, 42808])
pred_new.size(): torch.Size([5000, 42808])
pred_new.size(): torch.Size([5202, 42808])
pred_new.size(): torch.Size([2400, 42808])
ter_threshold: 0.398578
num_accepted / total 39 128
loss token level: tensor(10019.5078, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7416., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1782, 42808])
ter_threshold: 0.398659
num_accepted / total 10 48
loss token level: tensor(8818.8105, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2824., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2548, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.398764
num_accepted / total 27 128
loss token level: tensor(8897.6904, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2388., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2475, 42808])
pred_new.size(): torch.Size([3486, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([6882, 42808])
ter_threshold: 0.399142
num_accepted / total 9 80
loss token level: tensor(8526.1670, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2080., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([1248, 42808])
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([2745, 42808])
pred_new.size(): torch.Size([1512, 42808])
pred_new.size(): torch.Size([4560, 42808])
pred_new.size(): torch.Size([1560, 42808])
pred_new.size(): torch.Size([2352, 42808])
ter_threshold: 0.39987799999999996
num_accepted / total 25 80
loss token level: tensor(9001.5195, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4432., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1944, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.400209
num_accepted / total 72 160
loss token level: tensor(9198.8438, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6400., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2640, 42808])
ter_threshold: 0.400701
num_accepted / total 37 96
loss token level: tensor(8693.8242, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5196., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([6630, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([576, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([1904, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.401421
num_accepted / total 42 96
loss token level: tensor(9148.1084, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6468., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1428, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([1734, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.401984
num_accepted / total 137 232
loss token level: tensor(9377.1289, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7636., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3014, 42808])
pred_new.size(): torch.Size([5060, 42808])
pred_new.size(): torch.Size([1440, 42808])
ter_threshold: 0.40210599999999996
num_accepted / total 3 56
loss token level: tensor(10915.7656, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1435., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([2580, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1519, 42808])
pred_new.size(): torch.Size([4365, 42808])
lprobs.size(): torch.Size([3304, 42808])
ter_threshold: 0.402884
num_accepted / total 62 136
loss token level: tensor(9859.9141, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6504., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.402962
num_accepted / total 19 88
loss token level: tensor(9044.3047, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4792., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6370, 42808])
ter_threshold: 0.40322
num_accepted / total 39 136
loss token level: tensor(8382.7793, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6396., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.40327599999999997
num_accepted / total 44 136
loss token level: tensor(9983.7793, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7832., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.403433
num_accepted / total 29 72
loss token level: tensor(8669.5957, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10952., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.403738
num_accepted / total 449 512
loss token level: tensor(6816.0117, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5584., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.40383199999999997
num_accepted / total 18 80
loss token level: tensor(10492.0762, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: pred_new.size(): torch.Size([1736, 42808])
pred_new.size(): torch.Size([2950, 42808])
pred_new.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3045, 42808])
ter_threshold: 0.395122
num_accepted / total 66 168
loss token level: tensor(9791.7090, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5448., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4200, 42808])
pred_new.size(): torch.Size([2493, 42808])
pred_new.size(): torch.Size([2883, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([6164, 42808])
pred_new.size(): torch.Size([3600, 42808])
pred_new.size(): torch.Size([920, 42808])
pred_new.size(): torch.Size([528, 42808])
lprobs.size(): torch.Size([2816, 42808])
ter_threshold: 0.396539
num_accepted / total 13 72
loss token level: tensor(11124.7559, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2336., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3276, 42808])
pred_new.size(): torch.Size([2268, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1632, 42808])
ter_threshold: 0.397125
num_accepted / total 40 112
loss token level: tensor(8907.6289, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8792., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7744, 42808])
ter_threshold: 0.397189
num_accepted / total 11 56
loss token level: tensor(8901.1494, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2808., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1176, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([4455, 42808])
ter_threshold: 0.397509
num_accepted / total 93 168
loss token level: tensor(8942.4570, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7408., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3008, 42808])
pred_new.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.39808
num_accepted / total 10 64
loss token level: tensor(10201.5059, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4078., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([1470, 42808])
pred_new.size(): torch.Size([5586, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.39847899999999997
num_accepted / total 14 64
loss token level: tensor(9254.0967, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3044., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4064, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.398578
num_accepted / total 15 80
loss token level: tensor(8470.2998, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3754., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3652, 42808])
pred_new.size(): torch.Size([845, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([896, 42808])
lprobs.size(): torch.Size([2848, 42808])
ter_threshold: 0.399301
num_accepted / total 18 56
loss token level: tensor(9057.1807, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5000., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4446, 42808])
pred_new.size(): torch.Size([6240, 42808])
pred_new.size(): torch.Size([4095, 42808])
pred_new.size(): torch.Size([1020, 42808])
pred_new.size(): torch.Size([3060, 42808])
pred_new.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3135, 42808])
pred_new.size(): torch.Size([3720, 42808])
lprobs.size(): torch.Size([3336, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.400209
num_accepted / total 21 88
loss token level: tensor(8483.0898, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3216., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([585, 42808])
pred_new.size(): torch.Size([1244, 42808])
ter_threshold: 0.400701
num_accepted / total 105 184
loss token level: tensor(8684.5547, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7216., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([680, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([3510, 42808])
lprobs.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.401421
num_accepted / total 31 88
loss token level: tensor(8759.8242, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4872., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2782, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([2340, 42808])
ter_threshold: 0.401533
num_accepted / total 30 120
loss token level: tensor(10517.4746, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3482., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([2392, 42808])
ter_threshold: 0.40190499999999996
num_accepted / total 83 192
loss token level: tensor(8777.2588, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9584., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2090, 42808])
ter_threshold: 0.401984
num_accepted / total 132 224
loss token level: tensor(8326.8262, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7004., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6048, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1800, 42808])
pred_new.size(): torch.Size([4455, 42808])
pred_new.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1904, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([4092, 42808])
ter_threshold: 0.402884
num_accepted / total 69 144
loss token level: tensor(9542.9971, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6792., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4896, 42808])
ter_threshold: 0.40327599999999997
num_accepted / total 57 120
loss token level: tensor(8803.7129, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11520., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.403454
num_accepted / total 13 64
loss token level: tensor(9426.3555, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5216., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([672, 42808])
pred_new.size(): torch.Size([3267, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.403738
num_accepted / total 78 168
loss token level: tensor(8753.6387, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10352., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.403875
num_accepted / total 49 112
loss token level: tensor(8903.2441, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: ter_threshold: 0.40383199999999997
num_accepted / total 28 80
loss token level: tensor(9632.4297, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5504., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 02:48:27 | INFO | train_inner | epoch 012:   4262 / 9060 loss=6.668, nll_loss=3.34, ppl=10.13, wps=5950, ups=0.46, wpb=12939.4, bsz=425.7, num_updates=103900, lr=9.81052e-05, gnorm=0.88, loss_scale=16, train_wall=217, gb_free=14.7, wall=144501
pred_new.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([1188, 42808])
2023-09-22 02:51:56 | INFO | train_inner | epoch 012:   4362 / 9060 loss=6.701, nll_loss=3.364, ppl=10.3, wps=6187.2, ups=0.48, wpb=12919.1, bsz=420.7, num_updates=104000, lr=9.80581e-05, gnorm=0.896, loss_scale=16, train_wall=209, gb_free=14.6, wall=144709
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 02:55:27 | INFO | train_inner | epoch 012:   4462 / 9060 loss=6.608, nll_loss=3.283, ppl=9.73, wps=6136.3, ups=0.47, wpb=12952.9, bsz=401.3, num_updates=104100, lr=9.8011e-05, gnorm=0.885, loss_scale=16, train_wall=211, gb_free=14.7, wall=144920
pred_new.size(): torch.Size([1472, 42808])
2023-09-22 02:59:05 | INFO | train_inner | epoch 012:   4562 / 9060 loss=6.647, nll_loss=3.329, ppl=10.05, wps=5953.2, ups=0.46, wpb=12996.3, bsz=420.8, num_updates=104200, lr=9.79639e-05, gnorm=0.88, loss_scale=16, train_wall=218, gb_free=16, wall=145139
pred_new.size(): torch.Size([4032, 42808])
2023-09-22 03:02:34 | INFO | train_inner | epoch 012:   4662 / 9060 loss=6.666, nll_loss=3.343, ppl=10.14, wps=6194.4, ups=0.48, wpb=12926.6, bsz=430.2, num_updates=104300, lr=9.79169e-05, gnorm=0.894, loss_scale=16, train_wall=208, gb_free=14.5, wall=145347
pred_new.size(): torch.Size([6837, 42808])
2023-09-22 03:06:06 | INFO | train_inner | epoch 012:   4762 / 9060 loss=6.68, nll_loss=3.319, ppl=9.98, wps=6115.9, ups=0.47, wpb=12953.1, bsz=448.5, num_updates=104400, lr=9.787e-05, gnorm=0.907, loss_scale=16, train_wall=212, gb_free=14.4, wall=145559
ter_threshold: 0.404408
num_accepted / total 47 120
loss token level: tensor(10094.9102, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9744., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6461, 42808])
2023-09-22 03:09:52 | INFO | train_inner | epoch 012:   4862 / 9060 loss=6.645, nll_loss=3.298, ppl=9.83, wps=5733.4, ups=0.44, wpb=12993, bsz=433.2, num_updates=104500, lr=9.78232e-05, gnorm=0.892, loss_scale=16, train_wall=226, gb_free=14.2, wall=145786
lprobs.size(): torch.Size([2944, 42808])
2023-09-22 03:13:28 | INFO | train_inner | epoch 012:   4962 / 9060 loss=6.685, nll_loss=3.301, ppl=9.85, wps=6017.7, ups=0.46, wpb=13002.9, bsz=444.1, num_updates=104600, lr=9.77764e-05, gnorm=0.89, loss_scale=16, train_wall=216, gb_free=15, wall=146002
pred_new.size(): torch.Size([4658, 42808])
2023-09-22 03:17:06 | INFO | train_inner | epoch 012:   5062 / 9060 loss=6.655, nll_loss=3.316, ppl=9.96, wps=5955, ups=0.46, wpb=12962.2, bsz=443.3, num_updates=104700, lr=9.77297e-05, gnorm=0.897, loss_scale=16, train_wall=217, gb_free=14.6, wall=146220
2023-09-22 03:17:10 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
lprobs.size(): torch.Size([3304, 42808])
2023-09-22 03:20:43 | INFO | train_inner | epoch 012:   5163 / 9060 loss=6.677, nll_loss=3.337, ppl=10.1, wps=6005.1, ups=0.46, wpb=13026.7, bsz=428.6, num_updates=104800, lr=9.76831e-05, gnorm=0.888, loss_scale=8, train_wall=217, gb_free=14.7, wall=146437
2023-09-22 03:24:23 | INFO | train_inner | epoch 012:   5263 / 9060 loss=6.748, nll_loss=3.353, ppl=10.22, wps=5897.5, ups=0.45, wpb=12987.3, bsz=460.3, num_updates=104900, lr=9.76365e-05, gnorm=0.904, loss_scale=8, train_wall=220, gb_free=15.1, wall=146657
lprobs.size(): torch.Size([2640, 42808])
2023-09-22 03:27:55 | INFO | train_inner | epoch 012:   5363 / 9060 loss=6.772, nll_loss=3.379, ppl=10.41, wps=6150.7, ups=0.47, wpb=13027.9, bsz=442, num_updates=105000, lr=9.759e-05, gnorm=0.887, loss_scale=8, train_wall=212, gb_free=14.2, wall=146869
2023-09-22 03:31:28 | INFO | train_inner | epoch 012:   5463 / 9060 loss=6.706, nll_loss=3.317, ppl=9.97, wps=6124.5, ups=0.47, wpb=13024.9, bsz=425.3, num_updates=105100, lr=9.75436e-05, gnorm=0.891, loss_scale=8, train_wall=212, gb_free=14.5, wall=147081
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 03:35:04 | INFO | train_inner | epoch 012:   5563 / 9060 loss=6.627, nll_loss=3.292, ppl=9.8, wps=5951, ups=0.46, wpb=12880.8, bsz=403.4, num_updates=105200, lr=9.74972e-05, gnorm=0.895, loss_scale=8, train_wall=216, gb_free=14, wall=147298
pred_new.size(): torch.Size([1400, 42808])
2023-09-22 03:38:32 | INFO | train_inner | epoch 012:   5663 / 9060 loss=6.66, nll_loss=3.344, ppl=10.15, wps=6209.3, ups=0.48, wpb=12905.3, bsz=417.8, num_updates=105300, lr=9.74509e-05, gnorm=0.905, loss_scale=8, train_wall=208, gb_free=14.6, wall=147506
2023-09-22 03:42:07 | INFO | train_inner | epoch 012:   5763 / 9060 loss=6.609, nll_loss=3.282, ppl=9.73, wps=6011.6, ups=0.46, wpb=12938.9, bsz=421.4, num_updates=105400, lr=9.74047e-05, gnorm=0.887, loss_scale=8, train_wall=215, gb_free=14.4, wall=147721
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([6014, 42808])
2023-09-22 03:45:40 | INFO | train_inner | epoch 012:   5863 / 9060 loss=6.657, nll_loss=3.346, ppl=10.17, wps=6106.8, ups=0.47, wpb=13018, bsz=421.7, num_updates=105500, lr=9.73585e-05, gnorm=0.887, loss_scale=8, train_wall=213, gb_free=14.6, wall=147934
pred_new.size(): torch.Size([1470, 42808])
2023-09-22 03:49:24 | INFO | train_inner | epoch 012:   5963 / 9060 loss=6.752, nll_loss=3.327, ppl=10.04, wps=5855.5, ups=0.45, wpb=13085.7, bsz=450.1, num_updates=105600, lr=9.73124e-05, gnorm=0.906, loss_scale=8, train_wall=223, gb_free=13.2, wall=148157
ter_threshold: 0.40560399999999996
num_accepted / total 34 136
loss token level: tensor(10951.9795, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5984., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3384, 42808])
2023-09-22 03:52:56 | INFO | train_inner | epoch 012:   6063 / 9060 loss=6.694, nll_loss=3.344, ppl=10.15, wps=6112.3, ups=0.47, wpb=12979.9, bsz=430.2, num_updates=105700, lr=9.72663e-05, gnorm=0.922, loss_scale=8, train_wall=212, gb_free=14.8, wall=148370
pred_new.size(): torch.Size([3825, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([506, 42808])
2023-09-22 03:56:39 | INFO | train_inner | epoch 012:   6163 / 9060 loss=6.775, nll_loss=3.337, ppl=10.11, wps=5833.9, ups=0.45, wpb=12982.4, bsz=431.9, num_updates=105800, lr=9.72203e-05, gnorm=0.912, loss_scale=8, train_wall=222, gb_free=14.2, wall=148592
2023-09-22 04:00:00 | INFO | train_inner | epoch 012:   6263 / 9060 loss=6.689, nll_loss=3.329, ppl=10.05, wps=6458.9, ups=0.5, wpb=12978.4, bsz=439.9, num_updates=105900, lr=9.71744e-05, gnorm=0.894, loss_scale=8, train_wall=201, gb_free=16, wall=148793
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([4246, 42808])
ter_threshold: 0.405978
num_accepted / total 65 136
loss token level: tensor(8442.5430, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9968., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 04:03:27 | INFO | train_inner | epoch 012:   6363 / 9060 loss=6.632, nll_loss=3.307, ppl=9.9, wps=6300.1, ups=0.48, wpb=13026.9, bsz=429, num_updates=106000, lr=9.71286e-05, gnorm=0.882, loss_scale=8, train_wall=207, gb_free=14.2, wall=149000
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 04:06:55 | INFO | train_inner | epoch 012:   6463 / 9060 loss=6.637, nll_loss=3.307, ppl=9.9, wps=6195.3, ups=0.48, wpb=12938.6, bsz=429, num_updates=106100, lr=9.70828e-05, gnorm=0.885, loss_scale=8, train_wall=209, gb_free=13.9, wall=149209
2023-09-22 04:10:40 | INFO | train_inner | epoch 012:   6563 / 9060 loss=6.739, nll_loss=3.347, ppl=10.18, wps=5784.8, ups=0.45, wpb=12975.5, bsz=437.8, num_updates=106200, lr=9.70371e-05, gnorm=0.903, loss_scale=8, train_wall=224, gb_free=15, wall=149433
ter_threshold: 0.406203
num_accepted / total 25 88
loss token level: tensor(9962.6328, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7552., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1488, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 04:14:14 | INFO | train_inner | epoch 012:   6663 / 9060 loss=6.742, nll_loss=3.37, ppl=10.34, wps=6061.2, ups=0.47, wpb=13004.5, bsz=433.1, num_updates=106300, lr=9.69914e-05, gnorm=0.919, loss_scale=8, train_wall=214, gb_free=14.5, wall=149648
pred_new.size(): torch.Size([4715, 42808])
2023-09-22 04:17:42 | INFO | train_inner | epoch 012:   6763 / 9060 loss=6.743, nll_loss=3.352, ppl=10.21, wps=6234.1, ups=0.48, wpb=12965.5, bsz=427.3, num_updates=106400, lr=9.69458e-05, gnorm=0.907, loss_scale=8, train_wall=208, gb_free=14.1, wall=149856
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([5112, 42808])
ter_threshold: 0.406478
num_accepted / total 24 88
loss token level: tensor(9133.5137, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3498., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 04:21:12 | INFO | train_inner | epoch 012:   6863 / 9060 loss=6.803, nll_loss=3.378, ppl=10.4, wps=6154.5, ups=0.48, wpb=12927.4, bsz=416.9, num_updates=106500, lr=9.69003e-05, gnorm=0.929, loss_scale=8, train_wall=210, gb_free=13.9, wall=150066
2023-09-22 04:24:41 | INFO | train_inner | epoch 012:   6963 / 9060 loss=6.649, nll_loss=3.294, ppl=9.81, wps=6234, ups=0.48, wpb=13014.8, bsz=433.3, num_updates=106600, lr=9.68549e-05, gnorm=0.871, loss_scale=8, train_wall=209, gb_free=14.9, wall=150275
pred_new.size(): torch.Size([4905, 42808])
2023-09-22 04:28:27 | INFO | train_inner | epoch 012:   7063 / 9060 loss=6.833, nll_loss=3.407, ppl=10.61, wps=5726.1, ups=0.44, wpb=12945.2, bsz=421.5, num_updates=106700, lr=9.68095e-05, gnorm=0.963, loss_scale=8, train_wall=226, gb_free=13.5, wall=150501
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([4752, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.406771
num_accepted / total 25 96
loss token level: tensor(10047.3398, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3798., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 04:32:07 | INFO | train_inner | epoch 012:   7163 / 9060 loss=6.675, nll_loss=3.349, ppl=10.19, wps=5919.6, ups=0.45, wpb=13026.6, bsz=425.3, num_updates=106800, lr=9.67641e-05, gnorm=0.895, loss_scale=8, train_wall=220, gb_free=15.1, wall=150721
2023-09-22 04:35:33 | INFO | train_inner | epoch 012:   7263 / 9060 loss=6.627, nll_loss=3.311, ppl=9.93, wps=6314.1, ups=0.49, wpb=12996.8, bsz=447, num_updates=106900, lr=9.67189e-05, gnorm=0.878, loss_scale=8, train_wall=206, gb_free=15.3, wall=150926
pred_new.size(): torch.Size([1275, 42808])
2023-09-22 04:39:16 | INFO | train_inner | epoch 012:   7363 / 9060 loss=6.768, nll_loss=3.375, ppl=10.37, wps=5779, ups=0.45, wpb=12913.5, bsz=454.6, num_updates=107000, lr=9.66736e-05, gnorm=0.928, loss_scale=8, train_wall=223, gb_free=15.6, wall=151150
pred_new.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([1666, 42808])
2023-09-22 04:42:50 | INFO | train_inner | epoch 012:   7463 / 9060 loss=6.609, nll_loss=3.315, ppl=9.95, wps=6110.8, ups=0.47, wpb=13040.4, bsz=444.5, num_updates=107100, lr=9.66285e-05, gnorm=0.875, loss_scale=8, train_wall=213, gb_free=14.2, wall=151363
loss seque level: tensor(6040., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2760, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([420, 42808])
lprobs.size(): torch.Size([2576, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4578, 42808])
ter_threshold: 0.39919099999999996
num_accepted / total 8 56
loss token level: tensor(9670.7188, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2306., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1476, 42808])
lprobs.size(): torch.Size([2552, 42808])
pred_new.size(): torch.Size([2128, 42808])
pred_new.size(): torch.Size([5976, 42808])
pred_new.size(): torch.Size([3060, 42808])
pred_new.size(): torch.Size([5640, 42808])
pred_new.size(): torch.Size([1848, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2312, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([936, 42808])
lprobs.size(): torch.Size([2976, 42808])
ter_threshold: 0.400209
num_accepted / total 78 224
loss token level: tensor(8121.7393, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3804., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3024, 42808])
ter_threshold: 0.400701
num_accepted / total 30 88
loss token level: tensor(9706.6504, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5232., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1872, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1900, 42808])
lprobs.size(): torch.Size([2744, 42808])
pred_new.size(): torch.Size([4375, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5185, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([3144, 42808])
pred_new.size(): torch.Size([3496, 42808])
ter_threshold: 0.401359
num_accepted / total 7 40
loss token level: tensor(8433.4775, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4244., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1890, 42808])
pred_new.size(): torch.Size([1800, 42808])
pred_new.size(): torch.Size([1296, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1443, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2440, 42808])
ter_threshold: 0.401672
num_accepted / total 0 48
loss token level: tensor(9889.0957, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: 0
pred_new.size(): torch.Size([3444, 42808])
pred_new.size(): torch.Size([5060, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.40190499999999996
num_accepted / total 43 104
loss token level: tensor(9709.6426, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10728., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2838, 42808])
ter_threshold: 0.401984
num_accepted / total 21 96
loss token level: tensor(10676.3564, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3340., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5124, 42808])
pred_new.size(): torch.Size([2650, 42808])
pred_new.size(): torch.Size([4180, 42808])
pred_new.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3330, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([280, 42808])
pred_new.size(): torch.Size([2652, 42808])
pred_new.size(): torch.Size([1665, 42808])
ter_threshold: 0.402884
num_accepted / total 58 152
loss token level: tensor(9232.1602, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5424., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.402962
num_accepted / total 74 152
loss token level: tensor(9431.5576, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11552., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2392, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([1890, 42808])
lprobs.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([3192, 42808])
ter_threshold: 0.403738
num_accepted / total 107 232
loss token level: tensor(8250.4023, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7792., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.403823
num_accepted / total 2 40
loss token level: tensor(8196.7295, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(688.5000, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.40383199999999997
num_accepted / total 15 72
loss token level: tensor(8870.2305, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2670., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.403875
num_accepted / total 37 104
loss token level: tensor(9633.2734, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9064., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([2788, 42808])
pred_new.size(): torch.Size([4761, 42808])
pred_new.size(): torch.Size([312, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2688, 42808])
ter_threshold: 0.404408
num_accepted / total 86 176
loss token level: tensor(9673.8828, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1890, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([2704, 42808])
pred_new.size(): torch.Size([4844, 42808])
pred_new.size(): torch.Size([3150, 42808])
pred_new.size(): torch.Size([5472, 42808])
pred_new.size(): torch.Size([4820, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([2432, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([4386, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([6188, 42808])
pred_new.size(): torch.Size([1224, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([4185, 42808])
pred_new.size(): torch.Size([4118, 42808])
ter_threshold: 0.406478
num_accepted / total 46 136
loss token level: tensor(10023.2031, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4980., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.406483
num_accepted / total 52 136
loss token level: tensor(9344.4785, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9320., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([679, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2142, 42808])
ter_threshold: 0.406771
num_accepted / total 43 112
loss token level: tensor(9224.9805, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5596., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4374, 42808])
pred_new.size(): torch.Size([4968, 42808])
lprobs.size(): torch.Size([3232, 42808])
pred_new.size(): torch.Size([1404, 42808])
ter_threshold: 0.407197
num_accepted / total 40 112
2023-09-22 04:46:18 | INFO | train_inner | epoch 012:   7563 / 9060 loss=6.765, nll_loss=3.37, ppl=10.34, wps=6222.2, ups=0.48, wpb=12929, bsz=426.9, num_updates=107200, lr=9.65834e-05, gnorm=0.929, loss_scale=8, train_wall=208, gb_free=14.9, wall=151571
2023-09-22 04:49:50 | INFO | train_inner | epoch 012:   7663 / 9060 loss=6.768, nll_loss=3.374, ppl=10.36, wps=6107.1, ups=0.47, wpb=12981.4, bsz=424.1, num_updates=107300, lr=9.65384e-05, gnorm=0.917, loss_scale=8, train_wall=212, gb_free=14.7, wall=151784
2023-09-22 04:53:33 | INFO | train_inner | epoch 012:   7763 / 9060 loss=6.774, nll_loss=3.347, ppl=10.18, wps=5860.3, ups=0.45, wpb=13079.8, bsz=428.7, num_updates=107400, lr=9.64935e-05, gnorm=0.903, loss_scale=8, train_wall=223, gb_free=14.6, wall=152007
lprobs.size(): torch.Size([3256, 42808])
2023-09-22 04:57:07 | INFO | train_inner | epoch 012:   7863 / 9060 loss=6.623, nll_loss=3.328, ppl=10.04, wps=6091.2, ups=0.47, wpb=12981.2, bsz=433.2, num_updates=107500, lr=9.64486e-05, gnorm=0.881, loss_scale=8, train_wall=213, gb_free=14.4, wall=152220
ter_threshold: 0.40753
num_accepted / total 4 88
loss token level: tensor(9060.0078, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(725.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 05:00:41 | INFO | train_inner | epoch 012:   7963 / 9060 loss=6.739, nll_loss=3.338, ppl=10.11, wps=6027.4, ups=0.47, wpb=12914.5, bsz=438.4, num_updates=107600, lr=9.64037e-05, gnorm=0.897, loss_scale=8, train_wall=214, gb_free=14.3, wall=152434
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([3060, 42808])
lprobs.size(): torch.Size([3280, 42808])
2023-09-22 05:04:24 | INFO | train_inner | epoch 012:   8063 / 9060 loss=6.669, nll_loss=3.329, ppl=10.05, wps=5776.2, ups=0.45, wpb=12884.9, bsz=402.9, num_updates=107700, lr=9.6359e-05, gnorm=0.947, loss_scale=8, train_wall=223, gb_free=15, wall=152657
ter_threshold: 0.407786
num_accepted / total 12 72
loss token level: tensor(8768.5908, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1972., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 05:08:03 | INFO | train_inner | epoch 012:   8163 / 9060 loss=6.663, nll_loss=3.319, ppl=9.98, wps=5917.2, ups=0.46, wpb=12962, bsz=458.2, num_updates=107800, lr=9.63143e-05, gnorm=0.898, loss_scale=8, train_wall=219, gb_free=14.4, wall=152876
2023-09-22 05:11:36 | INFO | train_inner | epoch 012:   8263 / 9060 loss=6.602, nll_loss=3.284, ppl=9.74, wps=6098.2, ups=0.47, wpb=12994.2, bsz=436.6, num_updates=107900, lr=9.62696e-05, gnorm=0.893, loss_scale=8, train_wall=213, gb_free=15.8, wall=153089
ter_threshold: 0.407911
num_accepted / total 28 104
loss token level: tensor(8757.0820, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3718., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 05:15:09 | INFO | train_inner | epoch 012:   8363 / 9060 loss=6.729, nll_loss=3.326, ppl=10.03, wps=6077.9, ups=0.47, wpb=12951.6, bsz=437.5, num_updates=108000, lr=9.6225e-05, gnorm=0.927, loss_scale=8, train_wall=213, gb_free=14.1, wall=153303
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([2500, 42808])
2023-09-22 05:18:32 | INFO | train_inner | epoch 012:   8463 / 9060 loss=6.716, nll_loss=3.358, ppl=10.26, wps=6392.7, ups=0.49, wpb=12943, bsz=427.8, num_updates=108100, lr=9.61805e-05, gnorm=0.909, loss_scale=8, train_wall=202, gb_free=14.5, wall=153505
2023-09-22 05:22:13 | INFO | train_inner | epoch 012:   8563 / 9060 loss=6.779, nll_loss=3.377, ppl=10.39, wps=5911.7, ups=0.45, wpb=13076.7, bsz=421, num_updates=108200, lr=9.61361e-05, gnorm=0.898, loss_scale=8, train_wall=221, gb_free=14.4, wall=153726
ter_threshold: 0.408238
num_accepted / total 10 40
loss token level: tensor(8936.9736, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3580., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 05:25:50 | INFO | train_inner | epoch 012:   8663 / 9060 loss=6.824, nll_loss=3.384, ppl=10.44, wps=5973.8, ups=0.46, wpb=12964.5, bsz=449.1, num_updates=108300, lr=9.60917e-05, gnorm=0.917, loss_scale=8, train_wall=217, gb_free=14.3, wall=153943
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7448, 42808])
2023-09-22 05:29:18 | INFO | train_inner | epoch 012:   8763 / 9060 loss=6.79, nll_loss=3.425, ppl=10.74, wps=6199.4, ups=0.48, wpb=12927.3, bsz=401, num_updates=108400, lr=9.60473e-05, gnorm=0.948, loss_scale=8, train_wall=208, gb_free=14.9, wall=154152
2023-09-22 05:32:56 | INFO | train_inner | epoch 012:   8863 / 9060 loss=6.58, nll_loss=3.268, ppl=9.63, wps=5957.3, ups=0.46, wpb=12954.4, bsz=411.5, num_updates=108500, lr=9.60031e-05, gnorm=0.867, loss_scale=8, train_wall=217, gb_free=15.2, wall=154369
ter_threshold: 0.40854199999999996
num_accepted / total 9 16
loss token level: tensor(6517.0566, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6344., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
2023-09-22 05:36:32 | INFO | train_inner | epoch 012:   8963 / 9060 loss=6.81, nll_loss=3.4, ppl=10.55, wps=6036.2, ups=0.46, wpb=13031.5, bsz=440.9, num_updates=108600, lr=9.59589e-05, gnorm=0.927, loss_scale=8, train_wall=216, gb_free=14.6, wall=154585
pred_new.size(): torch.Size([4422, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-22 05:40:18 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-22 05:40:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 05:40:18 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-22 05:40:18 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-22 05:40:19 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-22 05:40:19 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-22 05:40:19 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-22 05:40:19 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-22 05:40:20 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-22 05:40:20 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-22 05:40:21 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-22 05:40:21 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-22 05:40:21 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein regnerischer Erfolg.
2023-09-22 05:40:21 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-22 05:40:22 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr an alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-22 05:40:22 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-22 05:40:22 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-22 05:40:22 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-22 05:40:23 | INFO | fairseq.tasks.translation | example hypothesis: Das Chatmodul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatgesprächen.
2023-09-22 05:40:23 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-22 05:40:24 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende geeignet sind.
2023-09-22 05:40:24 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-22 05:40:24 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstrasse in Richtung Chianciano Terme.
2023-09-22 05:40:24 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-22 05:40:25 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 05:40:25 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 05:40:25 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU riesige Mengen an Energie verschwendet.
2023-09-22 05:40:25 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-22 05:40:26 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Ausgabe.
2023-09-22 05:40:26 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-22 05:40:27 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich auch die Haltungsänderung in Kürze im Haushalt der Union widerspiegeln.
2023-09-22 05:40:27 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-22 05:40:27 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-22 05:40:27 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-22 05:40:28 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die allgemein bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-22 05:40:28 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-22 05:40:29 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-22 05:40:29 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-22 05:40:29 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, ihrem Berufsleben mehr Zeit zu widmen, als sie sich gewünscht hätten?
2023-09-22 05:40:29 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-22 05:40:30 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-22 05:40:30 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-22 05:40:31 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-22 05:40:31 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-22 05:40:31 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-22 05:40:31 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-22 05:40:32 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-22 05:40:32 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-22 05:40:33 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potenzielle Käufer dazu veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu machen.
2023-09-22 05:40:33 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-22 05:40:33 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-22 05:40:33 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-22 05:40:34 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung gelangen könnten.
2023-09-22 05:40:34 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-22 05:40:35 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze diese Debatte auch, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-22 05:40:35 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-22 05:40:35 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in einem Umkreis von etwa 8 km vom Strip.
2023-09-22 05:40:35 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-22 05:40:36 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-22 05:40:36 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-22 05:40:37 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! akustisch, interaktiv oder in schriftlicher Form die Realisierung von Tonbüchern an.
2023-09-22 05:40:37 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-22 05:40:37 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-22 05:40:37 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-22 05:40:38 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer inneren Unterstützung aufbauen, aber sie kann sich zur Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-22 05:40:38 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-22 05:40:39 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu dem Geld erhalten, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-22 05:40:39 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-22 05:40:39 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-22 05:40:39 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-22 05:40:40 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf allen Rechnerplattformen läuft.
2023-09-22 05:40:40 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-22 05:40:41 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-22 05:40:41 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-22 05:40:42 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherische Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv zentrale Teile seiner Agenda.
2023-09-22 05:40:42 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-22 05:40:42 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils-Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-22 05:40:42 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-22 05:40:43 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-22 05:40:43 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-22 05:40:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum sich diese Kriterien auf die Anwendung nur innerhalb der Grenzen Europas beschränken sollten.
2023-09-22 05:40:44 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-22 05:40:44 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-22 05:40:44 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-22 05:40:45 | INFO | fairseq.tasks.translation | example hypothesis: Nach dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens grundsätzlich mit den Vereinigten Staaten vorlegen müssen.
2023-09-22 05:40:45 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-22 05:40:46 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder spezielle Edition - unser breites Sortiment an Plastikbabyleartikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-22 05:40:46 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-22 05:40:46 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 05:40:46 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 05:40:47 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Bekanntwerden der AGB über Sachsituationen zu informieren, die mit diesen nicht vereinbar sind.
2023-09-22 05:40:47 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-22 05:40:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die vorangekommen ist und die die Notwendigkeit institutioneller Veränderungen erkannt hat, die sie eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung erfordert.
2023-09-22 05:40:47 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-22 05:40:48 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden geschaffen, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen..
2023-09-22 05:40:48 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-22 05:40:49 | INFO | fairseq.tasks.translation | example hypothesis: Wir erkennen die erheblichen Fortschritte an, die bei der Prüfung aller Fragen erzielt wurden, die jetzt Gegenstand der Diskussion über etwas sind, das gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-22 05:40:49 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-22 05:40:49 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus gesenkten Federn und Dämpfern für erstklassigen Spaß am Rad.
2023-09-22 05:40:49 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-22 05:40:50 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal war der Berichterstatter in der Lage, bisweilen unterschiedliche Meinungen und Beiträge zusammenzufassen und - wie ich sagen würde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 05:40:50 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 05:40:51 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederreglern mit einem trockenen ESP für den niedrigeren Leistungsbereich.
2023-09-22 05:40:51 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-22 05:40:51 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seit Jahrhunderten seine Freiheit und Unabhängigkeit verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-22 05:40:51 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-22 05:40:52 | INFO | fairseq.tasks.translation | example hypothesis: Zu einer Zeit, in der viele unserer traditionellen Branchen nach China und Fernost abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-22 05:40:52 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-22 05:40:53 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-22 05:40:53 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-22 05:40:53 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-22 05:40:53 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-22 05:40:54 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit wirklich sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-22 05:40:54 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-22 05:40:55 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-22 05:40:55 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-22 05:40:55 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Notfall gibt es jedoch noch einen weiteren: die Notsituation, an der die Kinder, der schwächste Teil der Bevölkerung, die ohne Familie, ohne Schutz und ohne Staat gelassen wurde.
2023-09-22 05:40:55 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-22 05:40:56 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis der Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen.
2023-09-22 05:40:56 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-22 05:40:57 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht befreit ist, nicht erst innerhalb des ersten, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis befleckt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-22 05:40:57 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-22 05:40:58 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen einen gewaltfreien Zeitraum zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu öffnen.
2023-09-22 05:40:58 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-22 05:40:58 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern freie und unabhängige Wahlen ermöglichen, und die Vereinigungsfreiheit sind von entscheidender Bedeutung, und es muss der Öffentlichkeit deutlich gemacht werden, dass niemand über dem Gesetz steht.
2023-09-22 05:40:58 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-22 05:40:59 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java-Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit garantieren (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-22 05:40:59 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-22 05:41:00 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für die Klärung des Anhangs.
2023-09-22 05:41:00 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-22 05:41:00 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass die von der IAO verhängten Sanktionen nicht als unvereinbar mit den WTO-Verträgen betrachtet werden.
2023-09-22 05:41:00 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-22 05:41:01 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische öffentlich-rechtliche Radio RTÉ, mit einer Frau, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen, teilgenommen.
2023-09-22 05:41:01 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-22 05:41:02 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-22 05:41:02 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-22 05:41:03 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas Besonderes wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-22 05:41:03 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-22 05:41:03 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, im wunderschönen Wien und im bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten offen.
2023-09-22 05:41:03 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-22 05:41:04 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-22 05:41:04 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-22 05:41:05 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, hieße zu naturalisieren und zu mystifizieren, was eine bestimmte Art von Vertragsverhältnis zwischen Einzelpersonen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Bedrohung, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-22 05:41:05 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-22 05:41:06 | INFO | fairseq.tasks.translation | example hypothesis: In der Gemeinschaftsgerichtsbarkeit zu einem Thema der personenbezogenen Daten sollte der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-22 05:41:06 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-22 05:41:06 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Autos, das man für weniger als 50.000 Dollar fahren kann, und wenn man in der Nähe von Toronto, Montreal oder Vancouver lebt, kann man die gesamte Lineup kostenlos ausprobieren.
2023-09-22 05:41:06 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-22 05:41:07 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso auch dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darlegung der Angelegenheit.
2023-09-22 05:41:07 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-22 05:41:08 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den ausgezeichneten Süßwasserfisch: gegrillter Hecht, Forelle mit Mandeln.
2023-09-22 05:41:08 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-22 05:41:09 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, eine Gesamtsicht zu geben, die es uns ermöglicht, näher auf die verschiedenen Fragen einzugehen und zu prüfen, welche Impulse die Europäische Union mit Blick auf die Zukunft geben kann.
2023-09-22 05:41:09 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-22 05:41:09 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber der "Scardona Records", Herr Branko Paić, einigten sich darauf, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-22 05:41:09 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-22 05:41:10 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo unmittelbare Bedrohungen für die bestehenden Arbeitsplätze bestehen und die Wettbewerbsfähigkeit schrittweise durch makroökonomische Politik, steuerliche Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, untergraben wird.
2023-09-22 05:41:10 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-22 05:41:11 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament mit einem ausgezeichneten Beispiel für die Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-22 05:41:11 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-22 05:41:12 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Folgen für den Rechts- und Rechtsbereich, was Norwegen und Island zu Ländern macht, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen gelten werden.
2023-09-22 05:41:12 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-22 05:41:13 | INFO | fairseq.tasks.translation | example hypothesis: Wir gehen mit voller Geschwindigkeit mit einem Schwenkboot hinunter den Mississippi, suchen nach dem großen verborgenen Schatz, verlieben uns in den schönen Becky Thatcher, der rein dynamisch ist, und vor allem werden wir große Freunde sein..........
2023-09-22 05:41:13 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-22 05:41:14 | INFO | fairseq.tasks.translation | example hypothesis: In der Praxis harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion und die Strafbarkeit der Sanktionen, die im Falle solcher Verstöße von Einzelpersonen angewendet werden können.
2023-09-22 05:41:14 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-22 05:41:15 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falized und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner erledigt und eine Gruppe von Bergern gefilmt haben, die seit Jahren von einem autoritären Regime verfolgt wurden, das jedes Prinzip der Demokratie missachtet.........
2023-09-22 05:41:15 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-22 05:41:15 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, Transport- und Sightseeing-Rezeption, Menü- und Presseservice, Geldwechsel, kostenloser Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-22 05:41:15 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-22 05:41:16 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, Ehefrau des Königs D. João II, und bekannt durch ihre Keramik international für ihre bildhaften und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-22 05:41:16 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-22 05:41:17 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger, die behaupten, dass es auf der einen Seite um gute Pro-Westler und auf der anderen Seite um die Anhänger des ehemaligen Regimes geht - auch das ist verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-22 05:41:17 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-22 05:41:18 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, da viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, auf diese Weise nicht abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-22 05:41:18 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-22 05:41:19 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden Informationen außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär an einen Aktionär weitergegeben, so werden diese auf Verlangen an jeden anderen Aktionär in der Aktionärsversammlung weitergegeben, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-22 05:41:19 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-22 05:41:20 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr miserables Leben führen.
2023-09-22 05:41:20 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-22 05:41:21 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem Mitgliedstaat oder die NATO hätten an diesem Kriegshandlung beteiligt sein können -, mit Informationen zu helfen, die es keinen Grund mehr gibt, geheim, versteckt oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen und die ganze Wahrheit erfahren können.
2023-09-22 05:41:21 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-22 05:41:22 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und eine 30-minütige Zugfahrt vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 05:41:22 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 05:41:23 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird das Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen von entscheidender Bedeutung sind, die die heutigen Offline-Plattformen nie erreichen können.
2023-09-22 05:41:23 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-22 05:41:23 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen deutlich machen, dass wir nicht nur für uns, sondern weltweit die Produkte vom Markt nehmen können, die ein ernsthaftes Risiko darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, denn diese Produkte können leicht recycelt werden, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt..................
2023-09-22 05:41:23 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-22 05:41:24 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem bloßen Plot der Modernität und Postmoderne oder dem klaren Widerstand reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und anhaltende Spannung jener beiden ästhetischen Politik anerkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verstrickt sind, die die Kunst als solche für uns identifizierbar machen - jene beiden Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führt..... Diese beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen, müssen wir anerkennen.
2023-09-22 05:41:24 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-22 05:41:25 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir gegeben haben und die meine Ausführungen eindeutig weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen unsere Aussprachen führen, und wenn es zur Abstimmung kommt, wenn die 40 Petenten nicht anwesend sind, werde ich nicht beantragen, die Beschlussfähigkeit zu prüfen.
2023-09-22 05:41:25 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-22 05:41:27 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker niemals die Einschränkung des nationalstaatlichen Prinzips akzeptiert haben, sind es paradoxerweise gerade sie, die nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung der ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen. Aber ohne das Ziel, eine einheitliche Kultur zu schaffen, aber auch die Entwicklung der ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen.
2023-09-22 05:41:27 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-22 05:41:28 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Weise als hybride Form veröffentlicht, die Rezensionen und Artikel des vierteljährlichen Magazins für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Websites des H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt...
2023-09-22 05:41:28 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-22 05:41:29 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit dem Eintreffen der neuen Smartphone-Generation haben Handys ihre Federn deutlich verwischt, von einst schillernden Taschenlampen über polyphonisch rostende Game Boy-Uhren bis hin zu schlichten Mini-PCs mit knackigem CD-Qualität-Stereo-Sound: Von nun an könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazern neuer technischer Entwicklungen entwickeln...
2023-09-22 05:41:29 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-22 05:41:31 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dientes la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se marchen.
2023-09-22 05:41:31 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-22 05:41:31 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 4.181 | nll_loss 2.209 | ppl 4.62 | bleu 29.18 | wps 16109.3 | wpb 12011.9 | bsz 398.1 | num_updates 108697 | best_bleu 29.46
2023-09-22 05:41:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 108697 updates
2023-09-22 05:41:31 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint12.pt
2023-09-22 05:41:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint12.pt
2023-09-22 05:41:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint12.pt (epoch 12 @ 108697 updates, score 29.18) (writing took 10.741462925972883 seconds)
2023-09-22 05:41:42 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2023-09-22 05:41:42 | INFO | train | epoch 012 | loss 6.692 | nll_loss 3.326 | ppl 10.02 | wps 6017.5 | ups 0.46 | wpb 12977.2 | bsz 430.6 | num_updates 108697 | lr 9.5916e-05 | gnorm 0.898 | loss_scale 8 | train_wall 19428 | gb_free 14.9 | wall 154896
2023-09-22 05:41:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 05:41:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-22 05:41:42 | INFO | fairseq.trainer | begin training epoch 13
2023-09-22 05:41:42 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-22 05:41:48 | INFO | train_inner | epoch 013:      3 / 9060 loss=6.739, nll_loss=3.352, ppl=10.21, wps=4071.7, ups=0.32, wpb=12892.8, bsz=417.3, num_updates=108700, lr=9.59147e-05, gnorm=0.926, loss_scale=8, train_wall=232, gb_free=14.7, wall=154902
2023-09-22 05:45:15 | INFO | train_inner | epoch 013:    103 / 9060 loss=6.696, nll_loss=3.289, ppl=9.77, wps=6305.1, ups=0.48, wpb=13022.2, bsz=435.5, num_updates=108800, lr=9.58706e-05, gnorm=0.894, loss_scale=16, train_wall=206, gb_free=14.8, wall=155108
pred_new.size(): torch.Size([4000, 42808])
pred_new.size(): torch.Size([3354, 42808])
2023-09-22 05:49:03 | INFO | train_inner | epoch 013:    203 / 9060 loss=6.723, nll_loss=3.291, ppl=9.79, wps=5650.7, ups=0.44, wpb=12882.9, bsz=435.1, num_updates=108900, lr=9.58266e-05, gnorm=0.919, loss_scale=16, train_wall=228, gb_free=15.1, wall=155336
2023-09-22 05:49:13 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
pred_new.size(): torch.Size([3150, 42808])
pred_new.size(): torch.Size([3852, 42808])
2023-09-22 05:52:46 | INFO | train_inner | epoch 013:    304 / 9060 loss=6.66, nll_loss=3.282, ppl=9.72, wps=5795.5, ups=0.45, wpb=12945.9, bsz=431.6, num_updates=109000, lr=9.57826e-05, gnorm=0.915, loss_scale=8, train_wall=223, gb_free=14.2, wall=155560
2023-09-22 05:56:17 | INFO | train_inner | epoch 013:    404 / 9060 loss=6.683, nll_loss=3.29, ppl=9.78, wps=6147.8, ups=0.48, wpb=12940.7, bsz=453.8, num_updates=109100, lr=9.57387e-05, gnorm=0.924, loss_scale=8, train_wall=210, gb_free=14.2, wall=155770
pred_new.size(): torch.Size([4304, 42808])
lprobs.size(): torch.Size([3040, 42808])
2023-09-22 05:59:53 | INFO | train_inner | epoch 013:    504 / 9060 loss=6.871, nll_loss=3.355, ppl=10.23, wps=6015, ups=0.46, wpb=13027.3, bsz=427.7, num_updates=109200, lr=9.56949e-05, gnorm=0.916, loss_scale=8, train_wall=216, gb_free=14.6, wall=155987
pred_new.size(): torch.Size([2635, 42808])
pred_new.size(): torch.Size([6840, 42808])
2023-09-22 06:03:40 | INFO | train_inner | epoch 013:    604 / 9060 loss=6.742, nll_loss=3.336, ppl=10.1, wps=5741.3, ups=0.44, wpb=13001.7, bsz=400.4, num_updates=109300, lr=9.56511e-05, gnorm=0.906, loss_scale=8, train_wall=226, gb_free=13.9, wall=156213
2023-09-22 06:07:13 | INFO | train_inner | epoch 013:    704 / 9060 loss=6.67, nll_loss=3.327, ppl=10.03, wps=6034.8, ups=0.47, wpb=12848.4, bsz=423, num_updates=109400, lr=9.56074e-05, gnorm=0.931, loss_scale=8, train_wall=213, gb_free=14.9, wall=156426
ter_threshold: 0.409425
num_accepted / total 18 64
loss token level: tensor(8738.2236, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4136., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 06:10:41 | INFO | train_inner | epoch 013:    804 / 9060 loss=6.77, nll_loss=3.349, ppl=10.19, wps=6225.8, ups=0.48, wpb=12994.2, bsz=420.2, num_updates=109500, lr=9.55637e-05, gnorm=0.901, loss_scale=8, train_wall=208, gb_free=14.2, wall=156635
pred_new.size(): torch.Size([1560, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([3718, 42808])
pred_new.size(): torch.Size([2052, 42808])
2023-09-22 06:14:19 | INFO | train_inner | epoch 013:    904 / 9060 loss=6.88, nll_loss=3.365, ppl=10.3, wps=6028.7, ups=0.46, wpb=13121.7, bsz=435.4, num_updates=109600, lr=9.55201e-05, gnorm=0.917, loss_scale=8, train_wall=217, gb_free=13.7, wall=156852
pred_new.size(): torch.Size([3900, 42808])
2023-09-22 06:17:57 | INFO | train_inner | epoch 013:   1004 / 9060 loss=6.723, nll_loss=3.295, ppl=9.82, wps=5984.1, ups=0.46, wpb=13026.7, bsz=440.5, num_updates=109700, lr=9.54765e-05, gnorm=0.9, loss_scale=8, train_wall=217, gb_free=14.9, wall=157070
lprobs.size(): torch.Size([3360, 42808])
2023-09-22 06:21:42 | INFO | train_inner | epoch 013:   1104 / 9060 loss=6.781, nll_loss=3.328, ppl=10.04, wps=5729.3, ups=0.44, wpb=12914.6, bsz=443.1, num_updates=109800, lr=9.54331e-05, gnorm=0.924, loss_scale=8, train_wall=225, gb_free=14.2, wall=157296
2023-09-22 06:25:20 | INFO | train_inner | epoch 013:   1204 / 9060 loss=6.769, nll_loss=3.359, ppl=10.26, wps=5984.9, ups=0.46, wpb=13010.2, bsz=440.6, num_updates=109900, lr=9.53896e-05, gnorm=0.919, loss_scale=8, train_wall=217, gb_free=14.5, wall=157513
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([7250, 42808])
2023-09-22 06:29:04 | INFO | train_inner | epoch 013:   1304 / 9060 loss=6.801, nll_loss=3.357, ppl=10.24, wps=5794.4, ups=0.45, wpb=13000.5, bsz=459, num_updates=110000, lr=9.53463e-05, gnorm=0.919, loss_scale=8, train_wall=224, gb_free=14.4, wall=157737
pred_new.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([1196, 42808])
pred_new.size(): torch.Size([4800, 42808])
2023-09-22 06:32:38 | INFO | train_inner | epoch 013:   1404 / 9060 loss=6.757, nll_loss=3.359, ppl=10.26, wps=6082.9, ups=0.47, wpb=13025.1, bsz=436.9, num_updates=110100, lr=9.53029e-05, gnorm=0.901, loss_scale=8, train_wall=214, gb_free=13.7, wall=157951
2023-09-22 06:36:21 | INFO | train_inner | epoch 013:   1504 / 9060 loss=6.857, nll_loss=3.402, ppl=10.57, wps=5748, ups=0.45, wpb=12843.4, bsz=437, num_updates=110200, lr=9.52597e-05, gnorm=0.934, loss_scale=8, train_wall=223, gb_free=14.7, wall=158175
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3536, 42808])
2023-09-22 06:40:04 | INFO | train_inner | epoch 013:   1604 / 9060 loss=6.755, nll_loss=3.359, ppl=10.26, wps=5824.4, ups=0.45, wpb=12940.5, bsz=420.6, num_updates=110300, lr=9.52165e-05, gnorm=0.944, loss_scale=8, train_wall=222, gb_free=15.4, wall=158397
ter_threshold: 0.41035499999999997
num_accepted / total 82 168
loss token level: tensor(8366.5488, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10048., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 06:43:42 | INFO | train_inner | epoch 013:   1704 / 9060 loss=6.798, nll_loss=3.354, ppl=10.22, wps=5920.3, ups=0.46, wpb=12954.3, bsz=437.8, num_updates=110400, lr=9.51734e-05, gnorm=0.923, loss_scale=8, train_wall=219, gb_free=15.3, wall=158616
pred_new.size(): torch.Size([312, 42808])
2023-09-22 06:47:28 | INFO | train_inner | epoch 013:   1804 / 9060 loss=6.777, nll_loss=3.325, ppl=10.02, wps=5716.4, ups=0.44, wpb=12897.5, bsz=431.4, num_updates=110500, lr=9.51303e-05, gnorm=0.914, loss_scale=8, train_wall=225, gb_free=15.1, wall=158842
pred_new.size(): torch.Size([5002, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3432, 42808])
2023-09-22 06:51:02 | INFO | train_inner | epoch 013:   1904 / 9060 loss=6.697, nll_loss=3.289, ppl=9.77, wps=6103.8, ups=0.47, wpb=13078.1, bsz=436.4, num_updates=110600, lr=9.50873e-05, gnorm=0.918, loss_scale=8, train_wall=214, gb_free=13.8, wall=159056
ter_threshold: 0.41060599999999997
num_accepted / total 9 56
loss token level: tensor(8896.1875, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2348., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3080, 42808])
2023-09-22 06:54:43 | INFO | train_inner | epoch 013:   2004 / 9060 loss=6.742, nll_loss=3.355, ppl=10.23, wps=5839.9, ups=0.45, wpb=12885.2, bsz=430.5, num_updates=110700, lr=9.50443e-05, gnorm=0.911, loss_scale=8, train_wall=220, gb_free=13.2, wall=159276
2023-09-22 06:58:32 | INFO | train_inner | epoch 013:   2104 / 9060 loss=6.799, nll_loss=3.362, ppl=10.28, wps=5648.2, ups=0.44, wpb=12952.8, bsz=416.8, num_updates=110800, lr=9.50014e-05, gnorm=0.955, loss_scale=8, train_wall=229, gb_free=13.2, wall=159506
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3240, 42808])
2023-09-22 07:02:29 | INFO | train_inner | epoch 013:   2204 / 9060 loss=6.832, nll_loss=3.395, ppl=10.52, wps=5461.1, ups=0.42, wpb=12920.6, bsz=434.2, num_updates=110900, lr=9.49586e-05, gnorm=0.944, loss_scale=8, train_wall=236, gb_free=15.1, wall=159742
lprobs.size(): torch.Size([3280, 42808])
2023-09-22 07:06:17 | INFO | train_inner | epoch 013:   2304 / 9060 loss=6.73, nll_loss=3.364, ppl=10.29, wps=5684.1, ups=0.44, wpb=12960.7, bsz=419.6, num_updates=111000, lr=9.49158e-05, gnorm=0.906, loss_scale=8, train_wall=228, gb_free=14.8, wall=159970
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([738, 42808])
pred_new.size(): torch.Size([6384, 42808])
2023-09-22 07:09:51 | INFO | train_inner | epoch 013:   2404 / 9060 loss=6.711, nll_loss=3.35, ppl=10.19, wps=6050.1, ups=0.47, wpb=12943.6, bsz=425.4, num_updates=111100, lr=9.48731e-05, gnorm=0.88, loss_scale=8, train_wall=214, gb_free=13.7, wall=160184
2023-09-22 07:13:41 | INFO | train_inner | epoch 013:   2504 / 9060 loss=6.728, nll_loss=3.35, ppl=10.19, wps=5656.2, ups=0.43, wpb=13022.5, bsz=402.5, num_updates=111200, lr=9.48304e-05, gnorm=0.905, loss_scale=8, train_wall=230, gb_free=14.2, wall=160415
lprobs.size(): torch.Size([2784, 42808])
2023-09-22 07:17:28 | INFO | train_inner | epoch 013:   2604 / 9060 loss=6.677, nll_loss=3.32, ppl=9.98, wps=5723.6, ups=0.44, wpb=12960.5, bsz=413.8, num_updates=111300, lr=9.47878e-05, gnorm=0.893, loss_scale=8, train_wall=226, gb_free=14.9, wall=160641
lprobs.size(): torch.Size([3528, 42808])
2023-09-22 07:21:07 | INFO | train_inner | epoch 013:   2704 / 9060 loss=6.717, nll_loss=3.317, ppl=9.97, wps=5950.4, ups=0.46, wpb=13056.2, bsz=408, num_updates=111400, lr=9.47452e-05, gnorm=0.898, loss_scale=8, train_wall=219, gb_free=14, wall=160860
pred_new.size(): torch.Size([3375, 42808])
lprobs.size(): torch.Size([3000, 42808])
2023-09-22 07:24:51 | INFO | train_inner | epoch 013:   2804 / 9060 loss=6.738, nll_loss=3.308, ppl=9.9, wps=5811, ups=0.45, wpb=13012.2, bsz=434.5, num_updates=111500, lr=9.47027e-05, gnorm=0.893, loss_scale=8, train_wall=224, gb_free=13.9, wall=161084
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([1631, 42808])
2023-09-22 07:28:30 | INFO | train_inner | epoch 013:   2904 / 9060 loss=6.72, nll_loss=3.318, ppl=9.97, wps=5934.1, ups=0.46, wpb=13022.6, bsz=451.3, num_updates=111600, lr=9.46603e-05, gnorm=0.931, loss_scale=8, train_wall=219, gb_free=13.6, wall=161304
tensor(3282., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.403875
num_accepted / total 144 256
loss token level: tensor(8481.6426, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10848., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.403887
num_accepted / total 5 56
loss token level: tensor(9102.8896, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1894., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([375, 42808])
ter_threshold: 0.404055
num_accepted / total 8 64
loss token level: tensor(10418.4717, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2156., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([396, 42808])
pred_new.size(): torch.Size([1836, 42808])
pred_new.size(): torch.Size([4200, 42808])
pred_new.size(): torch.Size([1880, 42808])
pred_new.size(): torch.Size([5032, 42808])
pred_new.size(): torch.Size([5831, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([700, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3392, 42808])
ter_threshold: 0.404961
num_accepted / total 86 168
loss token level: tensor(9594.4629, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11728., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1584, 42808])
pred_new.size(): torch.Size([4698, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.40549799999999997
num_accepted / total 2 24
loss token level: tensor(10267.4258, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1438., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([1694, 42808])
ter_threshold: 0.40560399999999996
num_accepted / total 50 128
loss token level: tensor(9006.5625, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9536., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([3840, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2712, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.406203
num_accepted / total 414 512
loss token level: tensor(7116.7070, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9640., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4000, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([4389, 42808])
lprobs.size(): torch.Size([3416, 42808])
pred_new.size(): torch.Size([2030, 42808])
pred_new.size(): torch.Size([2697, 42808])
ter_threshold: 0.406478
num_accepted / total 77 184
loss token level: tensor(9479.1816, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5576., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4524, 42808])
ter_threshold: 0.406771
num_accepted / total 56 128
loss token level: tensor(9380.8799, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6220., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1428, 42808])
pred_new.size(): torch.Size([3825, 42808])
pred_new.size(): torch.Size([1496, 42808])
pred_new.size(): torch.Size([5580, 42808])
pred_new.size(): torch.Size([1600, 42808])
lprobs.size(): torch.Size([2432, 42808])
pred_new.size(): torch.Size([3486, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([280, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.407911
num_accepted / total 25 104
loss token level: tensor(10031.3672, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3492., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4230, 42808])
ter_threshold: 0.408132
num_accepted / total 131 224
loss token level: tensor(8908.2285, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12248., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3627, 42808])
ter_threshold: 0.408242
num_accepted / total 10 48
loss token level: tensor(9366.5273, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4948., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4400, 42808])
pred_new.size(): torch.Size([4018, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([1246, 42808])
lprobs.size(): torch.Size([2856, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6767, 42808])
pred_new.size(): torch.Size([1280, 42808])
pred_new.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1696, 42808])
pred_new.size(): torch.Size([6578, 42808])
pred_new.size(): torch.Size([1615, 42808])
pred_new.size(): torch.Size([2190, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3627, 42808])
pred_new.size(): torch.Size([1980, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([1898, 42808])
pred_new.size(): torch.Size([2916, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([2380, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.410176
num_accepted / total 3 64
loss token level: tensor(12020.9961, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(755.5000, device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5874, 42808])
ter_threshold: 0.41035499999999997
num_accepted / total 189 256
loss token level: tensor(8889.6406, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(15312., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2072, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4770, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.410852
num_accepted / total 3 48
loss token level: tensor(10589.2695, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1462., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3008, 42808])
pred_new.size(): torch.Size([3834, 42808])
ter_threshold: 0.41091099999999997
num_accepted / total 27 104
loss token level: tensor(11112.5732, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5544., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1100, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([5200, 42808])
ter_threshold: 0.41131
num_accepted / total 51 120
loss token level: tensor(9464.8213, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6332., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.411347
num_accepted / total 4 48
loss token level: tensor(9641.4033, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2108., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2574, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1824, 42808])
ter_threshold: 0.411621
num_accepted / total 24 160
loss token level: tensor(12392.3301, device='cuda:3', grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1978, 42808])
ter_threshold: 0.411621
num_accepted / total 46 128
loss token level: tensor(9872.3555, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5320., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 07:32:07 | INFO | train_inner | epoch 013:   3004 / 9060 loss=6.759, nll_loss=3.344, ppl=10.16, wps=5990.2, ups=0.46, wpb=12979.3, bsz=437.5, num_updates=111700, lr=9.46179e-05, gnorm=0.913, loss_scale=8, train_wall=216, gb_free=13.8, wall=161520
2023-09-22 07:35:50 | INFO | train_inner | epoch 013:   3104 / 9060 loss=6.912, nll_loss=3.39, ppl=10.49, wps=5857.4, ups=0.45, wpb=13039.9, bsz=437.2, num_updates=111800, lr=9.45756e-05, gnorm=0.959, loss_scale=8, train_wall=222, gb_free=15.9, wall=161743
2023-09-22 07:39:36 | INFO | train_inner | epoch 013:   3204 / 9060 loss=6.781, nll_loss=3.383, ppl=10.43, wps=5765.3, ups=0.44, wpb=13053.4, bsz=430.1, num_updates=111900, lr=9.45333e-05, gnorm=0.908, loss_scale=8, train_wall=226, gb_free=14, wall=161969
pred_new.size(): torch.Size([2175, 42808])
2023-09-22 07:43:27 | INFO | train_inner | epoch 013:   3304 / 9060 loss=6.716, nll_loss=3.286, ppl=9.75, wps=5639.1, ups=0.43, wpb=13026.3, bsz=439.9, num_updates=112000, lr=9.44911e-05, gnorm=0.893, loss_scale=8, train_wall=231, gb_free=13.4, wall=162200
2023-09-22 07:44:57 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 07:47:22 | INFO | train_inner | epoch 013:   3405 / 9060 loss=6.731, nll_loss=3.37, ppl=10.34, wps=5455.9, ups=0.43, wpb=12829.9, bsz=420, num_updates=112100, lr=9.4449e-05, gnorm=0.934, loss_scale=4, train_wall=235, gb_free=15.6, wall=162436
lprobs.size(): torch.Size([3344, 42808])
2023-09-22 07:51:01 | INFO | train_inner | epoch 013:   3505 / 9060 loss=6.632, nll_loss=3.336, ppl=10.1, wps=5916.5, ups=0.46, wpb=12927.8, bsz=404.7, num_updates=112200, lr=9.44069e-05, gnorm=0.919, loss_scale=4, train_wall=218, gb_free=14.3, wall=162654
pred_new.size(): torch.Size([3510, 42808])
2023-09-22 07:54:40 | INFO | train_inner | epoch 013:   3605 / 9060 loss=6.749, nll_loss=3.324, ppl=10.02, wps=5922.2, ups=0.46, wpb=13007.9, bsz=432.3, num_updates=112300, lr=9.43648e-05, gnorm=0.911, loss_scale=4, train_wall=219, gb_free=12.9, wall=162874
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([2665, 42808])
2023-09-22 07:58:21 | INFO | train_inner | epoch 013:   3705 / 9060 loss=6.791, nll_loss=3.361, ppl=10.27, wps=5861, ups=0.45, wpb=12944.1, bsz=425.2, num_updates=112400, lr=9.43228e-05, gnorm=0.921, loss_scale=4, train_wall=221, gb_free=13.9, wall=163095
lprobs.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([716, 42808])
2023-09-22 08:02:07 | INFO | train_inner | epoch 013:   3805 / 9060 loss=6.756, nll_loss=3.363, ppl=10.29, wps=5759.6, ups=0.44, wpb=12994.9, bsz=429.1, num_updates=112500, lr=9.42809e-05, gnorm=0.917, loss_scale=4, train_wall=225, gb_free=14.6, wall=163320
tensor(10672., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([840, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.404208
num_accepted / total 14 72
loss token level: tensor(10966.6543, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5072., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1554, 42808])
pred_new.size(): torch.Size([3162, 42808])
pred_new.size(): torch.Size([3680, 42808])
pred_new.size(): torch.Size([1020, 42808])
ter_threshold: 0.404408
num_accepted / total 156 256
loss token level: tensor(8483.6201, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11152., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2928, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2952, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.404961
num_accepted / total 85 168
loss token level: tensor(8569.8584, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11392., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2304, 42808])
ter_threshold: 0.40548399999999996
num_accepted / total 13 64
loss token level: tensor(10305.6113, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5160., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3920, 42808])
ter_threshold: 0.40551499999999996
num_accepted / total 27 64
loss token level: tensor(8961.9805, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1280, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.40560399999999996
num_accepted / total 32 96
loss token level: tensor(8288.6172, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7008., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2160, 42808])
pred_new.size(): torch.Size([4692, 42808])
ter_threshold: 0.405978
num_accepted / total 80 152
loss token level: tensor(9312.8965, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12280., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3072, 42808])
ter_threshold: 0.406076
num_accepted / total 5 40
loss token level: tensor(8718.4160, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3024., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2232, 42808])
pred_new.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.406483
num_accepted / total 78 152
loss token level: tensor(9088.5273, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12272., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.40660399999999997
num_accepted / total 15 40
loss token level: tensor(8573.2090, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9184., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([2160, 42808])
pred_new.size(): torch.Size([1240, 42808])
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([1260, 42808])
pred_new.size(): torch.Size([1500, 42808])
pred_new.size(): torch.Size([1584, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4250, 42808])
pred_new.size(): torch.Size([3741, 42808])
lprobs.size(): torch.Size([3192, 42808])
ter_threshold: 0.40764999999999996
num_accepted / total 13 64
loss token level: tensor(9022.8721, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5168., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([2376, 42808])
pred_new.size(): torch.Size([1576, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3526, 42808])
pred_new.size(): torch.Size([1265, 42808])
ter_threshold: 0.408132
num_accepted / total 54 128
loss token level: tensor(9593.0117, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10704., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3185, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([318, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6210, 42808])
pred_new.size(): torch.Size([732, 42808])
pred_new.size(): torch.Size([4290, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4422, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([1080, 42808])
pred_new.size(): torch.Size([1972, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([2184, 42808])
lprobs.size(): torch.Size([2664, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3036, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([60, 42808])
pred_new.size(): torch.Size([1360, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1725, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.41083899999999995
num_accepted / total 9 16
loss token level: tensor(6375.0430, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11664., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([4810, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3952, 42808])
pred_new.size(): torch.Size([3510, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.411686
num_accepted / total 59 152
loss token level: tensor(10713.9199, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9896., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([952, 42808])
pred_new.size(): torch.Size([3534, 42808])
pred_new.size(): torch.Size([3807, 42808])
pred_new.size(): torch.Size([1128, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4800, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4860, 42808])
pred_new.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([2353, 42808])
ter_threshold: 0.412513
num_accepted / total 26 96
loss token level: tensor(9257.3594, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6672., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.412528
num_accepted / total 43 128
loss token level: tensor(8970.0488, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: ter_threshold: 0.412513
num_accepted / total 61 256
loss token level: tensor(7807.6079, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3000., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.41256
num_accepted / total 80 232
loss token level: tensor(10705.6348, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6748., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 08:05:39 | INFO | train_inner | epoch 013:   3905 / 9060 loss=6.711, nll_loss=3.355, ppl=10.23, wps=6130.5, ups=0.47, wpb=13012.8, bsz=418.5, num_updates=112600, lr=9.4239e-05, gnorm=0.907, loss_scale=4, train_wall=212, gb_free=15, wall=163533
pred_new.size(): torch.Size([6622, 42808])
2023-09-22 08:09:25 | INFO | train_inner | epoch 013:   4005 / 9060 loss=6.788, nll_loss=3.357, ppl=10.24, wps=5709.8, ups=0.44, wpb=12889.6, bsz=441.9, num_updates=112700, lr=9.41972e-05, gnorm=0.93, loss_scale=4, train_wall=225, gb_free=15.7, wall=163758
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([3213, 42808])
2023-09-22 08:13:07 | INFO | train_inner | epoch 013:   4105 / 9060 loss=6.667, nll_loss=3.261, ppl=9.59, wps=5794.4, ups=0.45, wpb=12878.1, bsz=462.2, num_updates=112800, lr=9.41554e-05, gnorm=0.886, loss_scale=4, train_wall=222, gb_free=15.6, wall=163981
pred_new.size(): torch.Size([3525, 42808])
2023-09-22 08:16:50 | INFO | train_inner | epoch 013:   4205 / 9060 loss=6.676, nll_loss=3.318, ppl=9.98, wps=5855.6, ups=0.45, wpb=13077.3, bsz=424.5, num_updates=112900, lr=9.41137e-05, gnorm=0.934, loss_scale=4, train_wall=223, gb_free=14.8, wall=164204
2023-09-22 08:20:36 | INFO | train_inner | epoch 013:   4305 / 9060 loss=6.764, nll_loss=3.345, ppl=10.16, wps=5802.7, ups=0.44, wpb=13107.5, bsz=425.8, num_updates=113000, lr=9.40721e-05, gnorm=0.909, loss_scale=4, train_wall=226, gb_free=14.3, wall=164430
2023-09-22 08:24:32 | INFO | train_inner | epoch 013:   4405 / 9060 loss=6.752, nll_loss=3.308, ppl=9.91, wps=5483.1, ups=0.42, wpb=12906.1, bsz=434.4, num_updates=113100, lr=9.40305e-05, gnorm=0.953, loss_scale=4, train_wall=235, gb_free=13.5, wall=164665
lprobs.size(): torch.Size([3360, 42808])
2023-09-22 08:28:17 | INFO | train_inner | epoch 013:   4505 / 9060 loss=6.755, nll_loss=3.326, ppl=10.03, wps=5758, ups=0.44, wpb=12998.8, bsz=446, num_updates=113200, lr=9.39889e-05, gnorm=0.917, loss_scale=4, train_wall=225, gb_free=13.1, wall=164891
2023-09-22 08:32:03 | INFO | train_inner | epoch 013:   4605 / 9060 loss=6.74, nll_loss=3.312, ppl=9.93, wps=5744.1, ups=0.44, wpb=12964, bsz=445.8, num_updates=113300, lr=9.39475e-05, gnorm=0.912, loss_scale=4, train_wall=225, gb_free=13.8, wall=165117
lprobs.size(): torch.Size([3552, 42808])
2023-09-22 08:35:37 | INFO | train_inner | epoch 013:   4705 / 9060 loss=6.762, nll_loss=3.401, ppl=10.56, wps=6063.2, ups=0.47, wpb=12955.6, bsz=428.2, num_updates=113400, lr=9.3906e-05, gnorm=0.907, loss_scale=4, train_wall=213, gb_free=14.4, wall=165330
pred_new.size(): torch.Size([7750, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-22 08:39:24 | INFO | train_inner | epoch 013:   4805 / 9060 loss=6.819, nll_loss=3.349, ppl=10.19, wps=5729.2, ups=0.44, wpb=13041.7, bsz=428.5, num_updates=113500, lr=9.38647e-05, gnorm=0.926, loss_scale=4, train_wall=227, gb_free=13.9, wall=165558
pred_new.size(): torch.Size([1710, 42808])
ter_threshold: 0.413587
num_accepted / total 17 64
loss token level: tensor(9089.6953, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7468., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 08:43:08 | INFO | train_inner | epoch 013:   4905 / 9060 loss=6.829, nll_loss=3.394, ppl=10.51, wps=5811, ups=0.45, wpb=13001.3, bsz=448.7, num_updates=113600, lr=9.38233e-05, gnorm=0.925, loss_scale=4, train_wall=223, gb_free=13.3, wall=165782
pred_new.size(): torch.Size([2442, 42808])
2023-09-22 08:46:41 | INFO | train_inner | epoch 013:   5005 / 9060 loss=6.767, nll_loss=3.376, ppl=10.38, wps=6092.1, ups=0.47, wpb=12965, bsz=437, num_updates=113700, lr=9.37821e-05, gnorm=0.895, loss_scale=4, train_wall=213, gb_free=14.1, wall=165994
pred_new.size(): torch.Size([4810, 42808])
2023-09-22 08:50:22 | INFO | train_inner | epoch 013:   5105 / 9060 loss=6.842, nll_loss=3.38, ppl=10.41, wps=5930.4, ups=0.45, wpb=13081.5, bsz=440.4, num_updates=113800, lr=9.37408e-05, gnorm=0.922, loss_scale=4, train_wall=220, gb_free=14.1, wall=166215
2023-09-22 08:54:04 | INFO | train_inner | epoch 013:   5205 / 9060 loss=6.736, nll_loss=3.333, ppl=10.08, wps=5848.3, ups=0.45, wpb=13002.9, bsz=420.2, num_updates=113900, lr=9.36997e-05, gnorm=0.896, loss_scale=4, train_wall=222, gb_free=13.2, wall=166437
pred_new.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([2520, 42808])
2023-09-22 08:57:52 | INFO | train_inner | epoch 013:   5305 / 9060 loss=6.809, nll_loss=3.362, ppl=10.29, wps=5713.4, ups=0.44, wpb=13054.3, bsz=435.5, num_updates=114000, lr=9.36586e-05, gnorm=0.925, loss_scale=4, train_wall=228, gb_free=14, wall=166666
pred_new.size(): torch.Size([6600, 42808])
pred_new.size(): torch.Size([3510, 42808])
2023-09-22 09:01:33 | INFO | train_inner | epoch 013:   5405 / 9060 loss=6.751, nll_loss=3.311, ppl=9.92, wps=5889.2, ups=0.45, wpb=13009.5, bsz=432.2, num_updates=114100, lr=9.36175e-05, gnorm=0.919, loss_scale=4, train_wall=221, gb_free=13.9, wall=166887
pred_new.size(): torch.Size([2898, 42808])
2023-09-22 09:05:21 | INFO | train_inner | epoch 013:   5505 / 9060 loss=6.805, nll_loss=3.384, ppl=10.44, wps=5700.2, ups=0.44, wpb=12965.9, bsz=421.5, num_updates=114200, lr=9.35765e-05, gnorm=0.936, loss_scale=4, train_wall=227, gb_free=13.6, wall=167114
lprobs.size(): torch.Size([2784, 42808])
pred_new.size(): torch.Size([5375, 42808])
2023-09-22 09:08:52 | INFO | train_inner | epoch 013:   5605 / 9060 loss=6.729, nll_loss=3.347, ppl=10.17, wps=6127.1, ups=0.47, wpb=12918.2, bsz=438.6, num_updates=114300, lr=9.35356e-05, gnorm=1.01, loss_scale=4, train_wall=211, gb_free=14.8, wall=167325
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 09:12:40 | INFO | train_inner | epoch 013:   5705 / 9060 loss=6.828, nll_loss=3.372, ppl=10.35, wps=5707.5, ups=0.44, wpb=13034.7, bsz=430.5, num_updates=114400, lr=9.34947e-05, gnorm=0.935, loss_scale=4, train_wall=228, gb_free=15.1, wall=167553
2023-09-22 09:16:29 | INFO | train_inner | epoch 013:   5805 / 9060 loss=6.606, nll_loss=3.278, ppl=9.7, wps=5617.9, ups=0.44, wpb=12863.2, bsz=406.6, num_updates=114500, lr=9.34539e-05, gnorm=0.886, loss_scale=4, train_wall=229, gb_free=14.7, wall=167782
pred_new.size(): torch.Size([5292, 42808])
pred_new.size(): torch.Size([4128, 42808])
2023-09-22 09:20:09 | INFO | train_inner | epoch 013:   5905 / 9060 loss=6.738, nll_loss=3.368, ppl=10.32, wps=5920.1, ups=0.45, wpb=13046.3, bsz=436.3, num_updates=114600, lr=9.34131e-05, gnorm=0.921, loss_scale=4, train_wall=220, gb_free=14.5, wall=168003
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 09:23:44 | INFO | train_inner | epoch 013:   6005 / 9060 loss=6.62, nll_loss=3.333, ppl=10.08, wps=6007.8, ups=0.47, wpb=12914.5, bsz=403.8, num_updates=114700, lr=9.33724e-05, gnorm=0.896, loss_scale=4, train_wall=215, gb_free=15, wall=168218
pred_new.size(): torch.Size([6525, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-22 09:27:23 | INFO | train_inner | epoch 013:   6105 / 9060 loss=6.736, nll_loss=3.333, ppl=10.07, wps=5957.2, ups=0.46, wpb=13047.2, bsz=424.3, num_updates=114800, lr=9.33317e-05, gnorm=0.905, loss_scale=4, train_wall=219, gb_free=14.6, wall=168437
2023-09-22 09:31:07 | INFO | train_inner | epoch 013:   6205 / 9060 loss=6.808, nll_loss=3.396, ppl=10.53, wps=5790.7, ups=0.45, wpb=12928.4, bsz=409.4, num_updates=114900, lr=9.32911e-05, gnorm=0.956, loss_scale=4, train_wall=223, gb_free=14.3, wall=168660
pred_new.size(): torch.Size([4030, 42808])
2023-09-22 09:34:58 | INFO | train_inner | epoch 013:   6305 / 9060 loss=6.77, nll_loss=3.344, ppl=10.16, wps=5633.8, ups=0.43, wpb=13063.2, bsz=431.7, num_updates=115000, lr=9.32505e-05, gnorm=0.938, loss_scale=4, train_wall=232, gb_free=15.2, wall=168892
lprobs.size(): torch.Size([3328, 42808])
2023-09-22 09:38:56 | INFO | train_inner | epoch 013:   6405 / 9060 loss=6.89, nll_loss=3.438, ppl=10.84, wps=5461.9, ups=0.42, wpb=12978.9, bsz=422.8, num_updates=115100, lr=9.321e-05, gnorm=0.966, loss_scale=4, train_wall=237, gb_free=14.5, wall=169130
2023-09-22 09:42:33 | INFO | train_inner | epoch 013:   6505 / 9060 loss=6.772, nll_loss=3.341, ppl=10.14, wps=6028.6, ups=0.46, wpb=13063.4, bsz=436.5, num_updates=115200, lr=9.31695e-05, gnorm=0.909, loss_scale=4, train_wall=216, gb_free=13.9, wall=169346
loss token level: tensor(10005.6621, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8944., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([1680, 42808])
ter_threshold: 0.40753
num_accepted / total 19 128
loss token level: tensor(12688.7871, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3648., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([4080, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.408242
num_accepted / total 9 48
loss token level: tensor(8994.8213, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4336., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3395, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.408613
num_accepted / total 36 80
loss token level: tensor(9379.2139, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11816., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.408725
num_accepted / total 0 64
loss token level: tensor(9508.5703, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: 0
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([7220, 42808])
pred_new.size(): torch.Size([1728, 42808])
pred_new.size(): torch.Size([2870, 42808])
pred_new.size(): torch.Size([2275, 42808])
pred_new.size(): torch.Size([3465, 42808])
ter_threshold: 0.40932
num_accepted / total 10 64
loss token level: tensor(9895.7031, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2222., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3744, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2432, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([4158, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([3720, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.410144
num_accepted / total 11 56
loss token level: tensor(10282.6914, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5020., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.410176
num_accepted / total 23 64
loss token level: tensor(8648.1055, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5296., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4505, 42808])
ter_threshold: 0.41035499999999997
num_accepted / total 75 128
loss token level: tensor(9074.6318, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14288., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3212, 42808])
pred_new.size(): torch.Size([3920, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3224, 42808])
pred_new.size(): torch.Size([3843, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3969, 42808])
ter_threshold: 0.41091099999999997
num_accepted / total 27 96
loss token level: tensor(11108.2109, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6952., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([3680, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.411347
num_accepted / total 14 48
loss token level: tensor(8137.3306, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6808., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([1170, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([1764, 42808])
ter_threshold: 0.411621
num_accepted / total 110 256
loss token level: tensor(8399.7383, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4944., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([560, 42808])
lprobs.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([2052, 42808])
pred_new.size(): torch.Size([1620, 42808])
pred_new.size(): torch.Size([402, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2500, 42808])
lprobs.size(): torch.Size([2904, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.412489
num_accepted / total 10 40
loss token level: tensor(8492.4902, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6088., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.412528
num_accepted / total 48 104
loss token level: tensor(8317.5566, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10784., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3150, 42808])
ter_threshold: 0.41256
num_accepted / total 54 128
loss token level: tensor(9297.2891, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10224., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2697, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.412977
num_accepted / total 6 48
loss token level: tensor(10212.5664, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1932., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1716, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3256, 42808])
ter_threshold: 0.413587
num_accepted / total 22 64
loss token level: tensor(9412.5605, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9600., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.413715
num_accepted / total 23 80
loss token level: tensor(10598.4590, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4276., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.413805
num_accepted / total 38 104
loss token level: tensor(9686.3760, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9352., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([7383, 42808])
lprobs.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([2337, 42808])
pred_new.size(): torch.Size([7301, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3296, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3075, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3366, 42808])
pred_new.size(): torch.Size([3103, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6045, 42808])
ter_threshold: 0.414964
num_accepted / total 10 56
loss token level: tensor(10503.9531, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2788., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.415187
num_accepted / total 35 88
loss token level: tensor(9242.7285, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10064., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.415216
num_accepted / total 27 64
loss token level: tensor(9412.3223, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level:ter_threshold: 0.415293
num_accepted / total 4 88
loss token level: tensor(13054.3896, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(712., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 09:46:21 | INFO | train_inner | epoch 013:   6605 / 9060 loss=6.756, nll_loss=3.377, ppl=10.39, wps=5673.6, ups=0.44, wpb=12942.2, bsz=435.1, num_updates=115300, lr=9.31291e-05, gnorm=0.997, loss_scale=4, train_wall=228, gb_free=15.2, wall=169574
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3000, 42808])
2023-09-22 09:49:56 | INFO | train_inner | epoch 013:   6705 / 9060 loss=6.767, nll_loss=3.358, ppl=10.25, wps=5992.1, ups=0.46, wpb=12897.2, bsz=419, num_updates=115400, lr=9.30887e-05, gnorm=0.914, loss_scale=4, train_wall=215, gb_free=14, wall=169790
2023-09-22 09:53:27 | INFO | train_inner | epoch 013:   6805 / 9060 loss=6.72, nll_loss=3.351, ppl=10.21, wps=6202.5, ups=0.48, wpb=13056.1, bsz=429.1, num_updates=115500, lr=9.30484e-05, gnorm=0.9, loss_scale=4, train_wall=210, gb_free=14.4, wall=170000
pred_new.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([1462, 42808])
pred_new.size(): torch.Size([2580, 42808])
ter_threshold: 0.41559
num_accepted / total 51 136
loss token level: tensor(8990.4258, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9056., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 09:57:19 | INFO | train_inner | epoch 013:   6905 / 9060 loss=6.836, nll_loss=3.381, ppl=10.42, wps=5584.4, ups=0.43, wpb=12989.8, bsz=435.8, num_updates=115600, lr=9.30082e-05, gnorm=0.937, loss_scale=4, train_wall=232, gb_free=13.9, wall=170233
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 10:01:06 | INFO | train_inner | epoch 013:   7005 / 9060 loss=6.698, nll_loss=3.337, ppl=10.1, wps=5757, ups=0.44, wpb=13068.6, bsz=414.6, num_updates=115700, lr=9.2968e-05, gnorm=0.917, loss_scale=4, train_wall=227, gb_free=14.4, wall=170460
pred_new.size(): torch.Size([3498, 42808])
2023-09-22 10:04:58 | INFO | train_inner | epoch 013:   7105 / 9060 loss=6.83, nll_loss=3.369, ppl=10.33, wps=5583.2, ups=0.43, wpb=12927.8, bsz=438, num_updates=115800, lr=9.29278e-05, gnorm=0.933, loss_scale=4, train_wall=231, gb_free=14, wall=170691
pred_new.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([2883, 42808])
lprobs.size(): torch.Size([3416, 42808])
2023-09-22 10:08:35 | INFO | train_inner | epoch 013:   7205 / 9060 loss=6.73, nll_loss=3.344, ppl=10.15, wps=5958.8, ups=0.46, wpb=12945.5, bsz=444.8, num_updates=115900, lr=9.28877e-05, gnorm=0.914, loss_scale=4, train_wall=217, gb_free=14.5, wall=170908
ter_threshold: 0.41596099999999997
num_accepted / total 9 72
loss token level: tensor(11346.1641, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3480., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1440, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 10:12:09 | INFO | train_inner | epoch 013:   7305 / 9060 loss=6.824, nll_loss=3.402, ppl=10.57, wps=6092.3, ups=0.47, wpb=13010.7, bsz=437.4, num_updates=116000, lr=9.28477e-05, gnorm=0.918, loss_scale=4, train_wall=213, gb_free=13.1, wall=171122
lprobs.size(): torch.Size([2880, 42808])
2023-09-22 10:15:42 | INFO | train_inner | epoch 013:   7405 / 9060 loss=6.684, nll_loss=3.329, ppl=10.05, wps=6011, ups=0.47, wpb=12827.9, bsz=426.6, num_updates=116100, lr=9.28077e-05, gnorm=0.931, loss_scale=4, train_wall=213, gb_free=14.2, wall=171335
pred_new.size(): torch.Size([4257, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-22 10:19:23 | INFO | train_inner | epoch 013:   7505 / 9060 loss=6.755, nll_loss=3.348, ppl=10.18, wps=5906.1, ups=0.45, wpb=13034.5, bsz=430.7, num_updates=116200, lr=9.27677e-05, gnorm=0.927, loss_scale=8, train_wall=220, gb_free=15, wall=171556
pred_new.size(): torch.Size([2400, 42808])
2023-09-22 10:23:11 | INFO | train_inner | epoch 013:   7605 / 9060 loss=6.749, nll_loss=3.356, ppl=10.24, wps=5662.3, ups=0.44, wpb=12949.5, bsz=432.7, num_updates=116300, lr=9.27278e-05, gnorm=0.944, loss_scale=8, train_wall=228, gb_free=14.7, wall=171785
lprobs.size(): torch.Size([3360, 42808])
2023-09-22 10:27:00 | INFO | train_inner | epoch 013:   7705 / 9060 loss=6.701, nll_loss=3.352, ppl=10.21, wps=5581.4, ups=0.44, wpb=12778.5, bsz=426.2, num_updates=116400, lr=9.2688e-05, gnorm=0.931, loss_scale=8, train_wall=229, gb_free=13.7, wall=172014
2023-09-22 10:30:48 | INFO | train_inner | epoch 013:   7805 / 9060 loss=6.738, nll_loss=3.335, ppl=10.09, wps=5697.3, ups=0.44, wpb=12996, bsz=460.3, num_updates=116500, lr=9.26482e-05, gnorm=0.923, loss_scale=8, train_wall=228, gb_free=15.8, wall=172242
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.41658399999999995
num_accepted / total 11 24
loss token level: tensor(7215.0161, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10208., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 10:34:27 | INFO | train_inner | epoch 013:   7905 / 9060 loss=6.854, nll_loss=3.418, ppl=10.69, wps=5928.7, ups=0.46, wpb=12936.9, bsz=430.1, num_updates=116600, lr=9.26085e-05, gnorm=0.96, loss_scale=8, train_wall=218, gb_free=15.4, wall=172460
2023-09-22 10:38:23 | INFO | train_inner | epoch 013:   8005 / 9060 loss=6.796, nll_loss=3.383, ppl=10.44, wps=5509.5, ups=0.42, wpb=13037.8, bsz=435.6, num_updates=116700, lr=9.25688e-05, gnorm=0.92, loss_scale=8, train_wall=236, gb_free=15.4, wall=172697
pred_new.size(): torch.Size([6954, 42808])
ter_threshold: 0.416722
num_accepted / total 84 160
loss token level: tensor(9432.0156, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7260., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 10:42:09 | INFO | train_inner | epoch 013:   8105 / 9060 loss=6.781, nll_loss=3.352, ppl=10.21, wps=5763.3, ups=0.44, wpb=12990.2, bsz=441, num_updates=116800, lr=9.25292e-05, gnorm=0.91, loss_scale=8, train_wall=225, gb_free=13.4, wall=172922
pred_new.size(): torch.Size([1908, 42808])
lprobs.size(): torch.Size([3400, 42808])
2023-09-22 10:45:54 | INFO | train_inner | epoch 013:   8205 / 9060 loss=6.757, nll_loss=3.353, ppl=10.22, wps=5768.5, ups=0.44, wpb=13006.4, bsz=427.4, num_updates=116900, lr=9.24896e-05, gnorm=0.908, loss_scale=8, train_wall=225, gb_free=14.8, wall=173148
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.41698999999999997
num_accepted / total 22 80
loss token level: tensor(9102.6875, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6568., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 10:49:50 | INFO | train_inner | epoch 013:   8305 / 9060 loss=6.741, nll_loss=3.32, ppl=9.98, wps=5478, ups=0.42, wpb=12937, bsz=436, num_updates=117000, lr=9.245e-05, gnorm=0.918, loss_scale=8, train_wall=236, gb_free=14.1, wall=173384
pred_new.size(): torch.Size([2415, 42808])
lprobs.size(): torch.Size([3416, 42808])
2023-09-22 10:53:45 | INFO | train_inner | epoch 013:   8405 / 9060 loss=6.742, nll_loss=3.362, ppl=10.28, wps=5544.6, ups=0.43, wpb=12994.2, bsz=427.8, num_updates=117100, lr=9.24105e-05, gnorm=0.928, loss_scale=8, train_wall=234, gb_free=14.8, wall=173618
pred_new.size(): torch.Size([1820, 42808])
pred_new.size(): torch.Size([1044, 42808])
2023-09-22 10:57:27 | INFO | train_inner | epoch 013:   8505 / 9060 loss=6.681, nll_loss=3.345, ppl=10.16, wps=5789, ups=0.45, wpb=12888, bsz=416.6, num_updates=117200, lr=9.23711e-05, gnorm=0.92, loss_scale=8, train_wall=222, gb_free=13.8, wall=173841
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3400, 42808])
2023-09-22 11:01:01 | INFO | train_inner | epoch 013:   8605 / 9060 loss=6.875, nll_loss=3.436, ppl=10.82, wps=6073.1, ups=0.47, wpb=12962, bsz=428.6, num_updates=117300, lr=9.23317e-05, gnorm=0.934, loss_scale=8, train_wall=213, gb_free=14.4, wall=174054
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([2030, 42808])
pred_new.size(): torch.Size([1596, 42808])
2023-09-22 11:04:50 | INFO | train_inner | epoch 013:   8705 / 9060 loss=6.826, nll_loss=3.409, ppl=10.63, wps=5666, ups=0.44, wpb=13004.1, bsz=428.2, num_updates=117400, lr=9.22924e-05, gnorm=0.928, loss_scale=8, train_wall=229, gb_free=13.8, wall=174284
ter_threshold: 0.417425
num_accepted / total 19 104
loss token level: tensor(8573.3174, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2230., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1216, 42808])
2023-09-22 11:08:49 | INFO | train_inner | epoch 013:   8805 / 9060 loss=6.642, nll_loss=3.303, ppl=9.87, wps=5430.3, ups=0.42, wpb=12973.3, bsz=437, num_updates=117500, lr=9.22531e-05, gnorm=0.898, loss_scale=8, train_wall=239, gb_free=14.1, wall=174523
ter_threshold: 0.41759199999999996
num_accepted / total 0 8
loss token level: tensor(6794.3223, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: 0
2023-09-22 11:12:52 | INFO | train_inner | epoch 013:   8905 / 9060 loss=6.807, nll_loss=3.384, ppl=10.44, wps=5367.5, ups=0.41, wpb=13022.9, bsz=419.4, num_updates=117600, lr=9.22139e-05, gnorm=0.929, loss_scale=8, train_wall=242, gb_free=12.9, wall=174765
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([3672, 42808])
2023-09-22 11:16:33 | INFO | train_inner | epoch 013:   9005 / 9060 loss=6.775, nll_loss=3.349, ppl=10.19, wps=5883.9, ups=0.45, wpb=13041.6, bsz=438.3, num_updates=117700, lr=9.21747e-05, gnorm=0.93, loss_scale=8, train_wall=221, gb_free=13.9, wall=174987
pred_new.size(): torch.Size([6895, 42808])
pred_new.size(): torch.Size([2730, 42808])
2023-09-22 11:18:47 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-22 11:18:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 11:18:48 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-22 11:18:48 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-22 11:18:49 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-22 11:18:49 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-22 11:18:49 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-22 11:18:49 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-22 11:18:50 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente vertraulich behandelt.
2023-09-22 11:18:50 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-22 11:18:50 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-22 11:18:50 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-22 11:18:51 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein ravierender Erfolg.
2023-09-22 11:18:51 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-22 11:18:51 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches Neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-22 11:18:51 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-22 11:18:52 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, was wir respektieren.
2023-09-22 11:18:52 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-22 11:18:52 | INFO | fairseq.tasks.translation | example hypothesis: Das Chatmodul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-22 11:18:52 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-22 11:18:53 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales Fernsehen und Internetzugang, die sowohl für Geschäftsreisende als auch für Urlauber attraktiv sind.
2023-09-22 11:18:53 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-22 11:18:54 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-22 11:18:54 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-22 11:18:54 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 11:18:54 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 11:18:55 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU insgesamt enorme Mengen an Energie verschwendet.
2023-09-22 11:18:55 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-22 11:18:55 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin enthält einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-22 11:18:55 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-22 11:18:56 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Haltungsänderung in Kürze auch im Haushalt der Union niederschlagen.
2023-09-22 11:18:56 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-22 11:18:56 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Produzenten als auch für die Agrarindustrie ist inakzeptabel.
2023-09-22 11:18:56 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-22 11:18:57 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-22 11:18:57 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-22 11:18:57 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-22 11:18:57 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-22 11:18:58 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-22 11:18:58 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-22 11:18:59 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-22 11:18:59 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-22 11:18:59 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-22 11:18:59 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-22 11:19:00 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-22 11:19:00 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-22 11:19:00 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-22 11:19:00 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-22 11:19:01 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu bringen, Eindrücke über die Qualität Ihrer Dienstleistungen und Produkte zu machen.
2023-09-22 11:19:01 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-22 11:19:01 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-22 11:19:01 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-22 11:19:02 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-22 11:19:02 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-22 11:19:02 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-22 11:19:02 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-22 11:19:03 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart verfügt über zwei Standorte in einem Umkreis von etwa 8 km vom Strip entfernt.
2023-09-22 11:19:03 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-22 11:19:04 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-22 11:19:04 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-22 11:19:04 | INFO | fairseq.tasks.translation | example hypothesis: HearDis! bietet Ihnen daher akustisch, interaktiv oder schriftlich die Realisierung von Klanghandbüchern an.
2023-09-22 11:19:04 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-22 11:19:05 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-22 11:19:05 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-22 11:19:05 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer internen Unterstützung aufbauen, aber sie kann sich bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen.
2023-09-22 11:19:05 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-22 11:19:06 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Ausreise Zugang zu dem von ihnen bezahlten Geld in die europäischen Sozialversicherungssysteme haben.
2023-09-22 11:19:06 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-22 11:19:07 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-22 11:19:07 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-22 11:19:07 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, für einige Formate gibt es leider keine freie Alternative, die auf allen Computerplattformen läuft.
2023-09-22 11:19:07 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-22 11:19:08 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie er Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-22 11:19:08 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-22 11:19:09 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Kernelemente seiner Agenda.
2023-09-22 11:19:09 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-22 11:19:09 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-22 11:19:09 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-22 11:19:10 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-22 11:19:10 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-22 11:19:10 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum sich diese Kriterien auf die Anwendung nur innerhalb der Grenzen Europas beschränken sollten.
2023-09-22 11:19:10 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-22 11:19:11 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-22 11:19:11 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-22 11:19:12 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens im Prinzip mit den Vereinigten Staaten abgeben müssen.
2023-09-22 11:19:12 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-22 11:19:12 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder spezielle Edition - unser breites Sortiment an PlastikBabyartikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-22 11:19:12 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-22 11:19:13 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 11:19:13 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 11:19:14 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Bekanntwerden dieser AGB über Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-22 11:19:14 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-22 11:19:14 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht hat und die Notwendigkeit institutioneller Veränderungen erkannt hat, die sie im Bereich der Außenpolitik und Verteidigung stärker präsent sein muss.
2023-09-22 11:19:14 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-22 11:19:15 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden geschaffen, mit Produktnachrichten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-22 11:19:15 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-22 11:19:16 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die wesentlichen Fortschritte anerkennen, die bei der Prüfung aller Fragen erzielt wurden, die jetzt zur Diskussion stehen, und die etwas knapp zwei Jahre alt sind, die neue transatlantische Agenda.
2023-09-22 11:19:16 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-22 11:19:16 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus gesenkten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-22 11:19:16 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-22 11:19:17 | INFO | fairseq.tasks.translation | example hypothesis: Einmal mehr ist es dem Berichterstatter gelungen, bisweilen unterschiedliche Ansichten und Beiträge zusammenzufassen und sie - wie ich sagen würde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 11:19:17 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 11:19:18 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Einbaugeräten mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-22 11:19:18 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-22 11:19:18 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-22 11:19:18 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-22 11:19:19 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und unseren Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-22 11:19:19 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-22 11:19:20 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-22 11:19:20 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-22 11:19:21 | INFO | fairseq.tasks.translation | example hypothesis: La final des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-22 11:19:21 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-22 11:19:21 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-22 11:19:21 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-22 11:19:22 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-22 11:19:22 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-22 11:19:23 | INFO | fairseq.tasks.translation | example hypothesis: Im Rahmen dieser Notsituation gibt es jedoch noch einen weiteren: die Notsituation, an der die Kinder, der schwächste Teil der Bevölkerung, die keine Familie, keinen Schutz und keinen Staat haben.
2023-09-22 11:19:23 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-22 11:19:23 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis der Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen.
2023-09-22 11:19:23 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-22 11:19:24 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, nicht erst innerhalb des Ersten realisiert wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-22 11:19:24 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-22 11:19:25 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher entscheidend, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in ihrer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren zur Wählerregistrierung wieder zu öffnen.
2023-09-22 11:19:25 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-22 11:19:25 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit geben, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-22 11:19:25 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-22 11:19:26 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java-Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit garantieren (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-22 11:19:26 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-22 11:19:27 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für die Klärung des Anhangs.
2023-09-22 11:19:27 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-22 11:19:27 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-22 11:19:27 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-22 11:19:28 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe vor kurzem an einer Debatte über das irische öffentlich-rechtliche Radio RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben senken und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-22 11:19:28 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-22 11:19:29 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-22 11:19:29 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-22 11:19:30 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas wie die Senkung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-22 11:19:30 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-22 11:19:30 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen.
2023-09-22 11:19:30 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-22 11:19:31 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-22 11:19:31 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-22 11:19:32 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, bedeutet, zu naturalisieren und zu mystizieren, was eine bestimmte Art von Vertragsbeziehung zwischen Einzelpersonen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Bedrohung, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-22 11:19:32 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-22 11:19:33 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn zum Beispiel die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-22 11:19:33 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-22 11:19:33 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der spaßigsten Autos unter 50.000 $und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-22 11:19:33 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-22 11:19:34 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für seinen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte und gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-22 11:19:34 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-22 11:19:35 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrillter Hecht, Forelle mit Mandeln.
2023-09-22 11:19:35 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-22 11:19:36 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, einen Gesamtüberblick zu geben, der es uns ermöglicht, die verschiedenen Fragen eingehender zu behandeln und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-22 11:19:36 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-22 11:19:36 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, stimmten überein, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-22 11:19:36 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-22 11:19:37 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wenn es Arbeitslosigkeit gibt, wenn die bestehenden Arbeitsplätze bedroht sind und die Wettbewerbsfähigkeit aufgrund von makroökonomischen Strategien, steuerlichen Maßnahmen und Zwängen, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-22 11:19:37 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-22 11:19:38 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text übernommen hat.
2023-09-22 11:19:38 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-22 11:19:39 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Folgen für den Rechts- und Rechtsbereich, wodurch Norwegen und Island Länder werden, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen gelten werden.
2023-09-22 11:19:39 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-22 11:19:40 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schichtboot durch den Mississippi fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein.
2023-09-22 11:19:40 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-22 11:19:41 | INFO | fairseq.tasks.translation | example hypothesis: Praktisch harmonisiert die Richtlinie die Definition der durch Schiffe verursachten Verschmutzung durch Einzelpersonen oder juristische Personen, den Umfang der Antwort und die Strafbarkeit der Sanktionen, die im Falle solcher von Einzelpersonen begangenen Verletzungen angewendet werden können.
2023-09-22 11:19:41 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-22 11:19:42 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falization und Vincent Reynaud wurden nämlich verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner geleistet und eine Gruppe von Bergregionen gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das jedes Prinzip der Demokratie missachtet.......
2023-09-22 11:19:42 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-22 11:19:42 | INFO | fairseq.tasks.translation | example hypothesis: Das Hotel bietet einen Concierge-Service, einen Friseur- und Schönheitssalon, einen Transport- und Sightseeing-Service, einen Wechselaustausch, kostenfreie Shoeshine und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-22 11:19:42 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-22 11:19:43 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, Ehefrau von König D. João II., und bekannt durch ihre Keramiken international bekannt für ihre bildhaften und satirischen Werke ist es auch einen Besuch wert.
2023-09-22 11:19:43 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-22 11:19:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um einen Fall guter prowestlicher Seite und der Befürworter des früheren Regimes auf der einen Seite handelt - das ist ebenfalls verwerflich, da die Rollen aller jetzt und davor bekannt sind.
2023-09-22 11:19:44 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-22 11:19:45 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich muss darauf hinweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise einbezogen werden, und das ist sicherlich ein Punkt, der irgendwie einbezogen werden sollte.
2023-09-22 11:19:45 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-22 11:19:46 | INFO | fairseq.tasks.translation | example hypothesis: (4) Soweit Informationen außerhalb einer Aktionärsversammlung einem Aktionär aus Gründen seines Status als Aktionär zur Verfügung gestellt wurden, werden diese Informationen auf Verlangen jedem anderen Aktionär in der Aktionärsversammlung zur Verfügung gestellt, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Beurteilung eines Tagesordnungspunktes zu ermöglichen.
2023-09-22 11:19:46 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-22 11:19:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Milliarden Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren fließen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr elendes Leben führen.
2023-09-22 11:19:47 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-22 11:19:48 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - denn sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder die NATO hätten an diesem Kriegshandlung beteiligt sein können -, bei der Information zu helfen, die es keinen Grund mehr gibt, geheim, versteckt oder geheim zu halten, damit wir die Fakten ans Licht bringen können und die ganze Wahrheit ans Licht bringen können.
2023-09-22 11:19:48 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-22 11:19:49 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Berliner Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmanslust und 30 Fahrminuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 11:19:49 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 11:19:50 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter Thales in Frankreich und unserer Business Unit Defence Electronics und Indra in Spanien wird die Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die modernen außerbörslichen Plattformen nie erreichen können.
2023-09-22 11:19:50 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-22 11:19:50 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar machen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte aus dem Markt zu nehmen, die ein ernsthaftes Risiko darstellen, nicht nur für den Binnenverbrauch, sondern auch auf dem globalen Markt, denn solche Produkte können leicht recycelt werden, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt................ wie Frau González Álvarez in ihrem neuen Änderungsantrag
2023-09-22 11:19:50 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-22 11:19:51 | INFO | fairseq.tasks.translation | example hypothesis: Unter der direkten Verschwörung der Moderne und Postmoderne oder der klaren Opposition reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und anhaltende Spannung jener beiden ästhetischen Politik anerkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die die Kunst als solche identifizierbar machen - jene beiden Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führt.
2023-09-22 11:19:51 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-22 11:19:52 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Aussprachen und angesichts der Ansichten, die Sie mir gegeben haben und die das, was ich soeben gesagt habe, eindeutig weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen unsere Debatten führen, und wenn die vierzig Petenten nicht anwesend sind, werde ich bei der Abstimmung nicht beantragen, die Beschlußfähigkeit zu prüfen. Wenn die vierzig Petenten nicht anwesend sind, werde ich nicht beantragen, die Beschlußfähigkeit zu prüfen.
2023-09-22 11:19:52 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-22 11:19:54 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Grundsatzes nie akzeptiert haben, dann sind es paradoxerweise gerade sie, die, wie kaum jemand weiß, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem nationale Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen. Aber ohne das Ziel, eine einheitliche Kultur zu schaffen, aber ohne die Entwicklung einer ethnischen, religiösen und kulturellen Vielfalt zu
2023-09-22 11:19:54 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-22 11:19:55 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Weise als hybride Form veröffentlicht und für H-Soz-u-Kult und über Mailinglisten sowie die Webseiten des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt.
2023-09-22 11:19:55 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-22 11:19:56 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Handys nicht nur ihre Federn deutlich verfeinert, sondern sich von einst blutenden Taschenwannuhren über polyphonisch tootende Game Boy-Ambitionen bis hin zu schlichten Mini-PCs mit knackigem CD-Qualität Stereo-Sound: Dank ihrer besonderen Kombination von Fähigkeiten können sie sich von den ehemaligen I-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen entwickeln.
2023-09-22 11:19:56 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-22 11:19:58 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dienerla defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se fuerza para que se fuerza; en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo unvermeidlich un fuerza para un konfliarmado; en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de cuenta de que ést
2023-09-22 11:19:58 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-22 11:19:59 | INFO | valid | epoch 013 | valid on 'valid' subset | loss 4.166 | nll_loss 2.192 | ppl 4.57 | bleu 29.42 | wps 16701.7 | wpb 12011.9 | bsz 398.1 | num_updates 117755 | best_bleu 29.46
2023-09-22 11:19:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 117755 updates
2023-09-22 11:19:59 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint13.pt
2023-09-22 11:20:05 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint13.pt
2023-09-22 11:20:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint13.pt (epoch 13 @ 117755 updates, score 29.42) (writing took 10.728198863973375 seconds)
2023-09-22 11:20:09 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2023-09-22 11:20:09 | INFO | train | epoch 013 | loss 6.757 | nll_loss 3.349 | ppl 10.19 | wps 5788.5 | ups 0.45 | wpb 12977.2 | bsz 430.6 | num_updates 117755 | lr 9.21532e-05 | gnorm 0.921 | loss_scale 8 | train_wall 20201 | gb_free 14.5 | wall 175203
2023-09-22 11:20:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 11:20:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-22 11:20:09 | INFO | fairseq.trainer | begin training epoch 14
2023-09-22 11:20:09 | INFO | fairseq_cli.train | Start iterating over samples
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2880, 42808])
2023-09-22 11:21:55 | INFO | train_inner | epoch 014:     45 / 9060 loss=6.799, nll_loss=3.389, ppl=10.48, wps=4017.9, ups=0.31, wpb=12922.6, bsz=423.7, num_updates=117800, lr=9.21356e-05, gnorm=0.973, loss_scale=8, train_wall=239, gb_free=14, wall=175308
lprobs.size(): torch.Size([3496, 42808])
2023-09-22 11:25:55 | INFO | train_inner | epoch 014:    145 / 9060 loss=6.852, nll_loss=3.386, ppl=10.45, wps=5408.1, ups=0.42, wpb=12977.8, bsz=426.7, num_updates=117900, lr=9.20965e-05, gnorm=0.959, loss_scale=8, train_wall=240, gb_free=15.1, wall=175548
lprobs.size(): torch.Size([3072, 42808])
2023-09-22 11:29:44 | INFO | train_inner | epoch 014:    245 / 9060 loss=6.732, nll_loss=3.328, ppl=10.04, wps=5681, ups=0.44, wpb=13007.8, bsz=426.1, num_updates=118000, lr=9.20575e-05, gnorm=0.907, loss_scale=8, train_wall=229, gb_free=14.3, wall=175777
2023-09-22 11:33:28 | INFO | train_inner | epoch 014:    345 / 9060 loss=6.73, nll_loss=3.294, ppl=9.81, wps=5793, ups=0.45, wpb=12979.1, bsz=438.1, num_updates=118100, lr=9.20185e-05, gnorm=0.903, loss_scale=8, train_wall=224, gb_free=14, wall=176001
lprobs.size(): torch.Size([3472, 42808])
2023-09-22 11:37:14 | INFO | train_inner | epoch 014:    445 / 9060 loss=6.712, nll_loss=3.3, ppl=9.85, wps=5790.9, ups=0.44, wpb=13074.7, bsz=416.2, num_updates=118200, lr=9.19795e-05, gnorm=0.902, loss_scale=8, train_wall=226, gb_free=13.9, wall=176227
pred_new.size(): torch.Size([6048, 42808])
2023-09-22 11:41:19 | INFO | train_inner | epoch 014:    545 / 9060 loss=6.682, nll_loss=3.273, ppl=9.67, wps=5314.6, ups=0.41, wpb=13018.4, bsz=447.8, num_updates=118300, lr=9.19407e-05, gnorm=0.913, loss_scale=8, train_wall=245, gb_free=14.2, wall=176472
ter_threshold: 0.418324
num_accepted / total 15 48
loss token level: tensor(8039.2139, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4080., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([900, 42808])
ter_threshold: 0.41837799999999997
num_accepted / total 5 80
loss token level: tensor(8802.3320, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1092., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 11:45:10 | INFO | train_inner | epoch 014:    645 / 9060 loss=6.786, nll_loss=3.335, ppl=10.09, wps=5591.6, ups=0.43, wpb=12947.1, bsz=427.9, num_updates=118400, lr=9.19018e-05, gnorm=0.94, loss_scale=8, train_wall=231, gb_free=13.9, wall=176704
2023-09-22 11:48:54 | INFO | train_inner | epoch 014:    745 / 9060 loss=6.803, nll_loss=3.343, ppl=10.15, wps=5839.6, ups=0.45, wpb=13046.2, bsz=438.8, num_updates=118500, lr=9.1863e-05, gnorm=0.928, loss_scale=8, train_wall=223, gb_free=13.7, wall=176927
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.418551
num_accepted / total 136 272
loss token level: tensor(9186.0547, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6108., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 11:52:53 | INFO | train_inner | epoch 014:    845 / 9060 loss=6.91, nll_loss=3.366, ppl=10.31, wps=5467.1, ups=0.42, wpb=13077, bsz=447, num_updates=118600, lr=9.18243e-05, gnorm=0.957, loss_scale=8, train_wall=239, gb_free=13.8, wall=177166
2023-09-22 11:56:41 | INFO | train_inner | epoch 014:    945 / 9060 loss=6.858, nll_loss=3.355, ppl=10.23, wps=5730, ups=0.44, wpb=13046.8, bsz=430.6, num_updates=118700, lr=9.17856e-05, gnorm=0.924, loss_scale=8, train_wall=227, gb_free=15.5, wall=177394
pred_new.size(): torch.Size([2944, 42808])
ter_threshold: 0.41876599999999997
num_accepted / total 10 64
loss token level: tensor(11334.3809, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2228., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 12:00:37 | INFO | train_inner | epoch 014:   1045 / 9060 loss=6.78, nll_loss=3.342, ppl=10.14, wps=5456.1, ups=0.42, wpb=12895.9, bsz=420.2, num_updates=118800, lr=9.1747e-05, gnorm=0.987, loss_scale=8, train_wall=236, gb_free=14.2, wall=177630
loss seque level: tensor(2070., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.411686
num_accepted / total 139 256
loss token level: tensor(7954.9229, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9304., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2332, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([4662, 42808])
pred_new.size(): torch.Size([1596, 42808])
ter_threshold: 0.412084
num_accepted / total 9 48
loss token level: tensor(8619.7891, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2414., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3416, 42808])
pred_new.size(): torch.Size([7254, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.412513
num_accepted / total 44 112
loss token level: tensor(9281.1855, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9632., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.412528
num_accepted / total 69 136
loss token level: tensor(8358.2764, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11128., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.412536
num_accepted / total 28 104
loss token level: tensor(9179.2793, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7040., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2697, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6498, 42808])
ter_threshold: 0.412617
num_accepted / total 3 64
loss token level: tensor(10410.8125, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(517., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.412904
num_accepted / total 17 64
loss token level: tensor(9212.2129, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6536., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([456, 42808])
pred_new.size(): torch.Size([2604, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.413231
num_accepted / total 16 56
loss token level: tensor(8517.8320, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4288., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([5175, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2160, 42808])
ter_threshold: 0.413715
num_accepted / total 9 64
loss token level: tensor(8308.9258, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1620., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([1587, 42808])
pred_new.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1496, 42808])
pred_new.size(): torch.Size([5280, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1323, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2970, 42808])
pred_new.size(): torch.Size([5151, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.41481
num_accepted / total 6 16
loss token level: tensor(6672.2378, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7592., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.415259
num_accepted / total 26 96
loss token level: tensor(10028.7764, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6920., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.415293
num_accepted / total 5 80
loss token level: tensor(9018.9580, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(715., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5626, 42808])
lprobs.size(): torch.Size([2640, 42808])
ter_threshold: 0.41559
num_accepted / total 146 272
loss token level: tensor(8398.0791, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10192., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([4674, 42808])
pred_new.size(): torch.Size([3108, 42808])
pred_new.size(): torch.Size([5950, 42808])
pred_new.size(): torch.Size([2170, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([1608, 42808])
pred_new.size(): torch.Size([2380, 42808])
ter_threshold: 0.416468
num_accepted / total 5 48
loss token level: tensor(11377.3809, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2692., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1584, 42808])
pred_new.size(): torch.Size([310, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([3420, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([5350, 42808])
ter_threshold: 0.416722
num_accepted / total 56 128
loss token level: tensor(8260.6611, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5248., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3069, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([2176, 42808])
pred_new.size(): torch.Size([4956, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([4935, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([2304, 42808])
pred_new.size(): torch.Size([330, 42808])
ter_threshold: 0.417425
num_accepted / total 63 208
loss token level: tensor(11634.2324, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4064., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2622, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([800, 42808])
pred_new.size(): torch.Size([2460, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([5304, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([4940, 42808])
pred_new.size(): torch.Size([6534, 42808])
ter_threshold: 0.41833
num_accepted / total 46 88
loss token level: tensor(9068.2559, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7968., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6290, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2625, 42808])
ter_threshold: 0.418551
num_accepted / total 20 80
loss token level: tensor(8367.0391, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3038., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.418589
num_accepted / total 21 64
loss token level: tensor(8505.4365, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7704., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.418609
num_accepted / total 64 152
loss token level: tensor(10884.2344, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9664., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([984, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 12:04:48 | INFO | train_inner | epoch 014:   1145 / 9060 loss=6.82, nll_loss=3.369, ppl=10.33, wps=5126.5, ups=0.4, wpb=12858.2, bsz=426.8, num_updates=118900, lr=9.17084e-05, gnorm=0.937, loss_scale=8, train_wall=251, gb_free=14.2, wall=177881
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3120, 42808])
2023-09-22 12:08:47 | INFO | train_inner | epoch 014:   1245 / 9060 loss=6.755, nll_loss=3.336, ppl=10.1, wps=5443.9, ups=0.42, wpb=13003.1, bsz=421.9, num_updates=119000, lr=9.16698e-05, gnorm=0.914, loss_scale=8, train_wall=239, gb_free=14.2, wall=178120
pred_new.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([4059, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-22 12:12:44 | INFO | train_inner | epoch 014:   1345 / 9060 loss=6.817, nll_loss=3.359, ppl=10.26, wps=5486, ups=0.42, wpb=13000.1, bsz=431.2, num_updates=119100, lr=9.16314e-05, gnorm=0.959, loss_scale=8, train_wall=237, gb_free=14.1, wall=178357
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 12:16:33 | INFO | train_inner | epoch 014:   1445 / 9060 loss=6.773, nll_loss=3.319, ppl=9.98, wps=5682.4, ups=0.44, wpb=13045.4, bsz=443, num_updates=119200, lr=9.15929e-05, gnorm=0.923, loss_scale=8, train_wall=229, gb_free=14.3, wall=178587
lprobs.size(): torch.Size([2160, 42808])
2023-09-22 12:20:45 | INFO | train_inner | epoch 014:   1545 / 9060 loss=6.88, nll_loss=3.359, ppl=10.26, wps=5169, ups=0.4, wpb=13004.1, bsz=423.4, num_updates=119300, lr=9.15545e-05, gnorm=0.963, loss_scale=8, train_wall=251, gb_free=14.3, wall=178838
pred_new.size(): torch.Size([5695, 42808])
2023-09-22 12:24:49 | INFO | train_inner | epoch 014:   1645 / 9060 loss=6.847, nll_loss=3.36, ppl=10.27, wps=5298.8, ups=0.41, wpb=12954.6, bsz=452.2, num_updates=119400, lr=9.15162e-05, gnorm=0.952, loss_scale=8, train_wall=244, gb_free=13.7, wall=179083
2023-09-22 12:28:50 | INFO | train_inner | epoch 014:   1745 / 9060 loss=6.718, nll_loss=3.309, ppl=9.91, wps=5395.1, ups=0.42, wpb=12964.2, bsz=406.2, num_updates=119500, lr=9.14779e-05, gnorm=0.935, loss_scale=8, train_wall=240, gb_free=13.9, wall=179323
lprobs.size(): torch.Size([3344, 42808])
2023-09-22 12:32:43 | INFO | train_inner | epoch 014:   1845 / 9060 loss=6.751, nll_loss=3.311, ppl=9.93, wps=5547, ups=0.43, wpb=12951.3, bsz=421.5, num_updates=119600, lr=9.14396e-05, gnorm=0.95, loss_scale=8, train_wall=233, gb_free=14.2, wall=179556
lprobs.size(): torch.Size([3192, 42808])
2023-09-22 12:36:45 | INFO | train_inner | epoch 014:   1945 / 9060 loss=6.753, nll_loss=3.322, ppl=10, wps=5359.5, ups=0.41, wpb=12956.6, bsz=412, num_updates=119700, lr=9.14014e-05, gnorm=0.935, loss_scale=8, train_wall=241, gb_free=13.3, wall=179798
pred_new.size(): torch.Size([1680, 42808])
lprobs.size(): torch.Size([3040, 42808])
2023-09-22 12:40:37 | INFO | train_inner | epoch 014:   2045 / 9060 loss=6.74, nll_loss=3.355, ppl=10.23, wps=5563.2, ups=0.43, wpb=12901.2, bsz=432.6, num_updates=119800, lr=9.13633e-05, gnorm=0.921, loss_scale=8, train_wall=232, gb_free=14.1, wall=180030
lprobs.size(): torch.Size([3456, 42808])
2023-09-22 12:44:51 | INFO | train_inner | epoch 014:   2145 / 9060 loss=6.77, nll_loss=3.348, ppl=10.18, wps=5062.2, ups=0.39, wpb=12883, bsz=437.6, num_updates=119900, lr=9.13252e-05, gnorm=0.942, loss_scale=8, train_wall=254, gb_free=14, wall=180285
lprobs.size(): torch.Size([3480, 42808])
2023-09-22 12:48:53 | INFO | train_inner | epoch 014:   2245 / 9060 loss=6.93, nll_loss=3.413, ppl=10.65, wps=5375.4, ups=0.41, wpb=12983.7, bsz=435.1, num_updates=120000, lr=9.12871e-05, gnorm=0.948, loss_scale=8, train_wall=241, gb_free=13.8, wall=180526
lprobs.size(): torch.Size([2880, 42808])
2023-09-22 12:52:46 | INFO | train_inner | epoch 014:   2345 / 9060 loss=6.88, nll_loss=3.393, ppl=10.5, wps=5585.6, ups=0.43, wpb=13014.1, bsz=437.5, num_updates=120100, lr=9.12491e-05, gnorm=0.961, loss_scale=8, train_wall=233, gb_free=14.3, wall=180759
pred_new.size(): torch.Size([2232, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7600, 42808])
lprobs.size(): torch.Size([2688, 42808])
2023-09-22 12:56:49 | INFO | train_inner | epoch 014:   2445 / 9060 loss=6.952, nll_loss=3.422, ppl=10.72, wps=5329.5, ups=0.41, wpb=12977.1, bsz=432.6, num_updates=120200, lr=9.12111e-05, gnorm=0.979, loss_scale=8, train_wall=243, gb_free=14.5, wall=181003
ter_threshold: 0.42027
num_accepted / total 41 136
loss token level: tensor(8392.2764, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6596., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 13:00:59 | INFO | train_inner | epoch 014:   2545 / 9060 loss=6.763, nll_loss=3.348, ppl=10.18, wps=5209.8, ups=0.4, wpb=12994.6, bsz=416.2, num_updates=120300, lr=9.11732e-05, gnorm=0.929, loss_scale=16, train_wall=249, gb_free=13.8, wall=181252
2023-09-22 13:01:31 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
lprobs.size(): torch.Size([3432, 42808])
2023-09-22 13:04:53 | INFO | train_inner | epoch 014:   2646 / 9060 loss=6.767, nll_loss=3.365, ppl=10.3, wps=5562.7, ups=0.43, wpb=13022.5, bsz=429.2, num_updates=120400, lr=9.11353e-05, gnorm=0.917, loss_scale=8, train_wall=234, gb_free=14.4, wall=181486
ter_threshold: 0.42041
num_accepted / total 5 56
loss token level: tensor(12228.6172, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2212., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3440, 42808])
2023-09-22 13:09:02 | INFO | train_inner | epoch 014:   2746 / 9060 loss=6.641, nll_loss=3.281, ppl=9.72, wps=5223.4, ups=0.4, wpb=13010.8, bsz=412.5, num_updates=120500, lr=9.10975e-05, gnorm=0.904, loss_scale=8, train_wall=249, gb_free=14.1, wall=181735
pred_new.size(): torch.Size([72, 42808])
2023-09-22 13:13:11 | INFO | train_inner | epoch 014:   2846 / 9060 loss=6.763, nll_loss=3.341, ppl=10.13, wps=5217.6, ups=0.4, wpb=12979.6, bsz=424.7, num_updates=120600, lr=9.10597e-05, gnorm=0.912, loss_scale=8, train_wall=248, gb_free=14.1, wall=181984
2023-09-22 13:17:16 | INFO | train_inner | epoch 014:   2946 / 9060 loss=6.877, nll_loss=3.407, ppl=10.61, wps=5248.9, ups=0.41, wpb=12905.2, bsz=448.7, num_updates=120700, lr=9.1022e-05, gnorm=0.95, loss_scale=8, train_wall=246, gb_free=13.9, wall=182230
pred_new.size(): torch.Size([5348, 42808])
pred_new.size(): torch.Size([1395, 42808])
pred_new.size(): torch.Size([4698, 42808])
2023-09-22 13:21:23 | INFO | train_inner | epoch 014:   3046 / 9060 loss=6.859, nll_loss=3.368, ppl=10.33, wps=5263.8, ups=0.41, wpb=12958.1, bsz=421.9, num_updates=120800, lr=9.09843e-05, gnorm=0.936, loss_scale=8, train_wall=246, gb_free=13.3, wall=182476
pred_new.size(): torch.Size([728, 42808])
lprobs.size(): torch.Size([2448, 42808])
2023-09-22 13:25:35 | INFO | train_inner | epoch 014:   3146 / 9060 loss=6.755, nll_loss=3.314, ppl=9.94, wps=5130, ups=0.4, wpb=12934.2, bsz=442.8, num_updates=120900, lr=9.09467e-05, gnorm=0.937, loss_scale=8, train_wall=252, gb_free=13.8, wall=182728
2023-09-22 13:25:55 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
lprobs.size(): torch.Size([3072, 42808])
2023-09-22 13:29:31 | INFO | train_inner | epoch 014:   3247 / 9060 loss=6.771, nll_loss=3.357, ppl=10.25, wps=5502.7, ups=0.42, wpb=12973.7, bsz=415.2, num_updates=121000, lr=9.09091e-05, gnorm=0.948, loss_scale=4, train_wall=236, gb_free=13.6, wall=182964
pred_new.size(): torch.Size([1710, 42808])
pred_new.size(): torch.Size([297, 42808])
lprobs.size(): torch.Size([3432, 42808])
2023-09-22 13:33:36 | INFO | train_inner | epoch 014:   3347 / 9060 loss=6.703, nll_loss=3.32, ppl=9.99, wps=5290, ups=0.41, wpb=12994, bsz=403.3, num_updates=121100, lr=9.08715e-05, gnorm=0.922, loss_scale=4, train_wall=245, gb_free=14.9, wall=183210
ter_threshold: 0.42117099999999996
num_accepted / total 15 72
loss token level: tensor(8688.4736, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4364., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 13:37:51 | INFO | train_inner | epoch 014:   3447 / 9060 loss=6.809, nll_loss=3.355, ppl=10.23, wps=5086.5, ups=0.39, wpb=12953.7, bsz=438.2, num_updates=121200, lr=9.08341e-05, gnorm=0.935, loss_scale=4, train_wall=254, gb_free=13.7, wall=183464
pred_new.size(): torch.Size([1314, 42808])
2023-09-22 13:41:50 | INFO | train_inner | epoch 014:   3547 / 9060 loss=6.838, nll_loss=3.374, ppl=10.37, wps=5439.7, ups=0.42, wpb=12995.8, bsz=434, num_updates=121300, lr=9.07966e-05, gnorm=0.931, loss_scale=4, train_wall=239, gb_free=13.7, wall=183703
2023-09-22 13:45:46 | INFO | train_inner | epoch 014:   3647 / 9060 loss=6.809, nll_loss=3.365, ppl=10.3, wps=5482.1, ups=0.42, wpb=12967.3, bsz=436.6, num_updates=121400, lr=9.07592e-05, gnorm=0.929, loss_scale=4, train_wall=236, gb_free=14.3, wall=183940
2023-09-22 13:50:00 | INFO | train_inner | epoch 014:   3747 / 9060 loss=6.821, nll_loss=3.373, ppl=10.36, wps=5117.7, ups=0.39, wpb=12966, bsz=450.2, num_updates=121500, lr=9.07218e-05, gnorm=0.96, loss_scale=4, train_wall=253, gb_free=13.2, wall=184193
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3216, 42808])
2023-09-22 13:53:53 | INFO | train_inner | epoch 014:   3847 / 9060 loss=6.84, nll_loss=3.407, ppl=10.61, wps=5532.8, ups=0.43, wpb=12918.5, bsz=437.9, num_updates=121600, lr=9.06845e-05, gnorm=0.926, loss_scale=4, train_wall=233, gb_free=13.9, wall=184427
pred_new.size(): torch.Size([2944, 42808])
2023-09-22 13:57:44 | INFO | train_inner | epoch 014:   3947 / 9060 loss=6.828, nll_loss=3.36, ppl=10.26, wps=5621.6, ups=0.43, wpb=12994.4, bsz=442.7, num_updates=121700, lr=9.06473e-05, gnorm=0.927, loss_scale=4, train_wall=231, gb_free=15, wall=184658
pred_new.size(): torch.Size([3220, 42808])
2023-09-22 14:01:51 | INFO | train_inner | epoch 014:   4047 / 9060 loss=6.725, nll_loss=3.312, ppl=9.93, wps=5242.4, ups=0.41, wpb=12939.8, bsz=432.5, num_updates=121800, lr=9.061e-05, gnorm=0.925, loss_scale=4, train_wall=247, gb_free=14.4, wall=184905
pred_new.size(): torch.Size([4680, 42808])
2023-09-22 14:05:48 | INFO | train_inner | epoch 014:   4147 / 9060 loss=6.757, nll_loss=3.344, ppl=10.15, wps=5476.8, ups=0.42, wpb=12977.4, bsz=450.2, num_updates=121900, lr=9.05729e-05, gnorm=0.925, loss_scale=4, train_wall=237, gb_free=14.7, wall=185142
lprobs.size(): torch.Size([3504, 42808])
2023-09-22 14:09:51 | INFO | train_inner | epoch 014:   4247 / 9060 loss=6.825, nll_loss=3.356, ppl=10.24, wps=5326.5, ups=0.41, wpb=12940.2, bsz=442.6, num_updates=122000, lr=9.05357e-05, gnorm=0.935, loss_scale=4, train_wall=243, gb_free=13.7, wall=185384
2023-09-22 14:13:53 | INFO | train_inner | epoch 014:   4347 / 9060 loss=6.854, nll_loss=3.373, ppl=10.36, wps=5409.1, ups=0.41, wpb=13073.2, bsz=450.2, num_updates=122100, lr=9.04987e-05, gnorm=0.944, loss_scale=4, train_wall=241, gb_free=13.5, wall=185626
lprobs.size(): torch.Size([3080, 42808])
2023-09-22 14:17:58 | INFO | train_inner | epoch 014:   4447 / 9060 loss=6.876, nll_loss=3.413, ppl=10.65, wps=5310.4, ups=0.41, wpb=13018.1, bsz=453.8, num_updates=122200, lr=9.04616e-05, gnorm=0.945, loss_scale=4, train_wall=245, gb_free=14.1, wall=185871
2023-09-22 14:21:59 | INFO | train_inner | epoch 014:   4547 / 9060 loss=6.695, nll_loss=3.341, ppl=10.13, wps=5367, ups=0.41, wpb=12942.5, bsz=407.8, num_updates=122300, lr=9.04246e-05, gnorm=0.931, loss_scale=4, train_wall=241, gb_free=14.2, wall=186112
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3120, 42808])
2023-09-22 14:26:23 | INFO | train_inner | epoch 014:   4647 / 9060 loss=6.911, nll_loss=3.394, ppl=10.51, wps=4903.3, ups=0.38, wpb=12931.1, bsz=441, num_updates=122400, lr=9.03877e-05, gnorm=0.955, loss_scale=4, train_wall=263, gb_free=14.9, wall=186376
pred_new.size(): torch.Size([4875, 42808])
2023-09-22 14:30:50 | INFO | train_inner | epoch 014:   4747 / 9060 loss=6.777, nll_loss=3.346, ppl=10.16, wps=4858.7, ups=0.37, wpb=13004, bsz=422, num_updates=122500, lr=9.03508e-05, gnorm=0.954, loss_scale=4, train_wall=267, gb_free=15.8, wall=186644
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 14:35:10 | INFO | train_inner | epoch 014:   4847 / 9060 loss=6.832, nll_loss=3.398, ppl=10.54, wps=5007.4, ups=0.38, wpb=13011.1, bsz=424, num_updates=122600, lr=9.03139e-05, gnorm=0.936, loss_scale=4, train_wall=260, gb_free=14, wall=186904
 tensor(6304., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.415259
num_accepted / total 37 136
loss token level: tensor(7967.1987, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4816., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.415293
num_accepted / total 18 112
loss token level: tensor(11063.2207, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2124., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2860, 42808])
ter_threshold: 0.41559
num_accepted / total 40 128
loss token level: tensor(9149.0176, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7760., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1575, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([3060, 42808])
pred_new.size(): torch.Size([3045, 42808])
pred_new.size(): torch.Size([708, 42808])
pred_new.size(): torch.Size([3920, 42808])
lprobs.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2100, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3078, 42808])
pred_new.size(): torch.Size([2346, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5504, 42808])
ter_threshold: 0.416722
num_accepted / total 46 152
loss token level: tensor(8548.4902, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3556., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3838, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([4653, 42808])
ter_threshold: 0.417115
num_accepted / total 16 80
loss token level: tensor(10318.8291, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5104., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2516, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([1368, 42808])
pred_new.size(): torch.Size([3024, 42808])
ter_threshold: 0.41743199999999997
num_accepted / total 18 112
loss token level: tensor(8633.4082, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1754., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3296, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([4374, 42808])
ter_threshold: 0.417798
num_accepted / total 11 40
loss token level: tensor(8654.9219, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6392., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.41780799999999996
num_accepted / total 3 48
loss token level: tensor(8999.6631, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(469.5000, device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2040, 42808])
pred_new.size(): torch.Size([864, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([4212, 42808])
pred_new.size(): torch.Size([1484, 42808])
pred_new.size(): torch.Size([6510, 42808])
ter_threshold: 0.418326
num_accepted / total 9 24
loss token level: tensor(7551.8555, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7856., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5940, 42808])
lprobs.size(): torch.Size([3392, 42808])
ter_threshold: 0.418551
num_accepted / total 33 104
loss token level: tensor(9307.1025, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4752., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.418609
num_accepted / total 45 112
loss token level: tensor(8847.1006, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9280., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4736, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([4350, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([600, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([5742, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.41945899999999997
num_accepted / total 87 160
loss token level: tensor(8768.6230, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8016., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2912, 42808])
ter_threshold: 0.419805
num_accepted / total 182 296
loss token level: tensor(9672.8438, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10640., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4830, 42808])
pred_new.size(): torch.Size([5913, 42808])
ter_threshold: 0.420219
num_accepted / total 10 64
loss token level: tensor(9850.9023, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2318., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3724, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.42027
num_accepted / total 45 128
loss token level: tensor(8973.7188, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8416., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5611, 42808])
pred_new.size(): torch.Size([1540, 42808])
ter_threshold: 0.42063
num_accepted / total 12 72
loss token level: tensor(10999.3320, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4536., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2280, 42808])
pred_new.size(): torch.Size([1377, 42808])
pred_new.size(): torch.Size([4995, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([2624, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([468, 42808])
pred_new.size(): torch.Size([714, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3288, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.42117099999999996
num_accepted / total 3 64
loss token level: tensor(9187.0312, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1220., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.42120599999999997
num_accepted / total 27 72
loss token level: tensor(9010.8789, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9296., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([1800, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.421552
num_accepted / total 34 88
loss token level: tensor(9427.7324, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10072., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4032, 42808])
ter_threshold: 0.422255
num_accepted / total 8 80
loss token level: tensor(12794.5479, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1253., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5177, 42808])
lprobs.size(): torch.Size([3312, 42808])
2023-09-22 14:39:18 | INFO | train_inner | epoch 014:   4947 / 9060 loss=6.655, nll_loss=3.294, ppl=9.81, wps=5208.7, ups=0.4, wpb=12912.1, bsz=424.2, num_updates=122700, lr=9.02771e-05, gnorm=0.92, loss_scale=4, train_wall=248, gb_free=14.9, wall=187152
pred_new.size(): torch.Size([3627, 42808])
2023-09-22 14:43:27 | INFO | train_inner | epoch 014:   5047 / 9060 loss=6.854, nll_loss=3.37, ppl=10.34, wps=5249.2, ups=0.4, wpb=13052.9, bsz=448.3, num_updates=122800, lr=9.02404e-05, gnorm=0.926, loss_scale=4, train_wall=248, gb_free=14.1, wall=187400
pred_new.size(): torch.Size([2496, 42808])
2023-09-22 14:47:24 | INFO | train_inner | epoch 014:   5147 / 9060 loss=6.799, nll_loss=3.326, ppl=10.03, wps=5512.8, ups=0.42, wpb=13099.9, bsz=434.6, num_updates=122900, lr=9.02036e-05, gnorm=0.945, loss_scale=4, train_wall=237, gb_free=13.9, wall=187638
pred_new.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 14:51:15 | INFO | train_inner | epoch 014:   5247 / 9060 loss=6.745, nll_loss=3.369, ppl=10.33, wps=5571.1, ups=0.43, wpb=12868.6, bsz=415.3, num_updates=123000, lr=9.0167e-05, gnorm=0.93, loss_scale=4, train_wall=231, gb_free=14.4, wall=187869
pred_new.size(): torch.Size([1165, 42808])
pred_new.size(): torch.Size([6208, 42808])
pred_new.size(): torch.Size([2475, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 14:55:15 | INFO | train_inner | epoch 014:   5347 / 9060 loss=6.796, nll_loss=3.395, ppl=10.52, wps=5364.7, ups=0.42, wpb=12881.5, bsz=434.2, num_updates=123100, lr=9.01303e-05, gnorm=0.967, loss_scale=4, train_wall=240, gb_free=13.9, wall=188109
pred_new.size(): torch.Size([4902, 42808])
pred_new.size(): torch.Size([2684, 42808])
lprobs.size(): torch.Size([3040, 42808])
2023-09-22 14:59:18 | INFO | train_inner | epoch 014:   5447 / 9060 loss=6.828, nll_loss=3.421, ppl=10.71, wps=5338.9, ups=0.41, wpb=12961, bsz=416.9, num_updates=123200, lr=9.00937e-05, gnorm=0.947, loss_scale=4, train_wall=242, gb_free=14.2, wall=188352
tensor(7848., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3948, 42808])
ter_threshold: 0.41256
num_accepted / total 62 128
loss token level: tensor(9711.7383, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12128., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5148, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([3080, 42808])
ter_threshold: 0.413224
num_accepted / total 0 8
loss token level: tensor(6891.5029, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: 0
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1680, 42808])
pred_new.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([4810, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3150, 42808])
ter_threshold: 0.413805
num_accepted / total 36 96
loss token level: tensor(8596.6875, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8712., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([7420, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([3996, 42808])
pred_new.size(): torch.Size([5130, 42808])
lprobs.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([4500, 42808])
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([324, 42808])
ter_threshold: 0.415187
num_accepted / total 5 72
loss token level: tensor(13996.5195, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1403., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.415292
num_accepted / total 1 8
loss token level: tensor(8314.7988, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1668., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([3784, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([1242, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([624, 42808])
pred_new.size(): torch.Size([148, 42808])
pred_new.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2970, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([2112, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.417011
num_accepted / total 6 32
loss token level: tensor(9020.2695, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2696., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3828, 42808])
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([2500, 42808])
pred_new.size(): torch.Size([1536, 42808])
pred_new.size(): torch.Size([5510, 42808])
pred_new.size(): torch.Size([3402, 42808])
ter_threshold: 0.417425
num_accepted / total 44 128
loss token level: tensor(9218.9355, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4776., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2604, 42808])
lprobs.size(): torch.Size([1776, 42808])
pred_new.size(): torch.Size([1800, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([2220, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4860, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([2673, 42808])
ter_threshold: 0.41837799999999997
num_accepted / total 65 152
loss token level: tensor(9487.5469, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9800., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3120, 42808])
ter_threshold: 0.418593
num_accepted / total 29 72
loss token level: tensor(9055.8643, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10752., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.418609
num_accepted / total 41 144
loss token level: tensor(11664.8340, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6120., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1040, 42808])
pred_new.size(): torch.Size([4752, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([2025, 42808])
pred_new.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([1584, 42808])
pred_new.size(): torch.Size([1610, 42808])
pred_new.size(): torch.Size([5913, 42808])
lprobs.size(): torch.Size([2832, 42808])
ter_threshold: 0.41945899999999997
num_accepted / total 44 128
loss token level: tensor(9888.2656, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5264., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.419805
num_accepted / total 135 224
loss token level: tensor(8574.2051, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11984., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4212, 42808])
pred_new.size(): torch.Size([4875, 42808])
lprobs.size(): torch.Size([2808, 42808])
ter_threshold: 0.420129
num_accepted / total 15 80
loss token level: tensor(8898.6426, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2500., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6450, 42808])
ter_threshold: 0.42027
num_accepted / total 91 232
loss token level: tensor(9769.0977, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7964., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3224, 42808])
pred_new.size(): torch.Size([5550, 42808])
pred_new.size(): torch.Size([2886, 42808])
pred_new.size(): torch.Size([4290, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([864, 42808])
pred_new.size(): torch.Size([1320, 42808])
pred_new.size(): torch.Size([1316, 42808])
pred_new.size(): torch.Size([1410, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([4355, 42808])
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([2280, 42808])
ter_threshold: 0.422313
num_accepted / total 5 40
loss token level: tensor(9913.9707, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1924., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([576, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3224, 42808])
pred_new.size(): torch.Size([1827, 42808])
pred_new.size(): torch.Size([3150, 42808])
ter_threshold: 0.422879
num_accepted / total 56 112
loss token level: tensor(8874.8125, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7228., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1260, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([7906, 42808])
pred_new.size(): torch.Size([744, 42808])
pred_new.size(): torch.Size([6256, 42808])
pred_new.size(): torch.Size([1680, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): 2023-09-22 15:03:26 | INFO | train_inner | epoch 014:   5547 / 9060 loss=6.806, nll_loss=3.374, ppl=10.37, wps=5252.4, ups=0.4, wpb=13007.4, bsz=428, num_updates=123300, lr=9.00572e-05, gnorm=0.951, loss_scale=4, train_wall=247, gb_free=15.6, wall=188599
pred_new.size(): torch.Size([3666, 42808])
2023-09-22 15:07:25 | INFO | train_inner | epoch 014:   5647 / 9060 loss=6.773, nll_loss=3.383, ppl=10.43, wps=5400, ups=0.42, wpb=12925.2, bsz=419.3, num_updates=123400, lr=9.00207e-05, gnorm=0.953, loss_scale=4, train_wall=239, gb_free=13.8, wall=188839
pred_new.size(): torch.Size([2496, 42808])
2023-09-22 15:11:21 | INFO | train_inner | epoch 014:   5747 / 9060 loss=6.749, nll_loss=3.328, ppl=10.04, wps=5473.7, ups=0.42, wpb=12892.6, bsz=434.3, num_updates=123500, lr=8.99843e-05, gnorm=0.923, loss_scale=4, train_wall=235, gb_free=15.1, wall=189074
pred_new.size(): torch.Size([2088, 42808])
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([2968, 42808])
pred_new.size(): torch.Size([1326, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([1232, 42808])
2023-09-22 15:15:36 | INFO | train_inner | epoch 014:   5847 / 9060 loss=6.918, nll_loss=3.431, ppl=10.79, wps=5059.9, ups=0.39, wpb=12937.8, bsz=422.4, num_updates=123600, lr=8.99478e-05, gnorm=0.955, loss_scale=4, train_wall=255, gb_free=13.1, wall=189330
2023-09-22 15:19:41 | INFO | train_inner | epoch 014:   5947 / 9060 loss=6.939, nll_loss=3.398, ppl=10.54, wps=5326.1, ups=0.41, wpb=13006.6, bsz=440.9, num_updates=123700, lr=8.99115e-05, gnorm=0.968, loss_scale=4, train_wall=244, gb_free=13.1, wall=189574
pred_new.size(): torch.Size([5014, 42808])
ter_threshold: 0.423757
num_accepted / total 44 136
loss token level: tensor(8522.9756, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7088., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.42375999999999997
num_accepted / total 19 112
loss token level: tensor(8910.6797, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2982., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3975, 42808])
2023-09-22 15:23:44 | INFO | train_inner | epoch 014:   6047 / 9060 loss=6.881, nll_loss=3.39, ppl=10.48, wps=5304, ups=0.41, wpb=12924.8, bsz=440.3, num_updates=123800, lr=8.98752e-05, gnorm=0.947, loss_scale=4, train_wall=243, gb_free=13.7, wall=189818
2023-09-22 15:27:44 | INFO | train_inner | epoch 014:   6147 / 9060 loss=6.829, nll_loss=3.416, ppl=10.68, wps=5435.5, ups=0.42, wpb=13030.2, bsz=415, num_updates=123900, lr=8.98389e-05, gnorm=0.929, loss_scale=4, train_wall=239, gb_free=14, wall=190058
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([1272, 42808])
2023-09-22 15:32:08 | INFO | train_inner | epoch 014:   6247 / 9060 loss=6.819, nll_loss=3.373, ppl=10.36, wps=4954, ups=0.38, wpb=13066.4, bsz=425.4, num_updates=124000, lr=8.98027e-05, gnorm=0.927, loss_scale=4, train_wall=263, gb_free=14.2, wall=190321
2023-09-22 15:36:35 | INFO | train_inner | epoch 014:   6347 / 9060 loss=6.719, nll_loss=3.336, ppl=10.1, wps=4899.6, ups=0.37, wpb=13086, bsz=408.9, num_updates=124100, lr=8.97665e-05, gnorm=0.923, loss_scale=4, train_wall=267, gb_free=14, wall=190588
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([2597, 42808])
2023-09-22 15:40:56 | INFO | train_inner | epoch 014:   6447 / 9060 loss=6.962, nll_loss=3.4, ppl=10.56, wps=4998.7, ups=0.38, wpb=13028.1, bsz=458.7, num_updates=124200, lr=8.97303e-05, gnorm=0.947, loss_scale=4, train_wall=260, gb_free=14.8, wall=190849
2023-09-22 15:45:13 | INFO | train_inner | epoch 014:   6547 / 9060 loss=6.79, nll_loss=3.363, ppl=10.29, wps=5054.4, ups=0.39, wpb=13007.3, bsz=447.8, num_updates=124300, lr=8.96942e-05, gnorm=0.916, loss_scale=4, train_wall=257, gb_free=15.2, wall=191106
pred_new.size(): torch.Size([1980, 42808])
pred_new.size(): torch.Size([3450, 42808])
2023-09-22 15:49:21 | INFO | train_inner | epoch 014:   6647 / 9060 loss=6.728, nll_loss=3.363, ppl=10.29, wps=5238.7, ups=0.4, wpb=12991.1, bsz=430.2, num_updates=124400, lr=8.96582e-05, gnorm=0.921, loss_scale=4, train_wall=248, gb_free=14.6, wall=191354
ter_threshold: 0.424432
num_accepted / total 29 96
loss token level: tensor(10728.6406, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7880., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.424493
num_accepted / total 93 168
loss token level: tensor(8918.8662, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11968., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 15:53:46 | INFO | train_inner | epoch 014:   6747 / 9060 loss=6.738, nll_loss=3.335, ppl=10.09, wps=4877.3, ups=0.38, wpb=12949.4, bsz=424.4, num_updates=124500, lr=8.96221e-05, gnorm=0.931, loss_scale=4, train_wall=265, gb_free=13.4, wall=191620
pred_new.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([2262, 42808])
lprobs.size(): torch.Size([3280, 42808])
2023-09-22 15:58:00 | INFO | train_inner | epoch 014:   6847 / 9060 loss=6.752, nll_loss=3.368, ppl=10.32, wps=5098.7, ups=0.39, wpb=12940, bsz=435.1, num_updates=124600, lr=8.95862e-05, gnorm=0.94, loss_scale=4, train_wall=254, gb_free=14.4, wall=191874
lprobs.size(): torch.Size([2856, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 16:02:08 | INFO | train_inner | epoch 014:   6947 / 9060 loss=6.891, nll_loss=3.423, ppl=10.72, wps=5231.6, ups=0.4, wpb=12948.8, bsz=421.5, num_updates=124700, lr=8.95502e-05, gnorm=0.955, loss_scale=4, train_wall=247, gb_free=14.1, wall=192121
2023-09-22 16:06:18 | INFO | train_inner | epoch 014:   7047 / 9060 loss=6.877, nll_loss=3.402, ppl=10.57, wps=5151.8, ups=0.4, wpb=12890.8, bsz=437.4, num_updates=124800, lr=8.95144e-05, gnorm=0.944, loss_scale=4, train_wall=250, gb_free=14.2, wall=192371
2023-09-22 16:10:25 | INFO | train_inner | epoch 014:   7147 / 9060 loss=6.977, nll_loss=3.471, ppl=11.09, wps=5253.3, ups=0.4, wpb=12984.6, bsz=438.6, num_updates=124900, lr=8.94785e-05, gnorm=0.951, loss_scale=4, train_wall=247, gb_free=13.9, wall=192619
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([3483, 42808])
2023-09-22 16:14:51 | INFO | train_inner | epoch 014:   7247 / 9060 loss=6.846, nll_loss=3.398, ppl=10.55, wps=4859.3, ups=0.38, wpb=12898.8, bsz=412.5, num_updates=125000, lr=8.94427e-05, gnorm=0.97, loss_scale=4, train_wall=265, gb_free=14.7, wall=192884
ter_threshold: 0.42505
num_accepted / total 29 80
loss token level: tensor(9365.8037, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9216., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 16:18:55 | INFO | train_inner | epoch 014:   7347 / 9060 loss=6.939, nll_loss=3.437, ppl=10.83, wps=5347.9, ups=0.41, wpb=13052.3, bsz=436.7, num_updates=125100, lr=8.9407e-05, gnorm=0.946, loss_scale=8, train_wall=244, gb_free=14.5, wall=193128
pred_new.size(): torch.Size([6496, 42808])
2023-09-22 16:23:21 | INFO | train_inner | epoch 014:   7447 / 9060 loss=6.894, nll_loss=3.426, ppl=10.75, wps=4882.7, ups=0.38, wpb=13005.5, bsz=441.4, num_updates=125200, lr=8.93713e-05, gnorm=0.947, loss_scale=8, train_wall=266, gb_free=13.7, wall=193394
lprobs.size(): torch.Size([2688, 42808])
ter_threshold: 0.42527
num_accepted / total 40 112
loss token level: tensor(10057.5986, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8824., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 16:27:25 | INFO | train_inner | epoch 014:   7547 / 9060 loss=6.903, nll_loss=3.415, ppl=10.67, wps=5289.1, ups=0.41, wpb=12924.3, bsz=428.2, num_updates=125300, lr=8.93356e-05, gnorm=0.959, loss_scale=8, train_wall=244, gb_free=14.1, wall=193639
2023-09-22 16:31:37 | INFO | train_inner | epoch 014:   7647 / 9060 loss=6.923, nll_loss=3.421, ppl=10.71, wps=5134, ups=0.4, wpb=12944.9, bsz=432.6, num_updates=125400, lr=8.93e-05, gnorm=0.97, loss_scale=8, train_wall=252, gb_free=13.7, wall=193891
2023-09-22 16:35:47 | INFO | train_inner | epoch 014:   7747 / 9060 loss=6.837, nll_loss=3.39, ppl=10.49, wps=5234.8, ups=0.4, wpb=13048, bsz=412.2, num_updates=125500, lr=8.92644e-05, gnorm=0.956, loss_scale=8, train_wall=249, gb_free=14.9, wall=194140
pred_new.size(): torch.Size([5010, 42808])
pred_new.size(): torch.Size([2394, 42808])
pred_new.size(): torch.Size([1900, 42808])
2023-09-22 16:39:58 | INFO | train_inner | epoch 014:   7847 / 9060 loss=6.785, nll_loss=3.398, ppl=10.54, wps=5135.2, ups=0.4, wpb=12921, bsz=418.1, num_updates=125600, lr=8.92288e-05, gnorm=0.93, loss_scale=8, train_wall=251, gb_free=13.8, wall=194392
pred_new.size(): torch.Size([900, 42808])
ter_threshold: 0.425643
num_accepted / total 25 88
loss token level: tensor(10096.1094, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6864., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.425654
num_accepted / total 39 160
loss token level: tensor(7752.2510, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2518., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 16:44:09 | INFO | train_inner | epoch 014:   7947 / 9060 loss=6.884, nll_loss=3.395, ppl=10.52, wps=5202.8, ups=0.4, wpb=13052.6, bsz=433.9, num_updates=125700, lr=8.91933e-05, gnorm=0.921, loss_scale=8, train_wall=251, gb_free=14.3, wall=194643
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5159, 42808])
2023-09-22 16:48:10 | INFO | train_inner | epoch 014:   8047 / 9060 loss=6.778, nll_loss=3.365, ppl=10.3, wps=5425.7, ups=0.42, wpb=13053.1, bsz=423.7, num_updates=125800, lr=8.91579e-05, gnorm=0.926, loss_scale=8, train_wall=240, gb_free=13.6, wall=194883
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.425882
num_accepted / total 30 112
loss token level: tensor(12043.9824, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6024., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 16:52:27 | INFO | train_inner | epoch 014:   8147 / 9060 loss=6.898, nll_loss=3.415, ppl=10.67, wps=5084.9, ups=0.39, wpb=13061.9, bsz=438.9, num_updates=125900, lr=8.91225e-05, gnorm=0.937, loss_scale=8, train_wall=257, gb_free=13.7, wall=195140
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 16:56:40 | INFO | train_inner | epoch 014:   8247 / 9060 loss=6.812, nll_loss=3.353, ppl=10.22, wps=5102.4, ups=0.39, wpb=12933.6, bsz=439.4, num_updates=126000, lr=8.90871e-05, gnorm=0.94, loss_scale=8, train_wall=253, gb_free=14.4, wall=195394
lprobs.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([840, 42808])
pred_new.size(): torch.Size([5280, 42808])
2023-09-22 17:00:55 | INFO | train_inner | epoch 014:   8347 / 9060 loss=6.805, nll_loss=3.397, ppl=10.54, wps=5076.3, ups=0.39, wpb=12932.4, bsz=437.8, num_updates=126100, lr=8.90517e-05, gnorm=0.948, loss_scale=8, train_wall=254, gb_free=14.2, wall=195648
2023-09-22 17:05:18 | INFO | train_inner | epoch 014:   8447 / 9060 loss=6.874, nll_loss=3.407, ppl=10.61, wps=4915.2, ups=0.38, wpb=12915.4, bsz=443.1, num_updates=126200, lr=8.90165e-05, gnorm=0.962, loss_scale=8, train_wall=263, gb_free=13.9, wall=195911
2023-09-22 17:09:26 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 17:09:34 | INFO | train_inner | epoch 014:   8548 / 9060 loss=6.968, nll_loss=3.415, ppl=10.67, wps=5094.4, ups=0.39, wpb=13053.9, bsz=439.2, num_updates=126300, lr=8.89812e-05, gnorm=0.962, loss_scale=4, train_wall=256, gb_free=14.2, wall=196167
2023-09-22 17:13:57 | INFO | train_inner | epoch 014:   8648 / 9060 loss=6.895, nll_loss=3.379, ppl=10.41, wps=4926.2, ups=0.38, wpb=12978.7, bsz=429.5, num_updates=126400, lr=8.8946e-05, gnorm=0.938, loss_scale=4, train_wall=263, gb_free=13.1, wall=196431
pred_new.size(): torch.Size([2072, 42808])
pred_new.size(): torch.Size([6076, 42808])
ter_threshold: 0.42649499999999996
num_accepted / total 20 80
loss token level: tensor(9911.1396, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6324., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 17:18:12 | INFO | train_inner | epoch 014:   8748 / 9060 loss=6.806, nll_loss=3.4, ppl=10.56, wps=5077.7, ups=0.39, wpb=12935.8, bsz=398.1, num_updates=126500, lr=8.89108e-05, gnorm=0.952, loss_scale=4, train_wall=255, gb_free=14.7, wall=196686
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([4620, 42808])
ter_threshold: 0.426598
num_accepted / total 52 120
loss token level: tensor(9134.8027, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6112., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 17:22:24 | INFO | train_inner | epoch 014:   8848 / 9060 loss=6.828, nll_loss=3.388, ppl=10.47, wps=5164.5, ups=0.4, wpb=13024, bsz=429.8, num_updates=126600, lr=8.88757e-05, gnorm=0.927, loss_scale=4, train_wall=252, gb_free=14.9, wall=196938
2023-09-22 17:26:46 | INFO | train_inner | epoch 014:   8948 / 9060 loss=6.947, nll_loss=3.428, ppl=10.76, wps=4945.4, ups=0.38, wpb=12920.3, bsz=433.3, num_updates=126700, lr=8.88406e-05, gnorm=0.991, loss_scale=4, train_wall=261, gb_free=15.6, wall=197199
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2904, 42808])
2023-09-22 17:31:12 | INFO | train_inner | epoch 014:   9048 / 9060 loss=6.759, nll_loss=3.382, ppl=10.42, wps=4881.2, ups=0.38, wpb=12996.7, bsz=404.9, num_updates=126800, lr=8.88056e-05, gnorm=0.918, loss_scale=4, train_wall=266, gb_free=13.9, wall=197465
2023-09-22 17:31:48 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-22 17:31:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 17:31:48 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-22 17:31:48 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-22 17:31:49 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-22 17:31:49 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-22 17:31:50 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-22 17:31:50 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-22 17:31:50 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-22 17:31:50 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-22 17:31:51 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-22 17:31:51 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-22 17:31:51 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu, und es war ein rasender Erfolg.
2023-09-22 17:31:51 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-22 17:31:52 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und Glückwünsche an unseren Präsidenten.
2023-09-22 17:31:52 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-22 17:31:53 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, was wir respektieren.
2023-09-22 17:31:53 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-22 17:31:53 | INFO | fairseq.tasks.translation | example hypothesis: Das Chatmodul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-22 17:31:53 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-22 17:31:54 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende gleichermaßen geeignet sind.
2023-09-22 17:31:54 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
lprobs.size(): torch.Size([3400, 42808])
2023-09-22 17:31:54 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-22 17:31:54 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-22 17:31:55 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 17:31:55 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-22 17:31:55 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU riesige Mengen an Energie verschwendet.
2023-09-22 17:31:55 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-22 17:31:56 | INFO | fairseq.tasks.translation | example hypothesis: Das Deutsche Linux Magazin hat einen Artikel des Gentoo Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-22 17:31:56 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-22 17:31:56 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellung in Kürze auch im Haushalt der Union niederschlagen.
2023-09-22 17:31:56 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-22 17:31:57 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-22 17:31:57 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-22 17:31:57 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die allgemein bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-22 17:31:57 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-22 17:31:58 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-22 17:31:58 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-22 17:31:58 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-22 17:31:58 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-22 17:31:59 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-22 17:31:59 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-22 17:31:59 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-22 17:31:59 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-22 17:32:00 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-22 17:32:00 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-22 17:32:01 | INFO | fairseq.tasks.translation | example hypothesis: Das funktionelle Bindeglied dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-22 17:32:01 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-22 17:32:01 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potentielle Käufer veranlassen, sich über die Qualität Ihres Services und Ihrer Produkte zu informieren.
2023-09-22 17:32:01 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-22 17:32:02 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter auf unbekanntes Territorium wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-22 17:32:02 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-22 17:32:02 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-22 17:32:02 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-22 17:32:03 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze diese Aussprache auch, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-22 17:32:03 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-22 17:32:04 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in etwa einem Umkreis von 8 km vom Strip entfernt.
2023-09-22 17:32:04 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-22 17:32:04 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Webportal-System basiert.
2023-09-22 17:32:04 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-22 17:32:05 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-22 17:32:05 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-22 17:32:05 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-22 17:32:05 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-22 17:32:06 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, kann sich aber bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-22 17:32:06 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-22 17:32:07 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Ausstieg Zugang zu dem Geld haben, das ihnen in die europäischen Sozialversicherungssysteme eingezahlt wird.
2023-09-22 17:32:07 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-22 17:32:07 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-22 17:32:07 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-22 17:32:08 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-22 17:32:08 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-22 17:32:08 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachkräfte zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-22 17:32:08 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-22 17:32:09 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-22 17:32:09 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-22 17:32:10 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils-Benutzer müssen splashutils erneut emergen, damit es korrekt funktionieren kann.
2023-09-22 17:32:10 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-22 17:32:10 | INFO | fairseq.tasks.translation | example hypothesis: Spieler von Horde und Allianz können Gegenstände nicht kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser benutzen.
2023-09-22 17:32:10 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-22 17:32:11 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-22 17:32:11 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-22 17:32:12 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn die Entlastung der Kommission für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-22 17:32:12 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-22 17:32:12 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens im Prinzip mit den Vereinigten Staaten abgeben müssen.
2023-09-22 17:32:12 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-22 17:32:13 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unsere breite Palette an Plastik-Babyartikeln ist beeindruckend, nicht zuletzt wegen ihrer hervorragenden Verarbeitung.
2023-09-22 17:32:13 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-22 17:32:13 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourismus"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 17:32:13 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-22 17:32:14 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis Kenntnis von Sachverhalten, die mit diesen AGB nicht kompatibel sind, über Sachverhalten zu informieren.
2023-09-22 17:32:14 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-22 17:32:15 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht hat und die die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung erfordert.
2023-09-22 17:32:15 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-22 17:32:15 | INFO | fairseq.tasks.translation | example hypothesis: Neben unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktnachrichten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-22 17:32:15 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-22 17:32:16 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte anerkennen, die bei der Prüfung aller Fragen, die jetzt zur Diskussion stehen, zu etwas, das gerade zwei Jahre alt ist, der neuen transatlantischen Agenda, erzielt wurden.
2023-09-22 17:32:16 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-22 17:32:17 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-22 17:32:17 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-22 17:32:18 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es der Berichterstatterin gelungen, zeitweise unterschiedliche Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 17:32:18 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-22 17:32:18 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT T T T-Modell unser Programm an trockenen elektrostatischen Niederlegern mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-22 17:32:18 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-22 17:32:19 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seit Jahrhunderten seine Freiheit und Unabhängigkeit verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-22 17:32:19 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-22 17:32:20 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-22 17:32:20 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-22 17:32:20 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-22 17:32:20 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-22 17:32:21 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-22 17:32:21 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-22 17:32:22 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht der Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-22 17:32:22 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-22 17:32:22 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-22 17:32:22 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-22 17:32:23 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch einen anderen: die Notsituation der Kinder, dem schwächsten Teil der Bevölkerung, der ohne Familie, ohne Schutz und ohne Staat gelassen wurde.
2023-09-22 17:32:23 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-22 17:32:24 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt ist, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen.
2023-09-22 17:32:24 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-22 17:32:24 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht befreit ist, erst nicht verwirklicht ist, bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, bis man sein wahres Selbst kennt.
2023-09-22 17:32:24 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-22 17:32:25 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher von entscheidender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in ihrer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Periode zu schaffen und das Verfahren zur Registrierung der Wähler wieder zu eröffnen.
2023-09-22 17:32:25 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-22 17:32:26 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit deutlich gemacht werden, dass niemand über dem Gesetz steht.
2023-09-22 17:32:26 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-22 17:32:27 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java-Programmiersprache mit J2EE-Techniken implementiert, die die Plattform- und Betriebssystem-Unabhängigkeit gewährleisten (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-22 17:32:27 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-22 17:32:27 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur stärkeren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für die Klärung des Anhangs.
2023-09-22 17:32:27 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-22 17:32:28 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-22 17:32:28 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-22 17:32:29 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich habe ich an einer Aussprache über den irischen öffentlich-rechtlichen Rundfunk RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben senken und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu senken.
2023-09-22 17:32:29 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-22 17:32:29 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-22 17:32:29 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-22 17:32:30 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie nach Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Bürgerschaft oder etwas so Spezielles wie die Verringerung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Studenten zugeschnitten ist.
2023-09-22 17:32:30 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-22 17:32:31 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.......
2023-09-22 17:32:31 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-22 17:32:32 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-22 17:32:32 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-22 17:32:33 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken, heißt, eine bestimmte Art von Vertragsverhältnis zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystizieren (unter ihnen ist oft die tatsächliche oder wahrgenommene Drohung, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-22 17:32:33 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-22 17:32:33 | INFO | fairseq.tasks.translation | example hypothesis: In der Rechtsprechung der Gemeinschaft zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn zum Beispiel die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-22 17:32:33 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-22 17:32:34 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Autos, das man für weniger als 50.000 $fahren kann, und wenn man in der Nähe von Toronto, Montreal oder Vancouver wohnt, kann man die gesamte Strecke kostenlos ausprobieren.
2023-09-22 17:32:34 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-22 17:32:35 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für seinen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-22 17:32:35 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-22 17:32:36 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die hervorragenden Süßwasserfische: gegrillter Hecht, Forelle mit Mandeln.
2023-09-22 17:32:36 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-22 17:32:36 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, einen Gesamtüberblick zu geben, der es uns ermöglicht, auf die verschiedenen Fragen eingehender einzugehen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-22 17:32:36 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-22 17:32:37 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, einigten sich darauf, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-22 17:32:37 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-22 17:32:38 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar gefährdet sind und die Wettbewerbsfähigkeit aufgrund der makroökonomischen Politik, der steuerlichen Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, schrittweise ausgehöhlt wird.
2023-09-22 17:32:38 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-22 17:32:39 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, einen Beitrag geleistet hat.
2023-09-22 17:32:39 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-22 17:32:40 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus mit den entsprechenden Folgen für den Rechts- und Rechtsbereich, wodurch Norwegen und Island, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden, die gemeinsamen Auslieferungsvorschriften gelten werden.
2023-09-22 17:32:40 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-22 17:32:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir fahren mit voller Geschwindigkeit mit einem Schichtboot hinunter den Mississippi, suchen nach dem großen verborgenen Schatz, verlieben uns in den schönen Becky Thatcher, der rein dynamisch ist, und vor allem werden wir große Freunde sein........................
2023-09-22 17:32:41 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-22 17:32:41 | INFO | fairseq.tasks.translation | example hypothesis: Praktisch harmonisiert die Richtlinie die Definition der durch Schiffe verursachten Verschmutzung durch Einzelpersonen oder juristische Personen, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die im Falle solcher Verstöße von Einzelpersonen verhängt werden können.
2023-09-22 17:32:41 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-22 17:32:42 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falization und Vincent Reynaud wurden nämlich verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner erledigt und eine Gruppe von Bergregionen gefilmt haben, die jahrelang von einem autoritären Regime gejagt wurden, das jeden Grundsatz der Demokratie missachtet.................
2023-09-22 17:32:42 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-22 17:32:43 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen ein Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Wechselstube, kostenfreie Shoeshine und WLAN. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-22 17:32:43 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-22 17:32:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquellen verdankt, die Königin D. Leonor, Ehefrau von König D. João II, und bekannt durch ihre Keramik, die international für ihre bildlichen und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-22 17:32:44 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-22 17:32:45 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um einen Fall guter Pro-Westler auf der einen Seite und Befürworter des ehemaligen Regimes auf der anderen Seite handelt - das ist ebenfalls verwerflich, da die Rollen von heute und davor allgemein bekannt sind.
2023-09-22 17:32:45 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-22 17:32:46 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, lassen Sie mich sagen, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, da viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt werden, und dies ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-22 17:32:46 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-22 17:32:46 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär aufgrund seines Status als Aktionär außerhalb einer Aktionärsversammlung Informationen zur Verfügung gestellt, so sind diese auf Verlangen an einen anderen Aktionär in der Hauptversammlung weiterzugeben, auch wenn diese Informationen nicht notwendig sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-22 17:32:46 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-22 17:32:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die in der Regel in die Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.
2023-09-22 17:32:47 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-22 17:32:48 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder die NATO in diesen Kriegshandlungen hätten verwickelt sein können -, mit Informationen zu helfen, die es keinen Grund mehr gibt, geheim, versteckt oder geheim zu halten, damit wir die Fakten ans Licht bringen können und die ganze Wahrheit gesagt werden kann.
2023-09-22 17:32:48 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-22 17:32:49 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30-minütige Zugfahrt vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 17:32:49 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-22 17:32:50 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Geschäftseinheit Defence Electronics und Indra in Spanien, wird der Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen beinhalten, die für nachhaltige und zuverlässige ISTAR-Missionen, die die heutigen außerhalb der Regalplattformen nie erreichen können, von entscheidender Bedeutung sind.
2023-09-22 17:32:50 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-22 17:32:51 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen unmissverständlich klarstellen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit jene Produkte vom Markt zu nehmen, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt ein ernstes Risiko darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 feststellt.
2023-09-22 17:32:51 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-22 17:32:52 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem bloßen Deckmantel der Moderne und Postmoderne oder der klaren Opposition von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und andauernde Spannung jener beiden ästhetischen Politiken anerkennen, die in eben jene Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.
2023-09-22 17:32:52 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-22 17:32:53 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Aussprachen und angesichts der Meinungen, die Sie mir gegeben haben, die das, was ich gerade gesagt habe, weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen unsere Aussprachen führen, und wenn die vierzig Petenten nicht anwesend sind, werde ich bei der Abstimmung nicht um die Prüfung der Beschlussfähigkeit bitten... Wenn die vierzig Petenten nicht anwesend sind, werde ich nicht um die Feststellung der Beschlussfähigkeit bitten.
2023-09-22 17:32:53 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-22 17:32:54 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips niemals akzeptiert haben, dann sind es paradoxerweise genau diese Völker, die nicht nur Zeugen eines alten, vergessenen Europa sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt sind, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung der ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen.............................
2023-09-22 17:32:54 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-22 17:32:55 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Weise als hybride Form veröffentlicht, die Rezensionen und Artikel im Quartalszeitschrift sind für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Webseiten des H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt................... H H H-Net mit Sitz in Berlin ist in Berlin, Berlin, Berlin)
2023-09-22 17:32:55 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-22 17:32:57 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit dem Einzug der neuen Smartphone-Generation haben Handys ihre Federn erheblich verfeinert und sich von einst geblasenen Taschenlampen über polyphonisch tootende Game Boy-Ambitionen bis hin zu schlichten Mini-PCs mit knackigem CD-Qualität Stereo-Sound gegossen: Künftig könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen entwickeln.
2023-09-22 17:32:57 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-22 17:32:59 | INFO | fairseq.tasks.translation | example hypothesis: En un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se se cuenta de que éstos jamás renunciarán a su tierra, haciendo un konfliarmado; en la dequé de dequé de dequado.
2023-09-22 17:32:59 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-22 17:32:59 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 4.161 | nll_loss 2.185 | ppl 4.55 | bleu 29.1 | wps 16654 | wpb 12011.9 | bsz 398.1 | num_updates 126812 | best_bleu 29.46
2023-09-22 17:32:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 126812 updates
2023-09-22 17:32:59 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint14.pt
2023-09-22 17:33:06 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint14.pt
2023-09-22 17:33:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint14.pt (epoch 14 @ 126812 updates, score 29.1) (writing took 11.273567288997583 seconds)
2023-09-22 17:33:10 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2023-09-22 17:33:10 | INFO | train | epoch 014 | loss 6.818 | nll_loss 3.37 | ppl 10.34 | wps 5251.6 | ups 0.4 | wpb 12977.4 | bsz 430.6 | num_updates 126812 | lr 8.88014e-05 | gnorm 0.94 | loss_scale 4 | train_wall 22274 | gb_free 13.7 | wall 197584
2023-09-22 17:33:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-22 17:33:11 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-22 17:33:11 | INFO | fairseq.trainer | begin training epoch 15
2023-09-22 17:33:11 | INFO | fairseq_cli.train | Start iterating over samples
pred_new.size(): torch.Size([5880, 42808])
2023-09-22 17:37:10 | INFO | train_inner | epoch 015:     88 / 9060 loss=6.853, nll_loss=3.36, ppl=10.27, wps=3600.1, ups=0.28, wpb=12903.1, bsz=435.9, num_updates=126900, lr=8.87706e-05, gnorm=0.963, loss_scale=4, train_wall=275, gb_free=13.6, wall=197824
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([2862, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 17:41:36 | INFO | train_inner | epoch 015:    188 / 9060 loss=6.767, nll_loss=3.346, ppl=10.17, wps=4802.6, ups=0.38, wpb=12784.6, bsz=422.8, num_updates=127000, lr=8.87357e-05, gnorm=0.95, loss_scale=4, train_wall=266, gb_free=14.1, wall=198090
2023-09-22 17:46:01 | INFO | train_inner | epoch 015:    288 / 9060 loss=6.871, nll_loss=3.389, ppl=10.48, wps=4921.7, ups=0.38, wpb=13019.7, bsz=433.5, num_updates=127100, lr=8.87007e-05, gnorm=0.939, loss_scale=4, train_wall=264, gb_free=13.9, wall=198354
2023-09-22 17:50:12 | INFO | train_inner | epoch 015:    388 / 9060 loss=6.812, nll_loss=3.322, ppl=10, wps=5204.4, ups=0.4, wpb=13050.7, bsz=452.7, num_updates=127200, lr=8.86659e-05, gnorm=0.919, loss_scale=4, train_wall=251, gb_free=13.5, wall=198605
pred_new.size(): torch.Size([2870, 42808])
2023-09-22 17:54:46 | INFO | train_inner | epoch 015:    488 / 9060 loss=6.93, nll_loss=3.376, ppl=10.38, wps=4734.3, ups=0.36, wpb=13006.4, bsz=428.9, num_updates=127300, lr=8.8631e-05, gnorm=0.963, loss_scale=4, train_wall=274, gb_free=13.1, wall=198880
pred_new.size(): torch.Size([3320, 42808])
2023-09-22 17:59:04 | INFO | train_inner | epoch 015:    588 / 9060 loss=6.925, nll_loss=3.398, ppl=10.54, wps=5033.3, ups=0.39, wpb=12967.3, bsz=426.9, num_updates=127400, lr=8.85962e-05, gnorm=0.962, loss_scale=4, train_wall=257, gb_free=14.4, wall=199138
pred_new.size(): torch.Size([3744, 42808])
2023-09-22 18:03:22 | INFO | train_inner | epoch 015:    688 / 9060 loss=6.941, nll_loss=3.381, ppl=10.42, wps=5085.7, ups=0.39, wpb=13108.3, bsz=431.3, num_updates=127500, lr=8.85615e-05, gnorm=0.956, loss_scale=4, train_wall=257, gb_free=14.8, wall=199395
2023-09-22 18:07:34 | INFO | train_inner | epoch 015:    788 / 9060 loss=6.78, nll_loss=3.346, ppl=10.16, wps=5141.8, ups=0.4, wpb=12958.4, bsz=419.5, num_updates=127600, lr=8.85268e-05, gnorm=0.935, loss_scale=4, train_wall=252, gb_free=14.9, wall=199647
pred_new.size(): torch.Size([2652, 42808])
ter_threshold: 0.427633
num_accepted / total 43 128
loss token level: tensor(8636.1094, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4496., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4032, 42808])
pred_new.size(): torch.Size([5160, 42808])
2023-09-22 18:11:51 | INFO | train_inner | epoch 015:    888 / 9060 loss=6.876, nll_loss=3.363, ppl=10.29, wps=5104.2, ups=0.39, wpb=13110.6, bsz=432.6, num_updates=127700, lr=8.84921e-05, gnorm=0.935, loss_scale=4, train_wall=257, gb_free=13.8, wall=199904
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([1794, 42808])
2023-09-22 18:16:15 | INFO | train_inner | epoch 015:    988 / 9060 loss=6.891, nll_loss=3.361, ppl=10.28, wps=4918.3, ups=0.38, wpb=13006.9, bsz=438.6, num_updates=127800, lr=8.84575e-05, gnorm=0.986, loss_scale=4, train_wall=264, gb_free=13.6, wall=200169
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([480, 42808])
ter_threshold: 0.41945899999999997
num_accepted / total 56 128
loss token level: tensor(9339.8848, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6264., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3256, 42808])
ter_threshold: 0.419805
num_accepted / total 37 96
loss token level: tensor(9476.8887, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10024., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2940, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.420129
num_accepted / total 102 232
loss token level: tensor(7466.4951, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3868., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5368, 42808])
pred_new.size(): torch.Size([4371, 42808])
pred_new.size(): torch.Size([567, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([1800, 42808])
lprobs.size(): torch.Size([2592, 42808])
ter_threshold: 0.42091599999999996
num_accepted / total 16 72
loss token level: tensor(10779.9209, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2928., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([288, 42808])
pred_new.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2580, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([5225, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.421552
num_accepted / total 16 88
loss token level: tensor(8902.9375, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4036., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3330, 42808])
pred_new.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6342, 42808])
lprobs.size(): torch.Size([2624, 42808])
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2438, 42808])
ter_threshold: 0.422879
num_accepted / total 84 136
loss token level: tensor(9002.4141, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8200., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5418, 42808])
pred_new.size(): torch.Size([5940, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3780, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([5664, 42808])
lprobs.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([4275, 42808])
ter_threshold: 0.42375999999999997
num_accepted / total 61 136
loss token level: tensor(8661.4316, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10272., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.424317
num_accepted / total 134 272
loss token level: tensor(7772.1592, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7824., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1296, 42808])
pred_new.size(): torch.Size([2420, 42808])
ter_threshold: 0.424411
num_accepted / total 76 136
loss token level: tensor(8967.7393, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13456., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.424493
num_accepted / total 41 136
loss token level: tensor(8575.8828, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5600., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([1680, 42808])
pred_new.size(): torch.Size([3969, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5198, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([6264, 42808])
pred_new.size(): torch.Size([4248, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.42527
num_accepted / total 59 136
loss token level: tensor(9608.0234, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10480., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.425293
num_accepted / total 17 72
loss token level: tensor(8534.5127, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5812., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([744, 42808])
ter_threshold: 0.425643
num_accepted / total 35 96
loss token level: tensor(9072.7666, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9280., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.425654
num_accepted / total 19 88
loss token level: tensor(9165.9248, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2992., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1694, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3960, 42808])
pred_new.size(): torch.Size([2100, 42808])
pred_new.size(): torch.Size([3509, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([3640, 42808])
ter_threshold: 0.426582
num_accepted / total 73 144
loss token level: tensor(8313.3457, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11072., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.426598
num_accepted / total 52 192
loss token level: tensor(11592.2314, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3616., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2475, 42808])
lprobs.size(): torch.Size([3392, 42808])
ter_threshold: 0.42671499999999996
num_accepted / total 11 48
loss token level: tensor(8924.2334, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3484., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([2925, 42808])
pred_new.size(): torch.Size([2852, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([1728, 42808])
ter_threshold: 0.427426
num_accepted / total 101 168
loss token level: tensor(8784.3896, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13568., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.427633
num_accepted / total 3 72
loss token level: tensor(8728.0547, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(508., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3724, 42808])
pred_new.size(): torch.Size([4312, 42808])
pred_new.size(): torch.Size([3465, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): lprobs.size(): torch.Size([3096, 42808])
2023-09-22 18:20:22 | INFO | train_inner | epoch 015:   1088 / 9060 loss=6.836, nll_loss=3.382, ppl=10.43, wps=5245.6, ups=0.41, wpb=12942, bsz=432.5, num_updates=127900, lr=8.84229e-05, gnorm=0.948, loss_scale=4, train_wall=246, gb_free=13, wall=200415
2023-09-22 18:24:24 | INFO | train_inner | epoch 015:   1188 / 9060 loss=6.82, nll_loss=3.364, ppl=10.29, wps=5384.6, ups=0.41, wpb=13057.6, bsz=444.3, num_updates=128000, lr=8.83883e-05, gnorm=0.953, loss_scale=4, train_wall=242, gb_free=13.8, wall=200658
lprobs.size(): torch.Size([2944, 42808])
2023-09-22 18:28:41 | INFO | train_inner | epoch 015:   1288 / 9060 loss=6.836, nll_loss=3.36, ppl=10.27, wps=5057.3, ups=0.39, wpb=12958.6, bsz=405.6, num_updates=128100, lr=8.83538e-05, gnorm=0.967, loss_scale=4, train_wall=256, gb_free=15.2, wall=200914
lprobs.size(): torch.Size([3136, 42808])
2023-09-22 18:33:13 | INFO | train_inner | epoch 015:   1388 / 9060 loss=6.885, nll_loss=3.348, ppl=10.18, wps=4755.6, ups=0.37, wpb=12928.4, bsz=449.6, num_updates=128200, lr=8.83194e-05, gnorm=0.994, loss_scale=4, train_wall=272, gb_free=14.7, wall=201186
ter_threshold: 0.42827099999999996
num_accepted / total 205 352
loss token level: tensor(7193.2021, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6512., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
2023-09-22 18:37:22 | INFO | train_inner | epoch 015:   1488 / 9060 loss=6.843, nll_loss=3.345, ppl=10.16, wps=5221.2, ups=0.4, wpb=13046.2, bsz=424, num_updates=128300, lr=8.82849e-05, gnorm=0.939, loss_scale=4, train_wall=250, gb_free=14.1, wall=201436
2023-09-22 18:41:37 | INFO | train_inner | epoch 015:   1588 / 9060 loss=6.778, nll_loss=3.334, ppl=10.08, wps=5143.1, ups=0.39, wpb=13072.3, bsz=453.3, num_updates=128400, lr=8.82506e-05, gnorm=0.955, loss_scale=4, train_wall=254, gb_free=14.8, wall=201690
ter_threshold: 0.42841399999999996
num_accepted / total 54 136
loss token level: tensor(9447.0781, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5760., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([1600, 42808])
2023-09-22 18:45:56 | INFO | train_inner | epoch 015:   1688 / 9060 loss=6.81, nll_loss=3.337, ppl=10.11, wps=5043.2, ups=0.39, wpb=13063.1, bsz=419.8, num_updates=128500, lr=8.82162e-05, gnorm=0.959, loss_scale=4, train_wall=259, gb_free=15.2, wall=201949
pred_new.size(): torch.Size([940, 42808])
2023-09-22 18:50:22 | INFO | train_inner | epoch 015:   1788 / 9060 loss=6.907, nll_loss=3.387, ppl=10.46, wps=4871.9, ups=0.38, wpb=12959.9, bsz=422.8, num_updates=128600, lr=8.81819e-05, gnorm=0.947, loss_scale=4, train_wall=266, gb_free=14, wall=202215
ter_threshold: 0.428616
num_accepted / total 34 80
loss token level: tensor(8800.5117, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5896., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2964, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 18:54:57 | INFO | train_inner | epoch 015:   1888 / 9060 loss=6.878, nll_loss=3.364, ppl=10.29, wps=4704.4, ups=0.36, wpb=12977.6, bsz=425.1, num_updates=128700, lr=8.81476e-05, gnorm=0.96, loss_scale=4, train_wall=276, gb_free=15.9, wall=202491
2023-09-22 18:59:16 | INFO | train_inner | epoch 015:   1988 / 9060 loss=6.868, nll_loss=3.358, ppl=10.25, wps=5015.9, ups=0.39, wpb=12976.6, bsz=430.2, num_updates=128800, lr=8.81134e-05, gnorm=0.972, loss_scale=4, train_wall=258, gb_free=13.6, wall=202750
pred_new.size(): torch.Size([6150, 42808])
lprobs.size(): torch.Size([3080, 42808])
ter_threshold: 0.42884599999999995
num_accepted / total 40 80
loss token level: tensor(9212.1143, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13856., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 19:03:30 | INFO | train_inner | epoch 015:   2088 / 9060 loss=6.868, nll_loss=3.42, ppl=10.7, wps=5053.9, ups=0.39, wpb=12813.8, bsz=431.2, num_updates=128900, lr=8.80792e-05, gnorm=0.966, loss_scale=4, train_wall=253, gb_free=14.1, wall=203003
ter_threshold: 0.428996
num_accepted / total 37 104
loss token level: tensor(9077.6982, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8312., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 19:07:53 | INFO | train_inner | epoch 015:   2188 / 9060 loss=6.833, nll_loss=3.391, ppl=10.49, wps=4896.9, ups=0.38, wpb=12893.4, bsz=427.2, num_updates=129000, lr=8.80451e-05, gnorm=0.956, loss_scale=4, train_wall=263, gb_free=13.8, wall=203266
pred_new.size(): torch.Size([2340, 42808])
lprobs.size(): torch.Size([3312, 42808])
2023-09-22 19:12:21 | INFO | train_inner | epoch 015:   2288 / 9060 loss=6.891, nll_loss=3.39, ppl=10.48, wps=4857.6, ups=0.37, wpb=13005.7, bsz=406.6, num_updates=129100, lr=8.8011e-05, gnorm=0.964, loss_scale=4, train_wall=267, gb_free=15, wall=203534
lprobs.size(): torch.Size([3008, 42808])
2023-09-22 19:16:40 | INFO | train_inner | epoch 015:   2388 / 9060 loss=6.844, nll_loss=3.353, ppl=10.22, wps=5000, ups=0.39, wpb=12947.2, bsz=463.9, num_updates=129200, lr=8.79769e-05, gnorm=0.991, loss_scale=4, train_wall=259, gb_free=13.2, wall=203793
pred_new.size(): torch.Size([1092, 42808])
2023-09-22 19:21:13 | INFO | train_inner | epoch 015:   2488 / 9060 loss=6.807, nll_loss=3.336, ppl=10.1, wps=4773.8, ups=0.37, wpb=13052.3, bsz=433.2, num_updates=129300, lr=8.79429e-05, gnorm=0.928, loss_scale=4, train_wall=273, gb_free=14.4, wall=204067
pred_new.size(): torch.Size([6831, 42808])
2023-09-22 19:25:27 | INFO | train_inner | epoch 015:   2588 / 9060 loss=6.922, nll_loss=3.395, ppl=10.52, wps=5114.5, ups=0.39, wpb=12999.1, bsz=466.8, num_updates=129400, lr=8.79089e-05, gnorm=0.945, loss_scale=4, train_wall=254, gb_free=13.6, wall=204321
lprobs.size(): torch.Size([2992, 42808])
2023-09-22 19:29:54 | INFO | train_inner | epoch 015:   2688 / 9060 loss=6.926, nll_loss=3.407, ppl=10.61, wps=4858.2, ups=0.38, wpb=12953.4, bsz=425.4, num_updates=129500, lr=8.7875e-05, gnorm=0.973, loss_scale=4, train_wall=266, gb_free=14.1, wall=204587
ter_threshold: 0.42950999999999995
num_accepted / total 31 56
loss token level: tensor(7523.7686, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12976., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.429533
num_accepted / total 13 48
loss token level: tensor(9011.6953, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7048., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 19:34:08 | INFO | train_inner | epoch 015:   2788 / 9060 loss=6.774, nll_loss=3.368, ppl=10.32, wps=5117.5, ups=0.39, wpb=13001.1, bsz=408.3, num_updates=129600, lr=8.7841e-05, gnorm=0.942, loss_scale=4, train_wall=254, gb_free=13.2, wall=204841
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1896, 42808])
2023-09-22 19:38:32 | INFO | train_inner | epoch 015:   2888 / 9060 loss=6.921, nll_loss=3.406, ppl=10.6, wps=4927.8, ups=0.38, wpb=13001.3, bsz=439.1, num_updates=129700, lr=8.78072e-05, gnorm=0.956, loss_scale=4, train_wall=264, gb_free=13.8, wall=205105
lprobs.size(): torch.Size([2320, 42808])
ter_threshold: 0.429745
num_accepted / total 54 112
loss token level: tensor(9349.7158, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12424., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 19:42:39 | INFO | train_inner | epoch 015:   2988 / 9060 loss=6.878, nll_loss=3.404, ppl=10.58, wps=5255.6, ups=0.4, wpb=12978.7, bsz=426.8, num_updates=129800, lr=8.77733e-05, gnorm=0.946, loss_scale=4, train_wall=247, gb_free=13.1, wall=205352
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 19:47:02 | INFO | train_inner | epoch 015:   3088 / 9060 loss=6.893, nll_loss=3.385, ppl=10.44, wps=4939.1, ups=0.38, wpb=12984.9, bsz=440.1, num_updates=129900, lr=8.77396e-05, gnorm=0.985, loss_scale=4, train_wall=263, gb_free=14.8, wall=205615
lprobs.size(): torch.Size([2904, 42808])
pred_new.size(): torch.Size([101, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-22 19:51:23 | INFO | train_inner | epoch 015:   3188 / 9060 loss=6.977, nll_loss=3.439, ppl=10.85, wps=4945.3, ups=0.38, wpb=12909.2, bsz=417.2, num_updates=130000, lr=8.77058e-05, gnorm=0.986, loss_scale=4, train_wall=261, gb_free=15, wall=205876
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3888, 42808])
ter_threshold: 0.430068
num_accepted / total 16 88
loss token level: tensor(11546.8174, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4344., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 19:55:30 | INFO | train_inner | epoch 015:   3288 / 9060 loss=6.729, nll_loss=3.286, ppl=9.75, wps=5246.7, ups=0.4, wpb=12956, bsz=429.2, num_updates=130100, lr=8.76721e-05, gnorm=0.95, loss_scale=4, train_wall=247, gb_free=15.2, wall=206123
lprobs.size(): torch.Size([3408, 42808])
2023-09-22 19:59:55 | INFO | train_inner | epoch 015:   3388 / 9060 loss=6.977, nll_loss=3.444, ppl=10.88, wps=4890.9, ups=0.38, wpb=12963.1, bsz=407.9, num_updates=130200, lr=8.76384e-05, gnorm=1.033, loss_scale=4, train_wall=265, gb_free=14.2, wall=206388
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([5777, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-22 20:04:08 | INFO | train_inner | epoch 015:   3488 / 9060 loss=6.862, nll_loss=3.411, ppl=10.64, wps=5109.9, ups=0.4, wpb=12932.6, bsz=438.4, num_updates=130300, lr=8.76048e-05, gnorm=0.956, loss_scale=4, train_wall=253, gb_free=14.8, wall=206641
pred_new.size(): torch.Size([9040, 42808])
2023-09-22 20:08:16 | INFO | train_inner | epoch 015:   3588 / 9060 loss=6.95, nll_loss=3.425, ppl=10.74, wps=5252.5, ups=0.4, wpb=13026, bsz=428.3, num_updates=130400, lr=8.75712e-05, gnorm=0.976, loss_scale=8, train_wall=248, gb_free=13.7, wall=206889
lprobs.size(): torch.Size([3248, 42808])
2023-09-22 20:12:23 | INFO | train_inner | epoch 015:   3688 / 9060 loss=6.847, nll_loss=3.391, ppl=10.49, wps=5258.1, ups=0.4, wpb=13013.3, bsz=417.6, num_updates=130500, lr=8.75376e-05, gnorm=0.956, loss_scale=8, train_wall=247, gb_free=15, wall=207137
lprobs.size(): torch.Size([2944, 42808])
2023-09-22 20:16:42 | INFO | train_inner | epoch 015:   3788 / 9060 loss=6.819, nll_loss=3.35, ppl=10.2, wps=5023.2, ups=0.39, wpb=13016.2, bsz=417.9, num_updates=130600, lr=8.75041e-05, gnorm=0.944, loss_scale=8, train_wall=259, gb_free=13.6, wall=207396
2023-09-22 20:17:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
lprobs.size(): torch.Size([3344, 42808])
2023-09-22 20:20:59 | INFO | train_inner | epoch 015:   3889 / 9060 loss=6.843, nll_loss=3.402, ppl=10.57, wps=5022.9, ups=0.39, wpb=12897.1, bsz=413.6, num_updates=130700, lr=8.74706e-05, gnorm=0.984, loss_scale=4, train_wall=257, gb_free=13.8, wall=207653
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-22 20:25:12 | INFO | train_inner | epoch 015:   3989 / 9060 loss=7.022, nll_loss=3.496, ppl=11.28, wps=5144.9, ups=0.4, wpb=13012.9, bsz=414.1, num_updates=130800, lr=8.74372e-05, gnorm=0.974, loss_scale=4, train_wall=253, gb_free=14.2, wall=207906
pred_new.size(): torch.Size([3120, 42808])
2023-09-22 20:29:32 | INFO | train_inner | epoch 015:   4089 / 9060 loss=7.045, nll_loss=3.454, ppl=10.96, wps=4997.5, ups=0.39, wpb=12966.1, bsz=444.8, num_updates=130900, lr=8.74038e-05, gnorm=0.99, loss_scale=4, train_wall=259, gb_free=15.1, wall=208165
ter_threshold: 0.430929
num_accepted / total 8 56
loss token level: tensor(9317.7402, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1696., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3192, 42808])
2023-09-22 20:33:46 | INFO | train_inner | epoch 015:   4189 / 9060 loss=6.962, nll_loss=3.43, ppl=10.78, wps=5074.1, ups=0.39, wpb=12928.5, bsz=432.2, num_updates=131000, lr=8.73704e-05, gnorm=0.97, loss_scale=4, train_wall=255, gb_free=13.9, wall=208420
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2205, 42808])
pred_new.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3900, 42808])
ter_threshold: 0.422879
num_accepted / total 13 88
loss token level: tensor(11885.1768, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2176., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([5824, 42808])
pred_new.size(): torch.Size([1668, 42808])
pred_new.size(): torch.Size([4080, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([5475, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([966, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.423757
num_accepted / total 69 168
loss token level: tensor(8251.8271, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7360., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2544, 42808])
ter_threshold: 0.424317
num_accepted / total 14 96
loss token level: tensor(8991.8574, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2388., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1748, 42808])
pred_new.size(): torch.Size([3654, 42808])
lprobs.size(): torch.Size([3216, 42808])
ter_threshold: 0.424478
num_accepted / total 24 80
loss token level: tensor(8840.4170, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8200., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([3654, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([3454, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([6270, 42808])
ter_threshold: 0.42505
num_accepted / total 22 72
loss token level: tensor(8911.1250, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7840., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6969, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3128, 42808])
ter_threshold: 0.42527
num_accepted / total 49 104
loss token level: tensor(9455.9316, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12176., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5300, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1989, 42808])
ter_threshold: 0.425643
num_accepted / total 32 96
loss token level: tensor(8379.4482, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7952., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.425882
num_accepted / total 75 136
loss token level: tensor(9719.0547, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12120., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([3978, 42808])
pred_new.size(): torch.Size([176, 42808])
pred_new.size(): torch.Size([4950, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3600, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([1794, 42808])
ter_threshold: 0.426582
num_accepted / total 115 176
loss token level: tensor(8885.7246, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14472., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.426801
num_accepted / total 10 56
loss token level: tensor(9062.8857, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4664., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3224, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1728, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6240, 42808])
lprobs.size(): torch.Size([2632, 42808])
ter_threshold: 0.427426
num_accepted / total 62 160
loss token level: tensor(10322.2070, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8368., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4674, 42808])
pred_new.size(): torch.Size([4278, 42808])
ter_threshold: 0.427633
num_accepted / total 40 104
loss token level: tensor(9105.1338, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5576., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3045, 42808])
pred_new.size(): torch.Size([370, 42808])
ter_threshold: 0.42778
num_accepted / total 9 16
loss token level: tensor(7063.6987, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12224., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([2592, 42808])
ter_threshold: 0.42821699999999996
num_accepted / total 19 72
loss token level: tensor(9115.7031, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3810., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1276, 42808])
ter_threshold: 0.42827099999999996
num_accepted / total 49 112
loss token level: tensor(9269.7070, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10024., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([1242, 42808])
pred_new.size(): torch.Size([1148, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2604, 42808])
lprobs.size(): torch.Size([3232, 42808])
pred_new.size(): torch.Size([864, 42808])
ter_threshold: 0.428996
num_accepted / total 116 184
loss token level: tensor(8596.7812, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13192., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([896, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([1720, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3080, 42808])
ter_threshold: 0.429594
num_accepted / total 27 88
loss token level: tensor(9686.3906, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4560., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3807, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([5184, 42808])
ter_threshold: 0.429745
num_accepted / total 38 96
loss token level: tensor(8685.8477, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8992., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5453, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1904, 42808])
ter_threshold: 0.430056
num_accepted / total 117 184
loss token level: tensor(8304.9688, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13392., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5670, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([6790, 42808])
pred_new.size(): torch.Size([7800, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([4365, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.43102799999999997
num_accepted / total 23 80
loss token level: tensor(9571.3770, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: lprobs.size(): torch.Size([3240, 42808])
2023-09-22 20:37:55 | INFO | train_inner | epoch 015:   4289 / 9060 loss=6.942, nll_loss=3.422, ppl=10.72, wps=5265.7, ups=0.4, wpb=13090.9, bsz=445.3, num_updates=131100, lr=8.73371e-05, gnorm=0.952, loss_scale=4, train_wall=248, gb_free=13.6, wall=208668
pred_new.size(): torch.Size([12420, 42808])
2023-09-22 20:42:07 | INFO | train_inner | epoch 015:   4389 / 9060 loss=6.814, nll_loss=3.353, ppl=10.21, wps=5144.5, ups=0.4, wpb=12984, bsz=432.8, num_updates=131200, lr=8.73038e-05, gnorm=0.946, loss_scale=4, train_wall=252, gb_free=14.2, wall=208921
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([2332, 42808])
2023-09-22 20:46:22 | INFO | train_inner | epoch 015:   4489 / 9060 loss=7.031, nll_loss=3.466, ppl=11.05, wps=5114.2, ups=0.39, wpb=13013.9, bsz=446.5, num_updates=131300, lr=8.72705e-05, gnorm=0.97, loss_scale=4, train_wall=254, gb_free=13.2, wall=209175
pred_new.size(): torch.Size([3540, 42808])
lprobs.size(): torch.Size([3528, 42808])
2023-09-22 20:50:31 | INFO | train_inner | epoch 015:   4589 / 9060 loss=6.774, nll_loss=3.338, ppl=10.11, wps=5237.2, ups=0.4, wpb=13052.5, bsz=418.8, num_updates=131400, lr=8.72373e-05, gnorm=0.976, loss_scale=4, train_wall=249, gb_free=13.9, wall=209424
lprobs.size(): torch.Size([3248, 42808])
2023-09-22 20:54:42 | INFO | train_inner | epoch 015:   4689 / 9060 loss=6.919, nll_loss=3.4, ppl=10.56, wps=5177, ups=0.4, wpb=13015.8, bsz=449.6, num_updates=131500, lr=8.72041e-05, gnorm=0.98, loss_scale=4, train_wall=251, gb_free=13.2, wall=209676
pred_new.size(): torch.Size([2056, 42808])
pred_new.size(): torch.Size([5796, 42808])
pred_new.size(): torch.Size([1536, 42808])
pred_new.size(): torch.Size([5680, 42808])
2023-09-22 20:58:59 | INFO | train_inner | epoch 015:   4789 / 9060 loss=6.867, nll_loss=3.407, ppl=10.61, wps=5080.3, ups=0.39, wpb=13015.2, bsz=436.7, num_updates=131600, lr=8.7171e-05, gnorm=0.957, loss_scale=4, train_wall=256, gb_free=14.5, wall=209932
pred_new.size(): torch.Size([6120, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3948, 42808])
2023-09-22 21:03:20 | INFO | train_inner | epoch 015:   4889 / 9060 loss=6.786, nll_loss=3.334, ppl=10.09, wps=4923.3, ups=0.38, wpb=12850.4, bsz=445.5, num_updates=131700, lr=8.71379e-05, gnorm=0.955, loss_scale=4, train_wall=261, gb_free=14, wall=210193
ter_threshold: 0.43172
num_accepted / total 18 80
loss token level: tensor(9092.0254, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2692., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 21:07:59 | INFO | train_inner | epoch 015:   4989 / 9060 loss=6.87, nll_loss=3.391, ppl=10.49, wps=4632.8, ups=0.36, wpb=12946.6, bsz=429.1, num_updates=131800, lr=8.71048e-05, gnorm=0.959, loss_scale=4, train_wall=279, gb_free=14.3, wall=210473
2023-09-22 21:12:17 | INFO | train_inner | epoch 015:   5089 / 9060 loss=6.809, nll_loss=3.415, ppl=10.67, wps=4999.7, ups=0.39, wpb=12910.7, bsz=422.7, num_updates=131900, lr=8.70718e-05, gnorm=0.941, loss_scale=4, train_wall=258, gb_free=15.2, wall=210731
torch.Size([2560, 42808])
pred_new.size(): torch.Size([2475, 42808])
pred_new.size(): torch.Size([672, 42808])
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([3066, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([6440, 42808])
pred_new.size(): torch.Size([6336, 42808])
lprobs.size(): torch.Size([2968, 42808])
lprobs.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([5529, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([4644, 42808])
ter_threshold: 0.424317
num_accepted / total 40 104
loss token level: tensor(9830.3613, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9648., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2232, 42808])
pred_new.size(): torch.Size([1815, 42808])
ter_threshold: 0.424411
num_accepted / total 181 272
loss token level: tensor(9890.3105, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4675, 42808])
pred_new.size(): torch.Size([4200, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([330, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([5850, 42808])
pred_new.size(): torch.Size([6318, 42808])
pred_new.size(): torch.Size([81, 42808])
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.42527
num_accepted / total 44 128
loss token level: tensor(10221.5391, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8552., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1206, 42808])
ter_threshold: 0.425432
num_accepted / total 65 136
loss token level: tensor(8948.3027, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11552., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([3596, 42808])
lprobs.size(): torch.Size([2760, 42808])
pred_new.size(): torch.Size([6348, 42808])
ter_threshold: 0.425882
num_accepted / total 37 96
loss token level: tensor(9840.2695, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([3588, 42808])
pred_new.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1984, 42808])
pred_new.size(): torch.Size([3108, 42808])
ter_threshold: 0.426459
num_accepted / total 0 24
loss token level: tensor(8504.7637, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: 0
pred_new.size(): torch.Size([2480, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2088, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([5610, 42808])
lprobs.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([1880, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([3886, 42808])
pred_new.size(): torch.Size([8690, 42808])
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.427426
num_accepted / total 61 128
loss token level: tensor(9788.8516, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11480., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5070, 42808])
pred_new.size(): torch.Size([3172, 42808])
pred_new.size(): torch.Size([1632, 42808])
pred_new.size(): torch.Size([4455, 42808])
pred_new.size(): torch.Size([4180, 42808])
lprobs.size(): torch.Size([3400, 42808])
ter_threshold: 0.42841399999999996
num_accepted / total 54 144
loss token level: tensor(8192.1289, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4668., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6216, 42808])
ter_threshold: 0.42851799999999995
num_accepted / total 8 64
loss token level: tensor(11661.7891, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1876., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([3108, 42808])
ter_threshold: 0.428624
num_accepted / total 1 24
loss token level: tensor(9409.4688, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(551., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2052, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([1808, 42808])
ter_threshold: 0.428996
num_accepted / total 31 96
loss token level: tensor(10517.7861, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8168., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([714, 42808])
pred_new.size(): torch.Size([2146, 42808])
pred_new.size(): torch.Size([1892, 42808])
pred_new.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([861, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3618, 42808])
ter_threshold: 0.429745
num_accepted / total 45 96
loss token level: tensor(9317.3633, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10800., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([770, 42808])
pred_new.size(): torch.Size([7830, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1530, 42808])
pred_new.size(): torch.Size([3724, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([6500, 42808])
lprobs.size(): torch.Size([3096, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.43104699999999996
num_accepted / total 15 64
loss token level: tensor(11449.5820, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5436., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3402, 42808])
pred_new.size(): torch.Size([2065, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.431465
num_accepted / total 1 40
loss token level: tensor(8869.8008, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(205.2500, device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.43149899999999997
num_accepted / total 17 56
loss token level: tensor(8192.1191, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7336., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4988, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([5810, 42808])
ter_threshold: 0.43161499999999997
num_accepted / total 40 88
loss token level: tensor(9200.1641, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9664., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2744, 42808])
pred_new.size(): torch.Size([4428, 42808])
ter_threshold: 0.43191599999999997
num_accepted / total 78 160
loss token level: ter_threshold: 0.43191599999999997
num_accepted / total 43 112
loss token level: tensor(9871.3604, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5600., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5882, 42808])
pred_new.size(): torch.Size([4200, 42808])
2023-09-22 21:16:35 | INFO | train_inner | epoch 015:   5189 / 9060 loss=6.955, nll_loss=3.461, ppl=11.01, wps=5044.1, ups=0.39, wpb=12981.5, bsz=431.7, num_updates=132000, lr=8.70388e-05, gnorm=0.962, loss_scale=4, train_wall=257, gb_free=13.5, wall=210988
pred_new.size(): torch.Size([1428, 42808])
pred_new.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-22 21:21:15 | INFO | train_inner | epoch 015:   5289 / 9060 loss=6.907, nll_loss=3.403, ppl=10.58, wps=4634.5, ups=0.36, wpb=13005.6, bsz=431.9, num_updates=132100, lr=8.70059e-05, gnorm=0.98, loss_scale=4, train_wall=280, gb_free=14.7, wall=211269
2023-09-22 21:26:01 | INFO | train_inner | epoch 015:   5389 / 9060 loss=6.901, nll_loss=3.391, ppl=10.49, wps=4556, ups=0.35, wpb=13004.8, bsz=429, num_updates=132200, lr=8.6973e-05, gnorm=0.961, loss_scale=4, train_wall=285, gb_free=14, wall=211554
ter_threshold: 0.432269
num_accepted / total 23 104
loss token level: tensor(8173.0835, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4584., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 21:30:10 | INFO | train_inner | epoch 015:   5489 / 9060 loss=6.885, nll_loss=3.403, ppl=10.58, wps=5213.6, ups=0.4, wpb=12990.9, bsz=423.3, num_updates=132300, lr=8.69401e-05, gnorm=0.951, loss_scale=4, train_wall=249, gb_free=15, wall=211803
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3072, 42808])
2023-09-22 21:34:26 | INFO | train_inner | epoch 015:   5589 / 9060 loss=6.924, nll_loss=3.421, ppl=10.71, wps=5067.6, ups=0.39, wpb=12995, bsz=437.3, num_updates=132400, lr=8.69072e-05, gnorm=0.971, loss_scale=4, train_wall=256, gb_free=15.6, wall=212060
pred_new.size(): torch.Size([5016, 42808])
2023-09-22 21:38:46 | INFO | train_inner | epoch 015:   5689 / 9060 loss=6.963, nll_loss=3.432, ppl=10.79, wps=4975.5, ups=0.39, wpb=12909.4, bsz=427.1, num_updates=132500, lr=8.68744e-05, gnorm=0.976, loss_scale=4, train_wall=259, gb_free=14.9, wall=212319
lprobs.size(): torch.Size([3344, 42808])
2023-09-22 21:43:08 | INFO | train_inner | epoch 015:   5789 / 9060 loss=6.898, nll_loss=3.39, ppl=10.48, wps=4948.8, ups=0.38, wpb=12970.4, bsz=422.5, num_updates=132600, lr=8.68417e-05, gnorm=0.977, loss_scale=4, train_wall=262, gb_free=15.1, wall=212581
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([2619, 42808])
2023-09-22 21:47:30 | INFO | train_inner | epoch 015:   5889 / 9060 loss=6.884, nll_loss=3.403, ppl=10.58, wps=4942.1, ups=0.38, wpb=12971.7, bsz=437.7, num_updates=132700, lr=8.6809e-05, gnorm=0.967, loss_scale=4, train_wall=262, gb_free=15.1, wall=212844
lprobs.size(): torch.Size([3200, 42808])
2023-09-22 21:52:08 | INFO | train_inner | epoch 015:   5989 / 9060 loss=6.978, nll_loss=3.444, ppl=10.88, wps=4701.2, ups=0.36, wpb=13029.6, bsz=443.6, num_updates=132800, lr=8.67763e-05, gnorm=0.967, loss_scale=4, train_wall=277, gb_free=14.1, wall=213121
pred_new.size(): torch.Size([2538, 42808])
pred_new.size(): torch.Size([756, 42808])
2023-09-22 21:56:44 | INFO | train_inner | epoch 015:   6089 / 9060 loss=6.992, nll_loss=3.454, ppl=10.96, wps=4691.6, ups=0.36, wpb=12967.1, bsz=442.1, num_updates=132900, lr=8.67436e-05, gnorm=0.997, loss_scale=4, train_wall=276, gb_free=15.2, wall=213397
2023-09-22 22:01:22 | INFO | train_inner | epoch 015:   6189 / 9060 loss=6.798, nll_loss=3.38, ppl=10.41, wps=4673.3, ups=0.36, wpb=12993, bsz=416.1, num_updates=133000, lr=8.6711e-05, gnorm=0.945, loss_scale=4, train_wall=278, gb_free=13.5, wall=213675
pred_new.size(): torch.Size([3616, 42808])
2023-09-22 22:06:08 | INFO | train_inner | epoch 015:   6289 / 9060 loss=6.885, nll_loss=3.416, ppl=10.67, wps=4524, ups=0.35, wpb=12955, bsz=446.4, num_updates=133100, lr=8.66784e-05, gnorm=0.956, loss_scale=4, train_wall=286, gb_free=14.4, wall=213962
pred_new.size(): torch.Size([3010, 42808])
2023-09-22 22:10:53 | INFO | train_inner | epoch 015:   6389 / 9060 loss=6.801, nll_loss=3.344, ppl=10.15, wps=4592.5, ups=0.35, wpb=13064.2, bsz=435.7, num_updates=133200, lr=8.66459e-05, gnorm=0.941, loss_scale=4, train_wall=284, gb_free=15.1, wall=214246
2023-09-22 22:15:43 | INFO | train_inner | epoch 015:   6489 / 9060 loss=6.868, nll_loss=3.43, ppl=10.78, wps=4431.7, ups=0.34, wpb=12851.1, bsz=417.6, num_updates=133300, lr=8.66134e-05, gnorm=0.967, loss_scale=4, train_wall=290, gb_free=13.8, wall=214536
lprobs.size(): torch.Size([3480, 42808])
2023-09-22 22:20:20 | INFO | train_inner | epoch 015:   6589 / 9060 loss=6.895, nll_loss=3.419, ppl=10.7, wps=4659.1, ups=0.36, wpb=12934, bsz=422.9, num_updates=133400, lr=8.65809e-05, gnorm=0.957, loss_scale=4, train_wall=277, gb_free=13.9, wall=214814
2023-09-22 22:25:08 | INFO | train_inner | epoch 015:   6689 / 9060 loss=6.928, nll_loss=3.413, ppl=10.65, wps=4503.1, ups=0.35, wpb=12955, bsz=427, num_updates=133500, lr=8.65485e-05, gnorm=0.989, loss_scale=4, train_wall=287, gb_free=14.2, wall=215101
pred_new.size(): torch.Size([5985, 42808])
2023-09-22 22:29:54 | INFO | train_inner | epoch 015:   6789 / 9060 loss=6.872, nll_loss=3.396, ppl=10.53, wps=4530.6, ups=0.35, wpb=12971.5, bsz=420, num_updates=133600, lr=8.65161e-05, gnorm=0.956, loss_scale=4, train_wall=286, gb_free=13.7, wall=215388
lprobs.size(): torch.Size([3536, 42808])
2023-09-22 22:34:39 | INFO | train_inner | epoch 015:   6889 / 9060 loss=6.99, nll_loss=3.467, ppl=11.06, wps=4534.9, ups=0.35, wpb=12920.1, bsz=415.4, num_updates=133700, lr=8.64837e-05, gnorm=1.027, loss_scale=4, train_wall=285, gb_free=14.1, wall=215673
2023-09-22 22:39:18 | INFO | train_inner | epoch 015:   6989 / 9060 loss=6.858, nll_loss=3.411, ppl=10.64, wps=4641.1, ups=0.36, wpb=12947.6, bsz=427, num_updates=133800, lr=8.64514e-05, gnorm=0.947, loss_scale=4, train_wall=279, gb_free=15.1, wall=215952
lprobs.size(): torch.Size([3264, 42808])
2023-09-22 22:43:58 | INFO | train_inner | epoch 015:   7089 / 9060 loss=6.899, nll_loss=3.447, ppl=10.91, wps=4635.7, ups=0.36, wpb=12981.6, bsz=429.8, num_updates=133900, lr=8.64191e-05, gnorm=0.959, loss_scale=4, train_wall=280, gb_free=14, wall=216232
ter_threshold: 0.433965
num_accepted / total 27 72
loss token level: tensor(8695.7988, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5656., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 22:48:32 | INFO | train_inner | epoch 015:   7189 / 9060 loss=6.98, nll_loss=3.434, ppl=10.8, wps=4734.1, ups=0.36, wpb=12978.4, bsz=440.7, num_updates=134000, lr=8.63868e-05, gnorm=0.975, loss_scale=4, train_wall=274, gb_free=14.3, wall=216506
ter_threshold: 0.43409
num_accepted / total 21 88
loss token level: tensor(10009.3457, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5792., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
2023-09-22 22:53:07 | INFO | train_inner | epoch 015:   7289 / 9060 loss=6.909, nll_loss=3.42, ppl=10.7, wps=4696.5, ups=0.36, wpb=12909.1, bsz=426.6, num_updates=134100, lr=8.63546e-05, gnorm=0.98, loss_scale=4, train_wall=275, gb_free=13.3, wall=216781
2023-09-22 22:57:32 | INFO | train_inner | epoch 015:   7389 / 9060 loss=6.974, nll_loss=3.466, ppl=11.05, wps=4882.8, ups=0.38, wpb=12911.8, bsz=438.1, num_updates=134200, lr=8.63224e-05, gnorm=0.973, loss_scale=4, train_wall=264, gb_free=14.2, wall=217045
2023-09-22 23:02:00 | INFO | train_inner | epoch 015:   7489 / 9060 loss=6.94, nll_loss=3.421, ppl=10.71, wps=4851.5, ups=0.37, wpb=13024.7, bsz=444.3, num_updates=134300, lr=8.62903e-05, gnorm=0.979, loss_scale=4, train_wall=268, gb_free=13.7, wall=217314
pred_new.size(): torch.Size([4200, 42808])
2023-09-22 23:06:31 | INFO | train_inner | epoch 015:   7589 / 9060 loss=7.057, nll_loss=3.492, ppl=11.25, wps=4829.3, ups=0.37, wpb=13055.9, bsz=445.2, num_updates=134400, lr=8.62582e-05, gnorm=0.989, loss_scale=4, train_wall=270, gb_free=14.4, wall=217584
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2451, 42808])
2023-09-22 23:11:01 | INFO | train_inner | epoch 015:   7689 / 9060 loss=7.019, nll_loss=3.453, ppl=10.95, wps=4828, ups=0.37, wpb=13046.1, bsz=439.5, num_updates=134500, lr=8.62261e-05, gnorm=0.979, loss_scale=4, train_wall=270, gb_free=14.4, wall=217854
2023-09-22 23:15:36 | INFO | train_inner | epoch 015:   7789 / 9060 loss=6.972, nll_loss=3.458, ppl=10.99, wps=4761.2, ups=0.36, wpb=13095, bsz=430, num_updates=134600, lr=8.61941e-05, gnorm=1.001, loss_scale=4, train_wall=275, gb_free=13.6, wall=218129
ter_threshold: 0.434637
num_accepted / total 38 128
loss token level: tensor(11826.1895, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7704., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 23:20:27 | INFO | train_inner | epoch 015:   7889 / 9060 loss=6.845, nll_loss=3.436, ppl=10.83, wps=4433.2, ups=0.34, wpb=12889.4, bsz=403.1, num_updates=134700, lr=8.61621e-05, gnorm=0.961, loss_scale=4, train_wall=290, gb_free=15.8, wall=218420
ter_threshold: 0.434785
num_accepted / total 1 16
loss token level: tensor(6426.3750, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(723.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 23:25:05 | INFO | train_inner | epoch 015:   7989 / 9060 loss=6.817, nll_loss=3.379, ppl=10.4, wps=4620.1, ups=0.36, wpb=12870.2, bsz=401, num_updates=134800, lr=8.61301e-05, gnorm=0.965, loss_scale=8, train_wall=278, gb_free=14.6, wall=218699
lprobs.size(): torch.Size([3552, 42808])
2023-09-22 23:29:42 | INFO | train_inner | epoch 015:   8089 / 9060 loss=7.004, nll_loss=3.436, ppl=10.82, wps=4709, ups=0.36, wpb=13032.8, bsz=440.4, num_updates=134900, lr=8.60982e-05, gnorm=0.981, loss_scale=8, train_wall=277, gb_free=13.7, wall=218975
ter_threshold: 0.434988
num_accepted / total 1 32
loss token level: tensor(14007.9219, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(643.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-22 23:34:19 | INFO | train_inner | epoch 015:   8189 / 9060 loss=6.869, nll_loss=3.411, ppl=10.64, wps=4643, ups=0.36, wpb=12888.9, bsz=416.7, num_updates=135000, lr=8.60663e-05, gnorm=0.974, loss_scale=8, train_wall=277, gb_free=14.6, wall=219253
lprobs.size(): torch.Size([3432, 42808])
2023-09-22 23:38:48 | INFO | train_inner | epoch 015:   8289 / 9060 loss=6.996, nll_loss=3.477, ppl=11.14, wps=4830.5, ups=0.37, wpb=12955.8, bsz=451.8, num_updates=135100, lr=8.60344e-05, gnorm=0.987, loss_scale=8, train_wall=268, gb_free=15, wall=219521
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([2640, 42808])
2023-09-22 23:43:19 | INFO | train_inner | epoch 015:   8389 / 9060 loss=6.927, nll_loss=3.429, ppl=10.77, wps=4790.6, ups=0.37, wpb=13006, bsz=416.4, num_updates=135200, lr=8.60026e-05, gnorm=0.971, loss_scale=8, train_wall=271, gb_free=13.9, wall=219793
2023-09-22 23:47:52 | INFO | train_inner | epoch 015:   8489 / 9060 loss=6.909, nll_loss=3.412, ppl=10.64, wps=4755.9, ups=0.37, wpb=12991.9, bsz=443.5, num_updates=135300, lr=8.59708e-05, gnorm=0.97, loss_scale=8, train_wall=273, gb_free=14.7, wall=220066
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1980, 42808])
2023-09-22 23:52:21 | INFO | train_inner | epoch 015:   8589 / 9060 loss=7.02, nll_loss=3.477, ppl=11.13, wps=4839.8, ups=0.37, wpb=13000.2, bsz=432.5, num_updates=135400, lr=8.59391e-05, gnorm=0.98, loss_scale=8, train_wall=268, gb_free=14.6, wall=220334
2023-09-22 23:56:53 | INFO | train_inner | epoch 015:   8689 / 9060 loss=6.904, nll_loss=3.442, ppl=10.87, wps=4781.9, ups=0.37, wpb=13001, bsz=412.9, num_updates=135500, lr=8.59074e-05, gnorm=1.018, loss_scale=8, train_wall=272, gb_free=14.2, wall=220606
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.43554
num_accepted / total 35 72
loss token level: tensor(8783.7178, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6952., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
2023-09-23 00:01:22 | INFO | train_inner | epoch 015:   8789 / 9060 loss=6.959, nll_loss=3.428, ppl=10.76, wps=4831, ups=0.37, wpb=13002.1, bsz=451.1, num_updates=135600, lr=8.58757e-05, gnorm=0.977, loss_scale=8, train_wall=269, gb_free=13.3, wall=220875
lprobs.size(): torch.Size([3000, 42808])
2023-09-23 00:05:42 | INFO | train_inner | epoch 015:   8889 / 9060 loss=6.908, nll_loss=3.426, ppl=10.75, wps=4998.8, ups=0.38, wpb=13004.6, bsz=423.7, num_updates=135700, lr=8.5844e-05, gnorm=1.003, loss_scale=8, train_wall=260, gb_free=13.4, wall=221136
ter_threshold: 0.435733
num_accepted / total 18 80
loss token level: tensor(9116.6543, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2800., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 00:10:03 | INFO | train_inner | epoch 015:   8989 / 9060 loss=6.837, nll_loss=3.421, ppl=10.71, wps=4921.5, ups=0.38, wpb=12842.6, bsz=412.6, num_updates=135800, lr=8.58124e-05, gnorm=0.958, loss_scale=8, train_wall=261, gb_free=16, wall=221397
ter_threshold: 0.435822
num_accepted / total 39 96
loss token level: tensor(8371.8193, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9776., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 00:13:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-23 00:13:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 00:13:21 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-23 00:13:21 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-23 00:13:21 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher vollkommen gerechtfertigt.
2023-09-23 00:13:21 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-23 00:13:22 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-23 00:13:22 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-23 00:13:23 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-23 00:13:23 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-23 00:13:23 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-23 00:13:23 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-23 00:13:24 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und war ein großer Erfolg.
2023-09-23 00:13:24 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-23 00:13:24 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-23 00:13:24 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-23 00:13:25 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-23 00:13:25 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-23 00:13:25 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-23 00:13:25 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-23 00:13:26 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales Fernsehen und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende geeignet sind.
2023-09-23 00:13:26 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-23 00:13:26 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-23 00:13:26 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-23 00:13:27 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 00:13:27 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 00:13:27 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU enorme Mengen an Energie verschwendet.
2023-09-23 00:13:27 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-23 00:13:28 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin enthält einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-23 00:13:28 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-23 00:13:29 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Haltung auch in Kürze im Haushalt der Union widerspiegeln.
2023-09-23 00:13:29 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-23 00:13:29 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-23 00:13:29 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-23 00:13:30 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-23 00:13:30 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-23 00:13:30 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-23 00:13:30 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-23 00:13:31 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-23 00:13:31 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-23 00:13:31 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-23 00:13:31 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-23 00:13:32 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-23 00:13:32 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-23 00:13:32 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-23 00:13:32 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-23 00:13:33 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-23 00:13:33 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-23 00:13:34 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-23 00:13:34 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-23 00:13:34 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-23 00:13:34 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-23 00:13:35 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-23 00:13:35 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-23 00:13:35 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Aussprache, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 00:13:35 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 00:13:36 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Orte in etwa einem Umkreis von 8 km vom Strip entfernt.
2023-09-23 00:13:36 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-23 00:13:37 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-23 00:13:37 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-23 00:13:37 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-23 00:13:37 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-23 00:13:38 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-23 00:13:38 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-23 00:13:38 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, kann sich jedoch auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu gewährleisten.
2023-09-23 00:13:38 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-23 00:13:39 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Ausreise Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-23 00:13:39 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-23 00:13:39 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-23 00:13:39 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-23 00:13:40 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, für einige Formate gibt es leider keine freie Alternative, die auf allen Computerplattformen läuft.
2023-09-23 00:13:40 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-23 00:13:41 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie er Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-23 00:13:41 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-23 00:13:41 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcherische Vorstellungen von niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv zentrale Teile seiner Agenda.
2023-09-23 00:13:41 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-23 00:13:42 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-23 00:13:42 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-23 00:13:42 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser benutzen.
2023-09-23 00:13:42 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-23 00:13:43 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien auf die Anwendung nur innerhalb der Grenzen Europas beschränkt werden sollten.
2023-09-23 00:13:43 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-23 00:13:44 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-23 00:13:44 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-23 00:13:44 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat grundsätzlich formelle Standpunkte zu bestimmten Details des Abkommens mit den Vereinigten Staaten abgeben müssen.
2023-09-23 00:13:44 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-23 00:13:45 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - unsere breite Palette an PlastikBabyartikeln ist beeindruckend, nicht zuletzt wegen ihrer herausragenden Verarbeitung.
2023-09-23 00:13:45 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-23 00:13:46 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 00:13:46 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 00:13:46 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis Kenntnis von Sachverhalten, die mit diesen AGB nicht vereinbar sind, über Sachverhalten zu informieren.
2023-09-23 00:13:46 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-23 00:13:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außen- und Verteidigungspolitik erfordert.
2023-09-23 00:13:47 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-23 00:13:48 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen erstellt.
2023-09-23 00:13:48 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-23 00:13:49 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Prüfung aller Fragen, die jetzt diskutiert werden, um etwas, das gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda, erzielt wurden.
2023-09-23 00:13:49 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-23 00:13:49 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die optimale Mischung aus gesenkten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-23 00:13:49 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-23 00:13:50 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal war es der Berichterstatterin gelungen, bisweilen unterschiedliche Meinungen und Beiträge zu fassen und sie - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 00:13:50 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 00:13:50 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederrichtern um ein trockenes ESP für den unteren Leistungsbereich.
2023-09-23 00:13:50 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-23 00:13:51 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-23 00:13:51 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-23 00:13:52 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-23 00:13:52 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-23 00:13:53 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und unsere Gemeinschaft der Nationen betreffen.
2023-09-23 00:13:53 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-23 00:13:53 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-23 00:13:53 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-23 00:13:54 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-23 00:13:54 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-23 00:13:55 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-23 00:13:55 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-23 00:13:55 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notlage gibt es jedoch noch eine weitere: die Notsituation der Kinder, des schwächsten Sektors der Bevölkerung, der keine Familie, keinen Schutz und keinen Staat mehr hat.
2023-09-23 00:13:55 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-23 00:13:56 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen.
2023-09-23 00:13:56 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-23 00:13:57 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, erst in den ersten Jahren realisiert wird, bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-23 00:13:57 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-23 00:13:57 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in ihrer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren zur Wählerregistrierung wieder aufzunehmen.
2023-09-23 00:13:57 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-23 00:13:58 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-23 00:13:58 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-23 00:13:59 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit garantieren (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-23 00:13:59 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-23 00:13:59 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für die Klärung des Anhangs.
2023-09-23 00:13:59 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-23 00:14:00 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung grundlegender Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-23 00:14:00 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-23 00:14:01 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Aussprache über das irische öffentlich-rechtliche Radio RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-23 00:14:01 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-23 00:14:02 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer besonnenen Haltung gratulieren.
2023-09-23 00:14:02 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-23 00:14:02 | INFO | fairseq.tasks.translation | example hypothesis: Ganz gleich, ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Bürgerschaft oder etwas so Konkretes wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-23 00:14:02 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-23 00:14:03 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und steht Spielern aller Nationalitäten offen.
2023-09-23 00:14:03 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-23 00:14:04 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-23 00:14:04 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-23 00:14:05 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken hieße, eine bestimmte Art von Vertragsbeziehung zwischen Einzelpersonen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen häufig die tatsächliche oder wahrgenommene Bedrohung, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-23 00:14:05 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-23 00:14:05 | INFO | fairseq.tasks.translation | example hypothesis: In der Gemeinschaftsgerichtsbarkeit zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn zum Beispiel die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung der Konvention erforderlich ist.
2023-09-23 00:14:05 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-23 00:14:06 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Autos mit weniger als 50.000 Dollar. Wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-23 00:14:06 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-23 00:14:07 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, und das gleiche gilt für den Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-23 00:14:07 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-23 00:14:08 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den ausgezeichneten Süßwasserfisch: gegrilltes Hecht, Forelle mit Mandeln.
2023-09-23 00:14:08 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-23 00:14:08 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, einen Gesamtüberblick zu geben, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu sehen, welchen Impuls die Europäische Union mit Blick auf die Zukunft geben kann.
2023-09-23 00:14:08 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-23 00:14:09 | INFO | fairseq.tasks.translation | example hypothesis: Der Leiter der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, haben sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009" geeinigt..................
2023-09-23 00:14:09 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-23 00:14:10 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo es unmittelbare Bedrohungen für bestehende Arbeitsplätze gibt und die Wettbewerbsfähigkeit aufgrund der makroökonomischen Politik, der steuerlichen Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-23 00:14:10 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-23 00:14:11 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, beigetragen hat.
2023-09-23 00:14:11 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-23 00:14:12 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus mit den entsprechenden Konsequenzen für den Rechts- und Rechtsbereich, wodurch Norwegen und Island, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsvorschriften gelten werden, die Anwendung finden werden.
2023-09-23 00:14:12 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-23 00:14:12 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit mit einem Schwenkboot den Mississippi hinunter fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein......................
2023-09-23 00:14:12 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-23 00:14:13 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Schiffe verursachten Verschmutzung durch Einzelpersonen oder Rechtspersonen, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die bei solchen Verstößen von Einzelpersonen angewendet werden können.
2023-09-23 00:14:13 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-23 00:14:14 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falizund Vincent Reynaud wurden nämlich verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner erledigt und eine Gruppe von Bergleuten gefilmt haben, die jahrelang von einem autoritären Regime gejagt wurden, das jeden Grundsatz der Demokratie missachtet...................
2023-09-23 00:14:14 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-23 00:14:15 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseurshop und ein Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Menü- und Presseservice, ein Währungsumtausch, kostenfreie Shoeshine und WLAN. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-23 00:14:15 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-23 00:14:16 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die von Königin D. Leonor, der Frau des Königs D. João II, und bekannt durch ihre international bekannten Keramiken für ihre figurativen und satirischen Werke ist es auch einen Besuch wert.
2023-09-23 00:14:16 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-23 00:14:17 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute Pro-Westler auf der einen Seite und Anhänger des früheren Regimes auf der anderen Seite handelt - auch das ist verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-23 00:14:17 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-23 00:14:18 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die unterschiedslos zwischen Flüssen und dem Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.
2023-09-23 00:14:18 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-23 00:14:19 | INFO | fairseq.tasks.translation | example hypothesis: (4) Sofern Informationen außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär an einen Aktionär übermittelt wurden, werden diese Informationen auf Antrag an jeden anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn solche Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-23 00:14:19 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-23 00:14:20 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Abermillionen Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren fließen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.
2023-09-23 00:14:20 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-23 00:14:20 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder der NATO an diesem Kriegshandlungen beteiligt gewesen wären -, bei Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, geheim oder geheim zu halten, damit wir die Tatsachen wirklich ans Licht bringen und die ganze Wahrheit sagen können...........................
2023-09-23 00:14:20 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-23 00:14:21 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug von der Innenstadt entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 00:14:21 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 00:14:22 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die moderne, außerhalb des Regals liegende Plattformen niemals erfüllen können.
2023-09-23 00:14:22 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-23 00:14:23 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir nicht nur für uns, sondern weltweit die Produkte vom Markt nehmen können, die eine ernste Gefahr darstellen, nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-23 00:14:23 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-23 00:14:24 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem bloßen Plot von Moderne und Postmoderne oder dem klaren Widerstand reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung dieser beiden ästhetischen Politik anerkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die Kunst als solche identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.................... Diese beiden Politiken, die letztlich zur Selbstunterdrückung
2023-09-23 00:14:24 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-23 00:14:25 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Aussprachen und angesichts der Meinungen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen unsere Aussprachen führen, und wenn die vierzig Petenten nicht anwesend sind, werde ich bei der Abstimmung nicht um die Prüfung der Beschlussfähigkeit bitten.
2023-09-23 00:14:25 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-23 00:14:26 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips niemals akzeptiert haben, so sind es paradoxerweise gerade sie, die nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem die nationalen Grenzen aufgehoben werden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, aber die Entwicklung der ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen...............................
2023-09-23 00:14:26 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-23 00:14:27 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Hinsicht als Hybridform veröffentlicht und für H-Soz-u-Kult und das Michigan-basierte H-Net an seine Abonnenten über Mailinglisten sowie die Webseiten des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net verteilt.
2023-09-23 00:14:27 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-23 00:14:29 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone nicht nur ihre Federn deutlich verwischt, sondern auch von einst wehenden Taschenlampen-Alarmuhren über polyphonisch tootende Game Boy-Uhren bis hin zu schmal klingenden Mini-PCs mit knusprigem Stereo-Sound in CD-Qualität: Durch ihre spezielle Kombination von Fähigkeiten können sie von den ehemaligen me-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen werden.
2023-09-23 00:14:29 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-23 00:14:31 | INFO | fairseq.tasks.translation | example hypothesis: En un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un konfliarmato; en l dedir de dedir de decilado.
2023-09-23 00:14:31 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-23 00:14:31 | INFO | valid | epoch 015 | valid on 'valid' subset | loss 4.153 | nll_loss 2.178 | ppl 4.52 | bleu 29.48 | wps 16753.6 | wpb 12011.9 | bsz 398.1 | num_updates 135871 | best_bleu 29.48
2023-09-23 00:14:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 135871 updates
2023-09-23 00:14:31 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint15.pt
2023-09-23 00:14:37 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint15.pt
2023-09-23 00:14:47 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint15.pt (epoch 15 @ 135871 updates, score 29.48) (writing took 15.507872465997934 seconds)
2023-09-23 00:14:47 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2023-09-23 00:14:47 | INFO | train | epoch 015 | loss 6.895 | nll_loss 3.402 | ppl 10.57 | wps 4878.7 | ups 0.38 | wpb 12977.2 | bsz 430.6 | num_updates 135871 | lr 8.579e-05 | gnorm 0.967 | loss_scale 8 | train_wall 23986 | gb_free 13.7 | wall 221680
2023-09-23 00:14:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 00:14:47 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-23 00:14:47 | INFO | fairseq.trainer | begin training epoch 16
2023-09-23 00:14:47 | INFO | fairseq_cli.train | Start iterating over samples
lprobs.size(): torch.Size([2224, 42808])
2023-09-23 00:16:05 | INFO | train_inner | epoch 016:     29 / 9060 loss=6.954, nll_loss=3.447, ppl=10.9, wps=3562.1, ups=0.28, wpb=12880.1, bsz=418.6, num_updates=135900, lr=8.57808e-05, gnorm=0.991, loss_scale=8, train_wall=275, gb_free=13.8, wall=221758
pred_new.size(): torch.Size([3774, 42808])
2023-09-23 00:20:32 | INFO | train_inner | epoch 016:    129 / 9060 loss=6.897, nll_loss=3.369, ppl=10.33, wps=4862.9, ups=0.37, wpb=12980.6, bsz=442.9, num_updates=136000, lr=8.57493e-05, gnorm=0.974, loss_scale=8, train_wall=267, gb_free=15.3, wall=222025
2023-09-23 00:25:24 | INFO | train_inner | epoch 016:    229 / 9060 loss=6.885, nll_loss=3.357, ppl=10.25, wps=4437.1, ups=0.34, wpb=12977.8, bsz=427.4, num_updates=136100, lr=8.57178e-05, gnorm=0.98, loss_scale=8, train_wall=292, gb_free=15.7, wall=222318
pred_new.size(): torch.Size([3408, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-23 00:29:52 | INFO | train_inner | epoch 016:    329 / 9060 loss=7.039, nll_loss=3.413, ppl=10.65, wps=4836.9, ups=0.37, wpb=12977, bsz=445.8, num_updates=136200, lr=8.56863e-05, gnorm=0.973, loss_scale=8, train_wall=268, gb_free=13.6, wall=222586
lprobs.size(): torch.Size([3008, 42808])
2023-09-23 00:33:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-23 00:34:35 | INFO | train_inner | epoch 016:    430 / 9060 loss=6.926, nll_loss=3.402, ppl=10.57, wps=4596.1, ups=0.35, wpb=13004.4, bsz=424.4, num_updates=136300, lr=8.56549e-05, gnorm=0.965, loss_scale=4, train_wall=283, gb_free=13.8, wall=222869
2023-09-23 00:39:17 | INFO | train_inner | epoch 016:    530 / 9060 loss=6.934, nll_loss=3.401, ppl=10.56, wps=4618.1, ups=0.36, wpb=13001.8, bsz=419.9, num_updates=136400, lr=8.56235e-05, gnorm=0.985, loss_scale=4, train_wall=281, gb_free=14, wall=223150
2023-09-23 00:43:34 | INFO | train_inner | epoch 016:    630 / 9060 loss=6.863, nll_loss=3.353, ppl=10.22, wps=5104.3, ups=0.39, wpb=13132.9, bsz=443.5, num_updates=136500, lr=8.55921e-05, gnorm=0.95, loss_scale=4, train_wall=257, gb_free=14.9, wall=223408
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3444, 42808])
2023-09-23 00:47:52 | INFO | train_inner | epoch 016:    730 / 9060 loss=6.885, nll_loss=3.388, ppl=10.47, wps=4970.7, ups=0.39, wpb=12803.8, bsz=443.1, num_updates=136600, lr=8.55608e-05, gnorm=1.079, loss_scale=4, train_wall=257, gb_free=15.6, wall=223665
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2576, 42808])
2023-09-23 00:52:20 | INFO | train_inner | epoch 016:    830 / 9060 loss=6.951, nll_loss=3.401, ppl=10.56, wps=4827.5, ups=0.37, wpb=12955.8, bsz=427.2, num_updates=136700, lr=8.55295e-05, gnorm=1.011, loss_scale=4, train_wall=268, gb_free=13.7, wall=223934
2023-09-23 00:56:50 | INFO | train_inner | epoch 016:    930 / 9060 loss=7.061, nll_loss=3.436, ppl=10.82, wps=4808.6, ups=0.37, wpb=12984.2, bsz=435.3, num_updates=136800, lr=8.54982e-05, gnorm=0.99, loss_scale=4, train_wall=270, gb_free=13.5, wall=224204
2023-09-23 01:01:21 | INFO | train_inner | epoch 016:   1030 / 9060 loss=6.998, nll_loss=3.435, ppl=10.82, wps=4801.9, ups=0.37, wpb=12985.3, bsz=428.7, num_updates=136900, lr=8.5467e-05, gnorm=0.988, loss_scale=4, train_wall=270, gb_free=14.8, wall=224474
lprobs.size(): torch.Size([2432, 42808])
2023-09-23 01:05:49 | INFO | train_inner | epoch 016:   1130 / 9060 loss=6.937, nll_loss=3.394, ppl=10.51, wps=4822, ups=0.37, wpb=12953.6, bsz=430.6, num_updates=137000, lr=8.54358e-05, gnorm=0.966, loss_scale=4, train_wall=268, gb_free=13.8, wall=224743
pred_new.size(): torch.Size([1911, 42808])
2023-09-23 01:10:12 | INFO | train_inner | epoch 016:   1230 / 9060 loss=6.866, nll_loss=3.383, ppl=10.43, wps=4928.2, ups=0.38, wpb=12961.2, bsz=421.4, num_updates=137100, lr=8.54046e-05, gnorm=0.954, loss_scale=4, train_wall=263, gb_free=14.1, wall=225006
pred_new.size(): torch.Size([2700, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3440, 42808])
2023-09-23 01:14:38 | INFO | train_inner | epoch 016:   1330 / 9060 loss=6.984, nll_loss=3.404, ppl=10.58, wps=4869.7, ups=0.38, wpb=12924.7, bsz=437.2, num_updates=137200, lr=8.53735e-05, gnorm=0.995, loss_scale=4, train_wall=265, gb_free=13.9, wall=225271
pred_new.size(): torch.Size([1798, 42808])
2023-09-23 01:18:50 | INFO | train_inner | epoch 016:   1430 / 9060 loss=6.869, nll_loss=3.407, ppl=10.61, wps=5088.8, ups=0.4, wpb=12846.7, bsz=407.8, num_updates=137300, lr=8.53424e-05, gnorm=0.979, loss_scale=4, train_wall=252, gb_free=14.7, wall=225524
2023-09-23 01:23:14 | INFO | train_inner | epoch 016:   1530 / 9060 loss=7.003, nll_loss=3.415, ppl=10.67, wps=4929, ups=0.38, wpb=12990.4, bsz=439.4, num_updates=137400, lr=8.53113e-05, gnorm=0.998, loss_scale=4, train_wall=263, gb_free=14.2, wall=225787
ter_threshold: 0.43744700000000003
num_accepted / total 17 56
loss token level: tensor(8769.0596, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4712., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 01:27:40 | INFO | train_inner | epoch 016:   1630 / 9060 loss=7.011, nll_loss=3.464, ppl=11.04, wps=4850.7, ups=0.38, wpb=12927.8, bsz=418.6, num_updates=137500, lr=8.52803e-05, gnorm=1.006, loss_scale=4, train_wall=266, gb_free=13.9, wall=226054
2023-09-23 01:31:52 | INFO | train_inner | epoch 016:   1730 / 9060 loss=7.007, nll_loss=3.453, ppl=10.95, wps=5171.4, ups=0.4, wpb=13015.5, bsz=436.8, num_updates=137600, lr=8.52493e-05, gnorm=0.977, loss_scale=4, train_wall=251, gb_free=15, wall=226305
2023-09-23 01:36:22 | INFO | train_inner | epoch 016:   1830 / 9060 loss=6.956, nll_loss=3.414, ppl=10.66, wps=4831.1, ups=0.37, wpb=13058.9, bsz=452.6, num_updates=137700, lr=8.52183e-05, gnorm=0.985, loss_scale=4, train_wall=270, gb_free=14.4, wall=226576
2023-09-23 01:40:35 | INFO | train_inner | epoch 016:   1930 / 9060 loss=6.91, nll_loss=3.423, ppl=10.72, wps=5085.4, ups=0.39, wpb=12885.5, bsz=441.9, num_updates=137800, lr=8.51874e-05, gnorm=0.975, loss_scale=4, train_wall=253, gb_free=14.2, wall=226829
pred_new.size(): torch.Size([3939, 42808])
2023-09-23 01:45:00 | INFO | train_inner | epoch 016:   2030 / 9060 loss=7.069, nll_loss=3.481, ppl=11.16, wps=4889.2, ups=0.38, wpb=12952.8, bsz=440, num_updates=137900, lr=8.51565e-05, gnorm=0.995, loss_scale=4, train_wall=265, gb_free=14.2, wall=227094
pred_new.size(): torch.Size([3612, 42808])
2023-09-23 01:49:25 | INFO | train_inner | epoch 016:   2130 / 9060 loss=7.04, nll_loss=3.456, ppl=10.97, wps=4891.5, ups=0.38, wpb=12960.6, bsz=438.2, num_updates=138000, lr=8.51257e-05, gnorm=0.995, loss_scale=4, train_wall=265, gb_free=14.5, wall=227359
ter_threshold: 0.438007
num_accepted / total 11 40
loss token level: tensor(7889.2842, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3756., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 01:53:47 | INFO | train_inner | epoch 016:   2230 / 9060 loss=6.977, nll_loss=3.415, ppl=10.67, wps=4951.5, ups=0.38, wpb=12945.7, bsz=416.2, num_updates=138100, lr=8.50948e-05, gnorm=1.01, loss_scale=4, train_wall=261, gb_free=14.1, wall=227620
2023-09-23 01:58:07 | INFO | train_inner | epoch 016:   2330 / 9060 loss=7.158, nll_loss=3.52, ppl=11.47, wps=5005.5, ups=0.38, wpb=13022, bsz=434.4, num_updates=138200, lr=8.5064e-05, gnorm=1.029, loss_scale=4, train_wall=260, gb_free=13.6, wall=227880
pred_new.size(): torch.Size([2139, 42808])
2023-09-23 02:02:37 | INFO | train_inner | epoch 016:   2430 / 9060 loss=6.953, nll_loss=3.411, ppl=10.63, wps=4817.5, ups=0.37, wpb=12995.2, bsz=436, num_updates=138300, lr=8.50333e-05, gnorm=1.024, loss_scale=4, train_wall=269, gb_free=13.9, wall=228150
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-23 02:07:00 | INFO | train_inner | epoch 016:   2530 / 9060 loss=7.001, nll_loss=3.443, ppl=10.88, wps=4903.2, ups=0.38, wpb=12907.3, bsz=440.3, num_updates=138400, lr=8.50026e-05, gnorm=1.003, loss_scale=4, train_wall=263, gb_free=14.2, wall=228413
2023-09-23 02:11:21 | INFO | train_inner | epoch 016:   2630 / 9060 loss=7.026, nll_loss=3.469, ppl=11.07, wps=4950.1, ups=0.38, wpb=12914.8, bsz=423.4, num_updates=138500, lr=8.49719e-05, gnorm=1.021, loss_scale=4, train_wall=261, gb_free=13.3, wall=228674
torch.Size([3520, 42808])
lprobs.size(): torch.Size([2784, 42808])
ter_threshold: 0.427941
num_accepted / total 13 56
loss token level: tensor(9402.6094, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6592., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3948, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4320, 42808])
ter_threshold: 0.42827099999999996
num_accepted / total 29 88
loss token level: tensor(8463.5879, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7204., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1332, 42808])
ter_threshold: 0.42841399999999996
num_accepted / total 122 224
loss token level: tensor(9441.1211, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7372., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([5472, 42808])
pred_new.size(): torch.Size([4514, 42808])
ter_threshold: 0.428996
num_accepted / total 47 104
loss token level: tensor(9233.8447, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11360., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2220, 42808])
pred_new.size(): torch.Size([1144, 42808])
pred_new.size(): torch.Size([4424, 42808])
ter_threshold: 0.429125
num_accepted / total 36 72
loss token level: tensor(8654.5449, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7372., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4100, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([6783, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.429533
num_accepted / total 12 48
loss token level: tensor(7758.4458, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6112., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2960, 42808])
ter_threshold: 0.429594
num_accepted / total 20 72
loss token level: tensor(9436.2539, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4224., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1116, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.429745
num_accepted / total 30 96
loss token level: tensor(10844.3398, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7968., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8029, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5842, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([2920, 42808])
pred_new.size(): torch.Size([4140, 42808])
ter_threshold: 0.430056
num_accepted / total 72 184
loss token level: tensor(10155.7930, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8052., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7081, 42808])
pred_new.size(): torch.Size([6985, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([990, 42808])
pred_new.size(): torch.Size([1776, 42808])
pred_new.size(): torch.Size([4838, 42808])
pred_new.size(): torch.Size([3360, 42808])
ter_threshold: 0.43161499999999997
num_accepted / total 386 512
loss token level: tensor(6793.4971, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6396., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.43191599999999997
num_accepted / total 67 128
loss token level: tensor(8935.2109, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7312., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6670, 42808])
pred_new.size(): torch.Size([2574, 42808])
pred_new.size(): torch.Size([896, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([570, 42808])
pred_new.size(): torch.Size([3864, 42808])
pred_new.size(): torch.Size([6327, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1160, 42808])
pred_new.size(): torch.Size([5589, 42808])
pred_new.size(): torch.Size([2392, 42808])
pred_new.size(): torch.Size([1508, 42808])
ter_threshold: 0.433589
num_accepted / total 16 64
loss token level: tensor(9216.7939, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6456., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([4416, 42808])
ter_threshold: 0.43401199999999995
num_accepted / total 32 80
loss token level: tensor(8600.2529, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9600., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.43409
num_accepted / total 40 104
loss token level: tensor(9164.9355, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9504., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([2548, 42808])
pred_new.size(): torch.Size([2538, 42808])
ter_threshold: 0.434637
num_accepted / total 119 224
loss token level: tensor(10137.4883, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11984., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([2550, 42808])
pred_new.size(): torch.Size([2460, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2760, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([1896, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1950, 42808])
ter_threshold: 0.435733
num_accepted / total 14 136
loss token level: tensor(8652.5684, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(963., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.435758
num_accepted / total 17 56
loss token level: tensor(8569.4434, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4252., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4080, 42808])
pred_new.size(): torch.Size([4050, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4440, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([3294, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6080, 42808])
pred_new.size(): torch.Size([4000, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([9207, 42808])
pred_new.size(): torch.Size([4002, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([6322, 42808])
ter_threshold: 0.437946
num_accepted / total 1 40
loss token level: tensor(12007.3691, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(635., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2604, 42808])
pred_new.size(): torch.Size([5580, 42808])
pred_new.size(): torch.Size([5940, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.438415
num_accepted / total 12 48
loss token level: tensor(9225.1641, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3472., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 02:15:41 | INFO | train_inner | epoch 016:   2730 / 9060 loss=6.963, nll_loss=3.423, ppl=10.73, wps=4962.7, ups=0.38, wpb=12926.2, bsz=440.3, num_updates=138600, lr=8.49412e-05, gnorm=0.989, loss_scale=4, train_wall=260, gb_free=14.2, wall=228935
ter_threshold: 0.438625
num_accepted / total 26 112
loss token level: tensor(12171.7920, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3400., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 02:19:56 | INFO | train_inner | epoch 016:   2830 / 9060 loss=6.933, nll_loss=3.428, ppl=10.77, wps=5137.3, ups=0.39, wpb=13090.1, bsz=422.5, num_updates=138700, lr=8.49106e-05, gnorm=0.965, loss_scale=4, train_wall=255, gb_free=15.2, wall=229190
2023-09-23 02:24:31 | INFO | train_inner | epoch 016:   2930 / 9060 loss=6.974, nll_loss=3.406, ppl=10.6, wps=4740.5, ups=0.36, wpb=13044.3, bsz=426.9, num_updates=138800, lr=8.488e-05, gnorm=0.987, loss_scale=4, train_wall=275, gb_free=13.9, wall=229465
ter_threshold: 0.43884
num_accepted / total 7 40
loss token level: tensor(9005.5293, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3796., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 02:28:55 | INFO | train_inner | epoch 016:   3030 / 9060 loss=7.063, nll_loss=3.458, ppl=10.99, wps=4921.2, ups=0.38, wpb=12959.9, bsz=452.7, num_updates=138900, lr=8.48494e-05, gnorm=0.986, loss_scale=4, train_wall=263, gb_free=14.3, wall=229728
pred_new.size(): torch.Size([4446, 42808])
2023-09-23 02:33:19 | INFO | train_inner | epoch 016:   3130 / 9060 loss=6.975, nll_loss=3.441, ppl=10.86, wps=4888.2, ups=0.38, wpb=12921.5, bsz=426.1, num_updates=139000, lr=8.48189e-05, gnorm=0.991, loss_scale=4, train_wall=264, gb_free=14.4, wall=229992
ter_threshold: 0.439023
num_accepted / total 70 136
loss token level: tensor(7934.2061, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10240., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3458, 42808])
2023-09-23 02:37:41 | INFO | train_inner | epoch 016:   3230 / 9060 loss=6.986, nll_loss=3.42, ppl=10.7, wps=4985.1, ups=0.38, wpb=13065, bsz=436.1, num_updates=139100, lr=8.47884e-05, gnorm=0.978, loss_scale=4, train_wall=262, gb_free=14.3, wall=230255
pred_new.size(): torch.Size([2900, 42808])
pred_new.size(): torch.Size([924, 42808])
2023-09-23 02:41:59 | INFO | train_inner | epoch 016:   3330 / 9060 loss=7.064, nll_loss=3.487, ppl=11.21, wps=5028, ups=0.39, wpb=12986.1, bsz=435, num_updates=139200, lr=8.47579e-05, gnorm=0.994, loss_scale=4, train_wall=258, gb_free=13.6, wall=230513
2023-09-23 02:46:13 | INFO | train_inner | epoch 016:   3430 / 9060 loss=6.94, nll_loss=3.449, ppl=10.92, wps=5143.4, ups=0.39, wpb=13024, bsz=422.2, num_updates=139300, lr=8.47275e-05, gnorm=0.969, loss_scale=4, train_wall=253, gb_free=14.3, wall=230766
lprobs.size(): torch.Size([3536, 42808])
2023-09-23 02:50:30 | INFO | train_inner | epoch 016:   3530 / 9060 loss=6.962, nll_loss=3.424, ppl=10.73, wps=5059.9, ups=0.39, wpb=13024.5, bsz=446.2, num_updates=139400, lr=8.46971e-05, gnorm=0.957, loss_scale=4, train_wall=257, gb_free=14.1, wall=231023
pred_new.size(): torch.Size([5025, 42808])
2023-09-23 02:54:54 | INFO | train_inner | epoch 016:   3630 / 9060 loss=6.954, nll_loss=3.406, ppl=10.6, wps=4924.2, ups=0.38, wpb=13004.4, bsz=428.9, num_updates=139500, lr=8.46668e-05, gnorm=1, loss_scale=4, train_wall=264, gb_free=14.7, wall=231288
ter_threshold: 0.439508
num_accepted / total 44 96
loss token level: tensor(9356.1934, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11816., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2928, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-23 02:59:19 | INFO | train_inner | epoch 016:   3730 / 9060 loss=6.97, nll_loss=3.413, ppl=10.65, wps=4915.4, ups=0.38, wpb=13014.4, bsz=431.4, num_updates=139600, lr=8.46364e-05, gnorm=0.981, loss_scale=4, train_wall=265, gb_free=14.3, wall=231552
2023-09-23 03:03:52 | INFO | train_inner | epoch 016:   3830 / 9060 loss=7.018, nll_loss=3.485, ppl=11.2, wps=4764.4, ups=0.37, wpb=13034.8, bsz=413.1, num_updates=139700, lr=8.46061e-05, gnorm=0.994, loss_scale=4, train_wall=273, gb_free=13.5, wall=231826
pred_new.size(): torch.Size([2576, 42808])
2023-09-23 03:08:22 | INFO | train_inner | epoch 016:   3930 / 9060 loss=6.873, nll_loss=3.412, ppl=10.64, wps=4794.2, ups=0.37, wpb=12914.5, bsz=424.3, num_updates=139800, lr=8.45759e-05, gnorm=0.984, loss_scale=4, train_wall=269, gb_free=15.1, wall=232095
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([2664, 42808])
ter_threshold: 0.439894
num_accepted / total 19 88
loss token level: tensor(10236.1729, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3156., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 03:12:55 | INFO | train_inner | epoch 016:   4030 / 9060 loss=6.942, nll_loss=3.421, ppl=10.71, wps=4750.2, ups=0.37, wpb=12970.8, bsz=420.2, num_updates=139900, lr=8.45456e-05, gnorm=0.975, loss_scale=4, train_wall=273, gb_free=13.9, wall=232368
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3312, 42808])
2023-09-23 03:17:39 | INFO | train_inner | epoch 016:   4130 / 9060 loss=6.928, nll_loss=3.446, ppl=10.9, wps=4552.4, ups=0.35, wpb=12917.4, bsz=433.4, num_updates=140000, lr=8.45154e-05, gnorm=0.996, loss_scale=4, train_wall=283, gb_free=13.4, wall=232652
2023-09-23 03:22:14 | INFO | train_inner | epoch 016:   4230 / 9060 loss=6.957, nll_loss=3.431, ppl=10.78, wps=4693.4, ups=0.36, wpb=12932.1, bsz=435.9, num_updates=140100, lr=8.44853e-05, gnorm=0.982, loss_scale=4, train_wall=275, gb_free=13.7, wall=232928
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3408, 42808])
2023-09-23 03:26:49 | INFO | train_inner | epoch 016:   4330 / 9060 loss=7.097, nll_loss=3.465, ppl=11.05, wps=4718.3, ups=0.36, wpb=12980.5, bsz=448.2, num_updates=140200, lr=8.44551e-05, gnorm=1.054, loss_scale=4, train_wall=275, gb_free=16.7, wall=233203
pred_new.size(): torch.Size([3402, 42808])
ter_threshold: 0.440276
num_accepted / total 39 112
loss token level: tensor(9553.2666, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4844., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 03:31:28 | INFO | train_inner | epoch 016:   4430 / 9060 loss=6.969, nll_loss=3.415, ppl=10.67, wps=4697.8, ups=0.36, wpb=13086.3, bsz=427.9, num_updates=140300, lr=8.4425e-05, gnorm=0.974, loss_scale=4, train_wall=278, gb_free=14.9, wall=233481
2023-09-23 03:35:59 | INFO | train_inner | epoch 016:   4530 / 9060 loss=7.106, nll_loss=3.5, ppl=11.31, wps=4804.7, ups=0.37, wpb=13032, bsz=438.1, num_updates=140400, lr=8.43949e-05, gnorm=0.996, loss_scale=8, train_wall=271, gb_free=13.8, wall=233753
pred_new.size(): torch.Size([3116, 42808])
lprobs.size(): torch.Size([3288, 42808])
2023-09-23 03:40:19 | INFO | train_inner | epoch 016:   4630 / 9060 loss=6.977, nll_loss=3.434, ppl=10.81, wps=5006.4, ups=0.38, wpb=13015, bsz=444.7, num_updates=140500, lr=8.43649e-05, gnorm=0.993, loss_scale=8, train_wall=260, gb_free=13.7, wall=234012
pred_new.size(): torch.Size([1984, 42808])
2023-09-23 03:44:46 | INFO | train_inner | epoch 016:   4730 / 9060 loss=6.979, nll_loss=3.42, ppl=10.7, wps=4844, ups=0.38, wpb=12915.8, bsz=443, num_updates=140600, lr=8.43349e-05, gnorm=1.014, loss_scale=8, train_wall=266, gb_free=14.1, wall=234279
tensor(7128., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([1960, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6776, 42808])
pred_new.size(): torch.Size([4080, 42808])
lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.43161499999999997
num_accepted / total 25 128
loss token level: tensor(8335.5898, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3612., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3036, 42808])
ter_threshold: 0.431697
num_accepted / total 38 88
loss token level: tensor(9422.1230, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11768., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1240, 42808])
ter_threshold: 0.431821
num_accepted / total 67 168
loss token level: tensor(11025.9453, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8200., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.43191599999999997
num_accepted / total 102 208
loss token level: tensor(9874.5518, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6568., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7636, 42808])
pred_new.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2952, 42808])
pred_new.size(): torch.Size([2574, 42808])
pred_new.size(): torch.Size([3276, 42808])
ter_threshold: 0.432269
num_accepted / total 46 96
loss token level: tensor(9436.1484, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12928., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([1652, 42808])
lprobs.size(): torch.Size([2240, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2893, 42808])
pred_new.size(): torch.Size([2574, 42808])
pred_new.size(): torch.Size([5148, 42808])
pred_new.size(): torch.Size([2813, 42808])
pred_new.size(): torch.Size([2064, 42808])
ter_threshold: 0.433005
num_accepted / total 58 152
loss token level: tensor(9007.8535, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5016., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([264, 42808])
pred_new.size(): torch.Size([4053, 42808])
pred_new.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([2820, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([3840, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([5580, 42808])
ter_threshold: 0.433965
num_accepted / total 24 72
loss token level: tensor(9316.8086, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4956., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1767, 42808])
pred_new.size(): torch.Size([4158, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([5611, 42808])
pred_new.size(): torch.Size([800, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2970, 42808])
ter_threshold: 0.434702
num_accepted / total 29 72
loss token level: tensor(8474.7676, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5980., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([3807, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.435629
num_accepted / total 30 80
loss token level: tensor(8697.7051, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8768., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.435733
num_accepted / total 33 88
loss token level: tensor(9169.8789, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5344., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.435758
num_accepted / total 11 56
loss token level: tensor(9137.0781, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2708., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.435822
num_accepted / total 34 96
loss token level: tensor(9369.9316, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8336., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3960, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([1998, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([3996, 42808])
pred_new.size(): torch.Size([648, 42808])
lprobs.size(): torch.Size([3224, 42808])
pred_new.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([2744, 42808])
pred_new.size(): torch.Size([1104, 42808])
pred_new.size(): torch.Size([576, 42808])
pred_new.size(): torch.Size([2325, 42808])
ter_threshold: 0.437241
num_accepted / total 23 56
loss token level: tensor(8743.7676, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6600., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.437609
num_accepted / total 7 40
loss token level: tensor(7735.6709, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2014., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7636, 42808])
pred_new.size(): torch.Size([6860, 42808])
pred_new.size(): torch.Size([1290, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5565, 42808])
lprobs.size(): torch.Size([2992, 42808])
ter_threshold: 0.438625
num_accepted / total 218 296
loss token level: tensor(8553.4043, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9016., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([96, 42808])
lprobs.size(): torch.Size([2408, 42808])
lprobs.size(): torch.Size([2576, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([6106, 42808])
pred_new.size(): torch.Size([3956, 42808])
pred_new.size(): torch.Size([8154, 42808])
pred_new.size(): torch.Size([3069, 42808])
ter_threshold: 0.43934799999999996
num_accepted / total 32 104
loss token level: tensor(9342.7939, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4060., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([4032, 42808])
pred_new.size(): torch.Size([1395, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2920, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([4320, 42808])
lprobs.size(): torch.Size([3008, 42808])
ter_threshold: 0.440276
num_accepted / total 171 272
loss token level: tensor(8316.7891, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7668., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2565, 42808])
ter_threshold: 0.440314
num_accepted / total 30 56
loss token level: tensor(7920.4385, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7376., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([5214, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.440677
num_accepted / total 18 56
loss token level: tensor(9739.4180, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2948, 42808])
2023-09-23 03:49:07 | INFO | train_inner | epoch 016:   4830 / 9060 loss=6.888, nll_loss=3.416, ppl=10.68, wps=4973.3, ups=0.38, wpb=13013.3, bsz=417.4, num_updates=140700, lr=8.43049e-05, gnorm=0.957, loss_scale=8, train_wall=261, gb_free=14, wall=234541
lprobs.size(): torch.Size([3240, 42808])
2023-09-23 03:53:53 | INFO | train_inner | epoch 016:   4930 / 9060 loss=6.921, nll_loss=3.406, ppl=10.6, wps=4513.7, ups=0.35, wpb=12901.4, bsz=425.5, num_updates=140800, lr=8.4275e-05, gnorm=1.003, loss_scale=8, train_wall=286, gb_free=14.4, wall=234827
lprobs.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([4485, 42808])
ter_threshold: 0.44088499999999997
num_accepted / total 4 40
loss token level: tensor(10201.2617, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2314., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 03:58:27 | INFO | train_inner | epoch 016:   5030 / 9060 loss=6.75, nll_loss=3.329, ppl=10.05, wps=4734.1, ups=0.37, wpb=12963.7, bsz=414.5, num_updates=140900, lr=8.42451e-05, gnorm=0.942, loss_scale=8, train_wall=274, gb_free=14.7, wall=235100
lprobs.size(): torch.Size([3136, 42808])
2023-09-23 04:03:06 | INFO | train_inner | epoch 016:   5130 / 9060 loss=7.055, nll_loss=3.425, ppl=10.74, wps=4670.3, ups=0.36, wpb=13032.3, bsz=446.8, num_updates=141000, lr=8.42152e-05, gnorm=0.995, loss_scale=8, train_wall=279, gb_free=13.3, wall=235379
2023-09-23 04:07:36 | INFO | train_inner | epoch 016:   5230 / 9060 loss=6.958, nll_loss=3.403, ppl=10.58, wps=4795.1, ups=0.37, wpb=12947.8, bsz=420.4, num_updates=141100, lr=8.41853e-05, gnorm=0.991, loss_scale=8, train_wall=270, gb_free=14.9, wall=235650
2023-09-23 04:12:05 | INFO | train_inner | epoch 016:   5330 / 9060 loss=6.859, nll_loss=3.395, ppl=10.52, wps=4804.8, ups=0.37, wpb=12910.8, bsz=432.2, num_updates=141200, lr=8.41555e-05, gnorm=0.984, loss_scale=8, train_wall=268, gb_free=13.8, wall=235918
pred_new.size(): torch.Size([4692, 42808])
ter_threshold: 0.441252
num_accepted / total 49 128
loss token level: tensor(9388.8906, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9808., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 04:16:56 | INFO | train_inner | epoch 016:   5430 / 9060 loss=6.872, nll_loss=3.404, ppl=10.58, wps=4474.3, ups=0.34, wpb=13041.5, bsz=419.4, num_updates=141300, lr=8.41257e-05, gnorm=0.995, loss_scale=8, train_wall=291, gb_free=14.7, wall=236210
lprobs.size(): torch.Size([3584, 42808])
2023-09-23 04:21:36 | INFO | train_inner | epoch 016:   5530 / 9060 loss=6.823, nll_loss=3.405, ppl=10.59, wps=4573.1, ups=0.36, wpb=12774.3, bsz=410.5, num_updates=141400, lr=8.4096e-05, gnorm=0.98, loss_scale=8, train_wall=279, gb_free=15.6, wall=236489
pred_new.size(): torch.Size([3276, 42808])
2023-09-23 04:26:22 | INFO | train_inner | epoch 016:   5630 / 9060 loss=7.034, nll_loss=3.483, ppl=11.18, wps=4532.3, ups=0.35, wpb=12960.7, bsz=417.1, num_updates=141500, lr=8.40663e-05, gnorm=0.982, loss_scale=8, train_wall=286, gb_free=13.7, wall=236775
pred_new.size(): torch.Size([2700, 42808])
pred_new.size(): torch.Size([1833, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1944, 42808])
2023-09-23 04:31:01 | INFO | train_inner | epoch 016:   5730 / 9060 loss=6.881, nll_loss=3.401, ppl=10.56, wps=4649.7, ups=0.36, wpb=12984.6, bsz=434.8, num_updates=141600, lr=8.40366e-05, gnorm=0.984, loss_scale=8, train_wall=279, gb_free=14.6, wall=237054
pred_new.size(): torch.Size([2397, 42808])
ter_threshold: 0.441664
num_accepted / total 77 152
loss token level: tensor(8518.2432, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10768., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 04:34:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-23 04:35:30 | INFO | train_inner | epoch 016:   5831 / 9060 loss=7.011, nll_loss=3.466, ppl=11.05, wps=4827, ups=0.37, wpb=12971.8, bsz=437.8, num_updates=141700, lr=8.40069e-05, gnorm=0.983, loss_scale=4, train_wall=268, gb_free=13.4, wall=237323
pred_new.size(): torch.Size([2848, 42808])
2023-09-23 04:40:05 | INFO | train_inner | epoch 016:   5931 / 9060 loss=6.94, nll_loss=3.43, ppl=10.78, wps=4697.7, ups=0.36, wpb=12946.8, bsz=411.8, num_updates=141800, lr=8.39773e-05, gnorm=1.008, loss_scale=4, train_wall=275, gb_free=13.6, wall=237599
2023-09-23 04:44:38 | INFO | train_inner | epoch 016:   6031 / 9060 loss=6.963, nll_loss=3.447, ppl=10.9, wps=4771.7, ups=0.37, wpb=13009.9, bsz=415.2, num_updates=141900, lr=8.39477e-05, gnorm=0.996, loss_scale=4, train_wall=272, gb_free=14.3, wall=237871
pred_new.size(): torch.Size([5940, 42808])
lprobs.size(): torch.Size([2592, 42808])
2023-09-23 04:49:04 | INFO | train_inner | epoch 016:   6131 / 9060 loss=6.984, nll_loss=3.434, ppl=10.81, wps=4900.1, ups=0.38, wpb=13027, bsz=434.7, num_updates=142000, lr=8.39181e-05, gnorm=0.986, loss_scale=4, train_wall=266, gb_free=15.7, wall=238137
2023-09-23 04:53:30 | INFO | train_inner | epoch 016:   6231 / 9060 loss=7.047, nll_loss=3.477, ppl=11.14, wps=4867.9, ups=0.38, wpb=12946.3, bsz=433.1, num_updates=142100, lr=8.38886e-05, gnorm=1.019, loss_scale=4, train_wall=266, gb_free=13.9, wall=238403
pred_new.size(): torch.Size([5406, 42808])
2023-09-23 04:58:02 | INFO | train_inner | epoch 016:   6331 / 9060 loss=7.057, nll_loss=3.464, ppl=11.03, wps=4773.8, ups=0.37, wpb=13013.7, bsz=431.4, num_updates=142200, lr=8.38591e-05, gnorm=1.001, loss_scale=4, train_wall=272, gb_free=13.7, wall=238676
ter_threshold: 0.4422
num_accepted / total 30 88
loss token level: tensor(9645.3760, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8640., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3472, 42808])
2023-09-23 05:02:37 | INFO | train_inner | epoch 016:   6431 / 9060 loss=6.976, nll_loss=3.458, ppl=10.99, wps=4751.1, ups=0.36, wpb=13056.6, bsz=435, num_updates=142300, lr=8.38296e-05, gnorm=0.977, loss_scale=4, train_wall=275, gb_free=15.8, wall=238950
pred_new.size(): torch.Size([2496, 42808])
2023-09-23 05:07:13 | INFO | train_inner | epoch 016:   6531 / 9060 loss=7.056, nll_loss=3.444, ppl=10.88, wps=4733.9, ups=0.36, wpb=13070.4, bsz=453.4, num_updates=142400, lr=8.38002e-05, gnorm=0.981, loss_scale=4, train_wall=276, gb_free=14.5, wall=239227
2023-09-23 05:11:40 | INFO | train_inner | epoch 016:   6631 / 9060 loss=6.98, nll_loss=3.462, ppl=11.02, wps=4897, ups=0.37, wpb=13073.3, bsz=410.8, num_updates=142500, lr=8.37708e-05, gnorm=0.991, loss_scale=4, train_wall=267, gb_free=14.5, wall=239494
ter_threshold: 0.442534
num_accepted / total 53 152
loss token level: tensor(8144.7607, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5552., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 05:16:19 | INFO | train_inner | epoch 016:   6731 / 9060 loss=7.024, nll_loss=3.442, ppl=10.87, wps=4645.5, ups=0.36, wpb=12960.7, bsz=440.3, num_updates=142600, lr=8.37414e-05, gnorm=0.993, loss_scale=4, train_wall=279, gb_free=14.9, wall=239773
tensor(9953.3350, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6984., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5010, 42808])
pred_new.size(): torch.Size([4572, 42808])
pred_new.size(): torch.Size([2622, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3096, 42808])
ter_threshold: 0.432064
num_accepted / total 3 56
loss token level: tensor(12967.2158, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1225., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2904, 42808])
ter_threshold: 0.432269
num_accepted / total 63 120
loss token level: tensor(9635.7598, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12736., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([7803, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4444, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1748, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([2842, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([1872, 42808])
pred_new.size(): torch.Size([5760, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2784, 42808])
pred_new.size(): torch.Size([4752, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([3885, 42808])
pred_new.size(): torch.Size([1980, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([5565, 42808])
ter_threshold: 0.434637
num_accepted / total 58 112
loss token level: tensor(9376.1387, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.435119
num_accepted / total 0 56
loss token level: tensor(15454.4072, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: 0
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2223, 42808])
pred_new.size(): torch.Size([296, 42808])
pred_new.size(): torch.Size([5423, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1280, 42808])
lprobs.size(): torch.Size([2944, 42808])
ter_threshold: 0.435733
num_accepted / total 113 208
loss token level: tensor(8528.4893, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6584., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.435921
num_accepted / total 42 88
loss token level: tensor(9265.6553, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6952., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2244, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3904, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([4000, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4847, 42808])
pred_new.size(): torch.Size([5760, 42808])
pred_new.size(): torch.Size([1666, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([3243, 42808])
lprobs.size(): torch.Size([2760, 42808])
pred_new.size(): torch.Size([2365, 42808])
pred_new.size(): torch.Size([2268, 42808])
pred_new.size(): torch.Size([6580, 42808])
pred_new.size(): torch.Size([5290, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([6624, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2745, 42808])
pred_new.size(): torch.Size([525, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([5198, 42808])
pred_new.size(): torch.Size([5208, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([4864, 42808])
pred_new.size(): torch.Size([3741, 42808])
pred_new.size(): torch.Size([3780, 42808])
ter_threshold: 0.43934799999999996
num_accepted / total 76 168
loss token level: tensor(9672.1152, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6152., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([976, 42808])
ter_threshold: 0.439453
num_accepted / total 35 88
loss token level: tensor(9785.6602, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5856., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8484, 42808])
pred_new.size(): torch.Size([3230, 42808])
pred_new.size(): torch.Size([3360, 42808])
ter_threshold: 0.43972999999999995
num_accepted / total 8 56
loss token level: tensor(9253.7559, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3754., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1904, 42808])
pred_new.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.440276
num_accepted / total 25 104
loss token level: tensor(11460.6934, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3278., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4224, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2542, 42808])
ter_threshold: 0.440462
num_accepted / total 3 16
loss token level: tensor(7752.1587, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2500., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8188, 42808])
pred_new.size(): torch.Size([2888, 42808])
pred_new.size(): torch.Size([2700, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([2952, 42808])
pred_new.size(): torch.Size([3600, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([4104, 42808])
pred_new.size(): torch.Size([5300, 42808])
ter_threshold: 0.441252
num_accepted / total 28 72
loss token level: tensor(8872.6992, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6176., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([2552, 42808])
pred_new.size(): torch.Size([2790, 42808])
pred_new.size(): torch.Size([2781, 42808])
pred_new.size(): torch.Size([2016, 42808])
ter_threshold: 0.441664
num_accepted / total 387 448
loss token level: tensor(7756.7065, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12768., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5400, 42808])
pred_new.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1575, 42808])
pred_new.size(): torch.Size([2304, 42808])
pred_new.size(): torch.Size([4059, 42808])
ter_threshold: 0.442094
num_accepted / total 32 72
loss token level: tensor(9453.9785, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6428., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3708, 42808])
pred_new.size(): torch.Size([4950, 42808])
pred_new.size(): torch.Size([952, 42808])
pred_new.size(): torch.Size([3969, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3224, 42808])
2023-09-23 05:21:12 | INFO | train_inner | epoch 016:   6831 / 9060 loss=6.928, nll_loss=3.397, ppl=10.53, wps=4419.8, ups=0.34, wpb=12949.8, bsz=428.6, num_updates=142700, lr=8.37121e-05, gnorm=0.992, loss_scale=4, train_wall=293, gb_free=13.7, wall=240066
pred_new.size(): torch.Size([2700, 42808])
pred_new.size(): torch.Size([4830, 42808])
2023-09-23 05:25:57 | INFO | train_inner | epoch 016:   6931 / 9060 loss=7.038, nll_loss=3.503, ppl=11.33, wps=4516.4, ups=0.35, wpb=12872.5, bsz=418.1, num_updates=142800, lr=8.36827e-05, gnorm=1.037, loss_scale=4, train_wall=285, gb_free=13.4, wall=240351
pred_new.size(): torch.Size([2016, 42808])
2023-09-23 05:30:48 | INFO | train_inner | epoch 016:   7031 / 9060 loss=6.945, nll_loss=3.445, ppl=10.89, wps=4434.4, ups=0.34, wpb=12897.8, bsz=408.9, num_updates=142900, lr=8.36535e-05, gnorm=1.004, loss_scale=4, train_wall=291, gb_free=14.6, wall=240641
ter_threshold: 0.442947
num_accepted / total 51 112
loss token level: tensor(9766.6543, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11824., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 05:35:41 | INFO | train_inner | epoch 016:   7131 / 9060 loss=7.01, nll_loss=3.46, ppl=11, wps=4411.6, ups=0.34, wpb=12948.8, bsz=452.8, num_updates=143000, lr=8.36242e-05, gnorm=1.01, loss_scale=4, train_wall=293, gb_free=14.4, wall=240935
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3780, 42808])
2023-09-23 05:40:25 | INFO | train_inner | epoch 016:   7231 / 9060 loss=7.019, nll_loss=3.456, ppl=10.97, wps=4556, ups=0.35, wpb=12923.5, bsz=439.4, num_updates=143100, lr=8.3595e-05, gnorm=1.012, loss_scale=4, train_wall=283, gb_free=13.8, wall=241219
lprobs.size(): torch.Size([3344, 42808])
2023-09-23 05:45:17 | INFO | train_inner | epoch 016:   7331 / 9060 loss=6.942, nll_loss=3.441, ppl=10.86, wps=4421.7, ups=0.34, wpb=12901.2, bsz=416.1, num_updates=143200, lr=8.35658e-05, gnorm=1.015, loss_scale=4, train_wall=291, gb_free=14, wall=241510
ter_threshold: 0.44324600000000003
num_accepted / total 23 80
loss token level: tensor(8934.6816, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7112., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 05:50:01 | INFO | train_inner | epoch 016:   7431 / 9060 loss=6.911, nll_loss=3.439, ppl=10.85, wps=4566.3, ups=0.35, wpb=12956.3, bsz=417.3, num_updates=143300, lr=8.35366e-05, gnorm=0.969, loss_scale=4, train_wall=283, gb_free=14.4, wall=241794
2023-09-23 05:54:45 | INFO | train_inner | epoch 016:   7531 / 9060 loss=7.009, nll_loss=3.478, ppl=11.14, wps=4584.9, ups=0.35, wpb=13041.8, bsz=424.2, num_updates=143400, lr=8.35075e-05, gnorm=1.004, loss_scale=4, train_wall=284, gb_free=14.4, wall=242079
lprobs.size(): torch.Size([3360, 42808])
2023-09-23 05:59:30 | INFO | train_inner | epoch 016:   7631 / 9060 loss=7.079, nll_loss=3.467, ppl=11.05, wps=4555.7, ups=0.35, wpb=12958.9, bsz=436.6, num_updates=143500, lr=8.34784e-05, gnorm=1.03, loss_scale=4, train_wall=284, gb_free=13.5, wall=242363
2023-09-23 06:04:01 | INFO | train_inner | epoch 016:   7731 / 9060 loss=6.805, nll_loss=3.373, ppl=10.36, wps=4768.4, ups=0.37, wpb=12943.7, bsz=430.8, num_updates=143600, lr=8.34493e-05, gnorm=0.953, loss_scale=4, train_wall=271, gb_free=14, wall=242634
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([7546, 42808])
lprobs.size(): torch.Size([3264, 42808])
2023-09-23 06:08:32 | INFO | train_inner | epoch 016:   7831 / 9060 loss=6.961, nll_loss=3.436, ppl=10.82, wps=4798.8, ups=0.37, wpb=13017.7, bsz=435.9, num_updates=143700, lr=8.34203e-05, gnorm=0.989, loss_scale=4, train_wall=271, gb_free=13.1, wall=242906
2023-09-23 06:13:11 | INFO | train_inner | epoch 016:   7931 / 9060 loss=6.883, nll_loss=3.416, ppl=10.67, wps=4666.5, ups=0.36, wpb=13008.8, bsz=437.1, num_updates=143800, lr=8.33913e-05, gnorm=0.981, loss_scale=4, train_wall=279, gb_free=15.5, wall=243184
pred_new.size(): torch.Size([3588, 42808])
2023-09-23 06:18:08 | INFO | train_inner | epoch 016:   8031 / 9060 loss=6.987, nll_loss=3.439, ppl=10.84, wps=4395.9, ups=0.34, wpb=13034.2, bsz=442.4, num_updates=143900, lr=8.33623e-05, gnorm=0.993, loss_scale=4, train_wall=296, gb_free=15.3, wall=243481
ter_threshold: 0.44396800000000003
num_accepted / total 56 128
loss token level: tensor(9162.3242, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6248., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2772, 42808])
2023-09-23 06:22:54 | INFO | train_inner | epoch 016:   8131 / 9060 loss=6.938, nll_loss=3.457, ppl=10.98, wps=4522.4, ups=0.35, wpb=12962.5, bsz=418, num_updates=144000, lr=8.33333e-05, gnorm=0.979, loss_scale=4, train_wall=286, gb_free=14.8, wall=243768
pred_new.size(): torch.Size([6560, 42808])
pred_new.size(): torch.Size([1377, 42808])
ter_threshold: 0.44407399999999997
num_accepted / total 79 144
loss token level: tensor(9522.7939, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12808., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.444091
num_accepted / total 32 72
loss token level: tensor(9330.8584, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7444., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.44409699999999996
num_accepted / total 16 64
loss token level: tensor(9165.6113, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6064., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 06:27:43 | INFO | train_inner | epoch 016:   8231 / 9060 loss=6.985, nll_loss=3.432, ppl=10.79, wps=4498.3, ups=0.35, wpb=12998.3, bsz=442.6, num_updates=144100, lr=8.33044e-05, gnorm=0.995, loss_scale=4, train_wall=289, gb_free=14.9, wall=244057
2023-09-23 06:32:19 | INFO | train_inner | epoch 016:   8331 / 9060 loss=6.97, nll_loss=3.465, ppl=11.04, wps=4716.6, ups=0.36, wpb=13016.5, bsz=435, num_updates=144200, lr=8.32755e-05, gnorm=0.987, loss_scale=4, train_wall=276, gb_free=14.4, wall=244333
2023-09-23 06:36:49 | INFO | train_inner | epoch 016:   8431 / 9060 loss=6.979, nll_loss=3.468, ppl=11.06, wps=4863.7, ups=0.37, wpb=13133.5, bsz=439.4, num_updates=144300, lr=8.32467e-05, gnorm=0.968, loss_scale=4, train_wall=270, gb_free=14.9, wall=244603
2023-09-23 06:41:33 | INFO | train_inner | epoch 016:   8531 / 9060 loss=6.974, nll_loss=3.424, ppl=10.74, wps=4539.6, ups=0.35, wpb=12908.8, bsz=451, num_updates=144400, lr=8.32178e-05, gnorm=0.979, loss_scale=4, train_wall=284, gb_free=13.9, wall=244887
pred_new.size(): torch.Size([3840, 42808])
ter_threshold: 0.444467
num_accepted / total 40 96
loss token level: tensor(9306.2666, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6008., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6240, 42808])
2023-09-23 06:46:21 | INFO | train_inner | epoch 016:   8631 / 9060 loss=7.074, nll_loss=3.493, ppl=11.26, wps=4531, ups=0.35, wpb=13028.4, bsz=414.6, num_updates=144500, lr=8.3189e-05, gnorm=1.015, loss_scale=4, train_wall=287, gb_free=13.8, wall=245174
pred_new.size(): torch.Size([1350, 42808])
2023-09-23 06:51:06 | INFO | train_inner | epoch 016:   8731 / 9060 loss=6.987, nll_loss=3.452, ppl=10.94, wps=4535.8, ups=0.35, wpb=12941.4, bsz=437.8, num_updates=144600, lr=8.31603e-05, gnorm=0.983, loss_scale=4, train_wall=285, gb_free=13.9, wall=245460
pred_new.size(): torch.Size([4264, 42808])
2023-09-23 06:55:55 | INFO | train_inner | epoch 016:   8831 / 9060 loss=6.929, nll_loss=3.41, ppl=10.63, wps=4554.3, ups=0.35, wpb=13129.5, bsz=411.1, num_updates=144700, lr=8.31315e-05, gnorm=0.966, loss_scale=4, train_wall=288, gb_free=13.9, wall=245748
pred_new.size(): torch.Size([4720, 42808])
2023-09-23 07:00:38 | INFO | train_inner | epoch 016:   8931 / 9060 loss=6.97, nll_loss=3.449, ppl=10.92, wps=4608.2, ups=0.35, wpb=13060.5, bsz=421.1, num_updates=144800, lr=8.31028e-05, gnorm=0.982, loss_scale=4, train_wall=283, gb_free=13.7, wall=246032
2023-09-23 07:05:21 | INFO | train_inner | epoch 016:   9031 / 9060 loss=6.966, nll_loss=3.456, ppl=10.97, wps=4540.1, ups=0.35, wpb=12837.9, bsz=423, num_updates=144900, lr=8.30741e-05, gnorm=0.998, loss_scale=4, train_wall=283, gb_free=16.1, wall=246314
2023-09-23 07:06:46 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-23 07:06:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 07:06:46 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-23 07:06:46 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-23 07:06:47 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-23 07:06:47 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-23 07:06:47 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-23 07:06:47 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-23 07:06:48 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-23 07:06:48 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-23 07:06:48 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-23 07:06:48 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-23 07:06:49 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein regnerischer Erfolg.
2023-09-23 07:06:49 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-23 07:06:50 | INFO | fairseq.tasks.translation | example hypothesis: (EN) Herr Präsident! Frohes Neues Jahr für alle und Glückwunsch an unseren Präsidenten.
2023-09-23 07:06:50 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-23 07:06:50 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-23 07:06:50 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-23 07:06:51 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-23 07:06:51 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-23 07:06:51 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten einen digitalen TV und Internetzugang, der sowohl für Geschäfts- als auch für Urlaubsreisende gleichermaßen geeignet ist.
2023-09-23 07:06:51 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-23 07:06:52 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-23 07:06:52 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-23 07:06:52 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 07:06:52 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 07:06:53 | INFO | fairseq.tasks.translation | example hypothesis: Insgesamt werden in der gesamten EU enorme Mengen an Energie verschwendet.
2023-09-23 07:06:53 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-23 07:06:53 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin enthält einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-23 07:06:53 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-23 07:06:54 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich auch die Haltungsänderung in Kürze im Haushalt der Union niederschlagen.
2023-09-23 07:06:54 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-23 07:06:54 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-23 07:06:54 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-23 07:06:55 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-23 07:06:55 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-23 07:06:56 | INFO | fairseq.tasks.translation | example hypothesis: Ich darf Sie daran erinnern, dass eines der Hauptziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-23 07:06:56 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-23 07:06:56 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-23 07:06:56 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-23 07:06:57 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Sitz und Produktionshallen in Stans.
2023-09-23 07:06:57 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-23 07:06:57 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-23 07:06:57 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-23 07:06:58 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer spezifischen politischen Kraft.
2023-09-23 07:06:58 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-23 07:06:58 | INFO | fairseq.tasks.translation | example hypothesis: Das funktionale Bindeglied dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-23 07:06:58 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-23 07:06:59 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerfreie Werbung kann potentielle Käufer dazu veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-23 07:06:59 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-23 07:07:00 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-23 07:07:00 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-23 07:07:00 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-23 07:07:00 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-23 07:07:01 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Debatte, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 07:07:01 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 07:07:01 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in einem Umkreis von etwa 8 km vom Strip entfernt.
2023-09-23 07:07:01 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-23 07:07:02 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-23 07:07:02 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-23 07:07:02 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-23 07:07:02 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-23 07:07:03 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung sowohl für Transferdruck als auch für Direktdruck erhältlich.
2023-09-23 07:07:03 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-23 07:07:04 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und Sicherheitszusammenarbeit mit Amerika verlassen.
2023-09-23 07:07:04 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-23 07:07:04 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Ausreise Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-23 07:07:04 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-23 07:07:05 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-23 07:07:05 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-23 07:07:05 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, für einige Formate gibt es leider keine freie Alternative, die auf allen Computer-Plattformen läuft.
2023-09-23 07:07:05 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-23 07:07:06 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-23 07:07:06 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-23 07:07:07 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Vorstellungen von niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-23 07:07:07 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-23 07:07:07 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils neu emergen, damit es richtig funktionieren kann.
2023-09-23 07:07:07 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-23 07:07:08 | INFO | fairseq.tasks.translation | example hypothesis: Horde und Allianzspieler können keine Gegenstände kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser benutzen.
2023-09-23 07:07:08 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-23 07:07:09 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum sich diese Kriterien auf die Anwendung nur innerhalb der Grenzen Europas beschränken sollten.
2023-09-23 07:07:09 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-23 07:07:09 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-23 07:07:09 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-23 07:07:10 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens mit den Vereinigten Staaten vorlegen müssen.
2023-09-23 07:07:10 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-23 07:07:11 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unser breites Sortiment an Plastik-Babyartikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-23 07:07:11 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-23 07:07:11 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 07:07:11 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 07:07:12 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis Kenntnis von Sachverhalten, die mit diesen AGB nicht vereinbar sind, über Sachverhalten zu informieren.
2023-09-23 07:07:12 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-23 07:07:12 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die die Notwendigkeit institutioneller Veränderungen vorangetrieben und erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung benötigt.
2023-09-23 07:07:12 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-23 07:07:13 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-23 07:07:13 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-23 07:07:14 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Prüfung aller Fragen erzielt wurden, die jetzt zur Diskussion stehen, und die etwas betreffen, das kaum zwei Jahre alt ist, nämlich die neue transatlantische Agenda.
2023-09-23 07:07:14 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-23 07:07:14 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Quellen und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-23 07:07:14 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-23 07:07:15 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal war der Berichterstatter in der Lage, bisweilen unterschiedliche Meinungen und Beiträge zusammenzufassen und - wie ich sagen würde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 07:07:15 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 07:07:16 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlagsgeräten mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-23 07:07:16 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-23 07:07:16 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-23 07:07:16 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-23 07:07:17 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-23 07:07:17 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-23 07:07:18 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-23 07:07:18 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-23 07:07:19 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 000 $.
2023-09-23 07:07:19 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-23 07:07:19 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht der Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-23 07:07:19 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-23 07:07:20 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Anzahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-23 07:07:20 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-23 07:07:21 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine andere: die Notsituation der Kinder, des schwächsten Bevölkerungssektors, die ohne Familie, ohne Schutz und ohne Staat geblieben sind.
2023-09-23 07:07:21 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-23 07:07:21 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht ausschließlich für ihre Flossen gefangen werden können.
2023-09-23 07:07:21 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-23 07:07:22 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht befreit ist, erst gar nicht verwirklicht ist, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, bis man sein wahres Selbst kennt.
2023-09-23 07:07:22 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-23 07:07:23 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher von grundlegender Bedeutung, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in unserer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen.
2023-09-23 07:07:23 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-23 07:07:23 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern freie Meinungsäußerung, freie und unabhängige Wahlen und Vereinigungsfreiheit geben, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-23 07:07:23 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-23 07:07:24 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java-Programmiersprache mit J2EE-Techniken, die Plattform und Betriebssystem Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-23 07:07:24 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-23 07:07:25 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Wir stimmen heute über einen Vorschlag ab, die europäische soziale Sicherheit klarer und flexibler zu koordinieren, und stimmen daher für die Klärung des Anhangs.
2023-09-23 07:07:25 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-23 07:07:26 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist ferner der Ansicht, dass die WTO-Mitgliedsländer eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen haben, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-23 07:07:26 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-23 07:07:27 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Aussprache über den irischen öffentlich-rechtlichen Rundfunk RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben senken und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu senken................
2023-09-23 07:07:27 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-23 07:07:27 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-23 07:07:27 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-23 07:07:28 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder etwas so Spezielles wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-23 07:07:28 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-23 07:07:29 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten offen.......................
2023-09-23 07:07:29 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-23 07:07:29 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, abgesehen von diesen wenigen Vorbehalten, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-23 07:07:29 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-23 07:07:30 | INFO | fairseq.tasks.translation | example hypothesis: Anders zu denken, hieße, zu naturalisieren und zu mystifizieren, was eine bestimmte Art von Vertragsverhältnis zwischen Individuen mit gemeinsamen Anliegen ist (unter ihnen häufig die tatsächliche oder wahrgenommene Bedrohung, durch institutionelle Hegemonie zerschlagen zu werden)!
2023-09-23 07:07:30 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-23 07:07:31 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollte der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn zum Beispiel die Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-23 07:07:31 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-23 07:07:32 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Autos mit weniger als 50.000 Dollar, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos für Sie ausprobieren.
2023-09-23 07:07:32 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-23 07:07:32 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darlegung der Angelegenheit.
2023-09-23 07:07:32 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-23 07:07:33 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den exzellenten Süßwasserfisch: gegrillter Hecht, Forelle mit Mandeln.
2023-09-23 07:07:33 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-23 07:07:34 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was ein politisches Handeln bedeutet, einen Gesamtüberblick zu geben, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu sehen, welche Impulse die Europäische Union mit Blick auf die Zukunft geben kann.
2023-09-23 07:07:34 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-23 07:07:35 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, haben sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009" geeinigt.
2023-09-23 07:07:35 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-23 07:07:36 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo unmittelbare Bedrohungen für bestehende Arbeitsplätze und Wettbewerbsfähigkeit aufgrund von makroökonomischen Politiken, Steuermaßnahmen und Zwängen, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt werden.
2023-09-23 07:07:36 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-23 07:07:36 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein ausgezeichnetes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text übernommen hat.
2023-09-23 07:07:36 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-23 07:07:37 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den Rechts- und Rechtsbereich, und macht Norwegen und Island zu Ländern, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes Anwendung finden werden.
2023-09-23 07:07:37 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-23 07:07:38 | INFO | fairseq.tasks.translation | example hypothesis: Wir gehen mit voller Geschwindigkeit mit einem Schichtboot hinunter den Mississippi, suchen nach dem großen verborgenen Schatz, verlieben uns in den schönen Becky Thatcher, der rein dynamisch ist, und vor allem werden wir große Freunde sein........................
2023-09-23 07:07:38 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-23 07:07:39 | INFO | fairseq.tasks.translation | example hypothesis: In praktischer Hinsicht harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder juristische Personen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion und den Strafcharakter der Sanktionen, die im Falle solcher Verstöße von Personen angewendet werden können.
2023-09-23 07:07:39 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-23 07:07:40 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden nämlich verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner geleistet und eine Gruppe von Bergleuten gefilmt haben, die seit Jahren von einem autoritären Regime gejagt werden, das jedes Prinzip der Demokratie missachtet..................
2023-09-23 07:07:40 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-23 07:07:40 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseurshop und Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Menü- und Presseservice, ein Geldwechsel, ein kostenloser Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-23 07:07:40 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-23 07:07:41 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, die Frau des Königs D. João II, geliebt hat, und die durch ihre international bekannten Keramiken für ihre figurativen und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-23 07:07:41 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-23 07:07:42 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es handele sich um gute Befürworter des Westens auf der einen Seite und Anhänger des ehemaligen Regimes auf der anderen Seite - das ist ebenfalls verwerflich, da die Rolle aller von heute und davor bekannt ist.
2023-09-23 07:07:42 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-23 07:07:43 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.........................
2023-09-23 07:07:43 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-23 07:07:44 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär Informationen zur Verfügung gestellt, so sind diese auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung weiterzugeben, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-23 07:07:44 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-23 07:07:45 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Abermillionen Euro in einige Programme fließen, die normalerweise in den Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr elendes Leben führen.
2023-09-23 07:07:45 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-23 07:07:46 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder der NATO hätten an diesem Kriegshandlungen beteiligt sein können -, bei Informationen zu helfen, die es keinen Grund mehr gibt, geheim, versteckt oder geheim zu halten, damit wir die Tatsachen wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann.........................
2023-09-23 07:07:46 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-23 07:07:47 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Bezirk Reinickendorf liegt 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 07:07:47 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 07:07:48 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, wird der Advanced UAV zusammen mit unserem Geschäftsbereich Defence Electronics und Indra in Spanien die modernsten, modularsten Sensorsuite und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die modernen außerbörslichen Plattformen niemals erreichen können.
2023-09-23 07:07:48 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-23 07:07:49 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte aus dem Markt zu nehmen, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt eine große Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.............................
2023-09-23 07:07:49 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-23 07:07:49 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Komplott von Modernität und Postmoderne oder der klaren Opposition von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung jener beiden Politik der Ästhetik anerkennen, die in genau die Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die Kunst als solche für uns identifizierbar machen - jene zwei Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führen........................
2023-09-23 07:07:49 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-23 07:07:51 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Debatten und der Stellungnahmen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen unsere Aussprachen führen, und wenn die vierzig Petenten nicht anwesend sind, werde ich nicht beantragen, die Beschlussfähigkeit zu prüfen.
2023-09-23 07:07:51 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-23 07:07:52 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker die Einschränkung des Prinzips des Nationalstaates niemals akzeptiert haben, sind es paradoxerweise gerade sie, die, kaum bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem nationale Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen...........................
2023-09-23 07:07:52 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-23 07:07:53 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Form als Hybridform veröffentlicht, die Rezensionen und Artikel des vierteljährlichen Magazins sind für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt................. H-Soz-u-Kult wurde in Kooperation mit der H-
2023-09-23 07:07:53 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-23 07:07:54 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit dem Eintreffen der neuen Smartphone-Generation haben Handys ihre Federn erheblich verfeinert und sich von einst blutigen Taschenwecker über polyphonisch tootende Game Boy-Aspiranten zu schlichten Mini-PCs mit knackigen CD-Qualität-Stereo-Sound gegossen: Von nun an könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-wannabes zu Trailblasern neuer technologischer Entwicklungen entwickeln............... Durch ihre besondere Kombination von Fähigkeiten können sie von den ehemaligen me-too-wannabes zu Trailbla
2023-09-23 07:07:54 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-23 07:07:56 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien distante la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se marchen.
2023-09-23 07:07:56 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-23 07:07:56 | INFO | valid | epoch 016 | valid on 'valid' subset | loss 4.153 | nll_loss 2.18 | ppl 4.53 | bleu 28.5 | wps 16769.7 | wpb 12011.9 | bsz 398.1 | num_updates 144929 | best_bleu 29.48
2023-09-23 07:07:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 144929 updates
2023-09-23 07:07:56 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint16.pt
2023-09-23 07:08:02 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint16.pt
2023-09-23 07:08:06 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint16.pt (epoch 16 @ 144929 updates, score 28.5) (writing took 9.627371898037381 seconds)
2023-09-23 07:08:06 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2023-09-23 07:08:06 | INFO | train | epoch 016 | loss 6.969 | nll_loss 3.433 | ppl 10.8 | wps 4740 | ups 0.37 | wpb 12977.3 | bsz 430.6 | num_updates 144929 | lr 8.30658e-05 | gnorm 0.991 | loss_scale 4 | train_wall 24695 | gb_free 13.5 | wall 246480
2023-09-23 07:08:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 07:08:06 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-23 07:08:06 | INFO | fairseq.trainer | begin training epoch 17
2023-09-23 07:08:06 | INFO | fairseq_cli.train | Start iterating over samples
pred_new.size(): torch.Size([3150, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-23 07:11:34 | INFO | train_inner | epoch 017:     71 / 9060 loss=7.161, nll_loss=3.511, ppl=11.4, wps=3495.9, ups=0.27, wpb=13042.3, bsz=452.8, num_updates=145000, lr=8.30455e-05, gnorm=1.001, loss_scale=4, train_wall=292, gb_free=15.1, wall=246687
pred_new.size(): torch.Size([2912, 42808])
2023-09-23 07:16:25 | INFO | train_inner | epoch 017:    171 / 9060 loss=7.12, nll_loss=3.446, ppl=10.9, wps=4436.2, ups=0.34, wpb=12909.8, bsz=423, num_updates=145100, lr=8.30169e-05, gnorm=1.025, loss_scale=4, train_wall=291, gb_free=14.7, wall=246978
ter_threshold: 0.445177
num_accepted / total 27 96
loss token level: tensor(8531.7656, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5704., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 07:21:12 | INFO | train_inner | epoch 017:    271 / 9060 loss=6.978, nll_loss=3.415, ppl=10.66, wps=4509.9, ups=0.35, wpb=12953.4, bsz=421.4, num_updates=145200, lr=8.29883e-05, gnorm=0.998, loss_scale=4, train_wall=287, gb_free=15, wall=247266
pred_new.size(): torch.Size([5676, 42808])
2023-09-23 07:25:57 | INFO | train_inner | epoch 017:    371 / 9060 loss=6.895, nll_loss=3.414, ppl=10.66, wps=4534, ups=0.35, wpb=12930.6, bsz=424.5, num_updates=145300, lr=8.29597e-05, gnorm=0.989, loss_scale=4, train_wall=285, gb_free=13.6, wall=247551
2023-09-23 07:30:40 | INFO | train_inner | epoch 017:    471 / 9060 loss=6.901, nll_loss=3.389, ppl=10.47, wps=4589.4, ups=0.35, wpb=12987.4, bsz=432.4, num_updates=145400, lr=8.29312e-05, gnorm=0.97, loss_scale=4, train_wall=283, gb_free=13.9, wall=247834
pred_new.size(): torch.Size([2266, 42808])
2023-09-23 07:35:16 | INFO | train_inner | epoch 017:    571 / 9060 loss=6.938, nll_loss=3.426, ppl=10.75, wps=4655.8, ups=0.36, wpb=12854.4, bsz=418.9, num_updates=145500, lr=8.29027e-05, gnorm=1.007, loss_scale=4, train_wall=276, gb_free=14.4, wall=248110
lprobs.size(): torch.Size([2992, 42808])
2023-09-23 07:39:50 | INFO | train_inner | epoch 017:    671 / 9060 loss=6.893, nll_loss=3.372, ppl=10.35, wps=4737.9, ups=0.37, wpb=12975.2, bsz=422.9, num_updates=145600, lr=8.28742e-05, gnorm=0.974, loss_scale=4, train_wall=274, gb_free=14.3, wall=248384
pred_new.size(): torch.Size([3168, 42808])
2023-09-23 07:44:22 | INFO | train_inner | epoch 017:    771 / 9060 loss=7.06, nll_loss=3.445, ppl=10.89, wps=4777.6, ups=0.37, wpb=13005.6, bsz=434.9, num_updates=145700, lr=8.28457e-05, gnorm=1.007, loss_scale=4, train_wall=272, gb_free=14.4, wall=248656
pred_new.size(): torch.Size([5670, 42808])
pred_new.size(): torch.Size([3940, 42808])
2023-09-23 07:49:23 | INFO | train_inner | epoch 017:    871 / 9060 loss=7.138, nll_loss=3.478, ppl=11.14, wps=4317, ups=0.33, wpb=12952, bsz=424.8, num_updates=145800, lr=8.28173e-05, gnorm=1.051, loss_scale=8, train_wall=300, gb_free=13.8, wall=248956
2023-09-23 07:54:10 | INFO | train_inner | epoch 017:    971 / 9060 loss=7.044, nll_loss=3.441, ppl=10.86, wps=4543, ups=0.35, wpb=13071.7, bsz=428.4, num_updates=145900, lr=8.27889e-05, gnorm=1.004, loss_scale=8, train_wall=287, gb_free=14.5, wall=249244
ter_threshold: 0.445992
num_accepted / total 6 48
loss token level: tensor(7891.0986, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1628., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 07:58:58 | INFO | train_inner | epoch 017:   1071 / 9060 loss=6.991, nll_loss=3.445, ppl=10.89, wps=4480, ups=0.35, wpb=12873.2, bsz=412.9, num_updates=146000, lr=8.27606e-05, gnorm=1.047, loss_scale=8, train_wall=287, gb_free=14.6, wall=249531
2023-09-23 08:03:38 | INFO | train_inner | epoch 017:   1171 / 9060 loss=6.823, nll_loss=3.346, ppl=10.17, wps=4625, ups=0.36, wpb=12956.2, bsz=412, num_updates=146100, lr=8.27323e-05, gnorm=0.959, loss_scale=8, train_wall=280, gb_free=14, wall=249811
pred_new.size(): torch.Size([1984, 42808])
2023-09-23 08:08:24 | INFO | train_inner | epoch 017:   1271 / 9060 loss=7.145, nll_loss=3.483, ppl=11.18, wps=4549.3, ups=0.35, wpb=13016.9, bsz=457.5, num_updates=146200, lr=8.2704e-05, gnorm=1.018, loss_scale=8, train_wall=286, gb_free=13.6, wall=250097
pred_new.size(): torch.Size([4473, 42808])
ter_threshold: 0.446298
num_accepted / total 54 112
loss token level: tensor(9204.3516, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6868., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 08:13:14 | INFO | train_inner | epoch 017:   1371 / 9060 loss=6.934, nll_loss=3.398, ppl=10.54, wps=4495.8, ups=0.34, wpb=13033.6, bsz=428.2, num_updates=146300, lr=8.26757e-05, gnorm=1.009, loss_scale=8, train_wall=290, gb_free=14.1, wall=250387
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([3979, 42808])
lprobs.size(): torch.Size([2904, 42808])
2023-09-23 08:17:57 | INFO | train_inner | epoch 017:   1471 / 9060 loss=7.048, nll_loss=3.439, ppl=10.84, wps=4582.9, ups=0.35, wpb=12959.2, bsz=432.1, num_updates=146400, lr=8.26475e-05, gnorm=1.014, loss_scale=8, train_wall=283, gb_free=14.1, wall=250670
lprobs.size(): torch.Size([3456, 42808])
2023-09-23 08:22:37 | INFO | train_inner | epoch 017:   1571 / 9060 loss=7.074, nll_loss=3.476, ppl=11.12, wps=4605.6, ups=0.36, wpb=12928.6, bsz=435.2, num_updates=146500, lr=8.26192e-05, gnorm=1.02, loss_scale=8, train_wall=280, gb_free=14, wall=250951
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3496, 42808])
2023-09-23 08:27:29 | INFO | train_inner | epoch 017:   1671 / 9060 loss=6.997, nll_loss=3.422, ppl=10.72, wps=4487.6, ups=0.34, wpb=13089.1, bsz=442.2, num_updates=146600, lr=8.25911e-05, gnorm=0.981, loss_scale=8, train_wall=291, gb_free=13.6, wall=251242
2023-09-23 08:32:15 | INFO | train_inner | epoch 017:   1771 / 9060 loss=7.035, nll_loss=3.47, ppl=11.08, wps=4502.5, ups=0.35, wpb=12885.4, bsz=421, num_updates=146700, lr=8.25629e-05, gnorm=1.04, loss_scale=8, train_wall=286, gb_free=14.9, wall=251529
2023-09-23 08:37:19 | INFO | train_inner | epoch 017:   1871 / 9060 loss=7.04, nll_loss=3.487, ppl=11.21, wps=4262.8, ups=0.33, wpb=12959.2, bsz=414.9, num_updates=146800, lr=8.25348e-05, gnorm=1.004, loss_scale=8, train_wall=304, gb_free=13.7, wall=251833
2023-09-23 08:42:09 | INFO | train_inner | epoch 017:   1971 / 9060 loss=6.978, nll_loss=3.435, ppl=10.82, wps=4462.2, ups=0.34, wpb=12951.3, bsz=445.8, num_updates=146900, lr=8.25067e-05, gnorm=0.996, loss_scale=8, train_wall=290, gb_free=15.8, wall=252123
2023-09-23 08:47:05 | INFO | train_inner | epoch 017:   2071 / 9060 loss=7.045, nll_loss=3.456, ppl=10.97, wps=4409, ups=0.34, wpb=13041.2, bsz=416.4, num_updates=147000, lr=8.24786e-05, gnorm=1.033, loss_scale=8, train_wall=296, gb_free=13.5, wall=252419
lprobs.size(): torch.Size([3120, 42808])
2023-09-23 08:51:37 | INFO | train_inner | epoch 017:   2171 / 9060 loss=7.039, nll_loss=3.448, ppl=10.91, wps=4748.7, ups=0.37, wpb=12911.2, bsz=451.4, num_updates=147100, lr=8.24506e-05, gnorm=1, loss_scale=8, train_wall=272, gb_free=14.6, wall=252690
2023-09-23 08:56:22 | INFO | train_inner | epoch 017:   2271 / 9060 loss=7.107, nll_loss=3.497, ppl=11.29, wps=4542.4, ups=0.35, wpb=12938.8, bsz=451.9, num_updates=147200, lr=8.24226e-05, gnorm=1.033, loss_scale=8, train_wall=285, gb_free=13.1, wall=252975
lprobs.size(): torch.Size([2992, 42808])
2023-09-23 09:01:14 | INFO | train_inner | epoch 017:   2371 / 9060 loss=7.105, nll_loss=3.503, ppl=11.34, wps=4452.3, ups=0.34, wpb=13012.6, bsz=437.7, num_updates=147300, lr=8.23946e-05, gnorm=1.019, loss_scale=8, train_wall=292, gb_free=13.8, wall=253268
2023-09-23 09:06:05 | INFO | train_inner | epoch 017:   2471 / 9060 loss=6.96, nll_loss=3.429, ppl=10.77, wps=4438.1, ups=0.34, wpb=12902.2, bsz=419, num_updates=147400, lr=8.23666e-05, gnorm=1.01, loss_scale=8, train_wall=290, gb_free=13.9, wall=253558
ter_threshold: 0.447405
num_accepted / total 2 8
loss token level: tensor(8216.2285, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2736., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 09:10:39 | INFO | train_inner | epoch 017:   2571 / 9060 loss=7.127, nll_loss=3.466, ppl=11.05, wps=4721.8, ups=0.36, wpb=12944.1, bsz=434.7, num_updates=147500, lr=8.23387e-05, gnorm=1.029, loss_scale=8, train_wall=274, gb_free=14.6, wall=253832
lprobs.size(): torch.Size([2520, 42808])
2023-09-23 09:15:07 | INFO | train_inner | epoch 017:   2671 / 9060 loss=7.149, nll_loss=3.504, ppl=11.34, wps=4854.4, ups=0.37, wpb=13027.2, bsz=445.3, num_updates=147600, lr=8.23108e-05, gnorm=1.022, loss_scale=8, train_wall=268, gb_free=14.1, wall=254101
lprobs.size(): torch.Size([3400, 42808])
2023-09-23 09:19:43 | INFO | train_inner | epoch 017:   2771 / 9060 loss=7.138, nll_loss=3.501, ppl=11.32, wps=4716.9, ups=0.36, wpb=13000.9, bsz=417.2, num_updates=147700, lr=8.22829e-05, gnorm=1.034, loss_scale=8, train_wall=275, gb_free=14, wall=254376
2023-09-23 09:24:15 | INFO | train_inner | epoch 017:   2871 / 9060 loss=6.948, nll_loss=3.43, ppl=10.78, wps=4781.4, ups=0.37, wpb=13008.3, bsz=419.5, num_updates=147800, lr=8.22551e-05, gnorm=0.987, loss_scale=8, train_wall=272, gb_free=14.7, wall=254649
pred_new.size(): torch.Size([1932, 42808])
2023-09-23 09:28:53 | INFO | train_inner | epoch 017:   2971 / 9060 loss=7.085, nll_loss=3.498, ppl=11.3, wps=4665.7, ups=0.36, wpb=12979.6, bsz=437, num_updates=147900, lr=8.22273e-05, gnorm=1.009, loss_scale=8, train_wall=278, gb_free=14.4, wall=254927
pred_new.size(): torch.Size([3795, 42808])
2023-09-23 09:33:38 | INFO | train_inner | epoch 017:   3071 / 9060 loss=7.023, nll_loss=3.438, ppl=10.84, wps=4545.8, ups=0.35, wpb=12935.7, bsz=441, num_updates=148000, lr=8.21995e-05, gnorm=1.018, loss_scale=8, train_wall=284, gb_free=15, wall=255211
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2772, 42808])
2023-09-23 09:38:31 | INFO | train_inner | epoch 017:   3171 / 9060 loss=6.97, nll_loss=3.408, ppl=10.61, wps=4449.8, ups=0.34, wpb=13067.6, bsz=436.6, num_updates=148100, lr=8.21717e-05, gnorm=0.996, loss_scale=8, train_wall=293, gb_free=13.1, wall=255505
lprobs.size(): torch.Size([3456, 42808])
2023-09-23 09:43:16 | INFO | train_inner | epoch 017:   3271 / 9060 loss=6.946, nll_loss=3.43, ppl=10.78, wps=4554.4, ups=0.35, wpb=12943.2, bsz=427.2, num_updates=148200, lr=8.2144e-05, gnorm=1, loss_scale=8, train_wall=284, gb_free=13.7, wall=255789
pred_new.size(): torch.Size([6975, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-23 09:47:55 | INFO | train_inner | epoch 017:   3371 / 9060 loss=7.031, nll_loss=3.448, ppl=10.91, wps=4612.1, ups=0.36, wpb=12863, bsz=421.2, num_updates=148300, lr=8.21163e-05, gnorm=1.032, loss_scale=8, train_wall=279, gb_free=13.2, wall=256068
pred_new.size(): torch.Size([1224, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3675, 42808])
2023-09-23 09:52:40 | INFO | train_inner | epoch 017:   3471 / 9060 loss=6.771, nll_loss=3.353, ppl=10.22, wps=4530.7, ups=0.35, wpb=12931.4, bsz=421.5, num_updates=148400, lr=8.20886e-05, gnorm=0.98, loss_scale=8, train_wall=285, gb_free=14.1, wall=256353
2023-09-23 09:57:36 | INFO | train_inner | epoch 017:   3571 / 9060 loss=7.013, nll_loss=3.432, ppl=10.79, wps=4409.1, ups=0.34, wpb=13056.4, bsz=439.5, num_updates=148500, lr=8.2061e-05, gnorm=1.002, loss_scale=8, train_wall=296, gb_free=15.6, wall=256650
pred_new.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3224, 42808])
2023-09-23 10:02:27 | INFO | train_inner | epoch 017:   3671 / 9060 loss=6.983, nll_loss=3.483, ppl=11.18, wps=4447.2, ups=0.34, wpb=12943.4, bsz=423.8, num_updates=148600, lr=8.20334e-05, gnorm=0.999, loss_scale=8, train_wall=291, gb_free=14.2, wall=256941
ter_threshold: 0.44864499999999996
num_accepted / total 65 144
loss token level: tensor(8366.1660, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8592., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 10:07:09 | INFO | train_inner | epoch 017:   3771 / 9060 loss=7.109, nll_loss=3.497, ppl=11.29, wps=4625.4, ups=0.35, wpb=13043.2, bsz=451.2, num_updates=148700, lr=8.20058e-05, gnorm=1.007, loss_scale=8, train_wall=282, gb_free=14.6, wall=257223
2023-09-23 10:11:47 | INFO | train_inner | epoch 017:   3871 / 9060 loss=7.014, nll_loss=3.498, ppl=11.3, wps=4699.2, ups=0.36, wpb=13063.4, bsz=436.9, num_updates=148800, lr=8.19782e-05, gnorm=0.998, loss_scale=8, train_wall=278, gb_free=15.1, wall=257501
2023-09-23 10:16:20 | INFO | train_inner | epoch 017:   3971 / 9060 loss=6.93, nll_loss=3.437, ppl=10.83, wps=4757.5, ups=0.37, wpb=12961.1, bsz=426.2, num_updates=148900, lr=8.19507e-05, gnorm=0.987, loss_scale=8, train_wall=272, gb_free=14.7, wall=257773
lprobs.size(): torch.Size([2920, 42808])
2023-09-23 10:21:08 | INFO | train_inner | epoch 017:   4071 / 9060 loss=6.918, nll_loss=3.407, ppl=10.61, wps=4500.7, ups=0.35, wpb=12973.3, bsz=428, num_updates=149000, lr=8.19232e-05, gnorm=0.981, loss_scale=8, train_wall=288, gb_free=14, wall=258061
pred_new.size(): torch.Size([500, 42808])
lprobs.size(): torch.Size([2720, 42808])
2023-09-23 10:26:05 | INFO | train_inner | epoch 017:   4171 / 9060 loss=6.945, nll_loss=3.422, ppl=10.72, wps=4332.2, ups=0.34, wpb=12856.7, bsz=406.5, num_updates=149100, lr=8.18957e-05, gnorm=1.012, loss_scale=8, train_wall=297, gb_free=15.7, wall=258358
pred_new.size(): torch.Size([1292, 42808])
2023-09-23 10:30:38 | INFO | train_inner | epoch 017:   4271 / 9060 loss=6.876, nll_loss=3.386, ppl=10.45, wps=4680.7, ups=0.37, wpb=12811.5, bsz=443.8, num_updates=149200, lr=8.18683e-05, gnorm=1.005, loss_scale=8, train_wall=273, gb_free=14.2, wall=258632
2023-09-23 10:35:09 | INFO | train_inner | epoch 017:   4371 / 9060 loss=6.984, nll_loss=3.426, ppl=10.75, wps=4821, ups=0.37, wpb=13030.6, bsz=434.7, num_updates=149300, lr=8.18408e-05, gnorm=0.988, loss_scale=8, train_wall=270, gb_free=13.6, wall=258902
pred_new.size(): torch.Size([1456, 42808])
2023-09-23 10:39:42 | INFO | train_inner | epoch 017:   4471 / 9060 loss=6.848, nll_loss=3.369, ppl=10.33, wps=4744.8, ups=0.37, wpb=12988.4, bsz=416, num_updates=149400, lr=8.18134e-05, gnorm=0.988, loss_scale=8, train_wall=273, gb_free=14, wall=259176
2023-09-23 10:44:16 | INFO | train_inner | epoch 017:   4571 / 9060 loss=7.123, nll_loss=3.498, ppl=11.29, wps=4757.9, ups=0.37, wpb=13004.3, bsz=441.8, num_updates=149500, lr=8.17861e-05, gnorm=1.03, loss_scale=8, train_wall=273, gb_free=13.2, wall=259449
pred_new.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-23 10:49:03 | INFO | train_inner | epoch 017:   4671 / 9060 loss=6.923, nll_loss=3.441, ppl=10.86, wps=4495.8, ups=0.35, wpb=12912.2, bsz=419.3, num_updates=149600, lr=8.17587e-05, gnorm=1.007, loss_scale=8, train_wall=287, gb_free=12.7, wall=259736
pred_new.size(): torch.Size([1650, 42808])
2023-09-23 10:53:56 | INFO | train_inner | epoch 017:   4771 / 9060 loss=7.198, nll_loss=3.518, ppl=11.45, wps=4449.4, ups=0.34, wpb=13044.1, bsz=436.6, num_updates=149700, lr=8.17314e-05, gnorm=1.02, loss_scale=8, train_wall=293, gb_free=13.3, wall=260029
pred_new.size(): torch.Size([1232, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1000, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([4472, 42808])
pred_new.size(): torch.Size([5270, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6832, 42808])
ter_threshold: 0.43934799999999996
num_accepted / total 58 152
loss token level: tensor(9759.6396, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5280., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([3795, 42808])
ter_threshold: 0.439453
num_accepted / total 24 80
loss token level: tensor(9440.6396, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4320., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5775, 42808])
ter_threshold: 0.439508
num_accepted / total 14 80
loss token level: tensor(9087.8877, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3644., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([9660, 42808])
pred_new.size(): torch.Size([2952, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([2646, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3504, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3680, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2926, 42808])
pred_new.size(): torch.Size([5610, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1472, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.441252
num_accepted / total 28 104
loss token level: tensor(11280.5068, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6020., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3690, 42808])
pred_new.size(): torch.Size([884, 42808])
pred_new.size(): torch.Size([2088, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.441664
num_accepted / total 28 128
loss token level: tensor(8692.3975, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3596., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([4640, 42808])
pred_new.size(): torch.Size([5904, 42808])
pred_new.size(): torch.Size([2408, 42808])
pred_new.size(): torch.Size([2028, 42808])
ter_threshold: 0.442534
num_accepted / total 80 176
loss token level: tensor(10574.5020, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10384., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3888, 42808])
pred_new.size(): torch.Size([2420, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([1508, 42808])
pred_new.size(): torch.Size([414, 42808])
pred_new.size(): torch.Size([2625, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([2048, 42808])
pred_new.size(): torch.Size([6375, 42808])
ter_threshold: 0.44396800000000003
num_accepted / total 48 128
loss token level: tensor(9717.9336, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5552., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6240, 42808])
ter_threshold: 0.44407399999999997
num_accepted / total 37 160
loss token level: tensor(12571.8418, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5056., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2430, 42808])
ter_threshold: 0.444091
num_accepted / total 37 88
loss token level: tensor(10072.8418, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6752., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3036, 42808])
pred_new.size(): torch.Size([3360, 42808])
ter_threshold: 0.444467
num_accepted / total 32 88
loss token level: tensor(9632.8975, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5156., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1914, 42808])
pred_new.size(): torch.Size([7128, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5448, 42808])
pred_new.size(): torch.Size([420, 42808])
pred_new.size(): torch.Size([5535, 42808])
pred_new.size(): torch.Size([3096, 42808])
pred_new.size(): torch.Size([1216, 42808])
pred_new.size(): torch.Size([4347, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.445177
num_accepted / total 43 112
loss token level: tensor(10157.9355, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8864., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([2730, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2784, 42808])
pred_new.size(): torch.Size([3510, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([1820, 42808])
ter_threshold: 0.446091
num_accepted / total 32 104
loss token level: tensor(8931.7441, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3716., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([957, 42808])
ter_threshold: 0.446298
num_accepted / total 42 96
loss token level: tensor(9782.1826, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6344., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2760, 42808])
pred_new.size(): torch.Size([4158, 42808])
pred_new.size(): torch.Size([2210, 42808])
pred_new.size(): torch.Size([552, 42808])
pred_new.size(): torch.Size([2511, 42808])
ter_threshold: 0.447014
num_accepted / total 89 176
loss token level: tensor(8100.1802, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6132., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([870, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4572, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([4794, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([6466, 42808])
pred_new.size(): torch.Size([3850, 42808])
pred_new.size(): torch.Size([504, 42808])
pred_new.size(): torch.Size([2130, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([1425, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2561, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1848, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([2912, 42808])
ter_threshold: 0.449132
num_accepted / total 91 144
loss token level: tensor(8887.9062, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8760., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2646, 42808])
pred_new.size(): torch.Size([2639, 42808])
pred_new.size(): torch.Size([6390, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([7872, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([4446, 42808])
pred_new.size():lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([1652, 42808])
2023-09-23 10:58:32 | INFO | train_inner | epoch 017:   4871 / 9060 loss=7.025, nll_loss=3.465, ppl=11.05, wps=4716.5, ups=0.36, wpb=13003.3, bsz=434.8, num_updates=149800, lr=8.17041e-05, gnorm=0.997, loss_scale=8, train_wall=275, gb_free=13.4, wall=260305
tensor(4928., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3408, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2560, 42808])
pred_new.size(): torch.Size([972, 42808])
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([2784, 42808])
ter_threshold: 0.440951
num_accepted / total 18 72
loss token level: tensor(8715.0420, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3120., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5876, 42808])
ter_threshold: 0.441252
num_accepted / total 39 136
loss token level: tensor(10802.4941, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7856., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2220, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([6216, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1080, 42808])
pred_new.size(): torch.Size([1728, 42808])
pred_new.size(): torch.Size([3285, 42808])
pred_new.size(): torch.Size([5040, 42808])
pred_new.size(): torch.Size([4947, 42808])
pred_new.size(): torch.Size([4028, 42808])
pred_new.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([4884, 42808])
pred_new.size(): torch.Size([2706, 42808])
ter_threshold: 0.442534
num_accepted / total 38 104
loss token level: tensor(8636.6270, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7224., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1768, 42808])
pred_new.size(): torch.Size([1378, 42808])
ter_threshold: 0.442947
num_accepted / total 148 224
loss token level: tensor(9014.6465, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14512., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2898, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1050, 42808])
lprobs.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([7920, 42808])
pred_new.size(): torch.Size([2964, 42808])
ter_threshold: 0.44396800000000003
num_accepted / total 37 104
loss token level: tensor(10380.4160, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5528., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4692, 42808])
pred_new.size(): torch.Size([6298, 42808])
ter_threshold: 0.44407399999999997
num_accepted / total 121 208
loss token level: tensor(8761.9082, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12080., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6324, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([4356, 42808])
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([7296, 42808])
pred_new.size(): torch.Size([6273, 42808])
pred_new.size(): torch.Size([6762, 42808])
pred_new.size(): torch.Size([1520, 42808])
pred_new.size(): torch.Size([2288, 42808])
pred_new.size(): torch.Size([630, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2772, 42808])
pred_new.size(): torch.Size([2838, 42808])
ter_threshold: 0.445177
num_accepted / total 190 256
loss token level: tensor(8573.1797, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(15152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4818, 42808])
ter_threshold: 0.445215
num_accepted / total 14 24
loss token level: tensor(6478.5337, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6912., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([3332, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2781, 42808])
pred_new.size(): torch.Size([441, 42808])
pred_new.size(): torch.Size([1440, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.446091
num_accepted / total 22 80
loss token level: tensor(7859.5542, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3160., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3952, 42808])
pred_new.size(): torch.Size([3069, 42808])
pred_new.size(): torch.Size([2410, 42808])
ter_threshold: 0.44648
num_accepted / total 7 80
loss token level: tensor(13373.6924, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2056., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([4836, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([1989, 42808])
pred_new.size(): torch.Size([2408, 42808])
pred_new.size(): torch.Size([8526, 42808])
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.447014
num_accepted / total 55 128
loss token level: tensor(9467.5986, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6008., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1000, 42808])
pred_new.size(): torch.Size([5265, 42808])
pred_new.size(): torch.Size([3864, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([265, 42808])
pred_new.size(): torch.Size([5542, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3400, 42808])
ter_threshold: 0.447648
num_accepted / total 18 64
loss token level: tensor(9581.8330, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7616., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([738, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([4704, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([6032, 42808])
pred_new.size(): torch.Size([880, 42808])
pred_new.size(): torch.Size([2430, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([232, 42808])
pred_new.size(): torch.Size([1664, 42808])
pred_new.size(): torch.Size([5763, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([3406, 42808])
pred_new.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([2704, 42808])
pred_new.size(): torch.Size([840, 42808])
lprobs.size(): torch.Size([2392, 42808])
pred_new.size(): torch.Size([2136, 42808])
pred_new.size(): torch.Size([1568, 42808])
ter_threshold: 0.44864499999999996
num_accepted / total 51 104
loss token level: tensor(8393.8994, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11168., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([630, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([648, 42808])
pred_new.size(): torch.Size([2268, 42808])
lprobs.size(): torch.Size([3232, 42808])
pred_new.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([5616, 42808])
pred_new.size(): torch.Size([3268, 42808])
pred_new.size(): torch.Size([2310, 42808])
lprobs.size(): torch.Size([3096, 42808])
pred_new.size(): torch.Size([5060, 42808])
ter_threshold: 0.449698
num_accepted / total 28 72
loss token level: tensor(9303.7100, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5920., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6264, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.449827
num_accepted / total 14 48
loss token level: tensor(8970.4414, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: 2023-09-23 11:03:11 | INFO | train_inner | epoch 017:   4971 / 9060 loss=7.134, nll_loss=3.486, ppl=11.21, wps=4655.6, ups=0.36, wpb=13024.3, bsz=437.2, num_updates=149900, lr=8.16769e-05, gnorm=1.01, loss_scale=16, train_wall=280, gb_free=13.6, wall=260585
2023-09-23 11:08:09 | INFO | train_inner | epoch 017:   5071 / 9060 loss=7.044, nll_loss=3.477, ppl=11.13, wps=4374.9, ups=0.34, wpb=13004.8, bsz=413.8, num_updates=150000, lr=8.16497e-05, gnorm=1.015, loss_scale=16, train_wall=297, gb_free=15, wall=260882
ter_threshold: 0.45009299999999997
num_accepted / total 41 104
loss token level: tensor(9300.6465, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5608., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 11:12:49 | INFO | train_inner | epoch 017:   5171 / 9060 loss=7.007, nll_loss=3.415, ppl=10.67, wps=4625.7, ups=0.36, wpb=12981.9, bsz=416.8, num_updates=150100, lr=8.16225e-05, gnorm=1.011, loss_scale=16, train_wall=280, gb_free=15.4, wall=261163
ter_threshold: 0.450142
num_accepted / total 14 64
loss token level: tensor(9918.3564, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5476., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 11:17:13 | INFO | train_inner | epoch 017:   5271 / 9060 loss=6.846, nll_loss=3.396, ppl=10.53, wps=4903.1, ups=0.38, wpb=12930.3, bsz=428.2, num_updates=150200, lr=8.15953e-05, gnorm=0.994, loss_scale=16, train_wall=263, gb_free=13.6, wall=261427
pred_new.size(): torch.Size([3360, 42808])
2023-09-23 11:22:07 | INFO | train_inner | epoch 017:   5371 / 9060 loss=7.227, nll_loss=3.535, ppl=11.59, wps=4417.3, ups=0.34, wpb=12965.9, bsz=441, num_updates=150300, lr=8.15681e-05, gnorm=1.029, loss_scale=16, train_wall=293, gb_free=13.7, wall=261720
ter_threshold: 0.450315
num_accepted / total 34 64
loss token level: tensor(8711.2305, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8088., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
2023-09-23 11:26:52 | INFO | train_inner | epoch 017:   5471 / 9060 loss=7.041, nll_loss=3.484, ppl=11.19, wps=4541.1, ups=0.35, wpb=12978.2, bsz=440.2, num_updates=150400, lr=8.1541e-05, gnorm=1.013, loss_scale=16, train_wall=286, gb_free=13.9, wall=262006
lprobs.size(): torch.Size([3584, 42808])
2023-09-23 11:31:37 | INFO | train_inner | epoch 017:   5571 / 9060 loss=7.057, nll_loss=3.476, ppl=11.12, wps=4526.9, ups=0.35, wpb=12884, bsz=424.9, num_updates=150500, lr=8.15139e-05, gnorm=1.006, loss_scale=16, train_wall=284, gb_free=14, wall=262290
ter_threshold: 0.450508
num_accepted / total 18 64
loss token level: tensor(8381.1914, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6248., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1450, 42808])
lprobs.size(): torch.Size([2976, 42808])
ter_threshold: 0.45055999999999996
num_accepted / total 47 96
loss token level: tensor(9169.0645, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12256., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 11:36:18 | INFO | train_inner | epoch 017:   5671 / 9060 loss=7.209, nll_loss=3.56, ppl=11.79, wps=4563.7, ups=0.36, wpb=12843.3, bsz=452.2, num_updates=150600, lr=8.14868e-05, gnorm=1.028, loss_scale=16, train_wall=281, gb_free=13.5, wall=262572
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.450667
num_accepted / total 13 48
loss token level: tensor(7899.1543, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6456., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 11:41:14 | INFO | train_inner | epoch 017:   5771 / 9060 loss=7.119, nll_loss=3.522, ppl=11.48, wps=4384, ups=0.34, wpb=12964, bsz=416.3, num_updates=150700, lr=8.14598e-05, gnorm=1.027, loss_scale=16, train_wall=295, gb_free=13.8, wall=262868
2023-09-23 11:46:02 | INFO | train_inner | epoch 017:   5871 / 9060 loss=6.906, nll_loss=3.4, ppl=10.56, wps=4491.7, ups=0.35, wpb=12930.6, bsz=415.2, num_updates=150800, lr=8.14328e-05, gnorm=0.994, loss_scale=16, train_wall=288, gb_free=13.2, wall=263156
2023-09-23 11:50:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2023-09-23 11:50:50 | INFO | train_inner | epoch 017:   5972 / 9060 loss=6.994, nll_loss=3.452, ppl=10.95, wps=4532.7, ups=0.35, wpb=13063, bsz=419, num_updates=150900, lr=8.14058e-05, gnorm=1.03, loss_scale=8, train_wall=288, gb_free=13.8, wall=263444
ter_threshold: 0.450909
num_accepted / total 24 88
loss token level: tensor(8719.0977, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3416., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 11:52:14 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
pred_new.size(): torch.Size([1740, 42808])
2023-09-23 11:55:34 | INFO | train_inner | epoch 017:   6073 / 9060 loss=7.014, nll_loss=3.425, ppl=10.74, wps=4603.3, ups=0.35, wpb=13051.7, bsz=423.1, num_updates=151000, lr=8.13788e-05, gnorm=1.01, loss_scale=4, train_wall=283, gb_free=14, wall=263727
pred_new.size(): torch.Size([3240, 42808])
2023-09-23 12:00:19 | INFO | train_inner | epoch 017:   6173 / 9060 loss=7.179, nll_loss=3.506, ppl=11.36, wps=4543.9, ups=0.35, wpb=12978.8, bsz=430.6, num_updates=151100, lr=8.13519e-05, gnorm=1.045, loss_scale=4, train_wall=285, gb_free=14.6, wall=264013
2023-09-23 12:04:56 | INFO | train_inner | epoch 017:   6273 / 9060 loss=7.106, nll_loss=3.502, ppl=11.33, wps=4688.8, ups=0.36, wpb=12956, bsz=435, num_updates=151200, lr=8.1325e-05, gnorm=1.031, loss_scale=4, train_wall=276, gb_free=14.9, wall=264289
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1806, 42808])
2023-09-23 12:09:42 | INFO | train_inner | epoch 017:   6373 / 9060 loss=7.09, nll_loss=3.528, ppl=11.54, wps=4515.7, ups=0.35, wpb=12914.3, bsz=416.1, num_updates=151300, lr=8.12981e-05, gnorm=1.061, loss_scale=4, train_wall=286, gb_free=13.8, wall=264575
lprobs.size(): torch.Size([3264, 42808])
2023-09-23 12:14:37 | INFO | train_inner | epoch 017:   6473 / 9060 loss=7.026, nll_loss=3.461, ppl=11.02, wps=4405.4, ups=0.34, wpb=12987, bsz=428.5, num_updates=151400, lr=8.12713e-05, gnorm=1.01, loss_scale=4, train_wall=295, gb_free=13.2, wall=264870
pred_new.size(): torch.Size([7020, 42808])
ter_threshold: 0.45147899999999996
num_accepted / total 14 64
loss token level: tensor(10785.8018, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3756., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 12:19:36 | INFO | train_inner | epoch 017:   6573 / 9060 loss=6.971, nll_loss=3.436, ppl=10.83, wps=4374.7, ups=0.33, wpb=13080.4, bsz=419.8, num_updates=151500, lr=8.12444e-05, gnorm=0.992, loss_scale=4, train_wall=299, gb_free=14.9, wall=265169
2023-09-23 12:24:18 | INFO | train_inner | epoch 017:   6673 / 9060 loss=7.08, nll_loss=3.486, ppl=11.2, wps=4612.7, ups=0.35, wpb=13026.1, bsz=436.6, num_updates=151600, lr=8.12176e-05, gnorm=1.018, loss_scale=4, train_wall=282, gb_free=13.9, wall=265451
pred_new.size(): torch.Size([4082, 42808])
2023-09-23 12:28:57 | INFO | train_inner | epoch 017:   6773 / 9060 loss=6.943, nll_loss=3.449, ppl=10.92, wps=4627.1, ups=0.36, wpb=12924.9, bsz=402.5, num_updates=151700, lr=8.11909e-05, gnorm=1, loss_scale=4, train_wall=279, gb_free=14.4, wall=265731
ter_threshold: 0.451783
num_accepted / total 49 128
loss token level: tensor(9824.6250, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5348., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3008, 42808])
2023-09-23 12:33:43 | INFO | train_inner | epoch 017:   6873 / 9060 loss=7.084, nll_loss=3.472, ppl=11.1, wps=4559.5, ups=0.35, wpb=13034.9, bsz=434.6, num_updates=151800, lr=8.11641e-05, gnorm=0.993, loss_scale=4, train_wall=286, gb_free=13.3, wall=266017
pred_new.size(): torch.Size([4972, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([5000, 42808])
pred_new.size(): torch.Size([2142, 42808])
pred_new.size(): torch.Size([5346, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2856, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([4514, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([1890, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2860, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1040, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5329, 42808])
ter_threshold: 0.44396800000000003
num_accepted / total 49 112
loss token level: tensor(8798.7852, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6000., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4425, 42808])
pred_new.size(): torch.Size([2850, 42808])
ter_threshold: 0.44407399999999997
num_accepted / total 71 136
loss token level: tensor(8340.6338, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12000., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7452, 42808])
pred_new.size(): torch.Size([2430, 42808])
ter_threshold: 0.444467
num_accepted / total 27 88
loss token level: tensor(8325.7012, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3768., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3915, 42808])
ter_threshold: 0.444566
num_accepted / total 17 24
loss token level: tensor(6374.4443, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8672., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([6930, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([5952, 42808])
pred_new.size(): torch.Size([7384, 42808])
pred_new.size(): torch.Size([3108, 42808])
pred_new.size(): torch.Size([2250, 42808])
pred_new.size(): torch.Size([2829, 42808])
pred_new.size(): torch.Size([3186, 42808])
ter_threshold: 0.44510700000000003
num_accepted / total 14 48
loss token level: tensor(8257.8096, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7372., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.445177
num_accepted / total 55 128
loss token level: tensor(8824.1055, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9768., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2793, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([6102, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2904, 42808])
pred_new.size(): torch.Size([1710, 42808])
pred_new.size(): torch.Size([4740, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([1458, 42808])
pred_new.size(): torch.Size([1728, 42808])
pred_new.size(): torch.Size([814, 42808])
ter_threshold: 0.446298
num_accepted / total 52 112
loss token level: tensor(9488.5459, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6796., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5066, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3780, 42808])
pred_new.size(): torch.Size([8120, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5644, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([2944, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3190, 42808])
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([3996, 42808])
ter_threshold: 0.447837
num_accepted / total 19 72
loss token level: tensor(8872.2080, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6296., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8008, 42808])
pred_new.size(): torch.Size([3132, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([5830, 42808])
pred_new.size(): torch.Size([3364, 42808])
pred_new.size(): torch.Size([1258, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([2484, 42808])
pred_new.size(): torch.Size([4428, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.44864499999999996
num_accepted / total 38 96
loss token level: tensor(8848.5449, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5280, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1850, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.449132
num_accepted / total 69 128
loss token level: tensor(9528.2188, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7744., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([816, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([868, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([7616, 42808])
ter_threshold: 0.449698
num_accepted / total 37 80
loss token level: tensor(8534.1855, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6588., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5031, 42808])
pred_new.size(): torch.Size([3172, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([2392, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([7560, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.4504
num_accepted / total 6 32
loss token level: tensor(8228.8379, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4568., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1025, 42808])
ter_threshold: 0.45055999999999996
num_accepted / total 67 112
loss token level: tensor(9049.9863, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13952., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.450652
num_accepted / total 34 96
loss token level: tensor(9630.0918, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4920., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2520, 42808])
ter_threshold: 0.450909
num_accepted / total 69 136
loss token level: tensor(9752.7715, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7172., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.451128
num_accepted / total 11 48
loss token level: tensor(8192.5869, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5304., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.451173
num_accepted / total 9 56
loss token level: tensor(10634.9043, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4248., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([5405, 42808])
pred_new.size(): torch.Size([4000, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.451835
num_accepted / total 78 160
2023-09-23 12:38:41 | INFO | train_inner | epoch 017:   6973 / 9060 loss=7.05, nll_loss=3.475, ppl=11.12, wps=4381.2, ups=0.34, wpb=13039.7, bsz=454, num_updates=151900, lr=8.11374e-05, gnorm=1.011, loss_scale=4, train_wall=297, gb_free=13.6, wall=266314
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([5782, 42808])
2023-09-23 12:43:33 | INFO | train_inner | epoch 017:   7073 / 9060 loss=7.081, nll_loss=3.5, ppl=11.31, wps=4449.1, ups=0.34, wpb=13005.8, bsz=440.3, num_updates=152000, lr=8.11107e-05, gnorm=1.005, loss_scale=4, train_wall=292, gb_free=13.6, wall=266607
2023-09-23 12:48:14 | INFO | train_inner | epoch 017:   7173 / 9060 loss=6.956, nll_loss=3.423, ppl=10.72, wps=4616.2, ups=0.36, wpb=12983, bsz=440.8, num_updates=152100, lr=8.1084e-05, gnorm=1.006, loss_scale=4, train_wall=281, gb_free=15, wall=266888
pred_new.size(): torch.Size([7038, 42808])
2023-09-23 12:52:48 | INFO | train_inner | epoch 017:   7273 / 9060 loss=7.035, nll_loss=3.485, ppl=11.2, wps=4739.6, ups=0.37, wpb=12982.1, bsz=427.2, num_updates=152200, lr=8.10574e-05, gnorm=1.01, loss_scale=4, train_wall=274, gb_free=13.8, wall=267162
ter_threshold: 0.452206
num_accepted / total 22 72
loss token level: tensor(10252.0977, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7988., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([2728, 42808])
2023-09-23 12:57:25 | INFO | train_inner | epoch 017:   7373 / 9060 loss=7.131, nll_loss=3.5, ppl=11.32, wps=4731.2, ups=0.36, wpb=13092.6, bsz=418.5, num_updates=152300, lr=8.10308e-05, gnorm=1.006, loss_scale=4, train_wall=276, gb_free=14, wall=267438
pred_new.size(): torch.Size([1476, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-23 13:02:26 | INFO | train_inner | epoch 017:   7473 / 9060 loss=7.156, nll_loss=3.541, ppl=11.64, wps=4316.2, ups=0.33, wpb=12976.4, bsz=426.1, num_updates=152400, lr=8.10042e-05, gnorm=1.041, loss_scale=4, train_wall=300, gb_free=15.1, wall=267739
ter_threshold: 0.452428
num_accepted / total 32 80
loss token level: tensor(8477.3984, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5520., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4452, 42808])
2023-09-23 13:07:12 | INFO | train_inner | epoch 017:   7573 / 9060 loss=6.956, nll_loss=3.461, ppl=11.02, wps=4555.6, ups=0.35, wpb=13029.2, bsz=422.6, num_updates=152500, lr=8.09776e-05, gnorm=1.002, loss_scale=4, train_wall=286, gb_free=14.3, wall=268025
2023-09-23 13:12:03 | INFO | train_inner | epoch 017:   7673 / 9060 loss=7.023, nll_loss=3.47, ppl=11.08, wps=4436.6, ups=0.34, wpb=12930.6, bsz=426.2, num_updates=152600, lr=8.09511e-05, gnorm=1.029, loss_scale=4, train_wall=291, gb_free=14.1, wall=268317
2023-09-23 13:16:49 | INFO | train_inner | epoch 017:   7773 / 9060 loss=7.12, nll_loss=3.503, ppl=11.34, wps=4541.9, ups=0.35, wpb=12969.9, bsz=435, num_updates=152700, lr=8.09246e-05, gnorm=1.033, loss_scale=4, train_wall=285, gb_free=14.3, wall=268602
pred_new.size(): torch.Size([6125, 42808])
2023-09-23 13:21:18 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-23 13:21:43 | INFO | train_inner | epoch 017:   7874 / 9060 loss=6.983, nll_loss=3.457, ppl=10.98, wps=4409.3, ups=0.34, wpb=12995.2, bsz=403.6, num_updates=152800, lr=8.08981e-05, gnorm=0.998, loss_scale=2, train_wall=294, gb_free=13.4, wall=268897
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3328, 42808])
2023-09-23 13:26:27 | INFO | train_inner | epoch 017:   7974 / 9060 loss=7.071, nll_loss=3.49, ppl=11.24, wps=4535.3, ups=0.35, wpb=12843.9, bsz=432.1, num_updates=152900, lr=8.08716e-05, gnorm=1.027, loss_scale=2, train_wall=283, gb_free=14.1, wall=269180
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-23 13:31:13 | INFO | train_inner | epoch 017:   8074 / 9060 loss=7.083, nll_loss=3.482, ppl=11.17, wps=4557.8, ups=0.35, wpb=13044.2, bsz=422.9, num_updates=153000, lr=8.08452e-05, gnorm=1.023, loss_scale=2, train_wall=286, gb_free=13.8, wall=269466
lprobs.size(): torch.Size([2880, 42808])
2023-09-23 13:35:41 | INFO | train_inner | epoch 017:   8174 / 9060 loss=7.183, nll_loss=3.521, ppl=11.48, wps=4885.9, ups=0.37, wpb=13103.2, bsz=452.6, num_updates=153100, lr=8.08188e-05, gnorm=1.012, loss_scale=2, train_wall=268, gb_free=14.4, wall=269734
2023-09-23 13:40:15 | INFO | train_inner | epoch 017:   8274 / 9060 loss=7.172, nll_loss=3.554, ppl=11.74, wps=4749.5, ups=0.37, wpb=13005.7, bsz=410.3, num_updates=153200, lr=8.07924e-05, gnorm=1.029, loss_scale=2, train_wall=274, gb_free=14.2, wall=270008
2023-09-23 13:45:00 | INFO | train_inner | epoch 017:   8374 / 9060 loss=7.099, nll_loss=3.522, ppl=11.49, wps=4576.2, ups=0.35, wpb=13031.1, bsz=452.4, num_updates=153300, lr=8.07661e-05, gnorm=1.008, loss_scale=2, train_wall=285, gb_free=13.3, wall=270293
2023-09-23 13:49:34 | INFO | train_inner | epoch 017:   8474 / 9060 loss=7.133, nll_loss=3.514, ppl=11.42, wps=4731.7, ups=0.36, wpb=12988.7, bsz=420.7, num_updates=153400, lr=8.07397e-05, gnorm=1.024, loss_scale=2, train_wall=274, gb_free=12.9, wall=270567
2023-09-23 13:54:02 | INFO | train_inner | epoch 017:   8574 / 9060 loss=7.006, nll_loss=3.431, ppl=10.79, wps=4826.8, ups=0.37, wpb=12949.3, bsz=446, num_updates=153500, lr=8.07134e-05, gnorm=1.004, loss_scale=2, train_wall=268, gb_free=13.2, wall=270836
pred_new.size(): torch.Size([3915, 42808])
2023-09-23 13:58:34 | INFO | train_inner | epoch 017:   8674 / 9060 loss=7.07, nll_loss=3.48, ppl=11.15, wps=4791.3, ups=0.37, wpb=13040.4, bsz=463, num_updates=153600, lr=8.06872e-05, gnorm=1.017, loss_scale=2, train_wall=272, gb_free=14, wall=271108
2023-09-23 14:02:50 | INFO | train_inner | epoch 017:   8774 / 9060 loss=6.996, nll_loss=3.451, ppl=10.94, wps=5096.9, ups=0.39, wpb=13014.2, bsz=440.2, num_updates=153700, lr=8.06609e-05, gnorm=0.989, loss_scale=2, train_wall=255, gb_free=13.3, wall=271363
pred_new.size(): torch.Size([6475, 42808])
2023-09-23 14:07:02 | INFO | train_inner | epoch 017:   8874 / 9060 loss=7.05, nll_loss=3.483, ppl=11.18, wps=5130.2, ups=0.4, wpb=12960.6, bsz=437.3, num_updates=153800, lr=8.06347e-05, gnorm=0.996, loss_scale=2, train_wall=252, gb_free=13.8, wall=271616
pred_new.size(): torch.Size([3588, 42808])
2023-09-23 14:11:29 | INFO | train_inner | epoch 017:   8974 / 9060 loss=7.072, nll_loss=3.471, ppl=11.09, wps=4919, ups=0.38, wpb=13091.2, bsz=453, num_updates=153900, lr=8.06085e-05, gnorm=0.993, loss_scale=2, train_wall=266, gb_free=13.2, wall=271882
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([6090, 42808])
pred_new.size(): torch.Size([1092, 42808])
lprobs.size(): torch.Size([2640, 42808])
2023-09-23 14:15:23 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-23 14:15:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 14:15:23 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-23 14:15:23 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-23 14:15:24 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher voll und ganz gerechtfertigt.
2023-09-23 14:15:24 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-23 14:15:24 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-23 14:15:24 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-23 14:15:25 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-23 14:15:25 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-23 14:15:25 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-23 14:15:25 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-23 14:15:26 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein Erfolg.
2023-09-23 14:15:26 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-23 14:15:27 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-23 14:15:27 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-23 14:15:27 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Initiativmonopol, das wir respektieren.
2023-09-23 14:15:27 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-23 14:15:28 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chat-Diskussionen.
2023-09-23 14:15:28 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-23 14:15:28 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über einen digitalen TV und Internetzugang, der sowohl für Geschäftsreisende als auch für Urlauber geeignet ist.
2023-09-23 14:15:28 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-23 14:15:29 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-23 14:15:29 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-23 14:15:29 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 14:15:29 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 14:15:30 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU enorme Mengen Energie verschwendet.
2023-09-23 14:15:30 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-23 14:15:30 | INFO | fairseq.tasks.translation | example hypothesis: Das Deutsche Linux Magazin enthält einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner aktuellen Nummer.
2023-09-23 14:15:30 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
lprobs.size(): torch.Size([2992, 42808])
2023-09-23 14:15:31 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Haltungsänderung auch in Kürze im Haushalt der Union niederschlagen.
2023-09-23 14:15:31 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-23 14:15:32 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-23 14:15:32 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-23 14:15:32 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-23 14:15:32 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-23 14:15:33 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-23 14:15:33 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-23 14:15:33 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie sich gewünscht hätten?
2023-09-23 14:15:33 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-23 14:15:34 | INFO | fairseq.tasks.translation | example hypothesis: Der größte Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-23 14:15:34 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-23 14:15:34 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-23 14:15:34 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-23 14:15:35 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-23 14:15:35 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-23 14:15:35 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Organs sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-23 14:15:35 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-23 14:15:36 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu bringen, sich um die Qualität Ihrer Dienstleistungen und Produkte zu machen.
2023-09-23 14:15:36 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-23 14:15:37 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-23 14:15:37 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-23 14:15:37 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-23 14:15:37 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-23 14:15:38 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Debatte, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 14:15:38 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 14:15:39 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in einem Umkreis von etwa 8 km vom Strip entfernt.
2023-09-23 14:15:39 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-23 14:15:39 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem bekannten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-23 14:15:39 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-23 14:15:40 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! akustisch, interaktiv oder schriftlich die Umsetzung von Klanghandbüchern an.
2023-09-23 14:15:40 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-23 14:15:40 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-23 14:15:40 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-23 14:15:41 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer inneren Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu gewährleisten.
2023-09-23 14:15:41 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-23 14:15:42 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu dem von ihnen bezahlten Geld in die europäischen Sozialversicherungssysteme haben.
2023-09-23 14:15:42 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-23 14:15:42 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet die Ascent Ti-Modell als Basis.
2023-09-23 14:15:42 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-23 14:15:43 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-23 14:15:43 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-23 14:15:44 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-23 14:15:44 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-23 14:15:44 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind die Thatcher-Ideen über geringere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv zentrale Teile seiner Agenda.
2023-09-23 14:15:44 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-23 14:15:45 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-23 14:15:45 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-23 14:15:45 | INFO | fairseq.tasks.translation | example hypothesis: Horde und Allianzspieler können keine Gegenstände kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser nutzen.
2023-09-23 14:15:45 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-23 14:15:46 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-23 14:15:46 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-23 14:15:47 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-23 14:15:47 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-23 14:15:47 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag der Kommission sieht vor, daß der Rat formelle Standpunkte zu bestimmten Details des Abkommens mit den Vereinigten Staaten abgeben muß.
2023-09-23 14:15:47 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-23 14:15:48 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderauflage - unser breites Angebot an Plastik-Babyartikeln ist beeindruckend, nicht zuletzt wegen seiner hervorragenden Verarbeitung.
2023-09-23 14:15:48 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-23 14:15:49 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 14:15:49 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 14:15:49 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Bekanntwerden dieser AGB über sachliche Sachverhalte zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-23 14:15:49 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-23 14:15:50 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz auf dem Gebiet der Außenpolitik und Verteidigung erfordert.
2023-09-23 14:15:50 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-23 14:15:51 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-23 14:15:51 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-23 14:15:51 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Prüfung aller Themen erzielt wurden, die jetzt diskutiert werden, und die etwas betreffen, das gerade zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-23 14:15:51 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-23 14:15:52 | INFO | fairseq.tasks.translation | example hypothesis: BILSTEIN B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Dämpfern für erstklassigen Spaß am Rad.
2023-09-23 14:15:52 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-23 14:15:53 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal war der Berichterstatter in der Lage, gelegentlich unterschiedliche Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 14:15:53 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 14:15:53 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm der trockenen elektrostatischen Niederschläge um einen trockenen ESP für den unteren Leistungsbereich.
2023-09-23 14:15:53 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-23 14:15:54 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-23 14:15:54 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-23 14:15:55 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-23 14:15:55 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-23 14:15:55 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und mit unserer Völkergemeinschaft zusammenhängen.
2023-09-23 14:15:55 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-23 14:15:56 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-23 14:15:56 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-23 14:15:57 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht der Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-23 14:15:57 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-23 14:15:57 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Anzahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-23 14:15:57 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-23 14:15:58 | INFO | fairseq.tasks.translation | example hypothesis: Im Rahmen dieser Notlage gibt es jedoch noch eine andere: die Notlage der Kinder, des schwächsten BevölkerungsBevölkerung, die ohne Familie, ohne Schutz und ohne Staat zurückgelassen wurde.
2023-09-23 14:15:58 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-23 14:15:59 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-23 14:15:59 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-23 14:15:59 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, erst nicht verwirklicht ist, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, bis man sein wahres Selbst kennt.
2023-09-23 14:15:59 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-23 14:16:00 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, um alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Wählerregistrierung wieder zu eröffnen.
2023-09-23 14:16:00 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-23 14:16:01 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgerinnen und Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit deutlich gemacht werden, dass niemand über dem Gesetz steht....................
2023-09-23 14:16:01 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-23 14:16:01 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-23 14:16:01 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-23 14:16:02 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für die Klärung des Anhangs.
2023-09-23 14:16:02 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-23 14:16:03 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist ferner der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen haben, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-23 14:16:03 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-23 14:16:04 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische öffentlich-rechtliche Radio RTE mit einer Frau teilgenommen, die sehr besorgt war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen..................
2023-09-23 14:16:04 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-23 14:16:04 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-23 14:16:04 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-23 14:16:05 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie nach Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas Spezielles wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-23 14:16:05 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-23 14:16:06 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und steht Spielern aller Nationalitäten offen.
2023-09-23 14:16:06 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-23 14:16:07 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-23 14:16:07 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-23 14:16:08 | INFO | fairseq.tasks.translation | example hypothesis: Anders zu denken, hieße, eine bestimmte Art von Vertragsverhältnis zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen häufig die tatsächliche oder wahrgenommene Drohung, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-23 14:16:08 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-23 14:16:08 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-23 14:16:08 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-23 14:16:09 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Autos, die man für weniger als 50.000 $fahren kann, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.....................
2023-09-23 14:16:09 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-23 14:16:10 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung dieser Angelegenheit.
2023-09-23 14:16:10 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-23 14:16:11 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrilltes Hecht, Forelle mit Mandeln.
2023-09-23 14:16:11 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-23 14:16:12 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, einen Gesamtüberblick zu geben, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft erhalten kann.
2023-09-23 14:16:12 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-23 14:16:12 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber der "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-23 14:16:12 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-23 14:16:13 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar gefährdet sind und die Wettbewerbsfähigkeit aufgrund der makroökonomischen Politik, der steuerlichen Maßnahmen und Zwänge, die nicht an die gegenwärtige Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-23 14:16:13 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-23 14:16:14 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die geltende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-23 14:16:14 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-23 14:16:15 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den rechtlichen und juristischen Bereich, wodurch Norwegen und Island, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsvorschriften gelten werden, zu......................
2023-09-23 14:16:15 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-23 14:16:16 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schwenkboot hinunter den Mississippi fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein......................
2023-09-23 14:16:16 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-23 14:16:16 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder Rechtspersonen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion und die Strafbarkeit der Sanktionen, die im Falle solcher Verstöße von Personen angewendet werden können.
2023-09-23 14:16:16 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-23 14:16:17 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falized und Vincent Reynaud wurden in der Tat verurteilt, weil sie ihre Arbeit als Journalisten und Kameramänner verübt und eine Gruppe von Bergleuten gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das sich über jeden Grundsatz der Demokratie hinwegsetzt.
2023-09-23 14:16:17 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-23 14:16:18 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen ein Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeingschalter, ein Mening- und Presseservice, eine Wechselstube, kostenfreie Schuhputzmaschine und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das Französische Viertel.
2023-09-23 14:16:18 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-23 14:16:19 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der von Königin D. Leonor, der Frau von König D. João II., geliebten Thermalquelle verdankt, und bekannt durch ihre Keramiken, die international für ihre figurativen und satirischen Werke bekannt sind, ist auch einen Besuch wert.
2023-09-23 14:16:19 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-23 14:16:20 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute Pro-Westler auf der einen Seite und Anhänger des früheren Regimes auf der anderen Seite handelt - das ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-23 14:16:20 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-23 14:16:21 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die unterschiedslos zwischen Flüssen und Meer fahren, nicht auf diese Weise erfasst werden, und dies ist sicherlich ein Punkt, der irgendwie berücksichtigt werden sollte.
2023-09-23 14:16:21 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-23 14:16:22 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär Informationen zur Verfügung gestellt, so werden diese auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn solche Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-23 14:16:22 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-23 14:16:22 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme gesteckt werden, die normalerweise in den Taschen verschiedener Diktatoren landen und ihren schönen Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.
2023-09-23 14:16:22 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-23 14:16:23 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder die NATO an diesem Kriegsakt beteiligt hätten -, mit Informationen zu helfen, die es keinen Grund mehr gibt, geheim, versteckt oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann..........................
2023-09-23 14:16:23 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-23 14:16:24 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Bezirk Reinickendorf liegt 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 14:16:24 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 14:16:25 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radargerät unter der Leitung von Thales in Frankreich sowie unserer Geschäftseinheit Defence Electronics und Indra in Spanien wird die Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen, die die heutigen außerhalb des Regals befindlichen Plattformen nie erreichen können, unerlässlich sind. die heute nicht mehr erreicht werden können.
2023-09-23 14:16:25 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-23 14:16:26 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir nicht nur für uns, sondern weltweit aus dem Markt nehmen können, die Produkte, die nicht nur für den Inlandsverbrauch, sondern auch auf dem globalen Markt eine große Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt................. Frau González Álvarez sagte in ihrem neuen Änderungsantrag 13.....
2023-09-23 14:16:26 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-23 14:16:27 | INFO | fairseq.tasks.translation | example hypothesis: Unter der einfachen Verschwörung von Moderne und Postmoderne oder der klaren Opposition von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung jener beiden ästhetischen Politiken anerkennen, die in die Formen der Sichtbarkeit und Verständlichkeit vergehen, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.............................
2023-09-23 14:16:27 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-23 14:16:28 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Aussprachen und angesichts der Stellungnahmen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen unsere Aussprachen führen, und bei der Abstimmung, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht um die Prüfung der Beschlussfähigkeit beantragen........................... - Was die Aussprache betrifft, so werden Sie mir jedoch in Anbetracht der Bedeutung der
2023-09-23 14:16:28 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-23 14:16:29 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips nie akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum jemand bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem nationale Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.........................
2023-09-23 14:16:29 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-23 14:16:30 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 mehrfach als hybride Form veröffentlicht, die Rezensionen und Artikel des vierteljährlich erscheinenden Magazins sind für H-Soz-u-Kult verfasst und über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt.
2023-09-23 14:16:30 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-23 14:16:31 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Einführung der neuen Smartphone-Generation haben Mobiltelefone ihre Federn deutlich verfeinert und sich von einst blutigen Taschenalarm-Uhren über polyphonisch tootelnde Game Boy-Ambitionen auf MiniPCs mit knackig CD-Qualität Stereo-Sound gegossen: Künftig könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen entwickeln........
2023-09-23 14:16:31 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-23 14:16:33 | INFO | fairseq.tasks.translation | example hypothesis: En un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un konfliarmado; en l dedir de dedir de quado está.
2023-09-23 14:16:33 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-23 14:16:34 | INFO | valid | epoch 017 | valid on 'valid' subset | loss 4.146 | nll_loss 2.176 | ppl 4.52 | bleu 28.34 | wps 16642.1 | wpb 12011.9 | bsz 398.1 | num_updates 153986 | best_bleu 29.48
2023-09-23 14:16:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 153986 updates
2023-09-23 14:16:34 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint17.pt
2023-09-23 14:16:41 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint17.pt
2023-09-23 14:16:45 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint17.pt (epoch 17 @ 153986 updates, score 28.34) (writing took 10.669775296002626 seconds)
2023-09-23 14:16:45 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2023-09-23 14:16:45 | INFO | train | epoch 017 | loss 7.032 | nll_loss 3.461 | ppl 11.01 | wps 4570 | ups 0.35 | wpb 12977.2 | bsz 430.6 | num_updates 153986 | lr 8.0586e-05 | gnorm 1.01 | loss_scale 2 | train_wall 25613 | gb_free 14.1 | wall 272198
2023-09-23 14:16:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 14:16:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-23 14:16:45 | INFO | fairseq.trainer | begin training epoch 18
2023-09-23 14:16:45 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-23 14:17:23 | INFO | train_inner | epoch 018:     14 / 9060 loss=6.894, nll_loss=3.408, ppl=10.62, wps=3614.8, ups=0.28, wpb=12806.6, bsz=429.3, num_updates=154000, lr=8.05823e-05, gnorm=1.014, loss_scale=2, train_wall=272, gb_free=14.9, wall=272236
2023-09-23 14:22:02 | INFO | train_inner | epoch 018:    114 / 9060 loss=7.139, nll_loss=3.485, ppl=11.2, wps=4632, ups=0.36, wpb=12912.2, bsz=426.4, num_updates=154100, lr=8.05561e-05, gnorm=1.044, loss_scale=2, train_wall=279, gb_free=13.1, wall=272515
pred_new.size(): torch.Size([2320, 42808])
2023-09-23 14:26:46 | INFO | train_inner | epoch 018:    214 / 9060 loss=7.072, nll_loss=3.465, ppl=11.04, wps=4558.5, ups=0.35, wpb=12955, bsz=414.6, num_updates=154200, lr=8.053e-05, gnorm=1.009, loss_scale=2, train_wall=284, gb_free=14.3, wall=272799
lprobs.size(): torch.Size([2800, 42808])
2023-09-23 14:31:36 | INFO | train_inner | epoch 018:    314 / 9060 loss=7.048, nll_loss=3.431, ppl=10.79, wps=4473.8, ups=0.35, wpb=12963.5, bsz=433.9, num_updates=154300, lr=8.05039e-05, gnorm=1.03, loss_scale=2, train_wall=290, gb_free=13.8, wall=273089
lprobs.size(): torch.Size([3288, 42808])
2023-09-23 14:36:02 | INFO | train_inner | epoch 018:    414 / 9060 loss=7.157, nll_loss=3.511, ppl=11.4, wps=4866.5, ups=0.38, wpb=12956.6, bsz=432, num_updates=154400, lr=8.04778e-05, gnorm=1.04, loss_scale=2, train_wall=266, gb_free=14.6, wall=273355
pred_new.size(): torch.Size([4836, 42808])
pred_new.size(): torch.Size([160, 42808])
2023-09-23 14:40:39 | INFO | train_inner | epoch 018:    514 / 9060 loss=7.2, nll_loss=3.526, ppl=11.52, wps=4686.9, ups=0.36, wpb=12993.9, bsz=440.1, num_updates=154500, lr=8.04518e-05, gnorm=1.027, loss_scale=2, train_wall=277, gb_free=14.6, wall=273633
2023-09-23 14:45:05 | INFO | train_inner | epoch 018:    614 / 9060 loss=6.945, nll_loss=3.408, ppl=10.61, wps=4866.1, ups=0.38, wpb=12944.1, bsz=451.8, num_updates=154600, lr=8.04258e-05, gnorm=1.007, loss_scale=2, train_wall=266, gb_free=13, wall=273899
ter_threshold: 0.454616
num_accepted / total 7 40
loss token level: tensor(8670.4590, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2476., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([550, 42808])
2023-09-23 14:49:35 | INFO | train_inner | epoch 018:    714 / 9060 loss=6.916, nll_loss=3.388, ppl=10.47, wps=4805.3, ups=0.37, wpb=12971.6, bsz=427.4, num_updates=154700, lr=8.03998e-05, gnorm=1.003, loss_scale=2, train_wall=270, gb_free=12.8, wall=274168
2023-09-23 14:54:05 | INFO | train_inner | epoch 018:    814 / 9060 loss=7.058, nll_loss=3.441, ppl=10.86, wps=4797.4, ups=0.37, wpb=12949, bsz=433, num_updates=154800, lr=8.03738e-05, gnorm=1.039, loss_scale=2, train_wall=270, gb_free=14.4, wall=274438
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([7770, 42808])
pred_new.size(): torch.Size([3000, 42808])
2023-09-23 14:58:26 | INFO | train_inner | epoch 018:    914 / 9060 loss=7.135, nll_loss=3.455, ppl=10.97, wps=4987.5, ups=0.38, wpb=13032.2, bsz=451.7, num_updates=154900, lr=8.03479e-05, gnorm=1.007, loss_scale=2, train_wall=261, gb_free=13.9, wall=274700
lprobs.size(): torch.Size([3520, 42808])
2023-09-23 15:02:58 | INFO | train_inner | epoch 018:   1014 / 9060 loss=7.154, nll_loss=3.48, ppl=11.15, wps=4796.2, ups=0.37, wpb=13030.1, bsz=464, num_updates=155000, lr=8.03219e-05, gnorm=1.037, loss_scale=2, train_wall=271, gb_free=13.8, wall=274971
2023-09-23 15:07:31 | INFO | train_inner | epoch 018:   1114 / 9060 loss=7.049, nll_loss=3.45, ppl=10.93, wps=4756.3, ups=0.37, wpb=12976.9, bsz=429, num_updates=155100, lr=8.0296e-05, gnorm=1.029, loss_scale=2, train_wall=273, gb_free=14.8, wall=275244
ter_threshold: 0.45509999999999995
num_accepted / total 87 136
loss token level: tensor(9168.0059, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9136., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 15:12:05 | INFO | train_inner | epoch 018:   1214 / 9060 loss=7.17, nll_loss=3.508, ppl=11.38, wps=4701.9, ups=0.37, wpb=12874.8, bsz=442.4, num_updates=155200, lr=8.02702e-05, gnorm=1.051, loss_scale=2, train_wall=274, gb_free=15, wall=275518
lprobs.size(): torch.Size([3296, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3120, 42808])
2023-09-23 15:16:37 | INFO | train_inner | epoch 018:   1314 / 9060 loss=7.104, nll_loss=3.503, ppl=11.34, wps=4787.4, ups=0.37, wpb=13021.9, bsz=434.6, num_updates=155300, lr=8.02443e-05, gnorm=1.012, loss_scale=2, train_wall=272, gb_free=13.9, wall=275790
lprobs.size(): torch.Size([3360, 42808])
2023-09-23 15:21:11 | INFO | train_inner | epoch 018:   1414 / 9060 loss=7.17, nll_loss=3.498, ppl=11.3, wps=4758.7, ups=0.36, wpb=13062.7, bsz=446.5, num_updates=155400, lr=8.02185e-05, gnorm=1.055, loss_scale=2, train_wall=274, gb_free=13.2, wall=276065
pred_new.size(): torch.Size([4719, 42808])
pred_new.size(): torch.Size([2754, 42808])
pred_new.size(): torch.Size([6048, 42808])
lprobs.size(): torch.Size([3104, 42808])
2023-09-23 15:25:44 | INFO | train_inner | epoch 018:   1514 / 9060 loss=7.09, nll_loss=3.473, ppl=11.11, wps=4753.2, ups=0.37, wpb=12978.4, bsz=421.3, num_updates=155500, lr=8.01927e-05, gnorm=1.046, loss_scale=2, train_wall=273, gb_free=13.4, wall=276338
pred_new.size(): torch.Size([3348, 42808])
2023-09-23 15:30:10 | INFO | train_inner | epoch 018:   1614 / 9060 loss=7.101, nll_loss=3.508, ppl=11.37, wps=4877.4, ups=0.38, wpb=12985.1, bsz=431.9, num_updates=155600, lr=8.01669e-05, gnorm=1.012, loss_scale=2, train_wall=266, gb_free=14.2, wall=276604
lprobs.size(): torch.Size([2544, 42808])
2023-09-23 15:34:53 | INFO | train_inner | epoch 018:   1714 / 9060 loss=7.069, nll_loss=3.448, ppl=10.91, wps=4574.8, ups=0.35, wpb=12948.3, bsz=434.6, num_updates=155700, lr=8.01412e-05, gnorm=1.014, loss_scale=2, train_wall=283, gb_free=15, wall=276887
pred_new.size(): torch.Size([5500, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1485, 42808])
2023-09-23 15:39:47 | INFO | train_inner | epoch 018:   1814 / 9060 loss=7.07, nll_loss=3.459, ppl=11, wps=4435.1, ups=0.34, wpb=13030.5, bsz=432, num_updates=155800, lr=8.01154e-05, gnorm=1.028, loss_scale=2, train_wall=294, gb_free=14, wall=277181
2023-09-23 15:44:23 | INFO | train_inner | epoch 018:   1914 / 9060 loss=7.103, nll_loss=3.487, ppl=11.21, wps=4720.3, ups=0.36, wpb=13007.7, bsz=429.9, num_updates=155900, lr=8.00898e-05, gnorm=1.019, loss_scale=2, train_wall=275, gb_free=15.6, wall=277456
2023-09-23 15:49:03 | INFO | train_inner | epoch 018:   2014 / 9060 loss=7.183, nll_loss=3.525, ppl=11.51, wps=4629.4, ups=0.36, wpb=12975.9, bsz=421.3, num_updates=156000, lr=8.00641e-05, gnorm=1.038, loss_scale=2, train_wall=280, gb_free=15.2, wall=277737
2023-09-23 15:53:43 | INFO | train_inner | epoch 018:   2114 / 9060 loss=7.138, nll_loss=3.522, ppl=11.49, wps=4635.2, ups=0.36, wpb=12987.1, bsz=443, num_updates=156100, lr=8.00384e-05, gnorm=1.03, loss_scale=2, train_wall=280, gb_free=14.1, wall=278017
2023-09-23 15:58:23 | INFO | train_inner | epoch 018:   2214 / 9060 loss=7.175, nll_loss=3.528, ppl=11.53, wps=4639.3, ups=0.36, wpb=12985, bsz=426.2, num_updates=156200, lr=8.00128e-05, gnorm=1.065, loss_scale=2, train_wall=280, gb_free=14.1, wall=278297
ter_threshold: 0.456206
num_accepted / total 4 32
loss token level: tensor(8601.4844, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2692., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
2023-09-23 16:03:01 | INFO | train_inner | epoch 018:   2314 / 9060 loss=7.056, nll_loss=3.477, ppl=11.14, wps=4679.8, ups=0.36, wpb=12995.2, bsz=427.5, num_updates=156300, lr=7.99872e-05, gnorm=1.025, loss_scale=2, train_wall=277, gb_free=12.5, wall=278574
pred_new.size(): torch.Size([2964, 42808])
2023-09-23 16:07:53 | INFO | train_inner | epoch 018:   2414 / 9060 loss=7.172, nll_loss=3.491, ppl=11.24, wps=4456.1, ups=0.34, wpb=13039.9, bsz=436, num_updates=156400, lr=7.99616e-05, gnorm=1.033, loss_scale=2, train_wall=292, gb_free=14.6, wall=278867
2023-09-23 16:12:37 | INFO | train_inner | epoch 018:   2514 / 9060 loss=7.166, nll_loss=3.509, ppl=11.39, wps=4588.8, ups=0.35, wpb=12991.9, bsz=436.8, num_updates=156500, lr=7.99361e-05, gnorm=1.061, loss_scale=2, train_wall=283, gb_free=14.6, wall=279150
pred_new.size(): torch.Size([1748, 42808])
lprobs.size(): torch.Size([3256, 42808])
ter_threshold: 0.45659099999999997
num_accepted / total 46 120
loss token level: tensor(9915.6953, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5328., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 16:17:16 | INFO | train_inner | epoch 018:   2614 / 9060 loss=6.973, nll_loss=3.421, ppl=10.71, wps=4668.6, ups=0.36, wpb=13029.5, bsz=414, num_updates=156600, lr=7.99106e-05, gnorm=1.001, loss_scale=2, train_wall=279, gb_free=14.5, wall=279429
pred_new.size(): torch.Size([5500, 42808])
pred_new.size(): torch.Size([6750, 42808])
2023-09-23 16:22:02 | INFO | train_inner | epoch 018:   2714 / 9060 loss=6.927, nll_loss=3.394, ppl=10.51, wps=4528.5, ups=0.35, wpb=12969.2, bsz=409.4, num_updates=156700, lr=7.9885e-05, gnorm=1.013, loss_scale=2, train_wall=286, gb_free=14.9, wall=279716
2023-09-23 16:26:49 | INFO | train_inner | epoch 018:   2814 / 9060 loss=7.048, nll_loss=3.452, ppl=10.94, wps=4536, ups=0.35, wpb=13003.8, bsz=430.6, num_updates=156800, lr=7.98596e-05, gnorm=1.024, loss_scale=2, train_wall=286, gb_free=13.7, wall=280002
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.456866
num_accepted / total 2 48
loss token level: tensor(8992.6436, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(752., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2736, 42808])
2023-09-23 16:31:37 | INFO | train_inner | epoch 018:   2914 / 9060 loss=7.105, nll_loss=3.48, ppl=11.16, wps=4488.2, ups=0.35, wpb=12944.7, bsz=434.1, num_updates=156900, lr=7.98341e-05, gnorm=1.027, loss_scale=4, train_wall=288, gb_free=15.4, wall=280291
pred_new.size(): torch.Size([4848, 42808])
lprobs.size(): torch.Size([2920, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-23 16:36:43 | INFO | train_inner | epoch 018:   3014 / 9060 loss=7.081, nll_loss=3.473, ppl=11.11, wps=4250.8, ups=0.33, wpb=12980.2, bsz=410.6, num_updates=157000, lr=7.98087e-05, gnorm=1.03, loss_scale=4, train_wall=305, gb_free=14.3, wall=280596
2023-09-23 16:41:35 | INFO | train_inner | epoch 018:   3114 / 9060 loss=7.123, nll_loss=3.501, ppl=11.32, wps=4453.8, ups=0.34, wpb=13014.3, bsz=436.6, num_updates=157100, lr=7.97833e-05, gnorm=1.052, loss_scale=4, train_wall=292, gb_free=14.2, wall=280888
lprobs.size(): torch.Size([3520, 42808])
2023-09-23 16:46:33 | INFO | train_inner | epoch 018:   3214 / 9060 loss=7.224, nll_loss=3.517, ppl=11.45, wps=4381.9, ups=0.34, wpb=13076, bsz=428.2, num_updates=157200, lr=7.97579e-05, gnorm=1.048, loss_scale=4, train_wall=298, gb_free=13.4, wall=281187
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2392, 42808])
ter_threshold: 0.457296
num_accepted / total 27 72
loss token level: tensor(8217.4102, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5104., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 16:51:12 | INFO | train_inner | epoch 018:   3314 / 9060 loss=7.064, nll_loss=3.51, ppl=11.39, wps=4632.1, ups=0.36, wpb=12908.6, bsz=437.8, num_updates=157300, lr=7.97325e-05, gnorm=1.032, loss_scale=4, train_wall=278, gb_free=14.6, wall=281465
pred_new.size(): torch.Size([7625, 42808])
pred_new.size(): torch.Size([3286, 42808])
pred_new.size(): torch.Size([2184, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-23 16:55:58 | INFO | train_inner | epoch 018:   3414 / 9060 loss=7.238, nll_loss=3.573, ppl=11.9, wps=4512.4, ups=0.35, wpb=12892.5, bsz=428.9, num_updates=157400, lr=7.97072e-05, gnorm=1.06, loss_scale=4, train_wall=285, gb_free=14, wall=281751
tensor(7712., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([8370, 42808])
pred_new.size(): torch.Size([3349, 42808])
ter_threshold: 0.45009299999999997
num_accepted / total 28 88
loss token level: tensor(7721.0674, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4096., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3416, 42808])
ter_threshold: 0.450265
num_accepted / total 18 56
loss token level: tensor(10604.1318, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5240., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2795, 42808])
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([5512, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.45072199999999996
num_accepted / total 23 80
loss token level: tensor(8482.3154, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6228., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([2442, 42808])
ter_threshold: 0.450909
num_accepted / total 156 224
loss token level: tensor(8540.4629, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9464., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([2200, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.451783
num_accepted / total 80 152
loss token level: tensor(8451.0820, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6664., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3072, 42808])
ter_threshold: 0.451835
num_accepted / total 12 88
loss token level: tensor(9198.3750, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1578., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5040, 42808])
pred_new.size(): torch.Size([4294, 42808])
ter_threshold: 0.45206199999999996
num_accepted / total 53 112
loss token level: tensor(10039.2158, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11600., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2862, 42808])
pred_new.size(): torch.Size([3225, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.452428
num_accepted / total 29 104
loss token level: tensor(11280.9531, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4050., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([5016, 42808])
lprobs.size(): torch.Size([3408, 42808])
ter_threshold: 0.452719
num_accepted / total 12 40
loss token level: tensor(9043.3613, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7244., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4680, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2254, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1330, 42808])
pred_new.size(): torch.Size([3588, 42808])
pred_new.size(): torch.Size([1710, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.453925
num_accepted / total 46 112
loss token level: tensor(9440.8711, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6336., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.45397699999999996
num_accepted / total 52 88
loss token level: tensor(8871.7207, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9120., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3408, 42808])
ter_threshold: 0.454118
num_accepted / total 107 192
loss token level: tensor(7923.7627, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6432., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2116, 42808])
pred_new.size(): torch.Size([3703, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([7345, 42808])
ter_threshold: 0.45483799999999996
num_accepted / total 97 152
loss token level: tensor(8517.7637, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14712., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4108, 42808])
pred_new.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([1748, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.45509999999999995
num_accepted / total 101 160
loss token level: tensor(8809.7471, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8640., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2304, 42808])
pred_new.size(): torch.Size([5220, 42808])
pred_new.size(): torch.Size([5670, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([4400, 42808])
pred_new.size(): torch.Size([5082, 42808])
ter_threshold: 0.456518
num_accepted / total 15 48
loss token level: tensor(9066.5117, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.45659099999999997
num_accepted / total 33 96
loss token level: tensor(9578.1113, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.456596
num_accepted / total 8 40
loss token level: tensor(9749.5264, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5236., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([7015, 42808])
ter_threshold: 0.456717
num_accepted / total 20 56
loss token level: tensor(9022.9043, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8768., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.456786
num_accepted / total 15 72
loss token level: tensor(8636.5996, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2920., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([9200, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.45710399999999995
num_accepted / total 87 168
loss token level: tensor(8561.9902, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6236., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2772, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([6090, 42808])
pred_new.size(): torch.Size([6270, 42808])
ter_threshold: 0.457418
num_accepted / total 19 80
loss token level: tensor(8072.1914, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: ter_threshold: 0.457418
num_accepted / total 41 96
loss token level: tensor(9483.3369, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10432., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1240, 42808])
2023-09-23 17:00:46 | INFO | train_inner | epoch 018:   3514 / 9060 loss=7.158, nll_loss=3.494, ppl=11.26, wps=4509.7, ups=0.35, wpb=12997.8, bsz=409.9, num_updates=157500, lr=7.96819e-05, gnorm=1.057, loss_scale=4, train_wall=288, gb_free=14.4, wall=282039
pred_new.size(): torch.Size([2160, 42808])
lprobs.size(): torch.Size([2880, 42808])
2023-09-23 17:05:23 | INFO | train_inner | epoch 018:   3614 / 9060 loss=7.095, nll_loss=3.499, ppl=11.31, wps=4667.3, ups=0.36, wpb=12958.1, bsz=439.2, num_updates=157600, lr=7.96566e-05, gnorm=1.039, loss_scale=4, train_wall=277, gb_free=13.7, wall=282317
2023-09-23 17:09:56 | INFO | train_inner | epoch 018:   3714 / 9060 loss=7.105, nll_loss=3.51, ppl=11.39, wps=4738.4, ups=0.37, wpb=12901.8, bsz=425.9, num_updates=157700, lr=7.96314e-05, gnorm=1.024, loss_scale=4, train_wall=272, gb_free=13.8, wall=282589
pred_new.size(): torch.Size([7020, 42808])
pred_new.size(): torch.Size([4539, 42808])
2023-09-23 17:14:24 | INFO | train_inner | epoch 018:   3814 / 9060 loss=7.069, nll_loss=3.484, ppl=11.19, wps=4843.9, ups=0.37, wpb=12993.1, bsz=411.9, num_updates=157800, lr=7.96061e-05, gnorm=1.036, loss_scale=4, train_wall=268, gb_free=13.5, wall=282857
pred_new.size(): torch.Size([5478, 42808])
2023-09-23 17:19:10 | INFO | train_inner | epoch 018:   3914 / 9060 loss=7.138, nll_loss=3.512, ppl=11.41, wps=4557.8, ups=0.35, wpb=13031.7, bsz=424.2, num_updates=157900, lr=7.95809e-05, gnorm=1.051, loss_scale=4, train_wall=286, gb_free=13.6, wall=283143
lprobs.size(): torch.Size([3456, 42808])
2023-09-23 17:24:10 | INFO | train_inner | epoch 018:   4014 / 9060 loss=7.263, nll_loss=3.542, ppl=11.65, wps=4312.3, ups=0.33, wpb=12946.1, bsz=419.8, num_updates=158000, lr=7.95557e-05, gnorm=1.076, loss_scale=4, train_wall=300, gb_free=15.2, wall=283444
2023-09-23 17:28:47 | INFO | train_inner | epoch 018:   4114 / 9060 loss=7.258, nll_loss=3.549, ppl=11.71, wps=4702.8, ups=0.36, wpb=13026.9, bsz=446.2, num_updates=158100, lr=7.95306e-05, gnorm=1.044, loss_scale=4, train_wall=277, gb_free=14.1, wall=283721
2023-09-23 17:33:39 | INFO | train_inner | epoch 018:   4214 / 9060 loss=7.174, nll_loss=3.525, ppl=11.51, wps=4467.2, ups=0.34, wpb=13058.1, bsz=427, num_updates=158200, lr=7.95054e-05, gnorm=1.048, loss_scale=4, train_wall=292, gb_free=14.2, wall=284013
2023-09-23 17:38:29 | INFO | train_inner | epoch 018:   4314 / 9060 loss=7.23, nll_loss=3.578, ppl=11.94, wps=4492.1, ups=0.35, wpb=13007, bsz=414.9, num_updates=158300, lr=7.94803e-05, gnorm=1.058, loss_scale=4, train_wall=289, gb_free=13.4, wall=284302
 torch.Size([6375, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([1020, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([8170, 42808])
ter_threshold: 0.45009299999999997
num_accepted / total 35 96
loss token level: tensor(9228.4141, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4884., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3024, 42808])
ter_threshold: 0.450411
num_accepted / total 1 32
loss token level: tensor(9095.8203, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(354.5000, device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.450508
num_accepted / total 20 72
loss token level: tensor(8523.3438, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6744., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2346, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.450542
num_accepted / total 66 112
loss token level: tensor(8537.2480, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13904., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.450652
num_accepted / total 70 136
loss token level: tensor(9206.0596, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6940., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4048, 42808])
ter_threshold: 0.450909
num_accepted / total 39 96
loss token level: tensor(9557.4404, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5912., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1530, 42808])
lprobs.size(): torch.Size([3120, 42808])
ter_threshold: 0.451173
num_accepted / total 16 64
loss token level: tensor(10940.1143, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6424., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1428, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([6834, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.451562
num_accepted / total 16 64
loss token level: tensor(9173.4111, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3484., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.451756
num_accepted / total 15 72
loss token level: tensor(9227.5596, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5168., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2255, 42808])
ter_threshold: 0.452109
num_accepted / total 51 136
loss token level: tensor(11675.5000, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8880., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5320, 42808])
pred_new.size(): torch.Size([2160, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([4599, 42808])
pred_new.size(): torch.Size([1386, 42808])
ter_threshold: 0.452457
num_accepted / total 15 56
loss token level: tensor(9686.0391, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6808., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3872, 42808])
pred_new.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6290, 42808])
ter_threshold: 0.452755
num_accepted / total 12 64
loss token level: tensor(9317.8555, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2752., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.452912
num_accepted / total 22 72
loss token level: tensor(9079.6230, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7840., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3048, 42808])
pred_new.size(): torch.Size([3100, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1440, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([5460, 42808])
pred_new.size(): torch.Size([4176, 42808])
pred_new.size(): torch.Size([5800, 42808])
pred_new.size(): torch.Size([840, 42808])
pred_new.size(): torch.Size([2100, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.453925
num_accepted / total 90 208
loss token level: tensor(10116.6426, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5640., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3420, 42808])
pred_new.size(): torch.Size([4872, 42808])
pred_new.size(): torch.Size([5250, 42808])
ter_threshold: 0.454504
num_accepted / total 8 32
loss token level: tensor(8918.6504, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3894., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.45453699999999997
num_accepted / total 40 80
loss token level: tensor(8453.4004, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12856., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3576, 42808])
pred_new.size(): torch.Size([4216, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3192, 42808])
ter_threshold: 0.455105
num_accepted / total 5 32
loss token level: tensor(8670.9990, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2310., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([5490, 42808])
pred_new.size(): torch.Size([2450, 42808])
pred_new.size(): torch.Size([6192, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([2772, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([3200, 42808])
ter_threshold: 0.456518
num_accepted / total 9 48
loss token level: tensor(10162.7920, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4248., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([6438, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.456809
num_accepted / total 81 224
loss token level: tensor(8487.1777, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4244., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.45710399999999995
num_accepted / total 48 128
loss token level: tensor(8479.9805, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4752., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2337, 42808])
pred_new.size(): torch.Size([2562, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.45772999999999997
num_accepted / total 9 40
loss token level: tensor(8682.9121, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5612., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3243, 42808])
pred_new.size(): torch.Size([4191, 42808])
pred_new.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([616, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3550, 42808])
2023-09-23 17:43:17 | INFO | train_inner | epoch 018:   4414 / 9060 loss=6.953, nll_loss=3.439, ppl=10.84, wps=4483.7, ups=0.35, wpb=12919.7, bsz=435.7, num_updates=158400, lr=7.94552e-05, gnorm=1.028, loss_scale=4, train_wall=288, gb_free=14.2, wall=284591
ter_threshold: 0.458465
num_accepted / total 87 152
loss token level: tensor(8795.0039, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7428., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1152, 42808])
2023-09-23 17:47:58 | INFO | train_inner | epoch 018:   4514 / 9060 loss=6.932, nll_loss=3.432, ppl=10.79, wps=4650.9, ups=0.36, wpb=13070.5, bsz=404.5, num_updates=158500, lr=7.94301e-05, gnorm=1.038, loss_scale=4, train_wall=281, gb_free=13.2, wall=284872
2023-09-23 17:52:35 | INFO | train_inner | epoch 018:   4614 / 9060 loss=7.279, nll_loss=3.604, ppl=12.16, wps=4706.6, ups=0.36, wpb=13018.6, bsz=435.8, num_updates=158600, lr=7.94051e-05, gnorm=1.057, loss_scale=4, train_wall=276, gb_free=13.8, wall=285148
2023-09-23 17:57:15 | INFO | train_inner | epoch 018:   4714 / 9060 loss=7.219, nll_loss=3.544, ppl=11.67, wps=4575.6, ups=0.36, wpb=12846.1, bsz=445.4, num_updates=158700, lr=7.93801e-05, gnorm=1.07, loss_scale=4, train_wall=280, gb_free=13.8, wall=285429
2023-09-23 18:02:01 | INFO | train_inner | epoch 018:   4814 / 9060 loss=7.235, nll_loss=3.558, ppl=11.78, wps=4566.2, ups=0.35, wpb=13016.4, bsz=438.3, num_updates=158800, lr=7.93551e-05, gnorm=1.044, loss_scale=4, train_wall=285, gb_free=15.2, wall=285714
pred_new.size(): torch.Size([3450, 42808])
2023-09-23 18:06:33 | INFO | train_inner | epoch 018:   4914 / 9060 loss=7.121, nll_loss=3.513, ppl=11.42, wps=4742.1, ups=0.37, wpb=12944.4, bsz=435.4, num_updates=158900, lr=7.93301e-05, gnorm=1.025, loss_scale=4, train_wall=273, gb_free=14.3, wall=285987
2023-09-23 18:11:14 | INFO | train_inner | epoch 018:   5014 / 9060 loss=7.171, nll_loss=3.539, ppl=11.62, wps=4618.8, ups=0.36, wpb=12976.6, bsz=428.3, num_updates=159000, lr=7.93052e-05, gnorm=1.043, loss_scale=4, train_wall=281, gb_free=15.6, wall=286268
2023-09-23 18:16:09 | INFO | train_inner | epoch 018:   5114 / 9060 loss=7.042, nll_loss=3.491, ppl=11.25, wps=4403.5, ups=0.34, wpb=12952.4, bsz=412.2, num_updates=159100, lr=7.92802e-05, gnorm=1.033, loss_scale=4, train_wall=294, gb_free=13.6, wall=286562
ter_threshold: 0.459175
num_accepted / total 12 56
loss token level: tensor(9116.5557, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5776., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 18:21:11 | INFO | train_inner | epoch 018:   5214 / 9060 loss=7.102, nll_loss=3.499, ppl=11.3, wps=4282.6, ups=0.33, wpb=12934.8, bsz=436.2, num_updates=159200, lr=7.92553e-05, gnorm=1.066, loss_scale=4, train_wall=302, gb_free=13.6, wall=286864
ter_threshold: 0.459284
num_accepted / total 74 136
loss token level: tensor(9143.1914, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13440., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 18:26:02 | INFO | train_inner | epoch 018:   5314 / 9060 loss=7.144, nll_loss=3.503, ppl=11.34, wps=4447.9, ups=0.34, wpb=12962.5, bsz=443.9, num_updates=159300, lr=7.92304e-05, gnorm=1.033, loss_scale=4, train_wall=291, gb_free=13.5, wall=287155
2023-09-23 18:31:02 | INFO | train_inner | epoch 018:   5414 / 9060 loss=7.201, nll_loss=3.529, ppl=11.55, wps=4351.8, ups=0.33, wpb=13043.6, bsz=460.7, num_updates=159400, lr=7.92056e-05, gnorm=1.109, loss_scale=4, train_wall=299, gb_free=14.3, wall=287455
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2968, 42808])
lprobs.size(): torch.Size([3392, 42808])
2023-09-23 18:35:55 | INFO | train_inner | epoch 018:   5514 / 9060 loss=7.149, nll_loss=3.536, ppl=11.6, wps=4414.7, ups=0.34, wpb=12949.2, bsz=422.3, num_updates=159500, lr=7.91808e-05, gnorm=1.059, loss_scale=4, train_wall=293, gb_free=15.1, wall=287749
2023-09-23 18:40:48 | INFO | train_inner | epoch 018:   5614 / 9060 loss=7.166, nll_loss=3.552, ppl=11.73, wps=4434.7, ups=0.34, wpb=13009.8, bsz=423.1, num_updates=159600, lr=7.91559e-05, gnorm=1.054, loss_scale=4, train_wall=293, gb_free=13.4, wall=288042
pred_new.size(): torch.Size([9184, 42808])
lprobs.size(): torch.Size([3072, 42808])
2023-09-23 18:45:47 | INFO | train_inner | epoch 018:   5714 / 9060 loss=7.224, nll_loss=3.564, ppl=11.83, wps=4344.8, ups=0.34, wpb=12967, bsz=451.4, num_updates=159700, lr=7.91312e-05, gnorm=1.068, loss_scale=4, train_wall=298, gb_free=15.5, wall=288340
2023-09-23 18:50:53 | INFO | train_inner | epoch 018:   5814 / 9060 loss=7.121, nll_loss=3.487, ppl=11.21, wps=4241.8, ups=0.33, wpb=12987.4, bsz=429.8, num_updates=159800, lr=7.91064e-05, gnorm=1.06, loss_scale=4, train_wall=306, gb_free=15.7, wall=288647
lprobs.size(): torch.Size([3040, 42808])
2023-09-23 18:55:52 | INFO | train_inner | epoch 018:   5914 / 9060 loss=7.049, nll_loss=3.469, ppl=11.08, wps=4316.3, ups=0.33, wpb=12915.5, bsz=423.2, num_updates=159900, lr=7.90817e-05, gnorm=1.043, loss_scale=4, train_wall=299, gb_free=13.4, wall=288946
pred_new.size(): torch.Size([2352, 42808])
2023-09-23 19:00:59 | INFO | train_inner | epoch 018:   6014 / 9060 loss=7.207, nll_loss=3.522, ppl=11.49, wps=4215.3, ups=0.33, wpb=12908.9, bsz=455.4, num_updates=160000, lr=7.90569e-05, gnorm=1.107, loss_scale=4, train_wall=306, gb_free=13.2, wall=289252
2023-09-23 19:05:56 | INFO | train_inner | epoch 018:   6114 / 9060 loss=7.184, nll_loss=3.526, ppl=11.52, wps=4318.6, ups=0.34, wpb=12867, bsz=422.6, num_updates=160100, lr=7.90322e-05, gnorm=1.099, loss_scale=4, train_wall=298, gb_free=13.8, wall=289550
pred_new.size(): torch.Size([5355, 42808])
pred_new.size(): torch.Size([9090, 42808])
2023-09-23 19:10:58 | INFO | train_inner | epoch 018:   6214 / 9060 loss=7.188, nll_loss=3.506, ppl=11.36, wps=4344.9, ups=0.33, wpb=13083.8, bsz=418.3, num_updates=160200, lr=7.90076e-05, gnorm=1.057, loss_scale=4, train_wall=301, gb_free=13.1, wall=289851
pred_new.size(): torch.Size([1743, 42808])
2023-09-23 19:15:53 | INFO | train_inner | epoch 018:   6314 / 9060 loss=6.972, nll_loss=3.426, ppl=10.75, wps=4410.2, ups=0.34, wpb=13013.6, bsz=421.2, num_updates=160300, lr=7.89829e-05, gnorm=1.017, loss_scale=4, train_wall=295, gb_free=14.4, wall=290146
2023-09-23 19:20:48 | INFO | train_inner | epoch 018:   6414 / 9060 loss=7.236, nll_loss=3.528, ppl=11.54, wps=4425.4, ups=0.34, wpb=13050.5, bsz=449, num_updates=160400, lr=7.89583e-05, gnorm=1.075, loss_scale=4, train_wall=295, gb_free=14.1, wall=290441
pred_new.size(): torch.Size([1890, 42808])
2023-09-23 19:25:36 | INFO | train_inner | epoch 018:   6514 / 9060 loss=7.106, nll_loss=3.528, ppl=11.54, wps=4511.5, ups=0.35, wpb=13008, bsz=425.3, num_updates=160500, lr=7.89337e-05, gnorm=1.066, loss_scale=4, train_wall=288, gb_free=13.7, wall=290729
ter_threshold: 0.460532
num_accepted / total 108 184
loss token level: tensor(9349.1182, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13056., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 19:30:28 | INFO | train_inner | epoch 018:   6614 / 9060 loss=7.231, nll_loss=3.54, ppl=11.63, wps=4408.3, ups=0.34, wpb=12893.2, bsz=439, num_updates=160600, lr=7.89091e-05, gnorm=1.103, loss_scale=4, train_wall=292, gb_free=13.5, wall=291022
lprobs.size(): torch.Size([2592, 42808])
2023-09-23 19:35:28 | INFO | train_inner | epoch 018:   6714 / 9060 loss=7.264, nll_loss=3.558, ppl=11.78, wps=4308.5, ups=0.33, wpb=12898.8, bsz=402.1, num_updates=160700, lr=7.88846e-05, gnorm=1.067, loss_scale=4, train_wall=299, gb_free=13.5, wall=291321
lprobs.size(): torch.Size([3128, 42808])
2023-09-23 19:40:15 | INFO | train_inner | epoch 018:   6814 / 9060 loss=7.145, nll_loss=3.529, ppl=11.55, wps=4502.3, ups=0.35, wpb=12933.4, bsz=405.3, num_updates=160800, lr=7.886e-05, gnorm=1.04, loss_scale=4, train_wall=287, gb_free=13.8, wall=291609
pred_new.size(): torch.Size([3192, 42808])
2023-09-23 19:45:01 | INFO | train_inner | epoch 018:   6914 / 9060 loss=7.094, nll_loss=3.537, ppl=11.61, wps=4536.8, ups=0.35, wpb=12975.5, bsz=418.9, num_updates=160900, lr=7.88355e-05, gnorm=1.049, loss_scale=4, train_wall=286, gb_free=13, wall=291895
pred_new.size(): torch.Size([768, 42808])
pred_new.size(): torch.Size([2805, 42808])
2023-09-23 19:49:52 | INFO | train_inner | epoch 018:   7014 / 9060 loss=7.275, nll_loss=3.582, ppl=11.97, wps=4494.1, ups=0.34, wpb=13078.6, bsz=448.7, num_updates=161000, lr=7.8811e-05, gnorm=1.041, loss_scale=8, train_wall=291, gb_free=13.9, wall=292186
2023-09-23 19:52:45 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-23 19:54:34 | INFO | train_inner | epoch 018:   7115 / 9060 loss=7.04, nll_loss=3.467, ppl=11.06, wps=4605.7, ups=0.35, wpb=12980.3, bsz=431.9, num_updates=161100, lr=7.87866e-05, gnorm=1.024, loss_scale=4, train_wall=282, gb_free=14.8, wall=292467
lprobs.size(): torch.Size([3520, 42808])
2023-09-23 19:59:22 | INFO | train_inner | epoch 018:   7215 / 9060 loss=7.058, nll_loss=3.464, ppl=11.04, wps=4522.8, ups=0.35, wpb=13033.4, bsz=440.5, num_updates=161200, lr=7.87621e-05, gnorm=1.012, loss_scale=4, train_wall=288, gb_free=14.3, wall=292756
pred_new.size(): torch.Size([5700, 42808])
pred_new.size(): torch.Size([5140, 42808])
2023-09-23 20:04:11 | INFO | train_inner | epoch 018:   7315 / 9060 loss=7.056, nll_loss=3.482, ppl=11.18, wps=4500.9, ups=0.35, wpb=13007.2, bsz=439.4, num_updates=161300, lr=7.87377e-05, gnorm=1.026, loss_scale=4, train_wall=289, gb_free=14.4, wall=293045
pred_new.size(): torch.Size([228, 42808])
2023-09-23 20:09:01 | INFO | train_inner | epoch 018:   7415 / 9060 loss=7.085, nll_loss=3.489, ppl=11.23, wps=4512.4, ups=0.35, wpb=13076.1, bsz=433, num_updates=161400, lr=7.87133e-05, gnorm=1.048, loss_scale=4, train_wall=290, gb_free=15.7, wall=293334
pred_new.size(): torch.Size([1539, 42808])
2023-09-23 20:13:57 | INFO | train_inner | epoch 018:   7515 / 9060 loss=7.176, nll_loss=3.527, ppl=11.53, wps=4398.8, ups=0.34, wpb=13042.7, bsz=440.6, num_updates=161500, lr=7.86889e-05, gnorm=1.05, loss_scale=4, train_wall=296, gb_free=15.6, wall=293631
loss token level: tensor(9285.4707, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6968., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7221, 42808])
ter_threshold: 0.452109
num_accepted / total 64 112
loss token level: tensor(9545.8018, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(15008., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([1140, 42808])
ter_threshold: 0.45232399999999995
num_accepted / total 20 64
loss token level: tensor(9852.1904, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7776., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.452428
num_accepted / total 81 136
loss token level: tensor(9069.1182, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8448., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2112, 42808])
pred_new.size(): torch.Size([5510, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2600, 42808])
ter_threshold: 0.45352
num_accepted / total 11 64
loss token level: tensor(8554.3389, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2460., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2193, 42808])
pred_new.size(): torch.Size([4680, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3080, 42808])
ter_threshold: 0.453925
num_accepted / total 25 88
loss token level: tensor(8517.9307, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3770., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1673, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([3120, 42808])
ter_threshold: 0.45426999999999995
num_accepted / total 4 24
loss token level: tensor(7402.8218, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2030., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2200, 42808])
pred_new.size(): torch.Size([4320, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1716, 42808])
pred_new.size(): torch.Size([2360, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.45506800000000003
num_accepted / total 32 80
loss token level: tensor(8940.7637, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10400., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.45509999999999995
num_accepted / total 60 112
loss token level: tensor(8790.9043, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.455594
num_accepted / total 25 72
loss token level: tensor(8686.5039, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7488., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4387, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2553, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([1296, 42808])
ter_threshold: 0.45659099999999997
num_accepted / total 19 104
loss token level: tensor(9022.3145, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2284., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([854, 42808])
pred_new.size(): torch.Size([3942, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.456786
num_accepted / total 5 56
loss token level: tensor(8337.6211, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(890.5000, device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.456809
num_accepted / total 52 128
loss token level: tensor(9624.9434, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5768., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([6732, 42808])
lprobs.size(): torch.Size([3408, 42808])
ter_threshold: 0.45710399999999995
num_accepted / total 117 184
loss token level: tensor(8518.8691, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7936., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2958, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7105, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([4988, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.457418
num_accepted / total 89 160
loss token level: tensor(8994.6367, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13240., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([594, 42808])
lprobs.size(): torch.Size([2400, 42808])
ter_threshold: 0.457639
num_accepted / total 18 56
loss token level: tensor(8224.4668, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4632., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([4725, 42808])
lprobs.size(): torch.Size([2208, 42808])
pred_new.size(): torch.Size([1701, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.458465
num_accepted / total 105 160
loss token level: tensor(9357.5781, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9568., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4095, 42808])
pred_new.size(): torch.Size([1900, 42808])
lprobs.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([6384, 42808])
ter_threshold: 0.45887100000000003
num_accepted / total 8 48
loss token level: tensor(8590.3379, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1984., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.459284
num_accepted / total 40 88
loss token level: tensor(8839.6719, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11072., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4494, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([4794, 42808])
pred_new.size(): torch.Size([6075, 42808])
pred_new.size(): torch.Size([5628, 42808])
pred_new.size(): torch.Size([2639, 42808])
pred_new.size(): torch.Size([6780, 42808])
pred_new.size(): torch.Size([7200, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([1624, 42808])
pred_new.size(): torch.Size([3600, 42808])
ter_threshold: 0.460532
num_accepted / total 64 128
loss token level: tensor(8491.3613, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11240., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2726, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([3300, 42808])
pred_new.size(): torch.Size([2160, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([2208, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3948, 42808])
ter_threshold: 0.46152099999999996
num_accepted / total 63 136
loss token level: tensor(9673.1514, device='cuda:1', grad_fn=<AddBackward0>)
2023-09-23 20:18:55 | INFO | train_inner | epoch 018:   7615 / 9060 loss=7.049, nll_loss=3.483, ppl=11.18, wps=4345, ups=0.34, wpb=12932.7, bsz=401, num_updates=161600, lr=7.86646e-05, gnorm=1.038, loss_scale=4, train_wall=297, gb_free=13.9, wall=293928
2023-09-23 20:23:49 | INFO | train_inner | epoch 018:   7715 / 9060 loss=7.23, nll_loss=3.534, ppl=11.58, wps=4432.8, ups=0.34, wpb=13027, bsz=444.5, num_updates=161700, lr=7.86403e-05, gnorm=1.042, loss_scale=4, train_wall=294, gb_free=13.9, wall=294222
pred_new.size(): torch.Size([5600, 42808])
2023-09-23 20:28:41 | INFO | train_inner | epoch 018:   7815 / 9060 loss=7.139, nll_loss=3.508, ppl=11.37, wps=4430.1, ups=0.34, wpb=12926.6, bsz=427.4, num_updates=161800, lr=7.8616e-05, gnorm=1.077, loss_scale=4, train_wall=292, gb_free=13.7, wall=294514
pred_new.size(): torch.Size([92, 42808])
lprobs.size(): torch.Size([2856, 42808])
2023-09-23 20:33:40 | INFO | train_inner | epoch 018:   7915 / 9060 loss=7.19, nll_loss=3.573, ppl=11.9, wps=4289, ups=0.33, wpb=12854, bsz=438.6, num_updates=161900, lr=7.85917e-05, gnorm=1.052, loss_scale=4, train_wall=299, gb_free=13.6, wall=294814
pred_new.size(): torch.Size([2016, 42808])
2023-09-23 20:38:37 | INFO | train_inner | epoch 018:   8015 / 9060 loss=7.135, nll_loss=3.51, ppl=11.39, wps=4358.8, ups=0.34, wpb=12929.4, bsz=430, num_updates=162000, lr=7.85674e-05, gnorm=1.031, loss_scale=4, train_wall=296, gb_free=14.5, wall=295110
pred_new.size(): torch.Size([6148, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-23 20:43:29 | INFO | train_inner | epoch 018:   8115 / 9060 loss=7.216, nll_loss=3.55, ppl=11.71, wps=4433.1, ups=0.34, wpb=12931.2, bsz=423.2, num_updates=162100, lr=7.85432e-05, gnorm=1.062, loss_scale=4, train_wall=291, gb_free=14.5, wall=295402
ter_threshold: 0.46218499999999996
num_accepted / total 44 128
loss token level: tensor(11946.8174, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7436., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 20:48:16 | INFO | train_inner | epoch 018:   8215 / 9060 loss=7.142, nll_loss=3.52, ppl=11.47, wps=4500.9, ups=0.35, wpb=12921.6, bsz=446.9, num_updates=162200, lr=7.8519e-05, gnorm=1.028, loss_scale=4, train_wall=287, gb_free=16, wall=295689
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([4608, 42808])
2023-09-23 20:53:15 | INFO | train_inner | epoch 018:   8315 / 9060 loss=7.037, nll_loss=3.467, ppl=11.06, wps=4344.3, ups=0.33, wpb=12998.9, bsz=405, num_updates=162300, lr=7.84948e-05, gnorm=1.047, loss_scale=4, train_wall=299, gb_free=13.4, wall=295988
ter_threshold: 0.462341
num_accepted / total 283 352
loss token level: tensor(8271.8389, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9472., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 20:57:52 | INFO | train_inner | epoch 018:   8415 / 9060 loss=7.11, nll_loss=3.483, ppl=11.18, wps=4724.2, ups=0.36, wpb=13079.7, bsz=462.5, num_updates=162400, lr=7.84706e-05, gnorm=1.013, loss_scale=4, train_wall=277, gb_free=16, wall=296265
ter_threshold: 0.462477
num_accepted / total 39 152
loss token level: tensor(12246.7520, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3584., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2816, 42808])
2023-09-23 21:02:50 | INFO | train_inner | epoch 018:   8515 / 9060 loss=7.046, nll_loss=3.472, ppl=11.09, wps=4374, ups=0.34, wpb=13032.1, bsz=443.3, num_updates=162500, lr=7.84465e-05, gnorm=1.013, loss_scale=4, train_wall=298, gb_free=15, wall=296563
2023-09-23 21:07:34 | INFO | train_inner | epoch 018:   8615 / 9060 loss=7.218, nll_loss=3.566, ppl=11.84, wps=4575.6, ups=0.35, wpb=12981, bsz=437.9, num_updates=162600, lr=7.84223e-05, gnorm=1.051, loss_scale=4, train_wall=283, gb_free=13.7, wall=296847
pred_new.size(): torch.Size([5511, 42808])
2023-09-23 21:12:21 | INFO | train_inner | epoch 018:   8715 / 9060 loss=7.203, nll_loss=3.584, ppl=11.99, wps=4489.6, ups=0.35, wpb=12900.5, bsz=421, num_updates=162700, lr=7.83982e-05, gnorm=1.056, loss_scale=4, train_wall=287, gb_free=12.9, wall=297134
lprobs.size(): torch.Size([2512, 42808])
pred_new.size(): torch.Size([6448, 42808])
2023-09-23 21:17:17 | INFO | train_inner | epoch 018:   8815 / 9060 loss=7.082, nll_loss=3.497, ppl=11.29, wps=4366.6, ups=0.34, wpb=12937.6, bsz=405.2, num_updates=162800, lr=7.83741e-05, gnorm=1.028, loss_scale=4, train_wall=296, gb_free=14.5, wall=297431
ter_threshold: 0.462871
num_accepted / total 36 96
loss token level: tensor(9877.7148, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5428., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 21:22:18 | INFO | train_inner | epoch 018:   8915 / 9060 loss=6.977, nll_loss=3.458, ppl=10.99, wps=4295.8, ups=0.33, wpb=12925, bsz=404.4, num_updates=162900, lr=7.83501e-05, gnorm=1.011, loss_scale=4, train_wall=301, gb_free=14, wall=297731
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5123, 42808])
2023-09-23 21:27:20 | INFO | train_inner | epoch 018:   9015 / 9060 loss=7.114, nll_loss=3.527, ppl=11.53, wps=4267.5, ups=0.33, wpb=12868, bsz=430.4, num_updates=163000, lr=7.8326e-05, gnorm=1.055, loss_scale=4, train_wall=301, gb_free=14.1, wall=298033
2023-09-23 21:29:36 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-23 21:29:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 21:29:36 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-23 21:29:36 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-23 21:29:37 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-23 21:29:37 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-23 21:29:37 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-23 21:29:37 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-23 21:29:38 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-23 21:29:38 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-23 21:29:38 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-23 21:29:38 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-23 21:29:39 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal fügte zusätzliche Inhalte hinzu und es war ein ravierender Erfolg.
2023-09-23 21:29:39 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-23 21:29:40 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-23 21:29:40 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-23 21:29:40 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-23 21:29:40 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-23 21:29:41 | INFO | fairseq.tasks.translation | example hypothesis: Das Chatmodul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-23 21:29:41 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-23 21:29:41 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende gleichermaßen geeignet sind.
2023-09-23 21:29:41 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-23 21:29:42 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-23 21:29:42 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-23 21:29:42 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 21:29:42 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-23 21:29:43 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU enorme Mengen an Energie verschwendet.
2023-09-23 21:29:43 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-23 21:29:43 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin trägt einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-23 21:29:43 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-23 21:29:44 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich auch die Haltungsänderung in Kürze im Haushalt der Union widerspiegeln.
2023-09-23 21:29:44 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-23 21:29:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-23 21:29:44 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-23 21:29:45 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-23 21:29:45 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-23 21:29:46 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-23 21:29:46 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-23 21:29:46 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen wurden gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-23 21:29:46 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-23 21:29:47 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Sitz und Produktionshallen in Stans.
2023-09-23 21:29:47 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-23 21:29:47 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-23 21:29:47 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-23 21:29:48 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-23 21:29:48 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-23 21:29:49 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionale Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution erfolgen.
2023-09-23 21:29:49 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-23 21:29:49 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potentielle Käufer dazu veranlassen, sich über die Qualität Ihres Services und Ihrer Produkte zu informieren.
2023-09-23 21:29:49 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-23 21:29:50 | INFO | fairseq.tasks.translation | example hypothesis: Während sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-23 21:29:50 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-23 21:29:50 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu unterbreiten, falls es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-23 21:29:50 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-23 21:29:51 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 21:29:51 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-23 21:29:52 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in einem Umkreis von etwa 8 km vom Strip entfernt.
2023-09-23 21:29:52 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-23 21:29:52 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-23 21:29:52 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-23 21:29:53 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-23 21:29:53 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-23 21:29:53 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-23 21:29:53 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-23 21:29:54 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-23 21:29:54 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-23 21:29:55 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Ausstieg Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme einzahlen.
2023-09-23 21:29:55 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-23 21:29:55 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-23 21:29:55 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-23 21:29:56 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, aber für einige Formate gibt es leider keine freie Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-23 21:29:56 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-23 21:29:57 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie man Ihnen helfen, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche ist.
2023-09-23 21:29:57 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-23 21:29:57 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Vorstellungen von niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-23 21:29:57 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-23 21:29:58 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-23 21:29:58 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-23 21:29:58 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können sich gegenseitig keine Gegenstände kaufen oder verkaufen, es sei denn, sie nutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-23 21:29:58 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-23 21:29:59 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollen.
2023-09-23 21:29:59 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-23 21:30:00 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-23 21:30:00 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-23 21:30:00 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens im Prinzip mit den Vereinigten Staaten abgeben müssen.
2023-09-23 21:30:00 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-23 21:30:01 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder spezielle Edition - unser breites Angebot an Plastikbabyleartikeln ist beeindruckend, nicht zuletzt durch seine hervorragende Verarbeitung.
2023-09-23 21:30:01 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-23 21:30:02 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 21:30:02 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-23 21:30:03 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Bekanntwerden dieser AGB über Sachsituationen zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-23 21:30:03 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-23 21:30:03 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, und die sieht, dass sie im Bereich der Außenpolitik und Verteidigung stärker Präsenz benötigt.
2023-09-23 21:30:03 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-23 21:30:04 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir einen Blog als Informationsportal für unsere Kunden, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-23 21:30:04 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-23 21:30:05 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die wir erzielt haben, wenn wir uns all die Fragen betrachten, die derzeit diskutiert werden, und die etwas betreffen, was gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-23 21:30:05 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-23 21:30:05 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-23 21:30:05 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-23 21:30:06 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal war der Berichterstatter in der Lage, gelegentlich unterschiedliche Meinungen und Beiträge zusammenzufassen und sie - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 21:30:06 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-23 21:30:07 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlagsgeräten mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-23 21:30:07 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-23 21:30:08 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seit Jahrhunderten seine Freiheit und Unabhängigkeit verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-23 21:30:08 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-23 21:30:08 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-23 21:30:08 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-23 21:30:09 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und sich auf unsere Gemeinschaft der Nationen beziehen.
2023-09-23 21:30:09 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-23 21:30:10 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-23 21:30:10 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-23 21:30:11 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürgerinnen und Bürger appellieren und das Grundrecht der Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-23 21:30:11 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-23 21:30:12 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-23 21:30:12 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-23 21:30:12 | INFO | fairseq.tasks.translation | example hypothesis: Im Rahmen dieser Notsituation gibt es jedoch noch einen weiteren: die Notsituation der Kinder, des schwächsten Sektors der Bevölkerung, die ohne Familie, ohne Schutz und ohne Staat gelassen wurden.
2023-09-23 21:30:12 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-23 21:30:13 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-23 21:30:13 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-23 21:30:14 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht befreit ist, nicht erst verwirklicht wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt....................
2023-09-23 21:30:14 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-23 21:30:15 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen einen gewaltfreien Zeitraum zu schaffen und das Verfahren für die Registrierung der Wähler wieder aufzunehmen...............
2023-09-23 21:30:15 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-23 21:30:16 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern freie Meinungsäußerung, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-23 21:30:16 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-23 21:30:17 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java-Programmiersprache mit J2EE-Techniken, die Plattform und Betriebssystem Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-23 21:30:17 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-23 21:30:17 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Sehr geehrte Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für die Klärung des Anhangs.
2023-09-23 21:30:17 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-23 21:30:18 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen haben, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Abkommen angesehen werden.
2023-09-23 21:30:18 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-23 21:30:19 | INFO | fairseq.tasks.translation | example hypothesis: Vor kurzem habe ich an einer Aussprache über das irische öffentlich-rechtliche Radio RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben senken und nicht genug tun, um die Ausgaben für die Entwicklungshilfe zu senken...............
2023-09-23 21:30:19 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-23 21:30:20 | INFO | fairseq.tasks.translation | example hypothesis: Vor diesem Hintergrund hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer besonnenen Haltung gratulieren.
2023-09-23 21:30:20 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-23 21:30:21 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie nach Inspiration für Ihren Unterricht oder konkreten Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas so Konkretes wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-23 21:30:21 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-23 21:30:22 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen.
2023-09-23 21:30:22 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-23 21:30:23 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-23 21:30:23 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-23 21:30:24 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken hieße, eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen auch die tatsächliche oder wahrgenommene Gefahr, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-23 21:30:24 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-23 21:30:24 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-23 21:30:24 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-23 21:30:25 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist einer der lustigsten Autos, die man für weniger als 50.000 $fahren kann, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos ausprobieren.
2023-09-23 21:30:25 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-23 21:30:26 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, und dasselbe gilt auch für den Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit.
2023-09-23 21:30:26 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-23 21:30:27 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den ausgezeichneten Frischwasserfisch: gegrillter Hecht, Forelle mit Mandeln.
2023-09-23 21:30:27 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-23 21:30:28 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, eine Gesamtsicht zu bieten, die es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu prüfen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-23 21:30:28 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-23 21:30:29 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, kamen überein, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-23 21:30:29 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-23 21:30:30 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen echten Wohlstand, wo es Arbeitslosigkeit gibt, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politik, steuerliche Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-23 21:30:30 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-23 21:30:31 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, beigetragen hat.
2023-09-23 21:30:31 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-23 21:30:32 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den rechtlichen und justiziellen Bereich, wodurch Norwegen und Island, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden, zu.....................
2023-09-23 21:30:32 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-23 21:30:33 | INFO | fairseq.tasks.translation | example hypothesis: Wir gehen mit voller Geschwindigkeit mit einem Schwenkboot hinunter den Mississippi, suchen nach dem großen verborgenen Schatz, verlieben uns in den schönen Becky Thatcher, der reinen Dynamit ist, und mehr als alles andere werden wir große Freunde sein....................
2023-09-23 21:30:33 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-23 21:30:34 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der Verschmutzung durch Schiffe, die durch Einzelpersonen oder juristische Personen verursacht werden, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die bei Verstößen von Personen verhängt werden können.
2023-09-23 21:30:34 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-23 21:30:34 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat nur deshalb verurteilt, weil sie ihre Arbeit als Journalisten und Kameramänner verrichtet und eine Gruppe von Bergbewohnern gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das sich über jeden Grundsatz der Demokratie hinwegsetzt.
2023-09-23 21:30:34 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-23 21:30:35 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseurgeschäft und ein Schönheitssalon, Transport- und Sightseeing-Service, eine Menü- und Presseservice, Geldwechsel, kostenfreie Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das Französische Viertel.
2023-09-23 21:30:35 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-23 21:30:36 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, Ehefrau von König D. João II., und bekannt durch ihre Keramik, die international für ihre figurativen und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-23 21:30:36 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-23 21:30:37 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute westliche Befürworter auf der einen und Anhänger des früheren Regimes auf der anderen Seite handelt - auch das ist verwerflich, da die Rollen aller heute und davor bekannt sind.
2023-09-23 21:30:37 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-23 21:30:38 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt sind, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte........................
2023-09-23 21:30:38 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-23 21:30:39 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär Informationen zur Verfügung gestellt, so werden diese auf Antrag an einen anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-23 21:30:39 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-23 21:30:40 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren fließen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.
2023-09-23 21:30:40 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-23 21:30:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder die NATO hätten an diesem Kriegsakt beteiligt sein können -, bei Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, versteckt oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann..........................
2023-09-23 21:30:41 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-23 21:30:42 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Berliner Stadtteil Reinickendorf liegt 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 21:30:42 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-23 21:30:43 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die modernen, nicht im Regal befindlichen Plattformen nie erreichen können.......................
2023-09-23 21:30:43 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-23 21:30:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz deutlich machen, dass wir nicht nur für uns, sondern weltweit auch die Produkte aus dem Markt nehmen können, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt ein ernstes Risiko darstellen, denn solche Produkte können leicht recycelt werden, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt..................................
2023-09-23 21:30:44 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-23 21:30:45 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem direkten Komplott von Moderne und Postmoderne oder dem klaren Widerstand von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung jener beiden ästhetischen Politik anerkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die die Kunst als solche für uns identifizierbar machen - jener beiden Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führt........................ Diese beiden Politiken
2023-09-23 21:30:45 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-23 21:30:46 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute angesichts der Bedeutung der Debatten und der Stellungnahmen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen werden wir unsere Aussprachen führen, und wenn die vierzig Petenten nicht anwesend sind, werde ich bei der Abstimmung nicht beantragen, die Beschlussfähigkeit zu überprüfen.
2023-09-23 21:30:46 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-23 21:30:47 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker niemals die Einschränkung des nationalstaatlichen Prinzips akzeptiert haben, so sind es paradoxerweise gerade diejenigen, die, kaum bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem die nationalen Grenzen aufgehoben wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung einer ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen..........................
2023-09-23 21:30:47 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
lprobs.size(): torch.Size([2640, 42808])
2023-09-23 21:30:48 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Hinsicht als Hybridform veröffentlicht, die Rezensionen und Artikel der Quartalszeitschrift sind für H-Soz-u-Kult verfasst und wurden über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an ihre Abonnenten verteilt.............. H-Soz-u-u-Kult, H-Kult und H
2023-09-23 21:30:48 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-23 21:30:49 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit dem Eintreffen der neuen Smartphone-Generation haben Handys ihre Federn deutlich verwischt, von einstmals blutigen Taschenwänden über polyphonisch tootende Game Boy-Aspiranten bis hin zu schrägen Mini-PCs mit knusprigem Stereo-Sound in CD-Qualität: Zukünftig könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen übergehen.
2023-09-23 21:30:49 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-23 21:30:51 | INFO | fairseq.tasks.translation | example hypothesis: El sistema del fin científico del proyecto, el coronel Quaritch, quien dirige la defensa de la base humana en Pandora, conence a Jake para que proportionle información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen; en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se cuenta de que éstos jamás renunciarán a su tierra.
2023-09-23 21:30:51 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-23 21:30:52 | INFO | valid | epoch 018 | valid on 'valid' subset | loss 4.138 | nll_loss 2.165 | ppl 4.48 | bleu 28.25 | wps 15631.9 | wpb 12011.9 | bsz 398.1 | num_updates 163045 | best_bleu 29.48
2023-09-23 21:30:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 163045 updates
2023-09-23 21:30:52 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint18.pt
2023-09-23 21:30:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint18.pt
2023-09-23 21:31:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint18.pt (epoch 18 @ 163045 updates, score 28.25) (writing took 10.056191462033894 seconds)
2023-09-23 21:31:02 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2023-09-23 21:31:02 | INFO | train | epoch 018 | loss 7.125 | nll_loss 3.502 | ppl 11.33 | wps 4511.7 | ups 0.35 | wpb 12977.2 | bsz 430.6 | num_updates 163045 | lr 7.83152e-05 | gnorm 1.042 | loss_scale 4 | train_wall 25947 | gb_free 13.8 | wall 298255
2023-09-23 21:31:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-23 21:31:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-23 21:31:02 | INFO | fairseq.trainer | begin training epoch 19
2023-09-23 21:31:02 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-23 21:33:49 | INFO | train_inner | epoch 019:     55 / 9060 loss=7.182, nll_loss=3.547, ppl=11.69, wps=3319.8, ups=0.26, wpb=12921.5, bsz=425.6, num_updates=163100, lr=7.8302e-05, gnorm=1.068, loss_scale=4, train_wall=303, gb_free=13.8, wall=298422
lprobs.size(): torch.Size([3168, 42808])
2023-09-23 21:38:52 | INFO | train_inner | epoch 019:    155 / 9060 loss=7.112, nll_loss=3.48, ppl=11.16, wps=4296.8, ups=0.33, wpb=13033.2, bsz=450.9, num_updates=163200, lr=7.8278e-05, gnorm=1.044, loss_scale=4, train_wall=303, gb_free=14.8, wall=298726
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([432, 42808])
pred_new.size(): torch.Size([6560, 42808])
2023-09-23 21:43:46 | INFO | train_inner | epoch 019:    255 / 9060 loss=7.118, nll_loss=3.494, ppl=11.27, wps=4447.8, ups=0.34, wpb=13080.6, bsz=442.6, num_updates=163300, lr=7.82541e-05, gnorm=1.038, loss_scale=4, train_wall=294, gb_free=13.5, wall=299020
pred_new.size(): torch.Size([5513, 42808])
2023-09-23 21:48:58 | INFO | train_inner | epoch 019:    355 / 9060 loss=7.044, nll_loss=3.427, ppl=10.76, wps=4160.6, ups=0.32, wpb=12955.1, bsz=424.7, num_updates=163400, lr=7.82301e-05, gnorm=1.062, loss_scale=4, train_wall=311, gb_free=14.6, wall=299331
ter_threshold: 0.463439
num_accepted / total 32 96
loss token level: tensor(9080.7861, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4380., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2124, 42808])
pred_new.size(): torch.Size([248, 42808])
2023-09-23 21:54:06 | INFO | train_inner | epoch 019:    455 / 9060 loss=7.309, nll_loss=3.564, ppl=11.83, wps=4186.6, ups=0.32, wpb=12902.5, bsz=430.4, num_updates=163500, lr=7.82062e-05, gnorm=1.075, loss_scale=4, train_wall=308, gb_free=14.2, wall=299639
pred_new.size(): torch.Size([5698, 42808])
pred_new.size(): torch.Size([2964, 42808])
2023-09-23 21:59:13 | INFO | train_inner | epoch 019:    555 / 9060 loss=7.172, nll_loss=3.5, ppl=11.32, wps=4208.9, ups=0.33, wpb=12943.2, bsz=433.3, num_updates=163600, lr=7.81823e-05, gnorm=1.084, loss_scale=4, train_wall=307, gb_free=15, wall=299947
lprobs.size(): torch.Size([3440, 42808])
2023-09-23 22:04:27 | INFO | train_inner | epoch 019:    655 / 9060 loss=7.166, nll_loss=3.477, ppl=11.14, wps=4176.6, ups=0.32, wpb=13083, bsz=436.2, num_updates=163700, lr=7.81584e-05, gnorm=1.043, loss_scale=4, train_wall=313, gb_free=12.6, wall=300260
pred_new.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([2130, 42808])
2023-09-23 22:09:28 | INFO | train_inner | epoch 019:    755 / 9060 loss=7.111, nll_loss=3.477, ppl=11.13, wps=4352.6, ups=0.33, wpb=13126.5, bsz=432.4, num_updates=163800, lr=7.81345e-05, gnorm=1.02, loss_scale=4, train_wall=301, gb_free=14.9, wall=300562
pred_new.size(): torch.Size([7128, 42808])
2023-09-23 22:14:40 | INFO | train_inner | epoch 019:    855 / 9060 loss=6.967, nll_loss=3.399, ppl=10.55, wps=4155.1, ups=0.32, wpb=12970.6, bsz=446.4, num_updates=163900, lr=7.81107e-05, gnorm=1.015, loss_scale=4, train_wall=312, gb_free=13.2, wall=300874
2023-09-23 22:19:54 | INFO | train_inner | epoch 019:    955 / 9060 loss=7.054, nll_loss=3.444, ppl=10.89, wps=4188.2, ups=0.32, wpb=13151.4, bsz=421.9, num_updates=164000, lr=7.80869e-05, gnorm=1.044, loss_scale=4, train_wall=314, gb_free=13.3, wall=301188
2023-09-23 22:25:03 | INFO | train_inner | epoch 019:   1055 / 9060 loss=7.238, nll_loss=3.512, ppl=11.41, wps=4193.5, ups=0.32, wpb=12943.8, bsz=446.9, num_updates=164100, lr=7.80631e-05, gnorm=1.05, loss_scale=4, train_wall=308, gb_free=13.4, wall=301496
lprobs.size(): torch.Size([3496, 42808])
2023-09-23 22:30:03 | INFO | train_inner | epoch 019:   1155 / 9060 loss=7.113, nll_loss=3.484, ppl=11.19, wps=4327, ups=0.33, wpb=12990.5, bsz=448.1, num_updates=164200, lr=7.80393e-05, gnorm=1.042, loss_scale=4, train_wall=300, gb_free=12.9, wall=301797
2023-09-23 22:34:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-23 22:35:06 | INFO | train_inner | epoch 019:   1256 / 9060 loss=7.069, nll_loss=3.464, ppl=11.03, wps=4292.7, ups=0.33, wpb=13019.8, bsz=418.3, num_updates=164300, lr=7.80156e-05, gnorm=1.11, loss_scale=2, train_wall=303, gb_free=13.6, wall=302100
pred_new.size(): torch.Size([3382, 42808])
pred_new.size(): torch.Size([1113, 42808])
2023-09-23 22:40:13 | INFO | train_inner | epoch 019:   1356 / 9060 loss=7.041, nll_loss=3.444, ppl=10.88, wps=4197.4, ups=0.33, wpb=12885.5, bsz=413, num_updates=164400, lr=7.79918e-05, gnorm=1.078, loss_scale=2, train_wall=307, gb_free=13.7, wall=302407
2023-09-23 22:45:15 | INFO | train_inner | epoch 019:   1456 / 9060 loss=6.979, nll_loss=3.44, ppl=10.85, wps=4315.1, ups=0.33, wpb=12993.8, bsz=444.6, num_updates=164500, lr=7.79681e-05, gnorm=1.032, loss_scale=2, train_wall=301, gb_free=14, wall=302708
ter_threshold: 0.46452099999999996
num_accepted / total 23 64
loss token level: tensor(9300.3652, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8808., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 22:50:21 | INFO | train_inner | epoch 019:   1556 / 9060 loss=7.09, nll_loss=3.472, ppl=11.1, wps=4247.1, ups=0.33, wpb=13003.2, bsz=442.7, num_updates=164600, lr=7.79444e-05, gnorm=1.043, loss_scale=2, train_wall=306, gb_free=13.7, wall=303014
pred_new.size(): torch.Size([2583, 42808])
2023-09-23 22:55:33 | INFO | train_inner | epoch 019:   1656 / 9060 loss=7.105, nll_loss=3.475, ppl=11.12, wps=4149.2, ups=0.32, wpb=12935.3, bsz=432.6, num_updates=164700, lr=7.79208e-05, gnorm=1.068, loss_scale=2, train_wall=311, gb_free=14.7, wall=303326
lprobs.size(): torch.Size([2800, 42808])
2023-09-23 23:00:52 | INFO | train_inner | epoch 019:   1756 / 9060 loss=7.143, nll_loss=3.532, ppl=11.57, wps=4062.8, ups=0.31, wpb=12991.5, bsz=396.3, num_updates=164800, lr=7.78971e-05, gnorm=1.063, loss_scale=2, train_wall=319, gb_free=14.2, wall=303646
pred_new.size(): torch.Size([1575, 42808])
lprobs.size(): torch.Size([2992, 42808])
2023-09-23 23:05:57 | INFO | train_inner | epoch 019:   1856 / 9060 loss=7.137, nll_loss=3.487, ppl=11.21, wps=4247.8, ups=0.33, wpb=12959.7, bsz=440.1, num_updates=164900, lr=7.78735e-05, gnorm=1.046, loss_scale=2, train_wall=305, gb_free=13, wall=303951
2023-09-23 23:11:08 | INFO | train_inner | epoch 019:   1956 / 9060 loss=7.21, nll_loss=3.547, ppl=11.69, wps=4167.4, ups=0.32, wpb=12953, bsz=430, num_updates=165000, lr=7.78499e-05, gnorm=1.067, loss_scale=2, train_wall=311, gb_free=14.3, wall=304262
lprobs.size(): torch.Size([2584, 42808])
2023-09-23 23:16:24 | INFO | train_inner | epoch 019:   2056 / 9060 loss=7.294, nll_loss=3.587, ppl=12.02, wps=4128.8, ups=0.32, wpb=13020.9, bsz=434.5, num_updates=165100, lr=7.78263e-05, gnorm=1.071, loss_scale=2, train_wall=315, gb_free=13.8, wall=304577
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([2976, 42808])
2023-09-23 23:21:35 | INFO | train_inner | epoch 019:   2156 / 9060 loss=7.19, nll_loss=3.512, ppl=11.41, wps=4147.7, ups=0.32, wpb=12921.8, bsz=413.5, num_updates=165200, lr=7.78028e-05, gnorm=1.062, loss_scale=2, train_wall=311, gb_free=13.8, wall=304889
ter_threshold: 0.465234
num_accepted / total 2 40
loss token level: tensor(9325.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(833., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3243, 42808])
2023-09-23 23:26:43 | INFO | train_inner | epoch 019:   2256 / 9060 loss=7.15, nll_loss=3.473, ppl=11.1, wps=4190.6, ups=0.32, wpb=12895, bsz=445.6, num_updates=165300, lr=7.77792e-05, gnorm=1.04, loss_scale=2, train_wall=307, gb_free=14.1, wall=305196
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.465334
num_accepted / total 94 168
loss token level: tensor(8065.3276, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10528., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-23 23:31:49 | INFO | train_inner | epoch 019:   2356 / 9060 loss=6.999, nll_loss=3.452, ppl=10.94, wps=4215.8, ups=0.33, wpb=12916.1, bsz=404.6, num_updates=165400, lr=7.77557e-05, gnorm=1.049, loss_scale=2, train_wall=306, gb_free=14, wall=305503
pred_new.size(): torch.Size([7372, 42808])
2023-09-23 23:36:57 | INFO | train_inner | epoch 019:   2456 / 9060 loss=7.065, nll_loss=3.472, ppl=11.1, wps=4185, ups=0.33, wpb=12863.9, bsz=445.5, num_updates=165500, lr=7.77322e-05, gnorm=1.081, loss_scale=2, train_wall=307, gb_free=15, wall=305810
2023-09-23 23:42:09 | INFO | train_inner | epoch 019:   2556 / 9060 loss=7.323, nll_loss=3.593, ppl=12.06, wps=4152.7, ups=0.32, wpb=12959, bsz=435.2, num_updates=165600, lr=7.77087e-05, gnorm=1.068, loss_scale=2, train_wall=312, gb_free=12.9, wall=306122
pred_new.size(): torch.Size([7268, 42808])
2023-09-23 23:47:25 | INFO | train_inner | epoch 019:   2656 / 9060 loss=7.2, nll_loss=3.52, ppl=11.47, wps=4107.3, ups=0.32, wpb=13010.4, bsz=423.2, num_updates=165700, lr=7.76853e-05, gnorm=1.091, loss_scale=2, train_wall=316, gb_free=13.6, wall=306439
pred_new.size(): torch.Size([2457, 42808])
pred_new.size(): torch.Size([6111, 42808])
2023-09-23 23:52:46 | INFO | train_inner | epoch 019:   2756 / 9060 loss=7.228, nll_loss=3.555, ppl=11.75, wps=4076.8, ups=0.31, wpb=13064.1, bsz=425.2, num_updates=165800, lr=7.76619e-05, gnorm=1.068, loss_scale=2, train_wall=320, gb_free=15.1, wall=306759
pred_new.size(): torch.Size([798, 42808])
lprobs.size(): torch.Size([3344, 42808])
2023-09-23 23:58:03 | INFO | train_inner | epoch 019:   2856 / 9060 loss=7.194, nll_loss=3.544, ppl=11.66, wps=4098.1, ups=0.32, wpb=12991, bsz=411.1, num_updates=165900, lr=7.76384e-05, gnorm=1.073, loss_scale=2, train_wall=317, gb_free=14.6, wall=307076
lprobs.size(): torch.Size([3200, 42808])
2023-09-24 00:03:23 | INFO | train_inner | epoch 019:   2956 / 9060 loss=7.284, nll_loss=3.555, ppl=11.75, wps=4065.1, ups=0.31, wpb=13018.9, bsz=435.8, num_updates=166000, lr=7.76151e-05, gnorm=1.068, loss_scale=2, train_wall=320, gb_free=13.6, wall=307397
2023-09-24 00:08:31 | INFO | train_inner | epoch 019:   3056 / 9060 loss=7.2, nll_loss=3.539, ppl=11.63, wps=4222.7, ups=0.33, wpb=12985.3, bsz=441, num_updates=166100, lr=7.75917e-05, gnorm=1.073, loss_scale=2, train_wall=307, gb_free=15.1, wall=307704
2023-09-24 00:13:30 | INFO | train_inner | epoch 019:   3156 / 9060 loss=7.174, nll_loss=3.538, ppl=11.62, wps=4353.2, ups=0.33, wpb=13044.5, bsz=430.5, num_updates=166200, lr=7.75683e-05, gnorm=1.038, loss_scale=2, train_wall=299, gb_free=14.9, wall=308004
2023-09-24 00:18:28 | INFO | train_inner | epoch 019:   3256 / 9060 loss=7.202, nll_loss=3.52, ppl=11.47, wps=4328.6, ups=0.34, wpb=12899.7, bsz=426.5, num_updates=166300, lr=7.7545e-05, gnorm=1.052, loss_scale=2, train_wall=298, gb_free=14.2, wall=308302
2023-09-24 00:23:34 | INFO | train_inner | epoch 019:   3356 / 9060 loss=7.201, nll_loss=3.556, ppl=11.76, wps=4230.8, ups=0.33, wpb=12927.5, bsz=430, num_updates=166400, lr=7.75217e-05, gnorm=1.08, loss_scale=2, train_wall=305, gb_free=13.1, wall=308607
ter_threshold: 0.466404
num_accepted / total 30 88
loss token level: tensor(9743.7578, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8624., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3024, 42808])
2023-09-24 00:28:38 | INFO | train_inner | epoch 019:   3456 / 9060 loss=7.217, nll_loss=3.501, ppl=11.32, wps=4237.2, ups=0.33, wpb=12881.7, bsz=438.2, num_updates=166500, lr=7.74984e-05, gnorm=1.068, loss_scale=2, train_wall=304, gb_free=14.9, wall=308911
2023-09-24 00:33:39 | INFO | train_inner | epoch 019:   3556 / 9060 loss=7.136, nll_loss=3.492, ppl=11.25, wps=4320.3, ups=0.33, wpb=13022.3, bsz=428.9, num_updates=166600, lr=7.74752e-05, gnorm=1.051, loss_scale=2, train_wall=301, gb_free=14.7, wall=309213
ter_threshold: 0.466607
num_accepted / total 56 112
loss token level: tensor(9324.5723, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12208., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 00:38:49 | INFO | train_inner | epoch 019:   3656 / 9060 loss=7.226, nll_loss=3.569, ppl=11.87, wps=4218, ups=0.32, wpb=13045.7, bsz=405.6, num_updates=166700, lr=7.74519e-05, gnorm=1.079, loss_scale=2, train_wall=309, gb_free=13.5, wall=309522
2023-09-24 00:44:01 | INFO | train_inner | epoch 019:   3756 / 9060 loss=7.057, nll_loss=3.453, ppl=10.95, wps=4159.2, ups=0.32, wpb=13013.3, bsz=437.5, num_updates=166800, lr=7.74287e-05, gnorm=1.042, loss_scale=2, train_wall=313, gb_free=14, wall=309835
pred_new.size(): torch.Size([4466, 42808])
ter_threshold: 0.458465
num_accepted / total 35 112
loss token level: tensor(11282.9902, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4488., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([840, 42808])
ter_threshold: 0.45882
num_accepted / total 48 96
loss token level: tensor(8761.8906, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12624., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.45887100000000003
num_accepted / total 10 56
loss token level: tensor(9290.6719, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2564., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.459141
num_accepted / total 24 64
loss token level: tensor(9274.0859, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5692., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.459284
num_accepted / total 42 96
loss token level: tensor(8786.1035, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9896., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([2552, 42808])
pred_new.size(): torch.Size([6448, 42808])
pred_new.size(): torch.Size([4752, 42808])
pred_new.size(): torch.Size([4437, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3024, 42808])
ter_threshold: 0.460665
num_accepted / total 3 56
loss token level: tensor(8639.1738, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1086., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2968, 42808])
pred_new.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.461273
num_accepted / total 11 40
loss token level: tensor(8184.7461, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3748., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.46152099999999996
num_accepted / total 82 128
loss token level: tensor(8245.1895, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8640., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([1680, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.46194599999999997
num_accepted / total 144 224
loss token level: tensor(8716.9648, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8800., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.46218499999999996
num_accepted / total 64 112
loss token level: tensor(9011.7324, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13904., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.462477
num_accepted / total 52 120
loss token level: tensor(8949.1289, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5976., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.46253500000000003
num_accepted / total 12 24
loss token level: tensor(7244.7544, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11824., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5106, 42808])
pred_new.size(): torch.Size([2650, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1056, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([3822, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.463439
num_accepted / total 134 224
loss token level: tensor(8364.0205, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6848., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.463476
num_accepted / total 21 64
loss token level: tensor(8743.9609, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7952., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.4635
num_accepted / total 24 64
loss token level: tensor(10803.6631, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10608., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.46357
num_accepted / total 26 72
loss token level: tensor(10349.9736, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5284., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2340, 42808])
pred_new.size(): torch.Size([2964, 42808])
pred_new.size(): torch.Size([4356, 42808])
ter_threshold: 0.463878
num_accepted / total 48 96
loss token level: tensor(9166.3887, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7528., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([3870, 42808])
ter_threshold: 0.464121
num_accepted / total 13 64
loss token level: tensor(10430.1602, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5580., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([3680, 42808])
pred_new.size(): torch.Size([2655, 42808])
pred_new.size(): torch.Size([5148, 42808])
pred_new.size(): torch.Size([7791, 42808])
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([118, 42808])
pred_new.size(): torch.Size([7659, 42808])
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([3465, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1566, 42808])
pred_new.size(): torch.Size([2240, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.465222
num_accepted / total 46 96
loss token level: tensor(9039.5146, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7024., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.465334
num_accepted / total 33 112
loss token level: tensor(11250.8496, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6368., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4553, 42808])
pred_new.size(): torch.Size([2490, 42808])
pred_new.size(): torch.Size([4365, 42808])
pred_new.size(): torch.Size([4738, 42808])
pred_new.size(): torch.Size([3640, 42808])
pred_new.size(): torch.Size([5568, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2816, 42808])
ter_threshold: 0.466607
num_accepted / total 101 168
loss token level: tensor(8624.9502, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13376., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.466748
num_accepted / total 111 176
loss token level: tensor(9003.9863, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8544., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4316, 42808])
lprobs.size(): torch.Size([2080, 42808])
ter_threshold: 0.46683399999999997
num_accepted / total 7 40
loss token level: tensor(9161.5557, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: ter_threshold: 0.466813
num_accepted / total 20 112
loss token level: tensor(13081.3926, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2322., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 00:49:07 | INFO | train_inner | epoch 019:   3856 / 9060 loss=7.149, nll_loss=3.505, ppl=11.36, wps=4258.4, ups=0.33, wpb=13007.5, bsz=443, num_updates=166900, lr=7.74055e-05, gnorm=1.09, loss_scale=2, train_wall=305, gb_free=13.2, wall=310140
2023-09-24 00:54:17 | INFO | train_inner | epoch 019:   3956 / 9060 loss=7.062, nll_loss=3.494, ppl=11.26, wps=4201.8, ups=0.32, wpb=13039.5, bsz=411.3, num_updates=167000, lr=7.73823e-05, gnorm=1.021, loss_scale=2, train_wall=310, gb_free=13.6, wall=310451
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.46706
num_accepted / total 38 128
loss token level: tensor(8606.1406, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6056., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 00:59:25 | INFO | train_inner | epoch 019:   4056 / 9060 loss=7.2, nll_loss=3.551, ppl=11.72, wps=4228.4, ups=0.32, wpb=13018, bsz=427.6, num_updates=167100, lr=7.73592e-05, gnorm=1.088, loss_scale=2, train_wall=308, gb_free=14.1, wall=310759
2023-09-24 01:04:34 | INFO | train_inner | epoch 019:   4156 / 9060 loss=7.17, nll_loss=3.521, ppl=11.48, wps=4234.9, ups=0.32, wpb=13100.4, bsz=422.7, num_updates=167200, lr=7.7336e-05, gnorm=1.046, loss_scale=2, train_wall=309, gb_free=14.3, wall=311068
2023-09-24 01:09:47 | INFO | train_inner | epoch 019:   4256 / 9060 loss=7.311, nll_loss=3.578, ppl=11.94, wps=4119.6, ups=0.32, wpb=12894, bsz=431.6, num_updates=167300, lr=7.73129e-05, gnorm=1.1, loss_scale=2, train_wall=313, gb_free=13.3, wall=311381
lprobs.size(): torch.Size([3536, 42808])
2023-09-24 01:14:57 | INFO | train_inner | epoch 019:   4356 / 9060 loss=7.306, nll_loss=3.568, ppl=11.86, wps=4199.5, ups=0.32, wpb=12988.2, bsz=423, num_updates=167400, lr=7.72898e-05, gnorm=1.076, loss_scale=2, train_wall=309, gb_free=14.1, wall=311690
2023-09-24 01:19:55 | INFO | train_inner | epoch 019:   4456 / 9060 loss=7.172, nll_loss=3.514, ppl=11.42, wps=4352.9, ups=0.33, wpb=12999.1, bsz=434, num_updates=167500, lr=7.72667e-05, gnorm=1.067, loss_scale=2, train_wall=298, gb_free=13.8, wall=311989
ter_threshold: 0.467522
num_accepted / total 21 64
loss token level: tensor(9920.4941, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8976., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 01:24:53 | INFO | train_inner | epoch 019:   4556 / 9060 loss=7.082, nll_loss=3.49, ppl=11.24, wps=4316.6, ups=0.34, wpb=12866.9, bsz=421.4, num_updates=167600, lr=7.72437e-05, gnorm=1.049, loss_scale=2, train_wall=298, gb_free=13.5, wall=312287
ter_threshold: 0.467623
num_accepted / total 23 80
loss token level: tensor(10456.9727, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3940., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.46769499999999997
num_accepted / total 29 56
loss token level: tensor(7004.3838, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5184., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 01:29:54 | INFO | train_inner | epoch 019:   4656 / 9060 loss=7.015, nll_loss=3.464, ppl=11.04, wps=4300.2, ups=0.33, wpb=12929.8, bsz=433.7, num_updates=167700, lr=7.72207e-05, gnorm=1.037, loss_scale=2, train_wall=300, gb_free=13.6, wall=312588
ter_threshold: 0.46770599999999996
num_accepted / total 44 96
loss token level: tensor(8709.9795, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10624., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
2023-09-24 01:34:52 | INFO | train_inner | epoch 019:   4756 / 9060 loss=7.111, nll_loss=3.484, ppl=11.19, wps=4315.3, ups=0.34, wpb=12875.2, bsz=443.1, num_updates=167800, lr=7.71976e-05, gnorm=1.065, loss_scale=2, train_wall=298, gb_free=14.3, wall=312886
tensor(4820., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3008, 42808])
pred_new.size(): torch.Size([4438, 42808])
ter_threshold: 0.457615
num_accepted / total 6 56
loss token level: tensor(11378.9727, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2522., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1600, 42808])
pred_new.size(): torch.Size([6760, 42808])
pred_new.size(): torch.Size([2415, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4212, 42808])
ter_threshold: 0.458036
num_accepted / total 7 40
loss token level: tensor(9874.3740, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4488., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([2496, 42808])
ter_threshold: 0.458465
num_accepted / total 57 112
loss token level: tensor(9037.8867, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7008., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1892, 42808])
pred_new.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7120, 42808])
pred_new.size(): torch.Size([2180, 42808])
pred_new.size(): torch.Size([1440, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2256, 42808])
pred_new.size(): torch.Size([8555, 42808])
ter_threshold: 0.45887100000000003
num_accepted / total 29 64
loss token level: tensor(8526.8789, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6816., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.459284
num_accepted / total 61 112
loss token level: tensor(9113.3779, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12592., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([1650, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([588, 42808])
pred_new.size(): torch.Size([6000, 42808])
pred_new.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([7446, 42808])
pred_new.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([3224, 42808])
pred_new.size(): torch.Size([2880, 42808])
ter_threshold: 0.46057499999999996
num_accepted / total 32 112
loss token level: tensor(11419.7109, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6240., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.460631
num_accepted / total 13 40
loss token level: tensor(7950.9106, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4448., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([2754, 42808])
pred_new.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.461341
num_accepted / total 60 120
loss token level: tensor(9571.7334, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11744., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([1752, 42808])
ter_threshold: 0.46152099999999996
num_accepted / total 74 144
loss token level: tensor(8847.3750, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6920., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5376, 42808])
lprobs.size(): torch.Size([3504, 42808])
pred_new.size(): torch.Size([2880, 42808])
ter_threshold: 0.462341
num_accepted / total 105 184
loss token level: tensor(8835.9941, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7504., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2968, 42808])
pred_new.size(): torch.Size([7452, 42808])
pred_new.size(): torch.Size([2000, 42808])
pred_new.size(): torch.Size([4048, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2576, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([2560, 42808])
ter_threshold: 0.463439
num_accepted / total 22 80
loss token level: tensor(8838.9844, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3676., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5580, 42808])
pred_new.size(): torch.Size([5712, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([1824, 42808])
ter_threshold: 0.463878
num_accepted / total 40 96
loss token level: tensor(9087.1621, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6056., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3150, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([2997, 42808])
pred_new.size(): torch.Size([8432, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2312, 42808])
lprobs.size(): torch.Size([2448, 42808])
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.465334
num_accepted / total 74 144
loss token level: tensor(9231.1133, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12504., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([9144, 42808])
pred_new.size(): torch.Size([1760, 42808])
pred_new.size(): torch.Size([6909, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([1606, 42808])
pred_new.size(): torch.Size([2040, 42808])
ter_threshold: 0.466225
num_accepted / total 123 232
loss token level: tensor(7579.8486, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4808., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7881, 42808])
pred_new.size(): torch.Size([3570, 42808])
ter_threshold: 0.466794
num_accepted / total 40 80
loss token level: tensor(9713.9521, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13024., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.46686300000000003
num_accepted / total 63 112
loss token level: tensor(9123.9209, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13632., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.46706
num_accepted / total 17 104
loss token level: tensor(9182.0410, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3242., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2210, 42808])
lprobs.size(): torch.Size([3128, 42808])
ter_threshold: 0.46770599999999996
num_accepted / total 53 112
loss token level: tensor(8486.5049, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10880., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3600, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.467855
num_accepted / total 75 128
loss token level: lprobs.size(): torch.Size([3416, 42808])
2023-09-24 01:40:05 | INFO | train_inner | epoch 019:   4856 / 9060 loss=7.249, nll_loss=3.548, ppl=11.7, wps=4190.6, ups=0.32, wpb=13079, bsz=455.8, num_updates=167900, lr=7.71746e-05, gnorm=1.072, loss_scale=2, train_wall=312, gb_free=15.1, wall=313198
2023-09-24 01:45:14 | INFO | train_inner | epoch 019:   4956 / 9060 loss=7.092, nll_loss=3.473, ppl=11.1, wps=4198.3, ups=0.32, wpb=12984.1, bsz=424.1, num_updates=168000, lr=7.71517e-05, gnorm=1.073, loss_scale=2, train_wall=309, gb_free=14.5, wall=313507
pred_new.size(): torch.Size([2652, 42808])
pred_new.size(): torch.Size([3080, 42808])
2023-09-24 01:50:18 | INFO | train_inner | epoch 019:   5056 / 9060 loss=7.047, nll_loss=3.489, ppl=11.23, wps=4231.6, ups=0.33, wpb=12885, bsz=413.8, num_updates=168100, lr=7.71287e-05, gnorm=1.046, loss_scale=2, train_wall=304, gb_free=13.8, wall=313812
pred_new.size(): torch.Size([3312, 42808])
2023-09-24 01:55:30 | INFO | train_inner | epoch 019:   5156 / 9060 loss=7.147, nll_loss=3.501, ppl=11.32, wps=4205.6, ups=0.32, wpb=13106.1, bsz=427.4, num_updates=168200, lr=7.71058e-05, gnorm=1.062, loss_scale=2, train_wall=311, gb_free=14.8, wall=314123
pred_new.size(): torch.Size([3648, 42808])
lprobs.size(): torch.Size([3072, 42808])
2023-09-24 02:00:42 | INFO | train_inner | epoch 019:   5256 / 9060 loss=7.129, nll_loss=3.535, ppl=11.59, wps=4169.2, ups=0.32, wpb=12992.5, bsz=413.1, num_updates=168300, lr=7.70829e-05, gnorm=1.06, loss_scale=2, train_wall=311, gb_free=13.5, wall=314435
lprobs.size(): torch.Size([3328, 42808])
2023-09-24 02:05:49 | INFO | train_inner | epoch 019:   5356 / 9060 loss=7.023, nll_loss=3.44, ppl=10.85, wps=4245.2, ups=0.33, wpb=13054.9, bsz=442.1, num_updates=168400, lr=7.706e-05, gnorm=1.041, loss_scale=4, train_wall=307, gb_free=13.5, wall=314743
pred_new.size(): torch.Size([2970, 42808])
pred_new.size(): torch.Size([2550, 42808])
2023-09-24 02:10:57 | INFO | train_inner | epoch 019:   5456 / 9060 loss=7.071, nll_loss=3.487, ppl=11.21, wps=4211.2, ups=0.33, wpb=12951, bsz=430.8, num_updates=168500, lr=7.70371e-05, gnorm=1.051, loss_scale=4, train_wall=307, gb_free=13.6, wall=315050
2023-09-24 02:16:11 | INFO | train_inner | epoch 019:   5556 / 9060 loss=7.155, nll_loss=3.522, ppl=11.49, wps=4112.9, ups=0.32, wpb=12932, bsz=425.8, num_updates=168600, lr=7.70143e-05, gnorm=1.071, loss_scale=4, train_wall=314, gb_free=14, wall=315365
pred_new.size(): torch.Size([2268, 42808])
pred_new.size(): torch.Size([3360, 42808])
2023-09-24 02:21:24 | INFO | train_inner | epoch 019:   5656 / 9060 loss=7.062, nll_loss=3.473, ppl=11.11, wps=4121.1, ups=0.32, wpb=12877.9, bsz=431, num_updates=168700, lr=7.69914e-05, gnorm=1.039, loss_scale=4, train_wall=312, gb_free=13.2, wall=315677
lprobs.size(): torch.Size([3240, 42808])
2023-09-24 02:26:38 | INFO | train_inner | epoch 019:   5756 / 9060 loss=7.103, nll_loss=3.478, ppl=11.14, wps=4111.8, ups=0.32, wpb=12948.1, bsz=429.4, num_updates=168800, lr=7.69686e-05, gnorm=1.1, loss_scale=4, train_wall=315, gb_free=13.5, wall=315992
lprobs.size(): torch.Size([3480, 42808])
2023-09-24 02:31:48 | INFO | train_inner | epoch 019:   5856 / 9060 loss=7.167, nll_loss=3.505, ppl=11.36, wps=4190, ups=0.32, wpb=12987.1, bsz=416.7, num_updates=168900, lr=7.69458e-05, gnorm=1.059, loss_scale=4, train_wall=310, gb_free=13.2, wall=316302
pred_new.size(): torch.Size([4740, 42808])
2023-09-24 02:36:53 | INFO | train_inner | epoch 019:   5956 / 9060 loss=7.23, nll_loss=3.573, ppl=11.9, wps=4256.6, ups=0.33, wpb=12949.8, bsz=433.9, num_updates=169000, lr=7.69231e-05, gnorm=1.059, loss_scale=4, train_wall=304, gb_free=14.9, wall=316606
2023-09-24 02:41:59 | INFO | train_inner | epoch 019:   6056 / 9060 loss=7.204, nll_loss=3.55, ppl=11.71, wps=4215.7, ups=0.33, wpb=12906.1, bsz=441.5, num_updates=169100, lr=7.69003e-05, gnorm=1.059, loss_scale=4, train_wall=306, gb_free=15.7, wall=316912
lprobs.size(): torch.Size([3264, 42808])
2023-09-24 02:47:11 | INFO | train_inner | epoch 019:   6156 / 9060 loss=7.122, nll_loss=3.515, ppl=11.44, wps=4127.9, ups=0.32, wpb=12896.9, bsz=417, num_updates=169200, lr=7.68776e-05, gnorm=1.05, loss_scale=4, train_wall=312, gb_free=14.4, wall=317225
2023-09-24 02:52:15 | INFO | train_inner | epoch 019:   6256 / 9060 loss=7.145, nll_loss=3.515, ppl=11.43, wps=4255.5, ups=0.33, wpb=12939.5, bsz=438.6, num_updates=169300, lr=7.68549e-05, gnorm=1.067, loss_scale=4, train_wall=304, gb_free=12.8, wall=317529
2023-09-24 02:57:22 | INFO | train_inner | epoch 019:   6356 / 9060 loss=7.235, nll_loss=3.549, ppl=11.7, wps=4209.1, ups=0.33, wpb=12915.9, bsz=439.8, num_updates=169400, lr=7.68322e-05, gnorm=1.088, loss_scale=4, train_wall=307, gb_free=13.9, wall=317836
lprobs.size(): torch.Size([3200, 42808])
2023-09-24 03:01:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
2023-09-24 03:02:35 | INFO | train_inner | epoch 019:   6457 / 9060 loss=7.172, nll_loss=3.568, ppl=11.86, wps=4171.8, ups=0.32, wpb=13032.1, bsz=439.3, num_updates=169500, lr=7.68095e-05, gnorm=1.06, loss_scale=2, train_wall=312, gb_free=13.7, wall=318148
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([4158, 42808])
pred_new.size(): torch.Size([720, 42808])
2023-09-24 03:07:44 | INFO | train_inner | epoch 019:   6557 / 9060 loss=7.216, nll_loss=3.559, ppl=11.78, wps=4177.6, ups=0.32, wpb=12937.7, bsz=443, num_updates=169600, lr=7.67869e-05, gnorm=1.105, loss_scale=2, train_wall=309, gb_free=13.5, wall=318458
ter_threshold: 0.46968
num_accepted / total 80 128
loss token level: tensor(9231.6787, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(14976., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 03:12:50 | INFO | train_inner | epoch 019:   6657 / 9060 loss=7.115, nll_loss=3.516, ppl=11.44, wps=4275.4, ups=0.33, wpb=13062.1, bsz=421.3, num_updates=169700, lr=7.67643e-05, gnorm=1.036, loss_scale=2, train_wall=305, gb_free=14.4, wall=318763
2023-09-24 03:18:12 | INFO | train_inner | epoch 019:   6757 / 9060 loss=7.205, nll_loss=3.567, ppl=11.85, wps=4020.8, ups=0.31, wpb=12967.9, bsz=420.8, num_updates=169800, lr=7.67417e-05, gnorm=1.083, loss_scale=2, train_wall=322, gb_free=13.7, wall=319086
lprobs.size(): torch.Size([3312, 42808])
2023-09-24 03:23:22 | INFO | train_inner | epoch 019:   6857 / 9060 loss=6.986, nll_loss=3.447, ppl=10.9, wps=4197.4, ups=0.32, wpb=13014.8, bsz=424, num_updates=169900, lr=7.67191e-05, gnorm=1.065, loss_scale=2, train_wall=310, gb_free=15.1, wall=319396
2023-09-24 03:25:49 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
2023-09-24 03:28:38 | INFO | train_inner | epoch 019:   6958 / 9060 loss=7.102, nll_loss=3.525, ppl=11.52, wps=4091, ups=0.32, wpb=12914.7, bsz=437.3, num_updates=170000, lr=7.66965e-05, gnorm=1.059, loss_scale=1, train_wall=315, gb_free=14.6, wall=319711
2023-09-24 03:33:48 | INFO | train_inner | epoch 019:   7058 / 9060 loss=7.364, nll_loss=3.643, ppl=12.49, wps=4200.9, ups=0.32, wpb=13029.7, bsz=449.6, num_updates=170100, lr=7.6674e-05, gnorm=1.069, loss_scale=1, train_wall=310, gb_free=13.4, wall=320022
2023-09-24 03:38:51 | INFO | train_inner | epoch 019:   7158 / 9060 loss=7.214, nll_loss=3.549, ppl=11.7, wps=4284.5, ups=0.33, wpb=12976.1, bsz=426.7, num_updates=170200, lr=7.66514e-05, gnorm=1.062, loss_scale=1, train_wall=303, gb_free=13.6, wall=320325
2023-09-24 03:43:57 | INFO | train_inner | epoch 019:   7258 / 9060 loss=7.213, nll_loss=3.568, ppl=11.86, wps=4272.5, ups=0.33, wpb=13081.7, bsz=439.9, num_updates=170300, lr=7.66289e-05, gnorm=1.093, loss_scale=1, train_wall=306, gb_free=14, wall=320631
pred_new.size(): torch.Size([4284, 42808])
2023-09-24 03:49:11 | INFO | train_inner | epoch 019:   7358 / 9060 loss=7.33, nll_loss=3.576, ppl=11.93, wps=4150.2, ups=0.32, wpb=13040.2, bsz=449, num_updates=170400, lr=7.66064e-05, gnorm=1.075, loss_scale=1, train_wall=314, gb_free=13.1, wall=320945
2023-09-24 03:54:11 | INFO | train_inner | epoch 019:   7458 / 9060 loss=7.262, nll_loss=3.561, ppl=11.8, wps=4361.1, ups=0.33, wpb=13057.3, bsz=448.5, num_updates=170500, lr=7.6584e-05, gnorm=1.06, loss_scale=1, train_wall=299, gb_free=13.3, wall=321244
pred_new.size(): torch.Size([1860, 42808])
2023-09-24 03:59:12 | INFO | train_inner | epoch 019:   7558 / 9060 loss=7.157, nll_loss=3.546, ppl=11.68, wps=4301.4, ups=0.33, wpb=12948.7, bsz=435.2, num_updates=170600, lr=7.65615e-05, gnorm=1.079, loss_scale=1, train_wall=301, gb_free=13, wall=321545
lprobs.size(): torch.Size([2880, 42808])
2023-09-24 04:04:10 | INFO | train_inner | epoch 019:   7658 / 9060 loss=7.17, nll_loss=3.513, ppl=11.42, wps=4372.7, ups=0.34, wpb=13043.5, bsz=424.2, num_updates=170700, lr=7.65391e-05, gnorm=1.056, loss_scale=1, train_wall=298, gb_free=14.3, wall=321844
2023-09-24 04:09:13 | INFO | train_inner | epoch 019:   7758 / 9060 loss=7.154, nll_loss=3.549, ppl=11.71, wps=4274.6, ups=0.33, wpb=12951, bsz=413.6, num_updates=170800, lr=7.65167e-05, gnorm=1.061, loss_scale=1, train_wall=303, gb_free=14.7, wall=322147
pred_new.size(): torch.Size([1872, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-24 04:14:20 | INFO | train_inner | epoch 019:   7858 / 9060 loss=7.146, nll_loss=3.523, ppl=11.49, wps=4247.2, ups=0.33, wpb=13023.9, bsz=425.4, num_updates=170900, lr=7.64943e-05, gnorm=1.073, loss_scale=1, train_wall=306, gb_free=14.7, wall=322453
pred_new.size(): torch.Size([3996, 42808])
2023-09-24 04:19:43 | INFO | train_inner | epoch 019:   7958 / 9060 loss=7.171, nll_loss=3.519, ppl=11.46, wps=3994.1, ups=0.31, wpb=12905.1, bsz=415.8, num_updates=171000, lr=7.64719e-05, gnorm=1.071, loss_scale=1, train_wall=323, gb_free=12.8, wall=322776
pred_new.size(): torch.Size([4446, 42808])
pred_new.size(): torch.Size([3402, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-24 04:24:55 | INFO | train_inner | epoch 019:   8058 / 9060 loss=7.199, nll_loss=3.529, ppl=11.54, wps=4171.9, ups=0.32, wpb=13031, bsz=435.5, num_updates=171100, lr=7.64496e-05, gnorm=1.081, loss_scale=1, train_wall=312, gb_free=13.8, wall=323089
lprobs.size(): torch.Size([2640, 42808])
2023-09-24 04:30:12 | INFO | train_inner | epoch 019:   8158 / 9060 loss=7.122, nll_loss=3.501, ppl=11.33, wps=4098.6, ups=0.32, wpb=12982.3, bsz=427, num_updates=171200, lr=7.64272e-05, gnorm=1.053, loss_scale=1, train_wall=316, gb_free=14.8, wall=323405
lprobs.size(): torch.Size([3560, 42808])
pred_new.size(): torch.Size([3040, 42808])
2023-09-24 04:35:23 | INFO | train_inner | epoch 019:   8258 / 9060 loss=7.301, nll_loss=3.568, ppl=11.86, wps=4171, ups=0.32, wpb=12990.1, bsz=438.3, num_updates=171300, lr=7.64049e-05, gnorm=1.082, loss_scale=1, train_wall=311, gb_free=13.3, wall=323717
loss seque level: tensor(6540., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([976, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([4624, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([5000, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3320, 42808])
ter_threshold: 0.46218499999999996
num_accepted / total 63 128
loss token level: tensor(8811.1533, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10336., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1120, 42808])
ter_threshold: 0.462341
num_accepted / total 210 320
loss token level: tensor(9001.9297, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7944., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.462477
num_accepted / total 21 80
loss token level: tensor(8796.3418, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3384., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([1760, 42808])
pred_new.size(): torch.Size([7840, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2300, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([6846, 42808])
lprobs.size(): torch.Size([2664, 42808])
pred_new.size(): torch.Size([6111, 42808])
pred_new.size(): torch.Size([2268, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([4118, 42808])
ter_threshold: 0.463878
num_accepted / total 100 176
loss token level: tensor(8115.9741, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6536., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([2968, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([5244, 42808])
pred_new.size(): torch.Size([7105, 42808])
pred_new.size(): torch.Size([6660, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.465083
num_accepted / total 47 96
loss token level: tensor(8802.3857, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11536., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.465222
num_accepted / total 52 128
loss token level: tensor(8182.0498, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4728., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.465334
num_accepted / total 23 96
loss token level: tensor(12406.7510, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5920., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4600, 42808])
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1100, 42808])
pred_new.size(): torch.Size([4628, 42808])
pred_new.size(): torch.Size([5757, 42808])
ter_threshold: 0.46610799999999997
num_accepted / total 82 128
loss token level: tensor(9668.4199, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8528., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.466225
num_accepted / total 50 104
loss token level: tensor(9799.6797, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6272., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.466415
num_accepted / total 11 40
loss token level: tensor(8618.1152, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4086., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.466607
num_accepted / total 43 104
loss token level: tensor(9168.1914, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10128., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([2914, 42808])
ter_threshold: 0.46686300000000003
num_accepted / total 119 168
loss token level: tensor(8791.5527, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(15840., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([2244, 42808])
pred_new.size(): torch.Size([4524, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.467855
num_accepted / total 125 232
loss token level: tensor(9884.4697, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6496., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.467944
num_accepted / total 13 32
loss token level: tensor(7078.8730, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8608., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2552, 42808])
pred_new.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2952, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2580, 42808])
ter_threshold: 0.468564
num_accepted / total 19 64
loss token level: tensor(8404.3936, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7396., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([2816, 42808])
ter_threshold: 0.46879899999999997
num_accepted / total 15 32
loss token level: tensor(7018.5322, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5688., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2888, 42808])
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([5035, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.469288
num_accepted / total 15 56
loss token level: tensor(9783.0293, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4192., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4320, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([992, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6765, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2889, 42808])
pred_new.size(): torch.Size([3420, 42808])
pred_new.size(): torch.Size([5328, 42808])
pred_new.size(): torch.Size([6876, 42808])
pred_new.size(): torch.Size([3969, 42808])
pred_new.size(): torch.Size([4641, 42808])
pred_new.size(): torch.Size([4880, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([3096, 42808])
pred_new.size(): torch.Size([912, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.47133
num_accepted / total 125 192
loss token level: lprobs.size(): torch.Size([2992, 42808])
ter_threshold: 0.47133
num_accepted / total 77 144
loss token level: tensor(8450.9180, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11152., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 04:40:45 | INFO | train_inner | epoch 019:   8358 / 9060 loss=7.141, nll_loss=3.49, ppl=11.24, wps=3978.6, ups=0.31, wpb=12809, bsz=415, num_updates=171400, lr=7.63826e-05, gnorm=1.086, loss_scale=1, train_wall=322, gb_free=14.7, wall=324039
lprobs.size(): torch.Size([2744, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2728, 42808])
pred_new.size(): torch.Size([2886, 42808])
2023-09-24 04:45:55 | INFO | train_inner | epoch 019:   8458 / 9060 loss=7.156, nll_loss=3.52, ppl=11.47, wps=4140.3, ups=0.32, wpb=12815.4, bsz=413.7, num_updates=171500, lr=7.63604e-05, gnorm=1.081, loss_scale=1, train_wall=309, gb_free=14.5, wall=324348
2023-09-24 04:51:09 | INFO | train_inner | epoch 019:   8558 / 9060 loss=7.268, nll_loss=3.548, ppl=11.69, wps=4124.9, ups=0.32, wpb=12944.7, bsz=445.9, num_updates=171600, lr=7.63381e-05, gnorm=1.093, loss_scale=1, train_wall=314, gb_free=13.9, wall=324662
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.471637
num_accepted / total 41 96
loss token level: tensor(8694.6953, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5960., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 04:56:08 | INFO | train_inner | epoch 019:   8658 / 9060 loss=7.049, nll_loss=3.467, ppl=11.05, wps=4338.9, ups=0.33, wpb=12965.8, bsz=435.3, num_updates=171700, lr=7.63159e-05, gnorm=1.076, loss_scale=1, train_wall=299, gb_free=13.8, wall=324961
pred_new.size(): torch.Size([3640, 42808])
ter_threshold: 0.471781
num_accepted / total 39 112
loss token level: tensor(10875.7930, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5064., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 05:01:07 | INFO | train_inner | epoch 019:   8758 / 9060 loss=7.118, nll_loss=3.526, ppl=11.52, wps=4355.1, ups=0.33, wpb=13025, bsz=430.8, num_updates=171800, lr=7.62937e-05, gnorm=1.054, loss_scale=1, train_wall=299, gb_free=15.2, wall=325260
ter_threshold: 0.47180999999999995
num_accepted / total 207 272
loss token level: tensor(8930.7129, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(15056., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4144, 42808])
2023-09-24 05:06:13 | INFO | train_inner | epoch 019:   8858 / 9060 loss=7.146, nll_loss=3.505, ppl=11.35, wps=4233.9, ups=0.33, wpb=12959.8, bsz=430.6, num_updates=171900, lr=7.62715e-05, gnorm=1.073, loss_scale=1, train_wall=306, gb_free=13, wall=325566
ter_threshold: 0.471993
num_accepted / total 61 176
loss token level: tensor(8074.7388, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5488., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 05:11:08 | INFO | train_inner | epoch 019:   8958 / 9060 loss=7.005, nll_loss=3.471, ppl=11.08, wps=4390.8, ups=0.34, wpb=12965.9, bsz=422.5, num_updates=172000, lr=7.62493e-05, gnorm=1.048, loss_scale=1, train_wall=295, gb_free=13.5, wall=325862
pred_new.size(): torch.Size([1050, 42808])
lprobs.size(): torch.Size([3264, 42808])
2023-09-24 05:16:16 | INFO | train_inner | epoch 019:   9058 / 9060 loss=7.183, nll_loss=3.553, ppl=11.74, wps=4248.6, ups=0.33, wpb=13071.9, bsz=428.7, num_updates=172100, lr=7.62271e-05, gnorm=1.064, loss_scale=1, train_wall=307, gb_free=14.1, wall=326169
2023-09-24 05:16:27 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-24 05:16:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-24 05:16:28 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-24 05:16:28 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-24 05:16:28 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-24 05:16:28 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-24 05:16:28 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterbringung.
2023-09-24 05:16:28 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-24 05:16:29 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-24 05:16:29 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-24 05:16:30 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-24 05:16:30 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-24 05:16:30 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein voller Erfolg.
2023-09-24 05:16:30 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-24 05:16:31 | INFO | fairseq.tasks.translation | example hypothesis: (EN) Herr Präsident! Frohes Neues Jahr für alle und Glückwünsche an unseren Präsidenten.
2023-09-24 05:16:31 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-24 05:16:31 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-24 05:16:31 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-24 05:16:32 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-24 05:16:32 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-24 05:16:33 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten digitales Fernsehen und Internetzugang, die sowohl für Geschäftsreisende als auch für Urlauber attraktiv sind.
2023-09-24 05:16:33 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-24 05:16:33 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-24 05:16:33 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-24 05:16:34 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-24 05:16:34 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-24 05:16:34 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU als Ganzes enorme Mengen an Energie verschwendet.
2023-09-24 05:16:34 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-24 05:16:35 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-24 05:16:35 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-24 05:16:35 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Haltungsänderung in Kürze auch im Haushalt der Union niederschlagen.
2023-09-24 05:16:35 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-24 05:16:36 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-24 05:16:36 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-24 05:16:37 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-24 05:16:37 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-24 05:16:37 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-24 05:16:37 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-24 05:16:38 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie sich gewünscht hätten?
2023-09-24 05:16:38 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-24 05:16:38 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-24 05:16:38 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-24 05:16:39 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer Vorsitzender des Aufsichtsrats ist.
2023-09-24 05:16:39 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-24 05:16:39 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-24 05:16:39 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-24 05:16:40 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionale Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-24 05:16:40 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
lprobs.size(): torch.Size([3312, 42808])
2023-09-24 05:16:41 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potenzielle Käufer veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-24 05:16:41 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-24 05:16:41 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-24 05:16:41 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-24 05:16:42 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-24 05:16:42 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-24 05:16:42 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Aussprache, Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-24 05:16:42 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-24 05:16:43 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Lagen im Umkreis von etwa 8 Kilometern.
2023-09-24 05:16:43 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-24 05:16:44 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem bekannten Open Source Php-Nuke Web-Portal-System basiert.
2023-09-24 05:16:44 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-24 05:16:44 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-24 05:16:44 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-24 05:16:45 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-24 05:16:45 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-24 05:16:45 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-24 05:16:45 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-24 05:16:46 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Abreise Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-24 05:16:46 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-24 05:16:47 | INFO | fairseq.tasks.translation | example hypothesis: Alle früheren Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-24 05:16:47 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-24 05:16:47 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine freie Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-24 05:16:47 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-24 05:16:48 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie er Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-24 05:16:48 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-24 05:16:49 | INFO | fairseq.tasks.translation | example hypothesis: Trotzdem sind die Thatcheristischen Ideen über geringere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv zentrale Teile seiner Agenda.
2023-09-24 05:16:49 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-24 05:16:49 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-24 05:16:49 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-24 05:16:50 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können sich keine Gegenstände kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser benutzen.
2023-09-24 05:16:50 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-24 05:16:50 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-24 05:16:50 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-24 05:16:51 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn die Entlastung der Kommission für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-24 05:16:51 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-24 05:16:52 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens mit den Vereinigten Staaten abgeben müssen.
2023-09-24 05:16:52 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-24 05:16:52 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder besondere Edition - unser breites Sortiment an Plastik-Babyartikeln überzeugt nicht zuletzt durch seine hervorragende Verarbeitung.
2023-09-24 05:16:52 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-24 05:16:53 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-24 05:16:53 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-24 05:16:54 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Bekanntwerden dieser AGB über Sachsituationen zu unterrichten, die mit diesen AGB nicht vereinbar sind.
2023-09-24 05:16:54 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-24 05:16:55 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, da sie eine stärkere Präsenz im Bereich der Außen- und Verteidigung benötigt.
2023-09-24 05:16:55 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-24 05:16:55 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-24 05:16:55 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-24 05:16:56 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Prüfung aller Themen erzielt wurden, die jetzt diskutiert werden, und die etwas betreffen, das gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-24 05:16:56 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-24 05:16:56 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die optimale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-24 05:16:56 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-24 05:16:57 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal war der Berichterstatter in der Lage, gelegentlich unterschiedliche Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-24 05:16:57 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-24 05:16:58 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlagsgeräten um einen trockenen ESP für den unteren Leistungsbereich.
2023-09-24 05:16:58 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-24 05:16:59 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seit Jahrhunderten seine Freiheit und Unabhängigkeit verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-24 05:16:59 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-24 05:16:59 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und unseren Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-24 05:16:59 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-24 05:17:00 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und stützt sich auf Verhandlungen mit Drittländern, von denen viele seit Jahren bestehen und mit unserer Völkergemeinschaft zusammenhängen.
2023-09-24 05:17:00 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-24 05:17:01 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-24 05:17:01 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-24 05:17:01 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht der Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-24 05:17:01 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-24 05:17:02 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-24 05:17:02 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-24 05:17:03 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine andere: die Notlage der Kinder, des schwächsten Bevölkerungsschichten, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-24 05:17:03 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-24 05:17:03 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und unterstrichen werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen.
2023-09-24 05:17:03 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-24 05:17:04 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, nicht erst in der ersten Welt realisiert ist, bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt.
2023-09-24 05:17:04 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-24 05:17:05 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen.
2023-09-24 05:17:05 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-24 05:17:06 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-24 05:17:06 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-24 05:17:06 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken, die Plattform und Betriebssystem-Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-24 05:17:06 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-24 05:17:07 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen somit für die Klärung des Anhangs.
2023-09-24 05:17:07 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-24 05:17:08 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen haben, und fordert die WTO auf, klar zu erklären, dass die von der IAO verhängten Sanktionen nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-24 05:17:08 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-24 05:17:09 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe vor kurzem an einer Aussprache über das irische Radio RTÉ des öffentlichen Dienstes teilgenommen, mit einer Frau, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-24 05:17:09 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
lprobs.size(): torch.Size([3360, 42808])
2023-09-24 05:17:09 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und ich möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-24 05:17:09 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-24 05:17:10 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie nach Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist................
2023-09-24 05:17:10 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-24 05:17:11 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, dem schönen Wien und dem bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten offen.
2023-09-24 05:17:11 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-24 05:17:12 | INFO | fairseq.tasks.translation | example hypothesis: - Herr Präsident! Ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-24 05:17:12 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-24 05:17:12 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken, hieße, eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen oft die reale oder wahrgenommene Bedrohung, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-24 05:17:12 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-24 05:17:13 | INFO | fairseq.tasks.translation | example hypothesis: In der Gemeinschaftsgerichtsbarkeit zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn zum Beispiel die Bürger Ansprüche erheben oder eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-24 05:17:13 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-24 05:17:14 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Autos unter $50.000 und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-24 05:17:14 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-24 05:17:15 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darlegung der Angelegenheit danken.
2023-09-24 05:17:15 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-24 05:17:15 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die hervorragenden Süßwasserfische: gegrillter Hecht, Forelle mit Mandeln.
2023-09-24 05:17:15 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-24 05:17:16 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, einen Gesamtüberblick zu bieten, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu prüfen, welche Impulse die Europäische Union im Hinblick auf die Zukunft erhalten kann.
2023-09-24 05:17:16 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-24 05:17:17 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, stimmten der Veröffentlichung eines Live-Albums "Bodulska balada 2009" zu.
2023-09-24 05:17:17 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-24 05:17:18 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze bedroht sind und die Wettbewerbsfähigkeit aufgrund der makroökonomischen Politik, der steuerlichen Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, schrittweise abgebaut wird.
2023-09-24 05:17:18 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-24 05:17:19 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein ausgezeichnetes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, das alle unsere Änderungsanträge in den Text aufgenommen hat.
2023-09-24 05:17:19 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-24 05:17:20 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den Rechts- und Rechtsbereich, was Norwegen und Island, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen gelten werden, zu den norwegischen und isländischen Ländern macht.
2023-09-24 05:17:20 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-24 05:17:20 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schichtboot den Mississippi hinunterfahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der reinen Dynamik ist, und vor allem werden wir große Freunde sein.......................
2023-09-24 05:17:20 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-24 05:17:21 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der Verschmutzung durch Schiffe, die durch Einzelpersonen oder Rechtspersonen verursacht wird, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die im Falle solcher Verstöße von Einzelpersonen verhängt werden können.
2023-09-24 05:17:21 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-24 05:17:22 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falized und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner verrichteten und eine Gruppe von Berbern filmten, die jahrelang von einem autoritären Regime gejagt wurden, das jedes Prinzip der Demokratie missachtet.
2023-09-24 05:17:22 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-24 05:17:23 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Wechselstube, kostenloser Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das Französische Viertel.
2023-09-24 05:17:23 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-24 05:17:24 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, die Frau von König D. João II., sehr geliebt ist, und die durch ihre Keramik international bekannt für ihre bildlichen und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-24 05:17:24 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-24 05:17:25 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es sei ein Fall guter Pro-Westler auf der einen Seite und Befürworter des früheren Regimes auf der anderen Seite - das ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-24 05:17:25 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-24 05:17:26 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und dem Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.......................
2023-09-24 05:17:26 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-24 05:17:26 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär aufgrund seines Status als Aktionär außerhalb einer Aktionärsversammlung Informationen übermittelt, so werden diese auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung übermittelt, auch wenn diese Informationen für eine ordnungsgemäße Bewertung eines Tagesordnungspunktes nicht erforderlich sind.
2023-09-24 05:17:26 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-24 05:17:27 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr elendes Leben führen.
2023-09-24 05:17:27 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-24 05:17:28 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder der NATO hätten in diesen Kriegshandlungen verwickelt sein können -, bei Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, geheimgehalten oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen und die ganze Wahrheit sagen können..........................
2023-09-24 05:17:28 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-24 05:17:29 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug von der Innenstadt entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-24 05:17:29 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-24 05:17:30 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Business Unit Defence Electronics und Indra in Spanien, wird das Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen, die die heutigen Plattformen außerhalb des Regals niemals erreichen können, von entscheidender Bedeutung sind. die moderne Offline-Plattformen niemals erreichen können.
2023-09-24 05:17:30 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-24 05:17:31 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir nicht nur für uns, sondern weltweit die Produkte vom Markt nehmen können, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt ein ernstes Risiko darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 feststellt.
2023-09-24 05:17:31 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-24 05:17:32 | INFO | fairseq.tasks.translation | example hypothesis: Unter dem einfachen Deckmantel der Modernität und Postmoderne oder des klaren Widerstands von reiner Kunst und engagierter Kunst müssen wir die originale und dauerhafte Spannung dieser beiden ästhetischen Politik erkennen, die in den Formen der Sichtbarkeit und Verständlichkeit verbirgt, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen..........................
2023-09-24 05:17:32 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-24 05:17:33 | INFO | fairseq.tasks.translation | example hypothesis: Doch was den heutigen Tag betrifft, so werde ich angesichts der Bedeutung der Aussprachen und der Stellungnahmen, die Sie mir abgegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der früheren Beschlüsse unsere Aussprachen führen, und bei der Abstimmung, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht beantragen, die Beschlußfähigkeit zu überprüfen.
2023-09-24 05:17:33 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-24 05:17:34 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips niemals akzeptiert haben, so sind es paradoxerweise gerade diejenigen, die, kaum bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen aufgehoben wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen.........................
2023-09-24 05:17:34 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-24 05:17:35 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Hinsicht als Hybridform publiziert, die Rezensionen und Artikel der vierteljährlichen Zeitschrift sind für H-Soz-u-Kult geschrieben und über Mailinglisten sowie über die Webseiten des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt.
2023-09-24 05:17:35 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-24 05:17:36 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Handys ihre Federn deutlich verdichtet, von einstigen Wecker im Taschenformat über polyphonisch tosende Game Boy-Ambitionen bis hin zu MiniPCs mit knackigem Stereo-Sound in CD-Qualität: Dank ihrer besonderen Kombination von Fähigkeiten könnten sie von den ehemaligen me-too-Wannabes zu Trailblazers neuer technologischer Entwicklungen entwickeln.
2023-09-24 05:17:36 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-24 05:17:39 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dirige la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen.
2023-09-24 05:17:39 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-24 05:17:39 | INFO | valid | epoch 019 | valid on 'valid' subset | loss 4.131 | nll_loss 2.158 | ppl 4.46 | bleu 28.61 | wps 16448.2 | wpb 12011.9 | bsz 398.1 | num_updates 172102 | best_bleu 29.48
2023-09-24 05:17:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 172102 updates
2023-09-24 05:17:39 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint19.pt
2023-09-24 05:17:45 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint19.pt
2023-09-24 05:17:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint19.pt (epoch 19 @ 172102 updates, score 28.61) (writing took 9.462211202015169 seconds)
2023-09-24 05:17:49 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2023-09-24 05:17:49 | INFO | train | epoch 019 | loss 7.155 | nll_loss 3.514 | ppl 11.43 | wps 4196.6 | ups 0.32 | wpb 12977.1 | bsz 430.6 | num_updates 172102 | lr 7.62267e-05 | gnorm 1.063 | loss_scale 1 | train_wall 27901 | gb_free 14 | wall 326262
2023-09-24 05:17:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-24 05:17:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-24 05:17:49 | INFO | fairseq.trainer | begin training epoch 20
2023-09-24 05:17:49 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-24 05:22:42 | INFO | train_inner | epoch 020:     98 / 9060 loss=7.064, nll_loss=3.441, ppl=10.86, wps=3340.2, ups=0.26, wpb=12917.5, bsz=402.2, num_updates=172200, lr=7.6205e-05, gnorm=1.052, loss_scale=1, train_wall=305, gb_free=14.3, wall=326556
ter_threshold: 0.472296
num_accepted / total 74 176
loss token level: tensor(10273.7305, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9704., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 05:27:48 | INFO | train_inner | epoch 020:    198 / 9060 loss=7.107, nll_loss=3.472, ppl=11.09, wps=4231.9, ups=0.33, wpb=12943.4, bsz=435, num_updates=172300, lr=7.61829e-05, gnorm=1.047, loss_scale=1, train_wall=306, gb_free=14.5, wall=326862
pred_new.size(): torch.Size([7203, 42808])
ter_threshold: 0.47233499999999995
num_accepted / total 26 72
loss token level: tensor(8537.9961, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8136., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.472358
num_accepted / total 27 96
loss token level: tensor(9957.5332, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3716., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1919, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-24 05:33:05 | INFO | train_inner | epoch 020:    298 / 9060 loss=7.317, nll_loss=3.581, ppl=11.97, wps=4135.8, ups=0.32, wpb=13081.5, bsz=453, num_updates=172400, lr=7.61608e-05, gnorm=1.085, loss_scale=1, train_wall=316, gb_free=13, wall=327178
ter_threshold: 0.472441
num_accepted / total 52 152
loss token level: tensor(8510.0117, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5800., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 05:38:08 | INFO | train_inner | epoch 020:    398 / 9060 loss=7.284, nll_loss=3.544, ppl=11.66, wps=4289.4, ups=0.33, wpb=13033.1, bsz=420.4, num_updates=172500, lr=7.61387e-05, gnorm=1.094, loss_scale=1, train_wall=304, gb_free=13.1, wall=327482
2023-09-24 05:43:15 | INFO | train_inner | epoch 020:    498 / 9060 loss=7.143, nll_loss=3.504, ppl=11.35, wps=4235.2, ups=0.33, wpb=12993.8, bsz=434.2, num_updates=172600, lr=7.61166e-05, gnorm=1.071, loss_scale=1, train_wall=307, gb_free=13.9, wall=327789
pred_new.size(): torch.Size([585, 42808])
pred_new.size(): torch.Size([7462, 42808])
pred_new.size(): torch.Size([728, 42808])
2023-09-24 05:48:26 | INFO | train_inner | epoch 020:    598 / 9060 loss=7.149, nll_loss=3.482, ppl=11.17, wps=4167, ups=0.32, wpb=12966.8, bsz=420.4, num_updates=172700, lr=7.60946e-05, gnorm=1.072, loss_scale=1, train_wall=311, gb_free=15.1, wall=328100
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3552, 42808])
2023-09-24 05:53:28 | INFO | train_inner | epoch 020:    698 / 9060 loss=7.155, nll_loss=3.515, ppl=11.43, wps=4304.5, ups=0.33, wpb=12980.3, bsz=428.1, num_updates=172800, lr=7.60726e-05, gnorm=1.063, loss_scale=1, train_wall=301, gb_free=14.8, wall=328401
pred_new.size(): torch.Size([6020, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-24 05:58:51 | INFO | train_inner | epoch 020:    798 / 9060 loss=7.397, nll_loss=3.616, ppl=12.26, wps=4005.6, ups=0.31, wpb=12952.5, bsz=430.6, num_updates=172900, lr=7.60506e-05, gnorm=1.163, loss_scale=1, train_wall=323, gb_free=13.5, wall=328725
2023-09-24 06:04:03 | INFO | train_inner | epoch 020:    898 / 9060 loss=7.207, nll_loss=3.529, ppl=11.55, wps=4145, ups=0.32, wpb=12926.1, bsz=418.2, num_updates=173000, lr=7.60286e-05, gnorm=1.09, loss_scale=1, train_wall=312, gb_free=14.6, wall=329037
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
2023-09-24 06:09:08 | INFO | train_inner | epoch 020:    998 / 9060 loss=7.148, nll_loss=3.48, ppl=11.15, wps=4289.4, ups=0.33, wpb=13093, bsz=438.8, num_updates=173100, lr=7.60066e-05, gnorm=1.33, loss_scale=1, train_wall=305, gb_free=14.4, wall=329342
lprobs.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-24 06:14:12 | INFO | train_inner | epoch 020:   1098 / 9060 loss=7.192, nll_loss=3.497, ppl=11.29, wps=4248.8, ups=0.33, wpb=12917.6, bsz=426.3, num_updates=173200, lr=7.59847e-05, gnorm=1.075, loss_scale=1, train_wall=304, gb_free=14.4, wall=329646
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-24 06:19:31 | INFO | train_inner | epoch 020:   1198 / 9060 loss=7.329, nll_loss=3.569, ppl=11.87, wps=4076.1, ups=0.31, wpb=12974.5, bsz=443.5, num_updates=173300, lr=7.59628e-05, gnorm=1.106, loss_scale=1, train_wall=318, gb_free=14.6, wall=329964
2023-09-24 06:24:44 | INFO | train_inner | epoch 020:   1298 / 9060 loss=7.124, nll_loss=3.492, ppl=11.25, wps=4120, ups=0.32, wpb=12888.9, bsz=430.2, num_updates=173400, lr=7.59408e-05, gnorm=1.092, loss_scale=1, train_wall=313, gb_free=13.9, wall=330277
lprobs.size(): torch.Size([3408, 42808])
2023-09-24 06:29:52 | INFO | train_inner | epoch 020:   1398 / 9060 loss=7.376, nll_loss=3.631, ppl=12.39, wps=4219.8, ups=0.32, wpb=12995.9, bsz=433.4, num_updates=173500, lr=7.5919e-05, gnorm=1.089, loss_scale=1, train_wall=308, gb_free=14.3, wall=330585
pred_new.size(): torch.Size([2805, 42808])
ter_threshold: 0.47353599999999996
num_accepted / total 27 72
loss token level: tensor(8812.7910, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8656., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.473551
num_accepted / total 41 80
loss token level: tensor(9334.1699, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12896., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([2592, 42808])
2023-09-24 06:35:05 | INFO | train_inner | epoch 020:   1498 / 9060 loss=7.198, nll_loss=3.499, ppl=11.31, wps=4142.5, ups=0.32, wpb=12999.7, bsz=459.8, num_updates=173600, lr=7.58971e-05, gnorm=1.071, loss_scale=1, train_wall=314, gb_free=14.9, wall=330899
2023-09-24 06:40:12 | INFO | train_inner | epoch 020:   1598 / 9060 loss=7.144, nll_loss=3.503, ppl=11.34, wps=4214.5, ups=0.33, wpb=12938.1, bsz=435, num_updates=173700, lr=7.58752e-05, gnorm=1.069, loss_scale=1, train_wall=307, gb_free=14.2, wall=331206
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3000, 42808])
2023-09-24 06:45:18 | INFO | train_inner | epoch 020:   1698 / 9060 loss=7.178, nll_loss=3.502, ppl=11.33, wps=4275.2, ups=0.33, wpb=13060, bsz=425, num_updates=173800, lr=7.58534e-05, gnorm=1.061, loss_scale=1, train_wall=305, gb_free=14.3, wall=331511
ter_threshold: 0.473809
num_accepted / total 13 56
loss token level: tensor(8578.3438, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2868., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3425, 42808])
2023-09-24 06:50:40 | INFO | train_inner | epoch 020:   1798 / 9060 loss=7.316, nll_loss=3.589, ppl=12.04, wps=4044.3, ups=0.31, wpb=13009.4, bsz=426, num_updates=173900, lr=7.58316e-05, gnorm=1.08, loss_scale=1, train_wall=321, gb_free=13.5, wall=331833
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2668, 42808])
2023-09-24 06:55:50 | INFO | train_inner | epoch 020:   1898 / 9060 loss=7.179, nll_loss=3.49, ppl=11.24, wps=4191.9, ups=0.32, wpb=13011.6, bsz=433.3, num_updates=174000, lr=7.58098e-05, gnorm=1.075, loss_scale=1, train_wall=310, gb_free=13.4, wall=332143
lprobs.size(): torch.Size([3584, 42808])
2023-09-24 07:00:49 | INFO | train_inner | epoch 020:   1998 / 9060 loss=7.111, nll_loss=3.518, ppl=11.45, wps=4316.5, ups=0.33, wpb=12927.7, bsz=428.6, num_updates=174100, lr=7.5788e-05, gnorm=1.059, loss_scale=2, train_wall=299, gb_free=13.8, wall=332443
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.474139
num_accepted / total 67 144
loss token level: tensor(9030.7842, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10928., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.47414
num_accepted / total 105 168
loss token level: tensor(8431.9062, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8224., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 07:05:58 | INFO | train_inner | epoch 020:   2098 / 9060 loss=7.193, nll_loss=3.544, ppl=11.66, wps=4188.4, ups=0.32, wpb=12928.8, bsz=417, num_updates=174200, lr=7.57663e-05, gnorm=1.077, loss_scale=2, train_wall=308, gb_free=13.6, wall=332752
2023-09-24 07:11:15 | INFO | train_inner | epoch 020:   2198 / 9060 loss=7.36, nll_loss=3.608, ppl=12.19, wps=4082.6, ups=0.32, wpb=12951.9, bsz=439.6, num_updates=174300, lr=7.57445e-05, gnorm=1.107, loss_scale=2, train_wall=317, gb_free=15.7, wall=333069
ter_threshold: 0.474371
num_accepted / total 4 56
loss token level: tensor(9299.7852, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1316., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 07:16:27 | INFO | train_inner | epoch 020:   2298 / 9060 loss=7.21, nll_loss=3.517, ppl=11.45, wps=4144.2, ups=0.32, wpb=12929.5, bsz=439.8, num_updates=174400, lr=7.57228e-05, gnorm=1.083, loss_scale=2, train_wall=312, gb_free=13.2, wall=333381
2023-09-24 07:21:34 | INFO | train_inner | epoch 020:   2398 / 9060 loss=7.105, nll_loss=3.508, ppl=11.38, wps=4237.2, ups=0.33, wpb=13011.7, bsz=407.4, num_updates=174500, lr=7.57011e-05, gnorm=1.109, loss_scale=2, train_wall=307, gb_free=13, wall=333688
pred_new.size(): torch.Size([1232, 42808])
pred_new.size(): torch.Size([2718, 42808])
2023-09-24 07:26:43 | INFO | train_inner | epoch 020:   2498 / 9060 loss=7.211, nll_loss=3.538, ppl=11.61, wps=4207.1, ups=0.32, wpb=12965.1, bsz=436.6, num_updates=174600, lr=7.56794e-05, gnorm=1.076, loss_scale=2, train_wall=308, gb_free=15.5, wall=333996
2023-09-24 07:31:54 | INFO | train_inner | epoch 020:   2598 / 9060 loss=7.234, nll_loss=3.53, ppl=11.55, wps=4151.7, ups=0.32, wpb=12940.3, bsz=407.9, num_updates=174700, lr=7.56578e-05, gnorm=1.081, loss_scale=2, train_wall=311, gb_free=13.1, wall=334308
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3216, 42808])
2023-09-24 07:37:02 | INFO | train_inner | epoch 020:   2698 / 9060 loss=7.327, nll_loss=3.58, ppl=11.96, wps=4212.7, ups=0.32, wpb=12962.4, bsz=444.1, num_updates=174800, lr=7.56361e-05, gnorm=1.092, loss_scale=2, train_wall=307, gb_free=12.9, wall=334615
2023-09-24 07:42:18 | INFO | train_inner | epoch 020:   2798 / 9060 loss=7.313, nll_loss=3.585, ppl=12, wps=4109.7, ups=0.32, wpb=12982.2, bsz=418.8, num_updates=174900, lr=7.56145e-05, gnorm=1.088, loss_scale=2, train_wall=316, gb_free=13.9, wall=334931
2023-09-24 07:47:34 | INFO | train_inner | epoch 020:   2898 / 9060 loss=7.332, nll_loss=3.594, ppl=12.08, wps=4129.7, ups=0.32, wpb=13037.6, bsz=433.4, num_updates=175000, lr=7.55929e-05, gnorm=1.092, loss_scale=2, train_wall=315, gb_free=13.6, wall=335247
tensor(4224., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.46686300000000003
num_accepted / total 51 96
loss token level: tensor(8846.2559, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11776., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.46706
num_accepted / total 15 88
loss token level: tensor(11923.0215, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4340., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.467091
num_accepted / total 23 64
loss token level: tensor(9272.2168, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9216., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2379, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([2640, 42808])
ter_threshold: 0.467855
num_accepted / total 30 96
loss token level: tensor(11491.5527, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4192., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([2222, 42808])
pred_new.size(): torch.Size([1040, 42808])
pred_new.size(): torch.Size([5724, 42808])
pred_new.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3393, 42808])
ter_threshold: 0.46882199999999996
num_accepted / total 9 56
loss token level: tensor(9737.0840, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4104., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([7245, 42808])
ter_threshold: 0.46919
num_accepted / total 3 32
loss token level: tensor(9811.2705, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2262., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.469479
num_accepted / total 12 80
loss token level: tensor(14138.1104, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4036., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([924, 42808])
lprobs.size(): torch.Size([2424, 42808])
ter_threshold: 0.46968
num_accepted / total 90 160
loss token level: tensor(9546.7363, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13136., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1974, 42808])
lprobs.size(): torch.Size([3296, 42808])
pred_new.size(): torch.Size([1020, 42808])
pred_new.size(): torch.Size([2622, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.47021599999999997
num_accepted / total 211 296
loss token level: tensor(9285.9062, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8600., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([6405, 42808])
pred_new.size(): torch.Size([4200, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2624, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([5670, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5735, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([1896, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2320, 42808])
pred_new.size(): torch.Size([5700, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([7791, 42808])
pred_new.size(): torch.Size([2436, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5481, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([1521, 42808])
ter_threshold: 0.471194
num_accepted / total 12 48
loss token level: tensor(9059.6914, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6392., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2128, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.471637
num_accepted / total 73 136
loss token level: tensor(9248.6484, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6980., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1628, 42808])
pred_new.size(): torch.Size([5688, 42808])
ter_threshold: 0.471781
num_accepted / total 97 176
loss token level: tensor(6705.8760, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4112., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.47180999999999995
num_accepted / total 91 144
loss token level: tensor(8906.8262, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(14640., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3120, 42808])
ter_threshold: 0.471993
num_accepted / total 14 80
loss token level: tensor(8750.1387, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3276., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2800, 42808])
ter_threshold: 0.472296
num_accepted / total 50 96
loss token level: tensor(8336.8906, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11104., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([7685, 42808])
pred_new.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.47283699999999995
num_accepted / total 39 96
loss token level: tensor(8569.4229, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5648., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2808, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.47304
num_accepted / total 36 80
loss token level: tensor(9379.6172, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6900., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([4704, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6960, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([3780, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2808, 42808])
lprobs.size(): torch.Size([3272, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2496, 42808])
ter_threshold: 0.474139
num_accepted / total 140 296
loss token level: tensor(10021.1074, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9016., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.47416
num_accepted / total 52 96
loss token level: tensor(9619.0479, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8864., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4578, 42808])
pred_new.size(): torch.Size([2970, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([4288, 42808])
pred_new.size(): torch.Size([3645, 42808])
pred_new.size(): ter_threshold: 0.47501
num_accepted / total 12 48
loss token level: tensor(8297.7744, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3684., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.475066
num_accepted / total 20 88
loss token level: tensor(12949.6484, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3554., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 07:52:40 | INFO | train_inner | epoch 020:   2998 / 9060 loss=7.108, nll_loss=3.535, ppl=11.59, wps=4220, ups=0.33, wpb=12941.2, bsz=428.8, num_updates=175100, lr=7.55713e-05, gnorm=1.054, loss_scale=2, train_wall=306, gb_free=14.4, wall=335554
ter_threshold: 0.475117
num_accepted / total 22 80
loss token level: tensor(9933.6387, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3886., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.475128
num_accepted / total 42 136
loss token level: tensor(12255.8887, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6672., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([972, 42808])
2023-09-24 07:57:58 | INFO | train_inner | epoch 020:   3098 / 9060 loss=7.147, nll_loss=3.526, ppl=11.52, wps=4056.6, ups=0.31, wpb=12880.4, bsz=462.8, num_updates=175200, lr=7.55497e-05, gnorm=1.074, loss_scale=2, train_wall=317, gb_free=13.5, wall=335871
ter_threshold: 0.475237
num_accepted / total 36 80
loss token level: tensor(9265.6318, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12160., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
2023-09-24 08:03:20 | INFO | train_inner | epoch 020:   3198 / 9060 loss=7.189, nll_loss=3.503, ppl=11.34, wps=4027, ups=0.31, wpb=12978.2, bsz=406.3, num_updates=175300, lr=7.55282e-05, gnorm=1.102, loss_scale=2, train_wall=322, gb_free=15.6, wall=336194
lprobs.size(): torch.Size([3528, 42808])
2023-09-24 08:08:27 | INFO | train_inner | epoch 020:   3298 / 9060 loss=7.162, nll_loss=3.526, ppl=11.52, wps=4256.3, ups=0.33, wpb=13046.9, bsz=446.6, num_updates=175400, lr=7.55067e-05, gnorm=1.061, loss_scale=2, train_wall=306, gb_free=13.5, wall=336500
pred_new.size(): torch.Size([4941, 42808])
2023-09-24 08:13:47 | INFO | train_inner | epoch 020:   3398 / 9060 loss=7.153, nll_loss=3.492, ppl=11.25, wps=4047.5, ups=0.31, wpb=12968.5, bsz=420.8, num_updates=175500, lr=7.54851e-05, gnorm=1.099, loss_scale=2, train_wall=320, gb_free=13, wall=336820
pred_new.size(): torch.Size([4794, 42808])
2023-09-24 08:19:04 | INFO | train_inner | epoch 020:   3498 / 9060 loss=7.18, nll_loss=3.499, ppl=11.3, wps=4128.9, ups=0.32, wpb=13093.6, bsz=439.3, num_updates=175600, lr=7.54636e-05, gnorm=1.054, loss_scale=2, train_wall=317, gb_free=14.3, wall=337138
2023-09-24 08:24:17 | INFO | train_inner | epoch 020:   3598 / 9060 loss=7.114, nll_loss=3.524, ppl=11.5, wps=4143.3, ups=0.32, wpb=12954.4, bsz=401.6, num_updates=175700, lr=7.54422e-05, gnorm=1.068, loss_scale=2, train_wall=312, gb_free=14.2, wall=337450
pred_new.size(): torch.Size([4950, 42808])
2023-09-24 08:29:34 | INFO | train_inner | epoch 020:   3698 / 9060 loss=7.297, nll_loss=3.566, ppl=11.85, wps=4092, ups=0.32, wpb=12976, bsz=427.4, num_updates=175800, lr=7.54207e-05, gnorm=1.097, loss_scale=2, train_wall=317, gb_free=12.9, wall=337767
pred_new.size(): torch.Size([4408, 42808])
2023-09-24 08:34:43 | INFO | train_inner | epoch 020:   3798 / 9060 loss=7.009, nll_loss=3.468, ppl=11.07, wps=4214.9, ups=0.32, wpb=13023, bsz=412.1, num_updates=175900, lr=7.53993e-05, gnorm=1.055, loss_scale=2, train_wall=309, gb_free=15, wall=338076
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-24 08:39:48 | INFO | train_inner | epoch 020:   3898 / 9060 loss=7.079, nll_loss=3.46, ppl=11, wps=4249.4, ups=0.33, wpb=12987.1, bsz=431.7, num_updates=176000, lr=7.53778e-05, gnorm=1.066, loss_scale=2, train_wall=305, gb_free=14.4, wall=338382
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2576, 42808])
2023-09-24 08:44:46 | INFO | train_inner | epoch 020:   3998 / 9060 loss=7.221, nll_loss=3.531, ppl=11.56, wps=4365.3, ups=0.34, wpb=12987.8, bsz=444.4, num_updates=176100, lr=7.53564e-05, gnorm=1.073, loss_scale=2, train_wall=297, gb_free=14.4, wall=338679
pred_new.size(): torch.Size([4050, 42808])
2023-09-24 08:49:53 | INFO | train_inner | epoch 020:   4098 / 9060 loss=7.312, nll_loss=3.571, ppl=11.88, wps=4217.9, ups=0.33, wpb=12928.4, bsz=442.7, num_updates=176200, lr=7.5335e-05, gnorm=1.105, loss_scale=2, train_wall=306, gb_free=12.3, wall=338986
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3240, 42808])
2023-09-24 08:54:58 | INFO | train_inner | epoch 020:   4198 / 9060 loss=7.225, nll_loss=3.554, ppl=11.74, wps=4212.3, ups=0.33, wpb=12867.9, bsz=427.3, num_updates=176300, lr=7.53137e-05, gnorm=1.104, loss_scale=2, train_wall=305, gb_free=13.5, wall=339291
pred_new.size(): torch.Size([6790, 42808])
pred_new.size(): torch.Size([7957, 42808])
2023-09-24 09:00:01 | INFO | train_inner | epoch 020:   4298 / 9060 loss=7.39, nll_loss=3.609, ppl=12.2, wps=4287.7, ups=0.33, wpb=13003.5, bsz=441.7, num_updates=176400, lr=7.52923e-05, gnorm=1.097, loss_scale=2, train_wall=303, gb_free=13.5, wall=339595
pred_new.size(): torch.Size([3540, 42808])
2023-09-24 09:05:11 | INFO | train_inner | epoch 020:   4398 / 9060 loss=7.148, nll_loss=3.493, ppl=11.26, wps=4209.7, ups=0.32, wpb=13044.4, bsz=441.4, num_updates=176500, lr=7.5271e-05, gnorm=1.054, loss_scale=2, train_wall=310, gb_free=13.9, wall=339905
2023-09-24 09:10:21 | INFO | train_inner | epoch 020:   4498 / 9060 loss=7.269, nll_loss=3.586, ppl=12.01, wps=4234, ups=0.32, wpb=13137.6, bsz=432.6, num_updates=176600, lr=7.52497e-05, gnorm=1.065, loss_scale=2, train_wall=310, gb_free=13.9, wall=340215
pred_new.size(): torch.Size([2304, 42808])
2023-09-24 09:15:39 | INFO | train_inner | epoch 020:   4598 / 9060 loss=7.254, nll_loss=3.561, ppl=11.8, wps=4091.3, ups=0.31, wpb=13000, bsz=425, num_updates=176700, lr=7.52284e-05, gnorm=1.087, loss_scale=2, train_wall=317, gb_free=14.4, wall=340533
pred_new.size(): torch.Size([4688, 42808])
2023-09-24 09:20:54 | INFO | train_inner | epoch 020:   4698 / 9060 loss=7.324, nll_loss=3.585, ppl=12, wps=4136.5, ups=0.32, wpb=13028.4, bsz=438.6, num_updates=176800, lr=7.52071e-05, gnorm=1.094, loss_scale=2, train_wall=315, gb_free=13.3, wall=340848
2023-09-24 09:25:58 | INFO | train_inner | epoch 020:   4798 / 9060 loss=7.074, nll_loss=3.502, ppl=11.33, wps=4243.2, ups=0.33, wpb=12880.2, bsz=411, num_updates=176900, lr=7.51858e-05, gnorm=1.074, loss_scale=2, train_wall=303, gb_free=13.4, wall=341151
2023-09-24 09:31:11 | INFO | train_inner | epoch 020:   4898 / 9060 loss=7.246, nll_loss=3.566, ppl=11.84, wps=4120.4, ups=0.32, wpb=12898.4, bsz=423.5, num_updates=177000, lr=7.51646e-05, gnorm=1.11, loss_scale=2, train_wall=313, gb_free=13.9, wall=341464
ter_threshold: 0.47705
num_accepted / total 34 80
loss token level: tensor(7494.2817, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5256., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 09:36:24 | INFO | train_inner | epoch 020:   4998 / 9060 loss=7.293, nll_loss=3.538, ppl=11.62, wps=4135.6, ups=0.32, wpb=12949.6, bsz=415.8, num_updates=177100, lr=7.51434e-05, gnorm=1.122, loss_scale=2, train_wall=313, gb_free=13.8, wall=341777
ter_threshold: 0.477101
num_accepted / total 12 40
loss token level: tensor(7413.9805, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3610., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([468, 42808])
2023-09-24 09:41:34 | INFO | train_inner | epoch 020:   5098 / 9060 loss=7.322, nll_loss=3.58, ppl=11.96, wps=4161.6, ups=0.32, wpb=12924.2, bsz=444.2, num_updates=177200, lr=7.51222e-05, gnorm=1.102, loss_scale=2, train_wall=310, gb_free=12.9, wall=342088
lprobs.size(): torch.Size([3040, 42808])
2023-09-24 09:46:38 | INFO | train_inner | epoch 020:   5198 / 9060 loss=7.275, nll_loss=3.593, ppl=12.06, wps=4297.5, ups=0.33, wpb=13036.1, bsz=448.9, num_updates=177300, lr=7.5101e-05, gnorm=1.075, loss_scale=2, train_wall=303, gb_free=13.9, wall=342391
2023-09-24 09:51:49 | INFO | train_inner | epoch 020:   5298 / 9060 loss=7.2, nll_loss=3.525, ppl=11.51, wps=4120.3, ups=0.32, wpb=12841, bsz=421.1, num_updates=177400, lr=7.50798e-05, gnorm=1.106, loss_scale=2, train_wall=311, gb_free=14.9, wall=342703
tensor(9327.6982, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8208., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.468047
num_accepted / total 22 64
loss token level: tensor(9243.4785, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4752., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2208, 42808])
pred_new.size(): torch.Size([7921, 42808])
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([2442, 42808])
lprobs.size(): torch.Size([2704, 42808])
pred_new.size(): torch.Size([5076, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([1320, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3080, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([4828, 42808])
pred_new.size(): torch.Size([510, 42808])
ter_threshold: 0.469288
num_accepted / total 20 64
loss token level: tensor(9394.1328, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4636., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.46968
num_accepted / total 57 112
loss token level: tensor(8736.1465, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11488., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([232, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([2784, 42808])
pred_new.size(): torch.Size([1248, 42808])
lprobs.size(): torch.Size([2800, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5022, 42808])
lprobs.size(): torch.Size([3232, 42808])
lprobs.size(): torch.Size([3216, 42808])
ter_threshold: 0.47132799999999997
num_accepted / total 12 48
loss token level: tensor(8370.8730, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5708., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.47156299999999995
num_accepted / total 16 56
loss token level: tensor(8713.9395, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6636., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.471637
num_accepted / total 34 96
loss token level: tensor(10085.8672, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5232., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4950, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([3348, 42808])
pred_new.size(): torch.Size([6968, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([2672, 42808])
pred_new.size(): torch.Size([1995, 42808])
ter_threshold: 0.472296
num_accepted / total 62 136
loss token level: tensor(9997.6621, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11216., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.472358
num_accepted / total 121 208
loss token level: tensor(9490.8027, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7848., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4366, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.472441
num_accepted / total 48 112
loss token level: tensor(9532.6084, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11304., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.472865
num_accepted / total 53 152
loss token level: tensor(11042.8311, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7776., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([4473, 42808])
pred_new.size(): torch.Size([5184, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.473488
num_accepted / total 8 40
loss token level: tensor(8696.2461, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3100., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4550, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([1428, 42808])
ter_threshold: 0.47416
num_accepted / total 215 272
loss token level: tensor(8158.5459, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9128., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3381, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6125, 42808])
pred_new.size(): torch.Size([3770, 42808])
pred_new.size(): torch.Size([686, 42808])
ter_threshold: 0.475066
num_accepted / total 31 72
loss token level: tensor(8607.5732, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6060., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.475117
num_accepted / total 31 72
loss token level: tensor(8651.7061, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6192., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5562, 42808])
ter_threshold: 0.475271
num_accepted / total 50 104
loss token level: tensor(8719.8262, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6736., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2112, 42808])
pred_new.size(): torch.Size([3630, 42808])
pred_new.size(): torch.Size([4917, 42808])
pred_new.size(): torch.Size([864, 42808])
pred_new.size(): torch.Size([2790, 42808])
ter_threshold: 0.475682
num_accepted / total 21 72
loss token level: tensor(8822.5449, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4068., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4095, 42808])
lprobs.size(): torch.Size([3008, 42808])
pred_new.size(): torch.Size([2850, 42808])
lprobs.size(): torch.Size([2664, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([2907, 42808])
pred_new.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([3600, 42808])
pred_new.size(): torch.Size([6499, 42808])
pred_new.size(): torch.Size([1470, 42808])
pred_new.size(): torch.Size([3024, 42808])
ter_threshold: 0.476705
num_accepted / total 6 24
loss token level: tensor(7416.4004, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3820, 42808])
pred_new.size(): torch.Size([5280, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([3306, 42808])
lprobs.size(): torch.Size([3216, 42808])
ter_threshold: 0.477101
num_accepted / total 8 40
loss token level: tensor(7480.5215, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2228., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([760, 42808])
ter_threshold: 0.477481
2023-09-24 09:56:57 | INFO | train_inner | epoch 020:   5398 / 9060 loss=7.182, nll_loss=3.545, ppl=11.67, wps=4236.5, ups=0.32, wpb=13037.9, bsz=418.6, num_updates=177500, lr=7.50587e-05, gnorm=1.066, loss_scale=2, train_wall=307, gb_free=14, wall=343011
lprobs.size(): torch.Size([3056, 42808])
pred_new.size(): torch.Size([5024, 42808])
2023-09-24 10:02:17 | INFO | train_inner | epoch 020:   5498 / 9060 loss=7.226, nll_loss=3.571, ppl=11.89, wps=4037.2, ups=0.31, wpb=12919.3, bsz=425.8, num_updates=177600, lr=7.50375e-05, gnorm=1.087, loss_scale=2, train_wall=320, gb_free=13.3, wall=343331
lprobs.size(): torch.Size([2576, 42808])
2023-09-24 10:07:13 | INFO | train_inner | epoch 020:   5598 / 9060 loss=7.154, nll_loss=3.503, ppl=11.34, wps=4368.7, ups=0.34, wpb=12922.9, bsz=432.2, num_updates=177700, lr=7.50164e-05, gnorm=1.065, loss_scale=2, train_wall=296, gb_free=13.7, wall=343626
2023-09-24 10:12:14 | INFO | train_inner | epoch 020:   5698 / 9060 loss=7.373, nll_loss=3.61, ppl=12.21, wps=4343.4, ups=0.33, wpb=13086.1, bsz=449.2, num_updates=177800, lr=7.49953e-05, gnorm=1.085, loss_scale=2, train_wall=301, gb_free=13.9, wall=343928
pred_new.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-24 10:17:21 | INFO | train_inner | epoch 020:   5798 / 9060 loss=7.265, nll_loss=3.535, ppl=11.59, wps=4243.1, ups=0.33, wpb=13033.3, bsz=448.6, num_updates=177900, lr=7.49742e-05, gnorm=1.064, loss_scale=2, train_wall=307, gb_free=13.6, wall=344235
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2727, 42808])
2023-09-24 10:22:44 | INFO | train_inner | epoch 020:   5898 / 9060 loss=7.225, nll_loss=3.541, ppl=11.64, wps=4033, ups=0.31, wpb=13020.8, bsz=444.3, num_updates=178000, lr=7.49532e-05, gnorm=1.116, loss_scale=2, train_wall=323, gb_free=13.5, wall=344558
ter_threshold: 0.478056
num_accepted / total 63 176
loss token level: tensor(8028.0850, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6032., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 10:27:45 | INFO | train_inner | epoch 020:   5998 / 9060 loss=7.21, nll_loss=3.54, ppl=11.63, wps=4330.2, ups=0.33, wpb=13002.8, bsz=449.5, num_updates=178100, lr=7.49321e-05, gnorm=1.07, loss_scale=2, train_wall=300, gb_free=13.7, wall=344858
ter_threshold: 0.478136
num_accepted / total 43 128
loss token level: tensor(8951.9609, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4496., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3080, 42808])
2023-09-24 10:32:56 | INFO | train_inner | epoch 020:   6098 / 9060 loss=7.239, nll_loss=3.559, ppl=11.78, wps=4175.3, ups=0.32, wpb=12984.7, bsz=419.6, num_updates=178200, lr=7.49111e-05, gnorm=1.109, loss_scale=4, train_wall=311, gb_free=13.4, wall=345169
pred_new.size(): torch.Size([5712, 42808])
2023-09-24 10:38:04 | INFO | train_inner | epoch 020:   6198 / 9060 loss=7.227, nll_loss=3.543, ppl=11.66, wps=4237, ups=0.32, wpb=13070.6, bsz=424.1, num_updates=178300, lr=7.48901e-05, gnorm=1.076, loss_scale=4, train_wall=308, gb_free=14.1, wall=345478
2023-09-24 10:43:22 | INFO | train_inner | epoch 020:   6298 / 9060 loss=7.236, nll_loss=3.566, ppl=11.85, wps=4087.3, ups=0.31, wpb=12991.9, bsz=440.1, num_updates=178400, lr=7.48691e-05, gnorm=1.086, loss_scale=4, train_wall=318, gb_free=14.1, wall=345795
pred_new.size(): torch.Size([5133, 42808])
pred_new.size(): torch.Size([1120, 42808])
lprobs.size(): torch.Size([3528, 42808])
2023-09-24 10:48:28 | INFO | train_inner | epoch 020:   6398 / 9060 loss=7.118, nll_loss=3.517, ppl=11.45, wps=4232.4, ups=0.33, wpb=12940.5, bsz=427.4, num_updates=178500, lr=7.48481e-05, gnorm=1.104, loss_scale=4, train_wall=305, gb_free=13.5, wall=346101
ter_threshold: 0.478547
num_accepted / total 16 80
loss token level: tensor(12048.7012, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4832., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5478, 42808])
2023-09-24 10:53:32 | INFO | train_inner | epoch 020:   6498 / 9060 loss=7.336, nll_loss=3.594, ppl=12.08, wps=4278.5, ups=0.33, wpb=13001.8, bsz=427.8, num_updates=178600, lr=7.48272e-05, gnorm=1.118, loss_scale=4, train_wall=304, gb_free=14.3, wall=346405
2023-09-24 10:58:42 | INFO | train_inner | epoch 020:   6598 / 9060 loss=7.339, nll_loss=3.613, ppl=12.23, wps=4159.1, ups=0.32, wpb=12907.8, bsz=425.5, num_updates=178700, lr=7.48062e-05, gnorm=1.117, loss_scale=4, train_wall=310, gb_free=14.4, wall=346715
2023-09-24 11:03:52 | INFO | train_inner | epoch 020:   6698 / 9060 loss=7.164, nll_loss=3.534, ppl=11.58, wps=4168.9, ups=0.32, wpb=12942.6, bsz=428, num_updates=178800, lr=7.47853e-05, gnorm=1.072, loss_scale=4, train_wall=310, gb_free=13.9, wall=347026
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-24 11:09:05 | INFO | train_inner | epoch 020:   6798 / 9060 loss=7.077, nll_loss=3.498, ppl=11.3, wps=4147.6, ups=0.32, wpb=12983.5, bsz=424.2, num_updates=178900, lr=7.47644e-05, gnorm=1.083, loss_scale=4, train_wall=313, gb_free=14.9, wall=347339
2023-09-24 11:14:13 | INFO | train_inner | epoch 020:   6898 / 9060 loss=7.228, nll_loss=3.541, ppl=11.64, wps=4227.5, ups=0.32, wpb=13010.9, bsz=448.8, num_updates=179000, lr=7.47435e-05, gnorm=1.108, loss_scale=4, train_wall=307, gb_free=13.7, wall=347647
pred_new.size(): torch.Size([1170, 42808])
pred_new.size(): torch.Size([2852, 42808])
2023-09-24 11:19:09 | INFO | train_inner | epoch 020:   6998 / 9060 loss=7.3, nll_loss=3.575, ppl=11.92, wps=4414.3, ups=0.34, wpb=13050.4, bsz=433.2, num_updates=179100, lr=7.47226e-05, gnorm=1.077, loss_scale=4, train_wall=295, gb_free=13.8, wall=347942
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([1040, 42808])
lprobs.size(): torch.Size([3552, 42808])
2023-09-24 11:24:20 | INFO | train_inner | epoch 020:   7098 / 9060 loss=7.309, nll_loss=3.567, ppl=11.85, wps=4178.5, ups=0.32, wpb=12990.8, bsz=448, num_updates=179200, lr=7.47018e-05, gnorm=1.091, loss_scale=4, train_wall=311, gb_free=14.9, wall=348253
2023-09-24 11:29:29 | INFO | train_inner | epoch 020:   7198 / 9060 loss=7.311, nll_loss=3.619, ppl=12.29, wps=4162.3, ups=0.32, wpb=12878.2, bsz=417.4, num_updates=179300, lr=7.4681e-05, gnorm=1.114, loss_scale=4, train_wall=309, gb_free=13.7, wall=348563
ter_threshold: 0.47930799999999996
num_accepted / total 14 72
loss token level: tensor(12065.2891, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4096., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([1872, 42808])
ter_threshold: 0.479373
num_accepted / total 29 64
loss token level: tensor(8887.1865, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11632., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3920, 42808])
2023-09-24 11:34:37 | INFO | train_inner | epoch 020:   7298 / 9060 loss=7.118, nll_loss=3.479, ppl=11.15, wps=4244.9, ups=0.32, wpb=13069.8, bsz=425.7, num_updates=179400, lr=7.46601e-05, gnorm=1.113, loss_scale=4, train_wall=308, gb_free=15.3, wall=348870
tensor(8388.0264, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12104., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([306, 42808])
pred_new.size(): torch.Size([3969, 42808])
ter_threshold: 0.471781
num_accepted / total 60 128
loss token level: tensor(10508.4121, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7192., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([2310, 42808])
pred_new.size(): torch.Size([928, 42808])
pred_new.size(): torch.Size([9675, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.472296
num_accepted / total 55 120
loss token level: tensor(8448.8652, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10064., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7708, 42808])
ter_threshold: 0.472321
num_accepted / total 9 56
loss token level: tensor(9565.6230, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.472358
num_accepted / total 40 88
loss token level: tensor(9462.1191, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6568., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5658, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.472441
num_accepted / total 66 160
loss token level: tensor(8236.5498, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8080., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2805, 42808])
pred_new.size(): torch.Size([7650, 42808])
pred_new.size(): torch.Size([1938, 42808])
lprobs.size(): torch.Size([3128, 42808])
ter_threshold: 0.47283699999999995
num_accepted / total 85 208
loss token level: tensor(7724.5010, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3796., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.472865
num_accepted / total 46 128
loss token level: tensor(8097.0942, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7080., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3216, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2730, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([4536, 42808])
pred_new.size(): torch.Size([5376, 42808])
pred_new.size(): torch.Size([3335, 42808])
lprobs.size(): torch.Size([3224, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([2960, 42808])
ter_threshold: 0.473809
num_accepted / total 6 48
loss token level: tensor(8812.4521, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1414., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.47414
num_accepted / total 84 160
loss token level: tensor(8381.1777, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6152., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.474252
num_accepted / total 13 56
loss token level: tensor(10079.5957, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6000., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.474371
num_accepted / total 25 72
loss token level: tensor(9389.9893, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8704., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2184, 42808])
pred_new.size(): torch.Size([408, 42808])
ter_threshold: 0.475128
num_accepted / total 133 192
loss token level: tensor(9166.8652, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(15264., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4896, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.475271
num_accepted / total 61 120
loss token level: tensor(10342.3867, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7344., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2640, 42808])
ter_threshold: 0.475989
num_accepted / total 22 72
loss token level: tensor(9330.8291, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4508., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([1160, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4540, 42808])
pred_new.size(): torch.Size([8062, 42808])
pred_new.size(): torch.Size([2816, 42808])
ter_threshold: 0.47658999999999996
num_accepted / total 14 64
loss token level: tensor(8283.0273, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3114., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7992, 42808])
pred_new.size(): torch.Size([2730, 42808])
pred_new.size(): torch.Size([3696, 42808])
pred_new.size(): torch.Size([2397, 42808])
pred_new.size(): torch.Size([217, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.477102
num_accepted / total 6 40
loss token level: tensor(9380.6602, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2072., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4437, 42808])
ter_threshold: 0.47714999999999996
num_accepted / total 9 88
loss token level: tensor(9272.3330, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1984., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7950, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([1285, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([2088, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([6350, 42808])
pred_new.size(): torch.Size([3515, 42808])
ter_threshold: 0.478056
num_accepted / total 72 128
loss token level: tensor(9448.6055, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13856., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6448, 42808])
ter_threshold: 0.47829
num_accepted / total 29 56
loss token level: tensor(8340.6006, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12400., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1558, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5472, 42808])
lprobs.size(): torch.Size([3224, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1720, 42808])
ter_threshold: 0.478805
num_accepted / total 23 72
loss token level: tensor(9608.4473, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4624., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([1365, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3774, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([7682, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): 2023-09-24 11:39:41 | INFO | train_inner | epoch 020:   7398 / 9060 loss=7.158, nll_loss=3.575, ppl=11.91, wps=4262.2, ups=0.33, wpb=12963.8, bsz=407.8, num_updates=179500, lr=7.46393e-05, gnorm=1.084, loss_scale=4, train_wall=304, gb_free=14.9, wall=349175
2023-09-24 11:44:48 | INFO | train_inner | epoch 020:   7498 / 9060 loss=7.311, nll_loss=3.567, ppl=11.85, wps=4253.1, ups=0.33, wpb=13031.4, bsz=458, num_updates=179600, lr=7.46186e-05, gnorm=1.103, loss_scale=4, train_wall=306, gb_free=14.3, wall=349481
lprobs.size(): torch.Size([3584, 42808])
2023-09-24 11:50:10 | INFO | train_inner | epoch 020:   7598 / 9060 loss=7.33, nll_loss=3.634, ppl=12.41, wps=4000.7, ups=0.31, wpb=12891.7, bsz=399.1, num_updates=179700, lr=7.45978e-05, gnorm=1.099, loss_scale=4, train_wall=322, gb_free=15.6, wall=349803
pred_new.size(): torch.Size([6630, 42808])
2023-09-24 11:55:27 | INFO | train_inner | epoch 020:   7698 / 9060 loss=7.375, nll_loss=3.617, ppl=12.27, wps=4089.3, ups=0.31, wpb=12990.2, bsz=434.4, num_updates=179800, lr=7.4577e-05, gnorm=1.087, loss_scale=4, train_wall=317, gb_free=12.9, wall=350121
pred_new.size(): torch.Size([2499, 42808])
2023-09-24 12:00:38 | INFO | train_inner | epoch 020:   7798 / 9060 loss=7.251, nll_loss=3.591, ppl=12.05, wps=4166.4, ups=0.32, wpb=12937.9, bsz=426.6, num_updates=179900, lr=7.45563e-05, gnorm=1.083, loss_scale=4, train_wall=310, gb_free=13.7, wall=350431
pred_new.size(): torch.Size([4400, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-24 12:05:54 | INFO | train_inner | epoch 020:   7898 / 9060 loss=7.309, nll_loss=3.597, ppl=12.1, wps=4072.1, ups=0.32, wpb=12858.4, bsz=437.2, num_updates=180000, lr=7.45356e-05, gnorm=1.131, loss_scale=4, train_wall=316, gb_free=14.1, wall=350747
pred_new.size(): torch.Size([5880, 42808])
ter_threshold: 0.480059
num_accepted / total 61 112
loss token level: tensor(9634.4355, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8160., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
2023-09-24 12:10:58 | INFO | train_inner | epoch 020:   7998 / 9060 loss=7.185, nll_loss=3.556, ppl=11.76, wps=4306.2, ups=0.33, wpb=13102.5, bsz=400.4, num_updates=180100, lr=7.45149e-05, gnorm=1.074, loss_scale=4, train_wall=304, gb_free=13.6, wall=351051
pred_new.size(): torch.Size([1600, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-24 12:15:59 | INFO | train_inner | epoch 020:   8098 / 9060 loss=7.325, nll_loss=3.606, ppl=12.18, wps=4307.4, ups=0.33, wpb=12943.9, bsz=438.2, num_updates=180200, lr=7.44942e-05, gnorm=1.121, loss_scale=4, train_wall=300, gb_free=13.3, wall=351352
pred_new.size(): torch.Size([3330, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.48028899999999997
num_accepted / total 11 40
loss token level: tensor(8687.9219, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7060., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 12:21:10 | INFO | train_inner | epoch 020:   8198 / 9060 loss=7.216, nll_loss=3.562, ppl=11.81, wps=4172.3, ups=0.32, wpb=12975.8, bsz=429.9, num_updates=180300, lr=7.44736e-05, gnorm=1.097, loss_scale=4, train_wall=311, gb_free=13.8, wall=351663
pred_new.size(): torch.Size([2125, 42808])
pred_new.size(): torch.Size([1200, 42808])
2023-09-24 12:26:18 | INFO | train_inner | epoch 020:   8298 / 9060 loss=7.145, nll_loss=3.515, ppl=11.44, wps=4179.8, ups=0.32, wpb=12873.4, bsz=437, num_updates=180400, lr=7.44529e-05, gnorm=1.09, loss_scale=4, train_wall=308, gb_free=14, wall=351971
lprobs.size(): torch.Size([3280, 42808])
2023-09-24 12:31:25 | INFO | train_inner | epoch 020:   8398 / 9060 loss=7.288, nll_loss=3.592, ppl=12.06, wps=4217.9, ups=0.32, wpb=12982.1, bsz=420, num_updates=180500, lr=7.44323e-05, gnorm=1.1, loss_scale=4, train_wall=308, gb_free=14.3, wall=352279
pred_new.size(): torch.Size([4850, 42808])
pred_new.size(): torch.Size([5390, 42808])
ter_threshold: 0.480591
num_accepted / total 29 80
loss token level: tensor(8426.6543, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4528., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 12:36:47 | INFO | train_inner | epoch 020:   8498 / 9060 loss=7.277, nll_loss=3.553, ppl=11.74, wps=4017.9, ups=0.31, wpb=12912.8, bsz=411.8, num_updates=180600, lr=7.44117e-05, gnorm=1.145, loss_scale=4, train_wall=321, gb_free=13.5, wall=352600
2023-09-24 12:41:51 | INFO | train_inner | epoch 020:   8598 / 9060 loss=7.239, nll_loss=3.554, ppl=11.75, wps=4266.9, ups=0.33, wpb=12966.7, bsz=426.8, num_updates=180700, lr=7.43911e-05, gnorm=1.097, loss_scale=4, train_wall=304, gb_free=15.1, wall=352904
pred_new.size(): torch.Size([3888, 42808])
2023-09-24 12:47:07 | INFO | train_inner | epoch 020:   8698 / 9060 loss=7.353, nll_loss=3.581, ppl=11.96, wps=4133.4, ups=0.32, wpb=13093.3, bsz=450.9, num_updates=180800, lr=7.43705e-05, gnorm=1.114, loss_scale=4, train_wall=316, gb_free=14.3, wall=353221
pred_new.size(): torch.Size([6591, 42808])
pred_new.size(): torch.Size([3059, 42808])
lprobs.size(): torch.Size([2968, 42808])
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([2100, 42808])
2023-09-24 12:52:18 | INFO | train_inner | epoch 020:   8798 / 9060 loss=7.315, nll_loss=3.591, ppl=12.05, wps=4155.3, ups=0.32, wpb=12911.6, bsz=411.6, num_updates=180900, lr=7.435e-05, gnorm=1.107, loss_scale=4, train_wall=310, gb_free=14.4, wall=353532
ter_threshold: 0.480915
num_accepted / total 69 208
loss token level: tensor(11732.1367, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4248., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 12:57:26 | INFO | train_inner | epoch 020:   8898 / 9060 loss=7.198, nll_loss=3.535, ppl=11.59, wps=4205, ups=0.32, wpb=12966.9, bsz=434.8, num_updates=181000, lr=7.43294e-05, gnorm=1.092, loss_scale=4, train_wall=308, gb_free=13.8, wall=353840
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.481089
num_accepted / total 124 208
loss token level: tensor(8653.3887, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7856., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 13:02:37 | INFO | train_inner | epoch 020:   8998 / 9060 loss=7.08, nll_loss=3.494, ppl=11.27, wps=4194.3, ups=0.32, wpb=13008.1, bsz=442.7, num_updates=181100, lr=7.43089e-05, gnorm=1.061, loss_scale=4, train_wall=310, gb_free=13.9, wall=354150
2023-09-24 13:05:51 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-24 13:05:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-24 13:05:51 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-24 13:05:51 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-24 13:05:52 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-24 13:05:52 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-24 13:05:52 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-24 13:05:52 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-24 13:05:53 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-24 13:05:53 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-24 13:05:54 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-24 13:05:54 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-24 13:05:54 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein voller Erfolg.
2023-09-24 13:05:54 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-24 13:05:55 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Frohes Neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-24 13:05:55 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-24 13:05:55 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-24 13:05:55 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-24 13:05:56 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-24 13:05:56 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-24 13:05:56 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Firmen- als auch für Privatreisende geeignet sind.
2023-09-24 13:05:56 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-24 13:05:57 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-24 13:05:57 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-24 13:05:57 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-24 13:05:57 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-24 13:05:58 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU insgesamt riesige Mengen Energie verschwendet.
2023-09-24 13:05:58 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-24 13:05:58 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-24 13:05:58 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-24 13:05:59 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Haltung auch in Kürze im Haushalt der Union niederschlagen.
2023-09-24 13:05:59 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-24 13:06:00 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-24 13:06:00 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-24 13:06:00 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-24 13:06:00 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-24 13:06:01 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-24 13:06:01 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-24 13:06:01 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit auf ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-24 13:06:01 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-24 13:06:02 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-24 13:06:02 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-24 13:06:03 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-24 13:06:03 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-24 13:06:03 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-24 13:06:03 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-24 13:06:04 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-24 13:06:04 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-24 13:06:04 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potenzielle Käufer dazu bringen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-24 13:06:04 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-24 13:06:05 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-24 13:06:05 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-24 13:06:06 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-24 13:06:06 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-24 13:06:06 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit, die diese Aussprache bietet, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-24 13:06:06 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-24 13:06:07 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart liegt in einem Umkreis von etwa 8 Kilometern vom Strip entfernt.
2023-09-24 13:06:07 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-24 13:06:07 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Webportal System basiert.
2023-09-24 13:06:07 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-24 13:06:08 | INFO | fairseq.tasks.translation | example hypothesis: Aus diesem Grund bietet HearDis! akustisch, interaktiv oder schriftlich die Realisierung von Klanghandbüchern an.
2023-09-24 13:06:08 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-24 13:06:09 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-24 13:06:09 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-24 13:06:09 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer internen Unterstützung aufbauen, aber sie kann sich bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-24 13:06:09 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-24 13:06:10 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Ausreise Zugang zu dem Geld haben, das ihnen in die europäischen Sozialversicherungssysteme eingezahlt wird.
2023-09-24 13:06:10 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-24 13:06:10 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-24 13:06:10 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-24 13:06:11 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, für einige Formate gibt es leider keine kostenlose Alternative, die auf allen Computer-Plattformen läuft.
2023-09-24 13:06:11 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-24 13:06:12 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird Ihnen auch helfen, qualifizierte Fachkräfte zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-24 13:06:12 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-24 13:06:12 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Vorstellungen von niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv Kernpunkte seiner Agenda.
2023-09-24 13:06:12 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-24 13:06:13 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils neu emergen, damit es korrekt funktioniert.
2023-09-24 13:06:13 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-24 13:06:14 | INFO | fairseq.tasks.translation | example hypothesis: Horde und Allianzspieler können Gegenstände nicht kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser benutzen.
2023-09-24 13:06:14 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-24 13:06:14 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollen.
2023-09-24 13:06:14 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-24 13:06:15 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt der Kommission auf der Grundlage eines Berichts von Herrn Wynn die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-24 13:06:15 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-24 13:06:16 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten grundsätzlichen Einzelheiten des Abkommens mit den Vereinigten Staaten abgeben müssen.
2023-09-24 13:06:16 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-24 13:06:16 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unser breites Sortiment an PlastikBabyartikeln überzeugt nicht zuletzt durch seine herausragende Verarbeitung.
2023-09-24 13:06:16 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-24 13:06:17 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-24 13:06:17 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-24 13:06:18 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx nach Kenntnis dieser AGB unverzüglich über sachliche Umstände zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-24 13:06:18 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-24 13:06:18 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung notwendig sieht.
2023-09-24 13:06:18 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-24 13:06:19 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-24 13:06:19 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-24 13:06:20 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte anerkennen, die bei der Prüfung aller Themen erzielt wurden, die jetzt zur Diskussion stehen und etwas betreffen, das kaum zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-24 13:06:20 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-24 13:06:20 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-24 13:06:20 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-24 13:06:21 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es der Berichterstatterin gelungen, zeitweise unterschiedliche Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-24 13:06:21 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-24 13:06:22 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlägen um einen trockenen ESP für den unteren Leistungsbereich.
2023-09-24 13:06:22 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-24 13:06:22 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der jahrhundertelang seine Freiheit und Unabhängigkeit verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-24 13:06:22 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-24 13:06:23 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Branchen nach China und Fernost abwandern, müssen wir uns auf unsere Innovation und unseren Einfallsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-24 13:06:23 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-24 13:06:24 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und mit unserer Gemeinschaft der Nationen zu tun haben.
2023-09-24 13:06:24 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-24 13:06:25 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restant qui se battront pour leur part de 32 000 $.
2023-09-24 13:06:25 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-24 13:06:25 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht der Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-24 13:06:25 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-24 13:06:26 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-24 13:06:26 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-24 13:06:27 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine weitere: die Notsituation der Kinder, des schwächsten Bevölkerungsschichten, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-24 13:06:27 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-24 13:06:27 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen.
2023-09-24 13:06:27 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-24 13:06:28 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht befreit, nicht erst verwirklicht ist, bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, bis man sein wahres Selbst kennt.............
2023-09-24 13:06:28 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-24 13:06:29 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen..............
2023-09-24 13:06:29 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-24 13:06:29 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgerinnen und Bürgern Meinungsfreiheit, freie und unabhängige Wahlen sowie Vereinigungsfreiheit geben, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-24 13:06:29 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-24 13:06:30 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken, die Plattform und Betriebssystem Unabhängigkeit (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-24 13:06:30 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-24 13:06:31 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für eine Klärung des Anhangs.
2023-09-24 13:06:31 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-24 13:06:32 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt wurden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-24 13:06:32 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-24 13:06:32 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Aussprache über das irische öffentlich-rechtliche Radio RTÉ mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für die Entwicklungshilfe zu kürzen................
2023-09-24 13:06:32 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-24 13:06:33 | INFO | fairseq.tasks.translation | example hypothesis: Vor diesem Hintergrund hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-24 13:06:33 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-24 13:06:34 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Bürgerschaft oder etwas so Konkretes wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist...............
2023-09-24 13:06:34 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-24 13:06:35 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten..........................
2023-09-24 13:06:35 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-24 13:06:35 | INFO | fairseq.tasks.translation | example hypothesis: - Herr Präsident! Ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte einen nützlichen und relevanten Beitrag zur Diskussion über Flexicurity darstellt, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-24 13:06:35 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-24 13:06:36 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken, hieße, eine bestimmte Art von Vertragsverhältnis zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen häufig die tatsächliche oder wahrgenommene Bedrohung, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-24 13:06:36 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-24 13:06:37 | INFO | fairseq.tasks.translation | example hypothesis: In der Gemeinschaftsgerichtsbarkeit zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-24 13:06:37 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-24 13:06:38 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er ist eines der lustigsten Autos unter $50.000 und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos ausprobieren.
2023-09-24 13:06:38 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-24 13:06:38 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung dieser Angelegenheit.
2023-09-24 13:06:38 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-24 13:06:39 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und den ausgezeichneten Süßwasserfisch: gegrillter Hecht, Forelle mit Mandeln.
2023-09-24 13:06:39 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-24 13:06:40 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, einen Gesamtüberblick zu geben, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu sehen, welchen Impuls die Europäische Union im Hinblick auf die Zukunft geben kann.................
2023-09-24 13:06:40 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-24 13:06:41 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, einigten sich auf die Veröffentlichung eines Live-Albums "Bodulska balada 2009".
2023-09-24 13:06:41 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-24 13:06:42 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen echten Wohlstand, wo Arbeitslosigkeit herrscht, wo unmittelbare Bedrohung für bestehende Arbeitsplätze besteht und die Wettbewerbsfähigkeit durch makroökonomische Politik, steuerliche Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-24 13:06:42 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-24 13:06:43 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in dieselbe allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein ausgezeichnetes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text übernommen hat.
2023-09-24 13:06:43 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-24 13:06:43 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Folgen für den Rechts- und Rechtsraum, und macht Norwegen und Island zu Staaten, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstands gelten.....................
2023-09-24 13:06:43 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-24 13:06:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden uns mit voller Geschwindigkeit in einem Schichtboot hinunter den Mississippi fahren, nach dem großen versteckten Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein.......................
2023-09-24 13:06:44 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-24 13:06:45 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der Meeresverschmutzung durch Schiffe, die durch Einzelpersonen oder juristische Personen verursacht wird, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die im Falle von Verletzungen durch Personen verhängt werden können.
2023-09-24 13:06:45 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-24 13:06:46 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falizund Vincent Reynaud wurden nämlich verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner verrichtet und eine Gruppe von Bergleuten gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das sich über jeden Grundsatz der Demokratie hinwegsetzt...............
2023-09-24 13:06:46 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-24 13:06:47 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels gehören Concierge-Service, ein Friseurgeschäft und ein Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Wäsche- und Presseservice, eine Wechselstube, kostenlose Schuhputzine und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das Französische Viertel.
2023-09-24 13:06:47 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-24 13:06:48 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der von Königin D. Leonor, der Frau von König D. João II., sehr geliebten Thermalquelle verdankt und durch ihre international bekannten Keramiken für ihre figurativen und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-24 13:06:48 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-24 13:06:48 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es handele sich um gute Befürworter des Westens auf der einen und Befürworter des früheren Regimes auf der anderen Seite - das ist ebenfalls verwerflich, da die Rollen aller heute und davor bekannt sind.
2023-09-24 13:06:48 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-24 13:06:49 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.........................
2023-09-24 13:06:49 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-24 13:06:50 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär aufgrund seines Status als Aktionär außerhalb einer Aktionärsversammlung Informationen zur Verfügung gestellt, so werden diese auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung weitergegeben, auch wenn solche Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-24 13:06:50 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-24 13:06:51 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die in der Regel in den Taschen verschiedener Diktatoren landen und ihren schönen Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr elendes Leben führen...........................
2023-09-24 13:06:51 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-24 13:06:52 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder der NATO hätten in diesen Kriegshandlungen verwickelt sein können -, mit Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, geheim oder geheim zu halten, damit wir die Tatsachen wirklich ans Licht bringen können und die ganze Wahrheit erfahren kann.........................
2023-09-24 13:06:52 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-24 13:06:53 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet...............................................
2023-09-24 13:06:53 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-24 13:06:54 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Geschäftseinheit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die heutige Plattform außerhalb des Regals nie erreichen kann........................
2023-09-24 13:06:54 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-24 13:06:55 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen unmissverständlich klarstellen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte vom Markt zu nehmen, die nicht nur für den Inlandsverbrauch, sondern auch für den Weltmarkt eine ernste Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 feststellt.
2023-09-24 13:06:55 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-24 13:06:56 | INFO | fairseq.tasks.translation | example hypothesis: Unter der direkten Verschwörung von Moderne und Postmoderne oder dem klaren Gegensatz von reiner Kunst und engagierter Kunst müssen wir die originale und dauerhafte Spannung jener beiden ästhetischen Politik anerkennen, die in den Formen der Sichtbarkeit und Verständlichkeit verbirgt, die Kunst als solche identifizierbar machen - jener beiden Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führt..............................
2023-09-24 13:06:56 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-24 13:06:57 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Aussprachen und der Meinungen, die Sie mir gegeben haben und die eindeutig weitgehend unterstützen, was ich gerade gesagt habe, und auf der Grundlage der vorangegangenen Beschlüsse unsere Aussprachen führen, und bei der Abstimmung werde ich, wenn die vierzig Petenten nicht anwesend sind, nicht beantragen, die Feststellung der Beschlussfähigkeit zu beantragen................................. wenn die Feststellung der
2023-09-24 13:06:57 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-24 13:06:58 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Begrenzung des nationalstaatlichen Prinzips nie akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum niemandem bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern die Entwicklung der ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen..........................
2023-09-24 13:06:58 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-24 13:06:59 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Form als Hybrid veröffentlicht und für H-Soz-u-Kult und Michigan-basierte H-Net an die Abonnenten über Mailinglisten sowie die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net verteilt.
2023-09-24 13:06:59 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-24 13:07:00 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit dem Einzug der neuen Smartphone-Generation haben Mobiltelefone ihre Federn deutlich verwischt, von einst schleichenden Wecker im Taschenformat über polyphonisch tootende Game Boy-Aspiranten bis hin zu schmal-schlichten Mini-PCs mit knackigem Stereo-Sound in CD-Qualität: Dank ihrer besonderen Kombination von Fähigkeiten können sie von den früheren me-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen werden.
2023-09-24 13:07:00 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-24 13:07:02 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dirige la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen.
2023-09-24 13:07:02 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-24 13:07:03 | INFO | valid | epoch 020 | valid on 'valid' subset | loss 4.136 | nll_loss 2.165 | ppl 4.49 | bleu 28.21 | wps 16441.2 | wpb 12011.9 | bsz 398.1 | num_updates 181162 | best_bleu 29.48
2023-09-24 13:07:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 181162 updates
2023-09-24 13:07:03 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint20.pt
2023-09-24 13:07:08 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint20.pt
2023-09-24 13:07:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint20.pt (epoch 20 @ 181162 updates, score 28.21) (writing took 9.373090955079533 seconds)
2023-09-24 13:07:12 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2023-09-24 13:07:12 | INFO | train | epoch 020 | loss 7.227 | nll_loss 3.546 | ppl 11.68 | wps 4174.6 | ups 0.32 | wpb 12977.2 | bsz 430.6 | num_updates 181162 | lr 7.42962e-05 | gnorm 1.091 | loss_scale 4 | train_wall 28058 | gb_free 13.6 | wall 354426
2023-09-24 13:07:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-24 13:07:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-24 13:07:13 | INFO | fairseq.trainer | begin training epoch 21
2023-09-24 13:07:13 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-24 13:09:07 | INFO | train_inner | epoch 021:     38 / 9060 loss=7.297, nll_loss=3.568, ppl=11.86, wps=3311.4, ups=0.26, wpb=12936.6, bsz=457.6, num_updates=181200, lr=7.42884e-05, gnorm=1.081, loss_scale=4, train_wall=309, gb_free=13.9, wall=354541
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3720, 42808])
2023-09-24 13:14:17 | INFO | train_inner | epoch 021:    138 / 9060 loss=7.113, nll_loss=3.467, ppl=11.05, wps=4229.6, ups=0.32, wpb=13080, bsz=417.7, num_updates=181300, lr=7.42679e-05, gnorm=1.072, loss_scale=4, train_wall=309, gb_free=14.4, wall=354850
pred_new.size(): torch.Size([4272, 42808])
2023-09-24 13:19:36 | INFO | train_inner | epoch 021:    238 / 9060 loss=7.13, nll_loss=3.467, ppl=11.06, wps=4027.7, ups=0.31, wpb=12888.2, bsz=437.1, num_updates=181400, lr=7.42474e-05, gnorm=1.094, loss_scale=4, train_wall=320, gb_free=13.7, wall=355170
pred_new.size(): torch.Size([6640, 42808])
lprobs.size(): torch.Size([3248, 42808])
2023-09-24 13:24:50 | INFO | train_inner | epoch 021:    338 / 9060 loss=7.292, nll_loss=3.558, ppl=11.78, wps=4127.6, ups=0.32, wpb=12926.4, bsz=438.6, num_updates=181500, lr=7.4227e-05, gnorm=1.085, loss_scale=4, train_wall=313, gb_free=13.8, wall=355483
pred_new.size(): torch.Size([1752, 42808])
2023-09-24 13:30:08 | INFO | train_inner | epoch 021:    438 / 9060 loss=7.14, nll_loss=3.462, ppl=11.02, wps=4078.1, ups=0.31, wpb=12986.8, bsz=413.7, num_updates=181600, lr=7.42065e-05, gnorm=1.074, loss_scale=4, train_wall=318, gb_free=14.2, wall=355802
lprobs.size(): torch.Size([2760, 42808])
2023-09-24 13:35:33 | INFO | train_inner | epoch 021:    538 / 9060 loss=7.309, nll_loss=3.574, ppl=11.91, wps=4012.9, ups=0.31, wpb=13048.3, bsz=418.2, num_updates=181700, lr=7.41861e-05, gnorm=1.091, loss_scale=4, train_wall=325, gb_free=14.8, wall=356127
2023-09-24 13:40:42 | INFO | train_inner | epoch 021:    638 / 9060 loss=7.312, nll_loss=3.531, ppl=11.56, wps=4199.4, ups=0.32, wpb=12982.2, bsz=438.2, num_updates=181800, lr=7.41657e-05, gnorm=1.15, loss_scale=4, train_wall=309, gb_free=14.1, wall=356436
2023-09-24 13:41:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
pred_new.size(): torch.Size([3990, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-24 13:46:07 | INFO | train_inner | epoch 021:    739 / 9060 loss=7.343, nll_loss=3.56, ppl=11.79, wps=4006.7, ups=0.31, wpb=13022.7, bsz=457, num_updates=181900, lr=7.41453e-05, gnorm=1.123, loss_scale=2, train_wall=325, gb_free=13.5, wall=356761
pred_new.size(): torch.Size([5587, 42808])
2023-09-24 13:51:16 | INFO | train_inner | epoch 021:    839 / 9060 loss=7.277, nll_loss=3.571, ppl=11.88, wps=4230.6, ups=0.32, wpb=13052.9, bsz=411.8, num_updates=182000, lr=7.41249e-05, gnorm=1.11, loss_scale=2, train_wall=308, gb_free=14, wall=357069
2023-09-24 13:56:22 | INFO | train_inner | epoch 021:    939 / 9060 loss=7.287, nll_loss=3.532, ppl=11.57, wps=4245.9, ups=0.33, wpb=13011.6, bsz=431.2, num_updates=182100, lr=7.41046e-05, gnorm=1.127, loss_scale=2, train_wall=306, gb_free=14, wall=357376
pred_new.size(): torch.Size([3384, 42808])
2023-09-24 14:01:26 | INFO | train_inner | epoch 021:   1039 / 9060 loss=7.219, nll_loss=3.536, ppl=11.6, wps=4278.2, ups=0.33, wpb=12974.2, bsz=422.2, num_updates=182200, lr=7.40842e-05, gnorm=1.143, loss_scale=2, train_wall=303, gb_free=13.9, wall=357679
2023-09-24 14:06:38 | INFO | train_inner | epoch 021:   1139 / 9060 loss=7.276, nll_loss=3.542, ppl=11.65, wps=4156.6, ups=0.32, wpb=12992.6, bsz=429.8, num_updates=182300, lr=7.40639e-05, gnorm=1.098, loss_scale=2, train_wall=312, gb_free=13.4, wall=357992
ter_threshold: 0.482349
num_accepted / total 53 104
loss token level: tensor(8904.7666, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11600., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 14:11:57 | INFO | train_inner | epoch 021:   1239 / 9060 loss=7.301, nll_loss=3.592, ppl=12.06, wps=4049.7, ups=0.31, wpb=12917.8, bsz=428.4, num_updates=182400, lr=7.40436e-05, gnorm=1.158, loss_scale=2, train_wall=319, gb_free=14.1, wall=358311
lprobs.size(): torch.Size([3280, 42808])
2023-09-24 14:17:16 | INFO | train_inner | epoch 021:   1339 / 9060 loss=7.2, nll_loss=3.588, ppl=12.03, wps=4028.6, ups=0.31, wpb=12843.3, bsz=407.2, num_updates=182500, lr=7.40233e-05, gnorm=1.106, loss_scale=2, train_wall=319, gb_free=13.9, wall=358630
pred_new.size(): torch.Size([5439, 42808])
ter_threshold: 0.482525
num_accepted / total 9 48
loss token level: tensor(10025.1104, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5044., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3168, 42808])
2023-09-24 14:22:23 | INFO | train_inner | epoch 021:   1439 / 9060 loss=7.259, nll_loss=3.562, ppl=11.81, wps=4208.2, ups=0.33, wpb=12934.3, bsz=414.3, num_updates=182600, lr=7.4003e-05, gnorm=1.1, loss_scale=2, train_wall=307, gb_free=14.8, wall=358937
2023-09-24 14:27:42 | INFO | train_inner | epoch 021:   1539 / 9060 loss=7.437, nll_loss=3.613, ppl=12.24, wps=4066.5, ups=0.31, wpb=12963.1, bsz=439.6, num_updates=182700, lr=7.39828e-05, gnorm=1.139, loss_scale=2, train_wall=319, gb_free=13.4, wall=359256
pred_new.size(): torch.Size([4968, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6439, 42808])
2023-09-24 14:33:00 | INFO | train_inner | epoch 021:   1639 / 9060 loss=7.246, nll_loss=3.559, ppl=11.78, wps=4068.5, ups=0.31, wpb=12946.3, bsz=435.4, num_updates=182800, lr=7.39626e-05, gnorm=1.1, loss_scale=2, train_wall=318, gb_free=14.6, wall=359574
pred_new.size(): torch.Size([6028, 42808])
2023-09-24 14:38:13 | INFO | train_inner | epoch 021:   1739 / 9060 loss=7.224, nll_loss=3.543, ppl=11.65, wps=4170.5, ups=0.32, wpb=13018.8, bsz=427.8, num_updates=182900, lr=7.39423e-05, gnorm=1.072, loss_scale=2, train_wall=312, gb_free=13.3, wall=359886
lprobs.size(): torch.Size([3120, 42808])
2023-09-24 14:43:36 | INFO | train_inner | epoch 021:   1839 / 9060 loss=7.385, nll_loss=3.573, ppl=11.9, wps=4019.9, ups=0.31, wpb=13002.6, bsz=429, num_updates=183000, lr=7.39221e-05, gnorm=1.113, loss_scale=2, train_wall=323, gb_free=15.3, wall=360210
pred_new.size(): torch.Size([2163, 42808])
2023-09-24 14:49:03 | INFO | train_inner | epoch 021:   1939 / 9060 loss=7.404, nll_loss=3.628, ppl=12.36, wps=3975.3, ups=0.31, wpb=13015.9, bsz=432, num_updates=183100, lr=7.39019e-05, gnorm=1.115, loss_scale=2, train_wall=327, gb_free=14.2, wall=360537
2023-09-24 14:54:16 | INFO | train_inner | epoch 021:   2039 / 9060 loss=7.311, nll_loss=3.576, ppl=11.93, wps=4138.5, ups=0.32, wpb=12947.5, bsz=440.2, num_updates=183200, lr=7.38818e-05, gnorm=1.119, loss_scale=2, train_wall=313, gb_free=13.9, wall=360850
2023-09-24 14:59:38 | INFO | train_inner | epoch 021:   2139 / 9060 loss=7.379, nll_loss=3.587, ppl=12.01, wps=4041, ups=0.31, wpb=13015.9, bsz=447.4, num_updates=183300, lr=7.38616e-05, gnorm=1.11, loss_scale=2, train_wall=322, gb_free=15.7, wall=361172
pred_new.size(): torch.Size([2208, 42808])
2023-09-24 15:05:03 | INFO | train_inner | epoch 021:   2239 / 9060 loss=7.301, nll_loss=3.558, ppl=11.78, wps=3996.2, ups=0.31, wpb=12961.7, bsz=433, num_updates=183400, lr=7.38415e-05, gnorm=1.122, loss_scale=2, train_wall=324, gb_free=14.5, wall=361496
2023-09-24 15:10:20 | INFO | train_inner | epoch 021:   2339 / 9060 loss=7.224, nll_loss=3.542, ppl=11.65, wps=4089.8, ups=0.32, wpb=12980.9, bsz=438, num_updates=183500, lr=7.38213e-05, gnorm=1.087, loss_scale=2, train_wall=317, gb_free=13.9, wall=361814
2023-09-24 15:15:30 | INFO | train_inner | epoch 021:   2439 / 9060 loss=7.434, nll_loss=3.626, ppl=12.35, wps=4182.6, ups=0.32, wpb=12944.5, bsz=447.9, num_updates=183600, lr=7.38012e-05, gnorm=1.107, loss_scale=2, train_wall=309, gb_free=13.7, wall=362123
pred_new.size(): torch.Size([5994, 42808])
2023-09-24 15:20:43 | INFO | train_inner | epoch 021:   2539 / 9060 loss=7.206, nll_loss=3.528, ppl=11.53, wps=4162.8, ups=0.32, wpb=13054.9, bsz=438.6, num_updates=183700, lr=7.37812e-05, gnorm=1.082, loss_scale=2, train_wall=313, gb_free=13.1, wall=362437
pred_new.size(): torch.Size([7140, 42808])
2023-09-24 15:25:52 | INFO | train_inner | epoch 021:   2639 / 9060 loss=7.334, nll_loss=3.616, ppl=12.26, wps=4188.3, ups=0.32, wpb=12949.9, bsz=428.7, num_updates=183800, lr=7.37611e-05, gnorm=1.098, loss_scale=2, train_wall=309, gb_free=13.9, wall=362746
pred_new.size(): torch.Size([4040, 42808])
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.483873
num_accepted / total 21 48
loss token level: tensor(8296.4082, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6744., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 15:30:54 | INFO | train_inner | epoch 021:   2739 / 9060 loss=7.458, nll_loss=3.657, ppl=12.61, wps=4309.6, ups=0.33, wpb=13012.9, bsz=431.6, num_updates=183900, lr=7.3741e-05, gnorm=1.121, loss_scale=2, train_wall=302, gb_free=13.9, wall=363048
2023-09-24 15:36:09 | INFO | train_inner | epoch 021:   2839 / 9060 loss=7.371, nll_loss=3.611, ppl=12.22, wps=4159.8, ups=0.32, wpb=13074.9, bsz=433.7, num_updates=184000, lr=7.3721e-05, gnorm=1.188, loss_scale=2, train_wall=314, gb_free=13.6, wall=363362
2023-09-24 15:41:19 | INFO | train_inner | epoch 021:   2939 / 9060 loss=7.467, nll_loss=3.631, ppl=12.39, wps=4172.5, ups=0.32, wpb=12948.7, bsz=428.6, num_updates=184100, lr=7.3701e-05, gnorm=1.109, loss_scale=2, train_wall=310, gb_free=14, wall=363673
2023-09-24 15:46:46 | INFO | train_inner | epoch 021:   3039 / 9060 loss=7.282, nll_loss=3.58, ppl=11.96, wps=3959.8, ups=0.31, wpb=12927.6, bsz=423, num_updates=184200, lr=7.36809e-05, gnorm=1.126, loss_scale=2, train_wall=326, gb_free=14.4, wall=363999
pred_new.size(): torch.Size([6327, 42808])
2023-09-24 15:51:54 | INFO | train_inner | epoch 021:   3139 / 9060 loss=7.2, nll_loss=3.529, ppl=11.54, wps=4174.3, ups=0.32, wpb=12885.2, bsz=424.2, num_updates=184300, lr=7.3661e-05, gnorm=1.093, loss_scale=2, train_wall=308, gb_free=13.4, wall=364308
pred_new.size(): torch.Size([3666, 42808])
2023-09-24 15:57:07 | INFO | train_inner | epoch 021:   3239 / 9060 loss=7.272, nll_loss=3.567, ppl=11.85, wps=4149.9, ups=0.32, wpb=12967.7, bsz=430.4, num_updates=184400, lr=7.3641e-05, gnorm=1.097, loss_scale=2, train_wall=312, gb_free=14.1, wall=364620
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.48449699999999996
num_accepted / total 12 48
loss token level: tensor(8837.2861, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3764., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 16:02:16 | INFO | train_inner | epoch 021:   3339 / 9060 loss=7.241, nll_loss=3.526, ppl=11.52, wps=4196.7, ups=0.32, wpb=12993.4, bsz=432.2, num_updates=184500, lr=7.3621e-05, gnorm=1.119, loss_scale=2, train_wall=309, gb_free=13.5, wall=364930
pred_new.size(): torch.Size([3564, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-24 16:07:25 | INFO | train_inner | epoch 021:   3439 / 9060 loss=7.302, nll_loss=3.576, ppl=11.92, wps=4211.1, ups=0.32, wpb=12987.9, bsz=427.2, num_updates=184600, lr=7.36011e-05, gnorm=1.111, loss_scale=2, train_wall=308, gb_free=12.9, wall=365238
torch.Size([2700, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.475128
num_accepted / total 28 104
loss token level: tensor(12114.0586, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6832., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.475237
num_accepted / total 39 72
loss token level: tensor(8983.7402, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13296., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3612, 42808])
pred_new.size(): torch.Size([5076, 42808])
pred_new.size(): torch.Size([3885, 42808])
pred_new.size(): torch.Size([5586, 42808])
pred_new.size(): torch.Size([1393, 42808])
pred_new.size(): torch.Size([4368, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3660, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3816, 42808])
pred_new.size(): torch.Size([4446, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([9348, 42808])
pred_new.size(): torch.Size([3406, 42808])
ter_threshold: 0.47658999999999996
num_accepted / total 7 56
loss token level: tensor(9029.5957, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1623., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1920, 42808])
pred_new.size(): torch.Size([1872, 42808])
pred_new.size(): torch.Size([2025, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([2080, 42808])
pred_new.size(): torch.Size([2670, 42808])
lprobs.size(): torch.Size([2856, 42808])
ter_threshold: 0.47714999999999996
num_accepted / total 40 96
loss token level: tensor(8782.3887, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9792., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3424, 42808])
pred_new.size(): torch.Size([2040, 42808])
pred_new.size(): torch.Size([7560, 42808])
pred_new.size(): torch.Size([3560, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2240, 42808])
pred_new.size(): torch.Size([4050, 42808])
pred_new.size(): torch.Size([7062, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3744, 42808])
pred_new.size(): torch.Size([3294, 42808])
ter_threshold: 0.478056
num_accepted / total 53 104
loss token level: tensor(10044.2637, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12152., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2784, 42808])
ter_threshold: 0.478307
num_accepted / total 55 88
loss token level: tensor(8722.5859, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9600., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6321, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([5625, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([4340, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2624, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([1890, 42808])
pred_new.size(): torch.Size([1728, 42808])
pred_new.size(): torch.Size([2508, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([9275, 42808])
pred_new.size(): torch.Size([5320, 42808])
pred_new.size(): torch.Size([1176, 42808])
lprobs.size(): torch.Size([2576, 42808])
ter_threshold: 0.480002
num_accepted / total 144 224
loss token level: tensor(8973.4160, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8712., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
ter_threshold: 0.480059
num_accepted / total 49 96
loss token level: tensor(9094.7686, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7228., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([5457, 42808])
pred_new.size(): torch.Size([2900, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([4998, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.480391
num_accepted / total 104 160
loss token level: tensor(8181.2432, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13696., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5460, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.480913
num_accepted / total 10 64
loss token level: tensor(13280.2676, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2268., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.480915
num_accepted / total 167 256
loss token level: tensor(8766.6631, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8264., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2800, 42808])
ter_threshold: 0.481089
num_accepted / total 16 88
loss token level: tensor(10518.8574, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2414., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1792, 42808])
pred_new.size(): torch.Size([5100, 42808])
pred_new.size(): torch.Size([3744, 42808])
pred_new.size(): torch.Size([5394, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([5880, 42808])
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([7412, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4131, 42808])
ter_threshold: 0.482349
num_accepted / total 112 176
loss token level: tensor(8925.9648, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(14208., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2000, 42808])
pred_new.size(): torch.Size([6670, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5576, 42808])
pred_new.size(): torch.Size([7800, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1032, 42808])
ter_threshold: 0.48316099999999995
num_accepted / total 167 224
loss token level: tensor(8829.4717, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(16576., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([7921, 42808])
pred_new.size(): torch.Size([4590, 42808])
pred_new.size(): torch.Size([6016, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.483815
num_accepted / total 34 88
loss token level: tensor(8345.2363, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9096., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.483944
num_accepted / total 47 96
loss token level: tensor(8445.2188, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6480., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.484164
num_accepted / total 32 80
loss token level: tensor(9327.0908, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10384., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([864, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.484669
num_accepted / total 7 48
loss token level: tensor(8725.5830, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: pred_new.size(): torch.Size([4464, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-24 16:12:35 | INFO | train_inner | epoch 021:   3539 / 9060 loss=7.204, nll_loss=3.514, ppl=11.42, wps=4196.1, ups=0.32, wpb=13008.2, bsz=413.9, num_updates=184700, lr=7.35811e-05, gnorm=1.112, loss_scale=2, train_wall=310, gb_free=14.5, wall=365548
pred_new.size(): torch.Size([4158, 42808])
2023-09-24 16:17:54 | INFO | train_inner | epoch 021:   3639 / 9060 loss=7.186, nll_loss=3.53, ppl=11.55, wps=4077, ups=0.31, wpb=13007, bsz=435.3, num_updates=184800, lr=7.35612e-05, gnorm=1.082, loss_scale=2, train_wall=319, gb_free=13.9, wall=365867
2023-09-24 16:23:01 | INFO | train_inner | epoch 021:   3739 / 9060 loss=7.097, nll_loss=3.462, ppl=11.02, wps=4200.8, ups=0.32, wpb=12926.5, bsz=433.7, num_updates=184900, lr=7.35413e-05, gnorm=1.064, loss_scale=2, train_wall=307, gb_free=14.9, wall=366175
pred_new.size(): torch.Size([4060, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4104, 42808])
2023-09-24 16:28:18 | INFO | train_inner | epoch 021:   3839 / 9060 loss=7.168, nll_loss=3.5, ppl=11.31, wps=4117.1, ups=0.32, wpb=13013.6, bsz=416.5, num_updates=185000, lr=7.35215e-05, gnorm=1.094, loss_scale=2, train_wall=316, gb_free=13.6, wall=366491
pred_new.size(): torch.Size([1248, 42808])
2023-09-24 16:33:25 | INFO | train_inner | epoch 021:   3939 / 9060 loss=7.22, nll_loss=3.572, ppl=11.89, wps=4233.3, ups=0.32, wpb=13026.6, bsz=428.3, num_updates=185100, lr=7.35016e-05, gnorm=1.092, loss_scale=2, train_wall=307, gb_free=13.4, wall=366799
lprobs.size(): torch.Size([3120, 42808])
2023-09-24 16:38:47 | INFO | train_inner | epoch 021:   4039 / 9060 loss=7.221, nll_loss=3.533, ppl=11.58, wps=4055, ups=0.31, wpb=13048.8, bsz=475.2, num_updates=185200, lr=7.34818e-05, gnorm=1.064, loss_scale=2, train_wall=322, gb_free=14.5, wall=367121
2023-09-24 16:44:02 | INFO | train_inner | epoch 021:   4139 / 9060 loss=7.282, nll_loss=3.568, ppl=11.86, wps=4128.5, ups=0.32, wpb=13019.2, bsz=418, num_updates=185300, lr=7.34619e-05, gnorm=1.104, loss_scale=2, train_wall=315, gb_free=14.1, wall=367436
pred_new.size(): torch.Size([4086, 42808])
2023-09-24 16:49:17 | INFO | train_inner | epoch 021:   4239 / 9060 loss=7.345, nll_loss=3.601, ppl=12.13, wps=4124.6, ups=0.32, wpb=12991.4, bsz=437.8, num_updates=185400, lr=7.34421e-05, gnorm=1.113, loss_scale=2, train_wall=315, gb_free=15.3, wall=367751
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7874, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-24 16:54:38 | INFO | train_inner | epoch 021:   4339 / 9060 loss=7.403, nll_loss=3.608, ppl=12.19, wps=4066.6, ups=0.31, wpb=13041, bsz=431.3, num_updates=185500, lr=7.34223e-05, gnorm=1.125, loss_scale=2, train_wall=320, gb_free=12.9, wall=368072
ter_threshold: 0.485557
num_accepted / total 31 72
loss token level: tensor(8807.1738, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11328., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1700, 42808])
2023-09-24 16:59:47 | INFO | train_inner | epoch 021:   4439 / 9060 loss=7.284, nll_loss=3.604, ppl=12.16, wps=4196.4, ups=0.32, wpb=12965.4, bsz=425.8, num_updates=185600, lr=7.34025e-05, gnorm=1.121, loss_scale=2, train_wall=309, gb_free=13.6, wall=368381
lprobs.size(): torch.Size([2576, 42808])
2023-09-24 17:04:52 | INFO | train_inner | epoch 021:   4539 / 9060 loss=7.29, nll_loss=3.6, ppl=12.12, wps=4218.2, ups=0.33, wpb=12851.6, bsz=422.4, num_updates=185700, lr=7.33828e-05, gnorm=1.125, loss_scale=2, train_wall=304, gb_free=12.7, wall=368685
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.485774
num_accepted / total 19 80
loss token level: tensor(8972.0371, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2928., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 17:09:47 | INFO | train_inner | epoch 021:   4639 / 9060 loss=7.324, nll_loss=3.631, ppl=12.39, wps=4416, ups=0.34, wpb=13029.2, bsz=448.6, num_updates=185800, lr=7.3363e-05, gnorm=1.084, loss_scale=2, train_wall=295, gb_free=15.2, wall=368980
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.48585199999999995
num_accepted / total 37 88
loss token level: tensor(8553.6016, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6132., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 17:14:51 | INFO | train_inner | epoch 021:   4739 / 9060 loss=7.426, nll_loss=3.636, ppl=12.43, wps=4282.8, ups=0.33, wpb=13029.9, bsz=431.6, num_updates=185900, lr=7.33433e-05, gnorm=1.115, loss_scale=2, train_wall=304, gb_free=13.8, wall=369284
ter_threshold: 0.48594
num_accepted / total 60 112
loss token level: tensor(9918.1387, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7872., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1848, 42808])
2023-09-24 17:19:58 | INFO | train_inner | epoch 021:   4839 / 9060 loss=7.449, nll_loss=3.655, ppl=12.6, wps=4250.6, ups=0.33, wpb=13038.6, bsz=439.8, num_updates=186000, lr=7.33236e-05, gnorm=1.118, loss_scale=4, train_wall=306, gb_free=13.6, wall=369591
pred_new.size(): torch.Size([5082, 42808])
2023-09-24 17:25:17 | INFO | train_inner | epoch 021:   4939 / 9060 loss=7.474, nll_loss=3.656, ppl=12.61, wps=4077.8, ups=0.31, wpb=13024.9, bsz=426.3, num_updates=186100, lr=7.33039e-05, gnorm=1.128, loss_scale=4, train_wall=319, gb_free=14.2, wall=369911
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.486121
num_accepted / total 43 80
loss token level: tensor(8936.5752, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13344., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.486156
num_accepted / total 41 88
loss token level: tensor(8530.1787, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10672., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3600, 42808])
2023-09-24 17:30:25 | INFO | train_inner | epoch 021:   5039 / 9060 loss=7.377, nll_loss=3.615, ppl=12.25, wps=4203.2, ups=0.33, wpb=12925.5, bsz=439.3, num_updates=186200, lr=7.32842e-05, gnorm=1.111, loss_scale=4, train_wall=307, gb_free=13.7, wall=370218
2023-09-24 17:35:28 | INFO | train_inner | epoch 021:   5139 / 9060 loss=7.374, nll_loss=3.604, ppl=12.16, wps=4275.3, ups=0.33, wpb=12953, bsz=438.4, num_updates=186300, lr=7.32645e-05, gnorm=1.114, loss_scale=4, train_wall=303, gb_free=13.9, wall=370521
2023-09-24 17:40:38 | INFO | train_inner | epoch 021:   5239 / 9060 loss=7.26, nll_loss=3.577, ppl=11.94, wps=4141.2, ups=0.32, wpb=12867.9, bsz=420.9, num_updates=186400, lr=7.32448e-05, gnorm=1.124, loss_scale=4, train_wall=310, gb_free=13.9, wall=370832
2023-09-24 17:46:03 | INFO | train_inner | epoch 021:   5339 / 9060 loss=7.322, nll_loss=3.632, ppl=12.4, wps=4007.5, ups=0.31, wpb=12990.9, bsz=431.8, num_updates=186500, lr=7.32252e-05, gnorm=1.119, loss_scale=4, train_wall=324, gb_free=14.9, wall=371156
2023-09-24 17:51:16 | INFO | train_inner | epoch 021:   5439 / 9060 loss=7.44, nll_loss=3.634, ppl=12.41, wps=4124.6, ups=0.32, wpb=12924.3, bsz=441.4, num_updates=186600, lr=7.32056e-05, gnorm=1.129, loss_scale=4, train_wall=313, gb_free=13.8, wall=371469
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-24 17:56:37 | INFO | train_inner | epoch 021:   5539 / 9060 loss=7.264, nll_loss=3.613, ppl=12.23, wps=4021.1, ups=0.31, wpb=12914.2, bsz=424.1, num_updates=186700, lr=7.3186e-05, gnorm=1.082, loss_scale=4, train_wall=321, gb_free=15.5, wall=371791
2023-09-24 18:01:45 | INFO | train_inner | epoch 021:   5639 / 9060 loss=7.227, nll_loss=3.581, ppl=11.97, wps=4207.3, ups=0.32, wpb=12959.4, bsz=425.8, num_updates=186800, lr=7.31664e-05, gnorm=1.115, loss_scale=4, train_wall=308, gb_free=14.2, wall=372099
2023-09-24 18:07:04 | INFO | train_inner | epoch 021:   5739 / 9060 loss=7.376, nll_loss=3.614, ppl=12.24, wps=4062.3, ups=0.31, wpb=12972.4, bsz=435.9, num_updates=186900, lr=7.31468e-05, gnorm=1.112, loss_scale=4, train_wall=319, gb_free=13.4, wall=372418
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.486912
num_accepted / total 47 176
loss token level: tensor(7984.4141, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2864., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 18:12:34 | INFO | train_inner | epoch 021:   5839 / 9060 loss=7.351, nll_loss=3.605, ppl=12.17, wps=3918.2, ups=0.3, wpb=12896.4, bsz=419, num_updates=187000, lr=7.31272e-05, gnorm=1.133, loss_scale=4, train_wall=329, gb_free=12.9, wall=372747
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2320, 42808])
2023-09-24 18:17:48 | INFO | train_inner | epoch 021:   5939 / 9060 loss=7.326, nll_loss=3.589, ppl=12.03, wps=4118.8, ups=0.32, wpb=12943.7, bsz=431.5, num_updates=187100, lr=7.31077e-05, gnorm=1.118, loss_scale=4, train_wall=314, gb_free=13.8, wall=373061
ter_threshold: 0.487153
num_accepted / total 4 64
loss token level: tensor(9408.7266, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1234., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2120, 42808])
2023-09-24 18:23:05 | INFO | train_inner | epoch 021:   6039 / 9060 loss=7.296, nll_loss=3.593, ppl=12.06, wps=4075.6, ups=0.32, wpb=12926, bsz=437.8, num_updates=187200, lr=7.30882e-05, gnorm=1.131, loss_scale=4, train_wall=317, gb_free=14, wall=373378
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.48721
num_accepted / total 31 80
loss token level: tensor(10401.2754, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9024., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 18:28:15 | INFO | train_inner | epoch 021:   6139 / 9060 loss=7.287, nll_loss=3.606, ppl=12.18, wps=4151.9, ups=0.32, wpb=12884, bsz=430.8, num_updates=187300, lr=7.30687e-05, gnorm=1.112, loss_scale=4, train_wall=310, gb_free=14, wall=373689
pred_new.size(): torch.Size([6328, 42808])
2023-09-24 18:33:27 | INFO | train_inner | epoch 021:   6239 / 9060 loss=7.426, nll_loss=3.685, ppl=12.86, wps=4144.7, ups=0.32, wpb=12918.6, bsz=418.1, num_updates=187400, lr=7.30492e-05, gnorm=1.13, loss_scale=4, train_wall=311, gb_free=14.5, wall=374000
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([4900, 42808])
pred_new.size(): torch.Size([4520, 42808])
2023-09-24 18:38:45 | INFO | train_inner | epoch 021:   6339 / 9060 loss=7.397, nll_loss=3.646, ppl=12.52, wps=4063.2, ups=0.31, wpb=12936.3, bsz=427.8, num_updates=187500, lr=7.30297e-05, gnorm=1.151, loss_scale=4, train_wall=318, gb_free=13.5, wall=374319
pred_new.size(): torch.Size([3744, 42808])
2023-09-24 18:44:02 | INFO | train_inner | epoch 021:   6439 / 9060 loss=7.414, nll_loss=3.635, ppl=12.43, wps=4107.2, ups=0.32, wpb=13013.7, bsz=458.2, num_updates=187600, lr=7.30102e-05, gnorm=1.108, loss_scale=4, train_wall=317, gb_free=13.1, wall=374636
2023-09-24 18:49:18 | INFO | train_inner | epoch 021:   6539 / 9060 loss=7.24, nll_loss=3.569, ppl=11.87, wps=4085.9, ups=0.32, wpb=12911.9, bsz=418.2, num_updates=187700, lr=7.29908e-05, gnorm=1.096, loss_scale=4, train_wall=316, gb_free=14.2, wall=374952
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.487719
num_accepted / total 4 40
loss token level: tensor(12900.6719, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2746., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.487745
num_accepted / total 14 48
loss token level: tensor(8147.0664, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3612., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 18:54:27 | INFO | train_inner | epoch 021:   6639 / 9060 loss=7.144, nll_loss=3.524, ppl=11.5, wps=4172.9, ups=0.32, wpb=12875.4, bsz=420.7, num_updates=187800, lr=7.29713e-05, gnorm=1.089, loss_scale=4, train_wall=308, gb_free=12.6, wall=375260
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-24 18:59:49 | INFO | train_inner | epoch 021:   6739 / 9060 loss=7.31, nll_loss=3.622, ppl=12.31, wps=4056.4, ups=0.31, wpb=13071.9, bsz=437.4, num_updates=187900, lr=7.29519e-05, gnorm=1.1, loss_scale=4, train_wall=322, gb_free=13.3, wall=375582
num_accepted / total 16 64
loss token level: tensor(10767.4043, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6424., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4350, 42808])
pred_new.size(): torch.Size([1485, 42808])
pred_new.size(): torch.Size([225, 42808])
pred_new.size(): torch.Size([900, 42808])
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.478056
num_accepted / total 73 136
loss token level: tensor(9324.7832, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12216., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2744, 42808])
ter_threshold: 0.478136
num_accepted / total 65 176
loss token level: tensor(8653.8779, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4000., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([8208, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([1692, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1920, 42808])
pred_new.size(): torch.Size([1276, 42808])
lprobs.size(): torch.Size([3072, 42808])
ter_threshold: 0.479566
num_accepted / total 13 48
loss token level: tensor(8390.7568, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7464., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1290, 42808])
pred_new.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([7252, 42808])
pred_new.size(): torch.Size([4896, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4960, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7905, 42808])
pred_new.size(): torch.Size([6853, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3424, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([1632, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.480591
num_accepted / total 44 88
loss token level: tensor(8462.2051, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6736., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3408, 42808])
pred_new.size(): torch.Size([6887, 42808])
ter_threshold: 0.480915
num_accepted / total 59 128
loss token level: tensor(8416.6592, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6016., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1440, 42808])
ter_threshold: 0.481089
num_accepted / total 35 104
loss token level: tensor(9107.8984, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4480., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([476, 42808])
pred_new.size(): torch.Size([2052, 42808])
pred_new.size(): torch.Size([1200, 42808])
lprobs.size(): torch.Size([3504, 42808])
lprobs.size(): torch.Size([2760, 42808])
pred_new.size(): torch.Size([4060, 42808])
pred_new.size(): torch.Size([5670, 42808])
pred_new.size(): torch.Size([2112, 42808])
pred_new.size(): torch.Size([4221, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([6536, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([1960, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2496, 42808])
pred_new.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([2580, 42808])
ter_threshold: 0.48343
num_accepted / total 113 192
loss token level: tensor(8078.2598, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7064., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3128, 42808])
ter_threshold: 0.483815
num_accepted / total 43 88
loss token level: tensor(8278.2598, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11584., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.483944
num_accepted / total 79 152
loss token level: tensor(9707.4922, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6816., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.48449699999999996
num_accepted / total 19 56
loss token level: tensor(9562.0430, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5332., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.484504
num_accepted / total 15 64
loss token level: tensor(11823.3027, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6420., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([284, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1116, 42808])
pred_new.size(): torch.Size([2790, 42808])
lprobs.size(): torch.Size([3232, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([5406, 42808])
ter_threshold: 0.485557
num_accepted / total 26 72
loss token level: tensor(8431.7441, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9232., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.485581
num_accepted / total 8 8
loss token level: tensor(5935.1616, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9888., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([6319, 42808])
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.486009
num_accepted / total 26 80
loss token level: tensor(9553.3086, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8200., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([7656, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([3956, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.486391
num_accepted / total 26 72
loss token level: tensor(9868.8623, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8168., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1104, 42808])
pred_new.size(): torch.Size([6642, 42808])
pred_new.size(): torch.Size([7728, 42808])
ter_threshold: 0.486754
num_accepted / total 39 80
loss token level: tensor(8543.2930, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6888., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2616, 42808])
pred_new.size(): torch.Size([6552, 42808])
pred_new.size(): torch.Size([2640, 42808])
ter_threshold: 0.48749299999999995
num_accepted / total 139 224
loss token level: tensor(8287.6729, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11776., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2496, 42808])
pred_new.size(): torch.Size([7544, 42808])
lprobs.size(): torch.Size([2968, 42808])
pred_new.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([3535, 42808])
lprobs.size(): torch.Size([2904, 42808])
lprobs.size(): lprobs.size(): torch.Size([3456, 42808])
2023-09-24 19:05:04 | INFO | train_inner | epoch 021:   6839 / 9060 loss=7.261, nll_loss=3.557, ppl=11.77, wps=4119.9, ups=0.32, wpb=12997.3, bsz=444.5, num_updates=188000, lr=7.29325e-05, gnorm=1.098, loss_scale=4, train_wall=315, gb_free=12.7, wall=375898
2023-09-24 19:10:18 | INFO | train_inner | epoch 021:   6939 / 9060 loss=7.353, nll_loss=3.571, ppl=11.89, wps=4167.3, ups=0.32, wpb=13045.8, bsz=431.7, num_updates=188100, lr=7.29131e-05, gnorm=1.103, loss_scale=4, train_wall=313, gb_free=14.1, wall=376211
ter_threshold: 0.488125
num_accepted / total 39 104
loss token level: tensor(11417.1631, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8056., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
2023-09-24 19:15:24 | INFO | train_inner | epoch 021:   7039 / 9060 loss=7.463, nll_loss=3.647, ppl=12.53, wps=4298.9, ups=0.33, wpb=13154.3, bsz=435.1, num_updates=188200, lr=7.28937e-05, gnorm=1.121, loss_scale=4, train_wall=306, gb_free=13.3, wall=376517
pred_new.size(): torch.Size([2964, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4032, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3440, 42808])
2023-09-24 19:20:39 | INFO | train_inner | epoch 021:   7139 / 9060 loss=7.342, nll_loss=3.592, ppl=12.06, wps=4155.7, ups=0.32, wpb=13103.8, bsz=431.8, num_updates=188300, lr=7.28744e-05, gnorm=1.127, loss_scale=4, train_wall=315, gb_free=14.1, wall=376832
2023-09-24 19:25:55 | INFO | train_inner | epoch 021:   7239 / 9060 loss=7.37, nll_loss=3.585, ppl=12, wps=4139.9, ups=0.32, wpb=13073.7, bsz=434.6, num_updates=188400, lr=7.2855e-05, gnorm=1.129, loss_scale=4, train_wall=316, gb_free=15.7, wall=377148
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6825, 42808])
2023-09-24 19:31:07 | INFO | train_inner | epoch 021:   7339 / 9060 loss=7.321, nll_loss=3.611, ppl=12.22, wps=4123.6, ups=0.32, wpb=12883.2, bsz=418.7, num_updates=188500, lr=7.28357e-05, gnorm=1.117, loss_scale=4, train_wall=312, gb_free=14.1, wall=377461
2023-09-24 19:36:29 | INFO | train_inner | epoch 021:   7439 / 9060 loss=7.467, nll_loss=3.677, ppl=12.79, wps=4026.6, ups=0.31, wpb=12971.2, bsz=426.4, num_updates=188600, lr=7.28164e-05, gnorm=1.132, loss_scale=4, train_wall=322, gb_free=14.1, wall=377783
pred_new.size(): torch.Size([6215, 42808])
ter_threshold: 0.48866299999999996
num_accepted / total 32 72
loss token level: tensor(8364.1357, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5752., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
2023-09-24 19:41:57 | INFO | train_inner | epoch 021:   7539 / 9060 loss=7.412, nll_loss=3.639, ppl=12.46, wps=3959.1, ups=0.3, wpb=12988.4, bsz=447.3, num_updates=188700, lr=7.27971e-05, gnorm=1.134, loss_scale=4, train_wall=328, gb_free=14.6, wall=378111
lprobs.size(): torch.Size([3264, 42808])
2023-09-24 19:47:22 | INFO | train_inner | epoch 021:   7639 / 9060 loss=7.414, nll_loss=3.646, ppl=12.52, wps=3987.7, ups=0.31, wpb=12954.3, bsz=440.9, num_updates=188800, lr=7.27778e-05, gnorm=1.133, loss_scale=4, train_wall=325, gb_free=14, wall=378436
pred_new.size(): torch.Size([2793, 42808])
2023-09-24 19:52:43 | INFO | train_inner | epoch 021:   7739 / 9060 loss=7.34, nll_loss=3.652, ppl=12.57, wps=4048.1, ups=0.31, wpb=12969.7, bsz=405.9, num_updates=188900, lr=7.27585e-05, gnorm=1.112, loss_scale=4, train_wall=320, gb_free=13.3, wall=378756
2023-09-24 19:58:05 | INFO | train_inner | epoch 021:   7839 / 9060 loss=7.374, nll_loss=3.623, ppl=12.32, wps=4005.7, ups=0.31, wpb=12936.5, bsz=419, num_updates=189000, lr=7.27393e-05, gnorm=1.124, loss_scale=4, train_wall=323, gb_free=14.6, wall=379079
lprobs.size(): torch.Size([3320, 42808])
2023-09-24 20:03:21 | INFO | train_inner | epoch 021:   7939 / 9060 loss=7.331, nll_loss=3.636, ppl=12.43, wps=4098.1, ups=0.32, wpb=12934, bsz=441.9, num_updates=189100, lr=7.27201e-05, gnorm=1.12, loss_scale=4, train_wall=315, gb_free=13.4, wall=379395
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([2736, 42808])
2023-09-24 20:08:30 | INFO | train_inner | epoch 021:   8039 / 9060 loss=7.242, nll_loss=3.577, ppl=11.94, wps=4197.9, ups=0.32, wpb=12963, bsz=426.6, num_updates=189200, lr=7.27008e-05, gnorm=1.105, loss_scale=4, train_wall=309, gb_free=13.1, wall=379703
2023-09-24 20:13:37 | INFO | train_inner | epoch 021:   8139 / 9060 loss=7.224, nll_loss=3.545, ppl=11.67, wps=4256.2, ups=0.33, wpb=13054.7, bsz=428, num_updates=189300, lr=7.26816e-05, gnorm=1.092, loss_scale=4, train_wall=306, gb_free=13.1, wall=380010
pred_new.size(): torch.Size([6030, 42808])
2023-09-24 20:18:54 | INFO | train_inner | epoch 021:   8239 / 9060 loss=7.317, nll_loss=3.599, ppl=12.12, wps=4066.8, ups=0.32, wpb=12892, bsz=410.7, num_updates=189400, lr=7.26624e-05, gnorm=1.165, loss_scale=4, train_wall=317, gb_free=14, wall=380327
torch.Size([1410, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([5335, 42808])
pred_new.size(): torch.Size([4841, 42808])
ter_threshold: 0.480059
num_accepted / total 101 152
loss token level: tensor(8343.9199, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9064., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.480128
num_accepted / total 4 56
loss token level: tensor(9403.9551, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1157., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([5250, 42808])
pred_new.size(): torch.Size([7326, 42808])
pred_new.size(): torch.Size([4750, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.480391
num_accepted / total 48 96
loss token level: tensor(8686.3906, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12384., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.48060899999999995
num_accepted / total 13 40
loss token level: tensor(9512.6377, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5496., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3570, 42808])
pred_new.size(): torch.Size([5427, 42808])
ter_threshold: 0.480915
num_accepted / total 41 88
loss token level: tensor(8892.8125, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.481089
num_accepted / total 66 120
loss token level: tensor(8958.8828, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7776., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2560, 42808])
pred_new.size(): torch.Size([3498, 42808])
pred_new.size(): torch.Size([7800, 42808])
pred_new.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2493, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([1200, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([3450, 42808])
pred_new.size(): torch.Size([2760, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([4026, 42808])
ter_threshold: 0.482349
num_accepted / total 113 224
loss token level: tensor(7557.3926, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7904., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2368, 42808])
pred_new.size(): torch.Size([5676, 42808])
lprobs.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([1850, 42808])
pred_new.size(): torch.Size([2178, 42808])
pred_new.size(): torch.Size([7626, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2200, 42808])
ter_threshold: 0.48316099999999995
num_accepted / total 68 120
loss token level: tensor(8855.9922, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14344., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([7421, 42808])
pred_new.size(): torch.Size([2600, 42808])
pred_new.size(): torch.Size([2158, 42808])
ter_threshold: 0.483815
num_accepted / total 54 104
loss token level: tensor(8499.3906, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12048., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2736, 42808])
ter_threshold: 0.483944
num_accepted / total 50 104
loss token level: tensor(8800.1328, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6912., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4288, 42808])
pred_new.size(): torch.Size([3420, 42808])
pred_new.size(): torch.Size([6498, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1800, 42808])
pred_new.size(): torch.Size([3570, 42808])
pred_new.size(): torch.Size([8580, 42808])
pred_new.size(): torch.Size([5544, 42808])
pred_new.size(): torch.Size([3077, 42808])
lprobs.size(): torch.Size([3160, 42808])
pred_new.size(): torch.Size([5358, 42808])
ter_threshold: 0.485557
num_accepted / total 35 72
loss token level: tensor(8631.0547, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11712., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6144, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.485774
num_accepted / total 23 112
loss token level: tensor(13107.9238, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2584., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.48585199999999995
num_accepted / total 71 128
loss token level: tensor(8314.7031, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7768., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8320, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.486156
num_accepted / total 112 160
loss token level: tensor(8398.3652, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14632., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([7062, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([600, 42808])
pred_new.size(): torch.Size([7650, 42808])
pred_new.size(): torch.Size([900, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.487172
num_accepted / total 18 40
loss token level: tensor(8363.0176, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10304., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4536, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6955, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([4050, 42808])
pred_new.size(): torch.Size([5550, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([3540, 42808])
ter_threshold: 0.48777099999999995
num_accepted / total 18 88
loss token level: tensor(8989.7021, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3236., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([2904, 42808])
ter_threshold: 0.488125
num_accepted / total 17 72
loss token level: tensor(8397.5439, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4472., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([4144, 42808])
ter_threshold: 0.488234
num_accepted / total 87 136
loss token level: tensor(9138.7383, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8856., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4275, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([9009, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([8547, 42808])
lprobs.size(): torch.Size([3120, 42808])
ter_threshold: 0.489082
num_accepted / total 23 64
loss token level: tensor(7934.4648, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6824., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1938, 42808])
pred_new.size(): torch.Size([2256, 42808])
pred_new.size(): torch.Size([7654, 42808])
ter_threshold: 0.489453
num_accepted / total 3 56
loss token level: tensor(9135.9873, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(926.5000, device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 20:23:55 | INFO | train_inner | epoch 021:   8339 / 9060 loss=7.194, nll_loss=3.564, ppl=11.82, wps=4320.4, ups=0.33, wpb=13018.3, bsz=453.8, num_updates=189500, lr=7.26433e-05, gnorm=1.074, loss_scale=4, train_wall=301, gb_free=14.9, wall=380628
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2752, 42808])
2023-09-24 20:29:15 | INFO | train_inner | epoch 021:   8439 / 9060 loss=7.153, nll_loss=3.51, ppl=11.4, wps=4062.4, ups=0.31, wpb=12981.8, bsz=422, num_updates=189600, lr=7.26241e-05, gnorm=1.094, loss_scale=4, train_wall=319, gb_free=14.6, wall=380948
pred_new.size(): torch.Size([5280, 42808])
2023-09-24 20:34:23 | INFO | train_inner | epoch 021:   8539 / 9060 loss=7.166, nll_loss=3.56, ppl=11.79, wps=4201, ups=0.32, wpb=12968.2, bsz=414.7, num_updates=189700, lr=7.2605e-05, gnorm=1.127, loss_scale=4, train_wall=308, gb_free=12.7, wall=381257
lprobs.size(): torch.Size([3552, 42808])
2023-09-24 20:39:42 | INFO | train_inner | epoch 021:   8639 / 9060 loss=7.41, nll_loss=3.635, ppl=12.42, wps=4108.1, ups=0.31, wpb=13106.3, bsz=441.9, num_updates=189800, lr=7.25858e-05, gnorm=1.113, loss_scale=4, train_wall=319, gb_free=13.2, wall=381576
lprobs.size(): torch.Size([3264, 42808])
2023-09-24 20:44:51 | INFO | train_inner | epoch 021:   8739 / 9060 loss=7.317, nll_loss=3.639, ppl=12.46, wps=4187, ups=0.32, wpb=12933.6, bsz=419.4, num_updates=189900, lr=7.25667e-05, gnorm=1.125, loss_scale=4, train_wall=309, gb_free=15, wall=381885
2023-09-24 20:49:54 | INFO | train_inner | epoch 021:   8839 / 9060 loss=7.245, nll_loss=3.563, ppl=11.82, wps=4285.8, ups=0.33, wpb=12985.6, bsz=428.6, num_updates=190000, lr=7.25476e-05, gnorm=1.086, loss_scale=4, train_wall=303, gb_free=14.6, wall=382188
ter_threshold: 0.49001799999999995
num_accepted / total 9 40
loss token level: tensor(8872.1113, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3922., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 20:55:03 | INFO | train_inner | epoch 021:   8939 / 9060 loss=7.179, nll_loss=3.532, ppl=11.57, wps=4175.9, ups=0.32, wpb=12909.9, bsz=422.9, num_updates=190100, lr=7.25285e-05, gnorm=1.118, loss_scale=8, train_wall=309, gb_free=13.8, wall=382497
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([8316, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.490197
num_accepted / total 39 104
loss token level: tensor(8596.3105, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8432., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 21:00:10 | INFO | train_inner | epoch 021:   9039 / 9060 loss=7.304, nll_loss=3.619, ppl=12.29, wps=4232, ups=0.33, wpb=12999.5, bsz=431.5, num_updates=190200, lr=7.25095e-05, gnorm=1.117, loss_scale=8, train_wall=307, gb_free=14.2, wall=382804
2023-09-24 21:01:20 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-24 21:01:20 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-24 21:01:21 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-24 21:01:21 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-24 21:01:21 | INFO | fairseq.tasks.translation | example hypothesis: Der Appell zum Handeln ist daher vollkommen gerechtfertigt.
2023-09-24 21:01:21 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-24 21:01:22 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-24 21:01:22 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-24 21:01:22 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-24 21:01:22 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-24 21:01:23 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-24 21:01:23 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-24 21:01:23 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein voller Erfolg.
2023-09-24 21:01:23 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-24 21:01:24 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-24 21:01:24 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-24 21:01:25 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-24 21:01:25 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-24 21:01:25 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-24 21:01:25 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-24 21:01:26 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer sind mit digitalem TV und Internetzugang ausgestattet, die sowohl für Geschäfts- als auch für Freizeitreisende attraktiv sind.
2023-09-24 21:01:26 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-24 21:01:26 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-24 21:01:26 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-24 21:01:27 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-24 21:01:27 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-24 21:01:27 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU riesige Mengen an Energie verschwendet.
2023-09-24 21:01:27 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-24 21:01:28 | INFO | fairseq.tasks.translation | example hypothesis: Das Deutsche Linux Magazin enthält einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer.
2023-09-24 21:01:28 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-24 21:01:28 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die veränderte Haltung in Kürze auch im Haushalt der Union niederschlagen.
2023-09-24 21:01:28 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-24 21:01:29 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für kleine Erzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-24 21:01:29 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-24 21:01:30 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-24 21:01:30 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-24 21:01:30 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-24 21:01:30 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-24 21:01:31 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-24 21:01:31 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-24 21:01:31 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Sitz und Produktionshallen in Stans.
2023-09-24 21:01:31 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-24 21:01:32 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender immer der Vorsitzende des Aufsichtsrats ist.
2023-09-24 21:01:32 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-24 21:01:32 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-24 21:01:32 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-24 21:01:33 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionale Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-24 21:01:33 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-24 21:01:34 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerbehaftete Anzeige kann potentielle Käufer dazu veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-24 21:01:34 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-24 21:01:34 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-24 21:01:34 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-24 21:01:35 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-24 21:01:35 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-24 21:01:35 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Aussprache, Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-24 21:01:35 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-24 21:01:36 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Orte im Umkreis von etwa 8 km vom Strip entfernt.
2023-09-24 21:01:36 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-24 21:01:37 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Webportal System basiert.
2023-09-24 21:01:37 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-24 21:01:38 | INFO | fairseq.tasks.translation | example hypothesis: Aus diesem Grund bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Tonbüchern an.
2023-09-24 21:01:38 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-24 21:01:38 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-24 21:01:38 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-24 21:01:39 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-24 21:01:39 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-24 21:01:39 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Ausreise Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme einzahlen.
2023-09-24 21:01:39 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-24 21:01:40 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-24 21:01:40 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-24 21:01:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind ständig auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine kostenlose Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-24 21:01:41 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-24 21:01:41 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-24 21:01:41 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-24 21:01:42 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind Thatcheristische Ideen über niedrigere und transparentere Steuerstrukturen und eine zentrale Kontrolle der Haushaltsausgaben definitiv zentrale Teile seiner Agenda.
2023-09-24 21:01:42 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-24 21:01:43 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils-Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-24 21:01:43 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-24 21:01:43 | INFO | fairseq.tasks.translation | example hypothesis: Horde- und Allianzspieler können sich keine Gegenstände gegenseitig kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-24 21:01:43 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-24 21:01:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollen.
2023-09-24 21:01:44 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-24 21:01:44 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-24 21:01:44 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-24 21:01:45 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu einigen Details des Abkommens grundsätzlich mit den Vereinigten Staaten abgeben müssen.
2023-09-24 21:01:45 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-24 21:01:46 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderauflage - unser breites Sortiment an PlastikBabyartikeln ist nicht zuletzt durch seine hervorragende Verarbeitung beeindruckend.
2023-09-24 21:01:46 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-24 21:01:47 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-24 21:01:47 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-24 21:01:47 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis Kenntnis Kenntnis Kenntnis von Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-24 21:01:47 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-24 21:01:48 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die die Notwendigkeit institutioneller Veränderungen vorangeschritten ist und erkennt, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung braucht.
2023-09-24 21:01:48 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-24 21:01:49 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-24 21:01:49 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-24 21:01:49 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die erzielt wurden, wenn wir uns alle Fragen ansehen, die jetzt diskutiert werden, und die etwas betreffen, was gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-24 21:01:49 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-24 21:01:50 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-24 21:01:50 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-24 21:01:51 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es der Berichterstatterin gelungen, zeitweise unterschiedliche Standpunkte und Beiträge zusammenzufassen und in einem sehr ausgewogenen Text zusammenzufassen - ich würde sagen -.
2023-09-24 21:01:51 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-24 21:01:51 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT T T-Modell unser Programm an trockenen elektrostatischen Niederrichtern um einen trockenen ESP für den unteren Leistungsbereich.
2023-09-24 21:01:51 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-24 21:01:52 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land..................
2023-09-24 21:01:52 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-24 21:01:53 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und Fernost abwandern, müssen wir uns auf unsere Innovation und Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-24 21:01:53 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-24 21:01:54 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und mit unserer Staatengemeinschaft zu tun haben.
2023-09-24 21:01:54 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-24 21:01:54 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-24 21:01:54 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-24 21:01:55 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-24 21:01:55 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-24 21:01:56 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-24 21:01:56 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-24 21:01:56 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine weitere: die Notsituation der Kinder, des schwächsten BevölkerungsBevölkerung, die ohne Familie, ohne Schutz und ohne Staat zurückgelassen wurde.
2023-09-24 21:01:56 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-24 21:01:57 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt ist, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen.
2023-09-24 21:01:57 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-24 21:01:58 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, nicht in der ersten Person realisiert ist, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, solange man nicht sein wahres Selbst kennt.
2023-09-24 21:01:58 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-24 21:01:59 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in unserer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen.............
2023-09-24 21:01:59 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-24 21:01:59 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht......................
2023-09-24 21:01:59 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-24 21:02:00 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken, die Plattform-und Betriebssystem-Unabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-24 21:02:00 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-24 21:02:01 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für die Klärung des Anhangs.
2023-09-24 21:02:01 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-24 21:02:01 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuß ist außerdem der Ansicht, daß die WTO-Mitglieder eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, daß Sanktionen der IAO nicht als unvereinbar mit den WTO-Verträgen betrachtet werden.........
2023-09-24 21:02:01 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-24 21:02:02 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische Radio des öffentlichen Dienstes RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.................
2023-09-24 21:02:02 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-24 21:02:03 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und ich möchte der Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-24 21:02:03 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-24 21:02:04 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Bürgerschaft oder so etwas wie die Senkung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.................
2023-09-24 21:02:04 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-24 21:02:04 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der Griechenland Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen..........................
2023-09-24 21:02:04 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
lprobs.size(): torch.Size([2952, 42808])
2023-09-24 21:02:05 | INFO | fairseq.tasks.translation | example hypothesis: - Herr Präsident! Ich glaube, dass der Bericht mit Ausnahme dieser wenigen Vorbehalte ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-24 21:02:05 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-24 21:02:06 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu glauben, hieße, eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen oft die tatsächliche oder wahrgenommene Gefahr, von institutioneller Hegemonie zerschlagen zu werden)!!!!!!!!!!!!!!!
2023-09-24 21:02:06 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-24 21:02:07 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder eine einheitliche Auslegung der Konvention erforderlich ist.
2023-09-24 21:02:07 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-24 21:02:07 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist einer der lustigsten Fahrzeuge für weniger als 50.000 $, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren..........................
2023-09-24 21:02:07 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-24 21:02:08 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit danken.......... - Herr Präsident, zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für seinen ausgezeichneten Bericht danken.
2023-09-24 21:02:08 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-24 21:02:09 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrillter Zander, Forelle mit Mandeln.
2023-09-24 21:02:09 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-24 21:02:10 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, einen Gesamtüberblick zu bieten, der es uns ermöglicht, näher auf die verschiedenen Fragen einzugehen und zu prüfen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann...................
2023-09-24 21:02:10 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-24 21:02:11 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, stimmten der Veröffentlichung eines Live-Albums "Bodulska balada 2009" zu veröffentlichen..................
2023-09-24 21:02:11 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-24 21:02:11 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Strategien, steuerliche Maßnahmen und Beschränkungen, die nicht an die bestehende Situation vor Ort angepasst sind, schrittweise ausgehöhlt wird.
2023-09-24 21:02:11 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-24 21:02:12 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein ausgezeichnetes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, beigetragen hat. der alle unsere Änderungsanträge in den Text übernommen hat..........
2023-09-24 21:02:12 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-24 21:02:13 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den Rechts- und Rechtsbereich hinaus, wodurch Norwegen und Island, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes gelten werden, gelten werden.
2023-09-24 21:02:13 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-24 21:02:14 | INFO | fairseq.tasks.translation | example hypothesis: Wir gehen mit voller Geschwindigkeit mit einem Schalterboot hinunter den Mississippi, suchen nach dem großen versteckten Schatz, verlieben uns in den schönen Becky Thatcher, der rein dynamisch ist, und vor allem werden wir große Freunde sein.........................
2023-09-24 21:02:14 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-24 21:02:15 | INFO | fairseq.tasks.translation | example hypothesis: In der Praxis harmonisiert die Richtlinie die Definition der durch Einzelpersonen oder Rechtspersonen verursachten Meeresverschmutzung, den Umfang der Antwort und die Strafbarkeit der Sanktionen, die im Falle solcher Verstöße von Einzelpersonen verhängt werden können.
2023-09-24 21:02:15 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-24 21:02:16 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falized und Vincent Reynaud wurden nämlich einfach wegen ihrer Tätigkeit als Journalisten und Kameramänner verurteilt, indem sie eine Gruppe von Bergsleuten filmen, die jahrelang von einem autoritären Regime verfolgt wurden, das sich über jeden Grundsatz der Demokratie hinwegsetzt, gejagt wurden.
2023-09-24 21:02:16 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-24 21:02:17 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, Transport- und Sightseeingservice, ein Wechselstube, kostenloser Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-24 21:02:17 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-24 21:02:18 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, Ehefrau von König D. João II, und bekannt durch ihre international bekannten Keramiken für ihre figurativen und satirischen Werke ist sie auch einen Besuch wert.
2023-09-24 21:02:18 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-24 21:02:18 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es handele sich um gute Befürworter des Westens auf der einen Seite und Anhänger des früheren Regimes auf der anderen Seite - auch das ist verwerflich, da die Rolle aller jetzt und davor bekannt ist.
2023-09-24 21:02:18 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-24 21:02:19 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die unterschiedslos zwischen Flüssen und Meer fahren, nicht auf diese Weise behandelt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte........................
2023-09-24 21:02:19 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-24 21:02:20 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Hauptversammlung aufgrund seines Status als Aktionär Informationen zur Verfügung gestellt, so werden diese auf Verlangen jedem anderen Aktionär in der Hauptversammlung zur Verfügung gestellt, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen...............................
2023-09-24 21:02:20 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-24 21:02:21 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren fließen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen Menschen in unseren eigenen Ländern leben, die auch ein sehr elendes Leben führen...............................
2023-09-24 21:02:21 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-24 21:02:22 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, Flugzeuge aus einem der Mitgliedstaaten oder der NATO hätten an diesem Kriegshandlungen beteiligt sein können -, bei Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, verschwiegen oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit erfahren kann.........................
2023-09-24 21:02:22 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
lprobs.size(): torch.Size([3200, 42808])
2023-09-24 21:02:23 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Berliner Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit der Bahn vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-24 21:02:23 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-24 21:02:24 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, sowie unserer Geschäftseinheit Defence Electronics und Indra in Spanien wird das Advanced UAV die modernsten, modularen Sensor- und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die moderne Offline-Plattformen nie erreichen können.............................
2023-09-24 21:02:24 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-24 21:02:25 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir nicht nur für uns, sondern weltweit vom Markt nehmen können, die Produkte, die nicht nur für den Inlandsverbrauch, sondern auch für den Weltmarkt eine große Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt....................................
2023-09-24 21:02:25 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-24 21:02:26 | INFO | fairseq.tasks.translation | example hypothesis: Unter der einfachen Verschwörung von Modernität und Postmoderne oder der klaren Opposition von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung jener beiden Politiken der Ästhetik erkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verwickelt sind, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen.................. die die die die letztlich zu ihrer
2023-09-24 21:02:26 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-24 21:02:27 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Debatten und der Stellungnahmen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Entscheidungen unsere Debatten führen, und bei der Abstimmung, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht beantragen, die Beschlussfähigkeit zu überprüfen....................., wenn die 40 Petenten nicht anwesend sind, wenn die vierzig Petenten nicht anwesend sind, werde ich keine
2023-09-24 21:02:27 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-24 21:02:28 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips nie akzeptiert haben, so sind es paradoxerweise gerade sie, die, kaum bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem nationale Grenzen beseitigt sind, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen..........................
2023-09-24 21:02:28 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-24 21:02:29 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Hinsicht als hybride Form veröffentlicht, die Rezensionen und Artikel der vierteljährlich erscheinenden Zeitschrift sind für H-Soz-u-Kult verfasst und über Mailinglisten sowie die Webseiten des Berliner H-Soz-u-Kult und des Michigan-H-Net an ihre Abonnenten verteilt........... H-Soz-u-Kult und H-Kult sowie das Michigan-Net in Berlin wurden
2023-09-24 21:02:29 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-24 21:02:30 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Einführung der neuen Smartphone-Generation haben Mobiltelefone ihre Federn deutlich verwischt, indem sie sich von einst wackeligen Taschenwänden über polyphonisch tootende Game Boy-Aspiranten bis hin zu Mini-PCs mit knackigem Stereo-Sound in CD-Qualität schmolzen: Von nun an könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Trailblazers neuer technologischer Entwicklungen entwickeln........... dank ihrer besonderen Kombination der Fähigkeiten, die sie von den ehemaligen me-too-Wannabes zu Trail
2023-09-24 21:02:30 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-24 21:02:32 | INFO | fairseq.tasks.translation | example hypothesis: En la pandora de la base humana, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se fuerza para que se marchen; en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un konflimado; en l édeberdir de decié lado está.
2023-09-24 21:02:32 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-24 21:02:33 | INFO | valid | epoch 021 | valid on 'valid' subset | loss 4.123 | nll_loss 2.161 | ppl 4.47 | bleu 27.23 | wps 16368.5 | wpb 12011.9 | bsz 398.1 | num_updates 190221 | best_bleu 29.48
2023-09-24 21:02:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 190221 updates
2023-09-24 21:02:33 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint21.pt
2023-09-24 21:02:38 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint21.pt
2023-09-24 21:02:42 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint21.pt (epoch 21 @ 190221 updates, score 27.23) (writing took 9.627189164049923 seconds)
2023-09-24 21:02:42 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2023-09-24 21:02:42 | INFO | train | epoch 021 | loss 7.304 | nll_loss 3.584 | ppl 11.99 | wps 4120.7 | ups 0.32 | wpb 12977.5 | bsz 430.6 | num_updates 190221 | lr 7.25055e-05 | gnorm 1.112 | loss_scale 8 | train_wall 28423 | gb_free 13.8 | wall 382956
2023-09-24 21:02:42 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-24 21:02:43 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-24 21:02:43 | INFO | fairseq.trainer | begin training epoch 22
2023-09-24 21:02:43 | INFO | fairseq_cli.train | Start iterating over samples
ter_threshold: 0.490295
num_accepted / total 21 64
loss token level: tensor(8613.5840, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8008., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 21:06:51 | INFO | train_inner | epoch 022:     79 / 9060 loss=7.365, nll_loss=3.606, ppl=12.17, wps=3244.4, ups=0.25, wpb=12992.4, bsz=433.4, num_updates=190300, lr=7.24904e-05, gnorm=1.113, loss_scale=8, train_wall=318, gb_free=12.1, wall=383204
2023-09-24 21:11:58 | INFO | train_inner | epoch 022:    179 / 9060 loss=7.314, nll_loss=3.564, ppl=11.83, wps=4221.2, ups=0.33, wpb=12977, bsz=444.9, num_updates=190400, lr=7.24714e-05, gnorm=1.105, loss_scale=8, train_wall=307, gb_free=13, wall=383512
2023-09-24 21:17:13 | INFO | train_inner | epoch 022:    279 / 9060 loss=7.388, nll_loss=3.558, ppl=11.77, wps=4132, ups=0.32, wpb=13016.2, bsz=446.5, num_updates=190500, lr=7.24524e-05, gnorm=1.142, loss_scale=8, train_wall=315, gb_free=14.9, wall=383827
pred_new.size(): torch.Size([8307, 42808])
2023-09-24 21:22:23 | INFO | train_inner | epoch 022:    379 / 9060 loss=7.364, nll_loss=3.583, ppl=11.98, wps=4223.4, ups=0.32, wpb=13061.2, bsz=416.6, num_updates=190600, lr=7.24333e-05, gnorm=1.157, loss_scale=8, train_wall=309, gb_free=13.2, wall=384136
pred_new.size(): torch.Size([5211, 42808])
2023-09-24 21:27:42 | INFO | train_inner | epoch 022:    479 / 9060 loss=7.4, nll_loss=3.605, ppl=12.17, wps=4072.3, ups=0.31, wpb=13002.2, bsz=434.9, num_updates=190700, lr=7.24144e-05, gnorm=1.143, loss_scale=8, train_wall=319, gb_free=14.6, wall=384455
ter_threshold: 0.490759
num_accepted / total 57 136
loss token level: tensor(8905.6465, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4944., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 21:33:04 | INFO | train_inner | epoch 022:    579 / 9060 loss=7.418, nll_loss=3.593, ppl=12.07, wps=3985, ups=0.31, wpb=12854, bsz=429.6, num_updates=190800, lr=7.23954e-05, gnorm=1.134, loss_scale=8, train_wall=322, gb_free=13.5, wall=384778
lprobs.size(): torch.Size([2480, 42808])
2023-09-24 21:38:28 | INFO | train_inner | epoch 022:    679 / 9060 loss=7.415, nll_loss=3.618, ppl=12.28, wps=3979.8, ups=0.31, wpb=12870.6, bsz=433.4, num_updates=190900, lr=7.23764e-05, gnorm=1.144, loss_scale=8, train_wall=323, gb_free=14.2, wall=385101
2023-09-24 21:43:51 | INFO | train_inner | epoch 022:    779 / 9060 loss=7.453, nll_loss=3.652, ppl=12.57, wps=4039.5, ups=0.31, wpb=13035.4, bsz=458.9, num_updates=191000, lr=7.23575e-05, gnorm=1.144, loss_scale=8, train_wall=322, gb_free=13.4, wall=385424
pred_new.size(): torch.Size([2373, 42808])
pred_new.size(): torch.Size([2070, 42808])
pred_new.size(): torch.Size([3696, 42808])
ter_threshold: 0.49109
num_accepted / total 82 152
loss token level: tensor(8478.2744, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11904., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 21:49:10 | INFO | train_inner | epoch 022:    879 / 9060 loss=7.186, nll_loss=3.486, ppl=11.2, wps=4051.3, ups=0.31, wpb=12931.1, bsz=430.6, num_updates=191100, lr=7.23385e-05, gnorm=1.104, loss_scale=8, train_wall=319, gb_free=13.5, wall=385743
ter_threshold: 0.491166
num_accepted / total 6 48
loss token level: tensor(11974.0176, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3156., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 21:54:34 | INFO | train_inner | epoch 022:    979 / 9060 loss=7.48, nll_loss=3.663, ppl=12.67, wps=4017, ups=0.31, wpb=13027.9, bsz=432.4, num_updates=191200, lr=7.23196e-05, gnorm=1.134, loss_scale=8, train_wall=324, gb_free=13.8, wall=386068
ter_threshold: 0.49121899999999996
num_accepted / total 31 64
loss token level: tensor(8842.4414, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11920., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 22:00:12 | INFO | train_inner | epoch 022:   1079 / 9060 loss=7.464, nll_loss=3.613, ppl=12.24, wps=3841.7, ups=0.3, wpb=13000, bsz=422.2, num_updates=191300, lr=7.23007e-05, gnorm=1.157, loss_scale=8, train_wall=338, gb_free=13.9, wall=386406
2023-09-24 22:05:34 | INFO | train_inner | epoch 022:   1179 / 9060 loss=7.318, nll_loss=3.583, ppl=11.98, wps=4033.6, ups=0.31, wpb=12989.5, bsz=440.6, num_updates=191400, lr=7.22818e-05, gnorm=1.105, loss_scale=8, train_wall=322, gb_free=13.2, wall=386728
lprobs.size(): torch.Size([3496, 42808])
2023-09-24 22:10:56 | INFO | train_inner | epoch 022:   1279 / 9060 loss=7.295, nll_loss=3.56, ppl=11.79, wps=4039.4, ups=0.31, wpb=12988, bsz=414.9, num_updates=191500, lr=7.22629e-05, gnorm=1.136, loss_scale=8, train_wall=321, gb_free=14, wall=387049
lprobs.size(): torch.Size([3520, 42808])
2023-09-24 22:16:15 | INFO | train_inner | epoch 022:   1379 / 9060 loss=7.296, nll_loss=3.569, ppl=11.87, wps=4062.4, ups=0.31, wpb=12947.5, bsz=431, num_updates=191600, lr=7.22441e-05, gnorm=1.124, loss_scale=8, train_wall=318, gb_free=12.8, wall=387368
pred_new.size(): torch.Size([3306, 42808])
2023-09-24 22:21:35 | INFO | train_inner | epoch 022:   1479 / 9060 loss=7.412, nll_loss=3.597, ppl=12.1, wps=4067.5, ups=0.31, wpb=13024.9, bsz=430.6, num_updates=191700, lr=7.22252e-05, gnorm=1.124, loss_scale=8, train_wall=320, gb_free=14.7, wall=387688
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6110, 42808])
2023-09-24 22:26:58 | INFO | train_inner | epoch 022:   1579 / 9060 loss=7.44, nll_loss=3.646, ppl=12.52, wps=4008, ups=0.31, wpb=12946.9, bsz=430.5, num_updates=191800, lr=7.22064e-05, gnorm=1.147, loss_scale=8, train_wall=323, gb_free=12.5, wall=388011
ter_threshold: 0.49185599999999996
num_accepted / total 75 136
loss token level: tensor(9683.1924, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13760., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 22:32:31 | INFO | train_inner | epoch 022:   1679 / 9060 loss=7.454, nll_loss=3.617, ppl=12.27, wps=3892.8, ups=0.3, wpb=12974.6, bsz=439.9, num_updates=191900, lr=7.21876e-05, gnorm=1.135, loss_scale=8, train_wall=333, gb_free=14.8, wall=388345
pred_new.size(): torch.Size([5589, 42808])
lprobs.size(): torch.Size([3432, 42808])
2023-09-24 22:38:00 | INFO | train_inner | epoch 022:   1779 / 9060 loss=7.411, nll_loss=3.601, ppl=12.13, wps=3955.5, ups=0.3, wpb=13004.8, bsz=434.2, num_updates=192000, lr=7.21688e-05, gnorm=1.12, loss_scale=8, train_wall=329, gb_free=13.8, wall=388674
ter_threshold: 0.492073
num_accepted / total 183 256
loss token level: tensor(9668.7275, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13360., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-24 22:43:30 | INFO | train_inner | epoch 022:   1879 / 9060 loss=7.275, nll_loss=3.547, ppl=11.69, wps=3921.8, ups=0.3, wpb=12937.1, bsz=430.2, num_updates=192100, lr=7.215e-05, gnorm=1.129, loss_scale=8, train_wall=330, gb_free=13.3, wall=389003
2023-09-24 22:45:07 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-24 22:48:57 | INFO | train_inner | epoch 022:   1980 / 9060 loss=7.413, nll_loss=3.618, ppl=12.28, wps=3987.8, ups=0.31, wpb=13029, bsz=429.4, num_updates=192200, lr=7.21312e-05, gnorm=1.202, loss_scale=4, train_wall=326, gb_free=15.4, wall=389330
2023-09-24 22:54:26 | INFO | train_inner | epoch 022:   2080 / 9060 loss=7.553, nll_loss=3.702, ppl=13.02, wps=3944.4, ups=0.3, wpb=12988.1, bsz=431.4, num_updates=192300, lr=7.21125e-05, gnorm=1.159, loss_scale=4, train_wall=329, gb_free=13.8, wall=389659
lprobs.size(): torch.Size([3008, 42808])
2023-09-24 22:59:52 | INFO | train_inner | epoch 022:   2180 / 9060 loss=7.334, nll_loss=3.581, ppl=11.97, wps=4001.1, ups=0.31, wpb=13046.3, bsz=433.8, num_updates=192400, lr=7.20937e-05, gnorm=1.138, loss_scale=4, train_wall=326, gb_free=14.4, wall=389985
2023-09-24 23:05:28 | INFO | train_inner | epoch 022:   2280 / 9060 loss=7.368, nll_loss=3.634, ppl=12.42, wps=3852.9, ups=0.3, wpb=12930.9, bsz=416.3, num_updates=192500, lr=7.2075e-05, gnorm=1.159, loss_scale=4, train_wall=335, gb_free=15.3, wall=390321
pred_new.size(): torch.Size([3162, 42808])
2023-09-24 23:10:53 | INFO | train_inner | epoch 022:   2380 / 9060 loss=7.26, nll_loss=3.568, ppl=11.86, wps=4007.2, ups=0.31, wpb=13046.9, bsz=413, num_updates=192600, lr=7.20563e-05, gnorm=1.111, loss_scale=4, train_wall=325, gb_free=12.8, wall=390647
tensor(2240., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([4560, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([8802, 42808])
ter_threshold: 0.484885
num_accepted / total 32 88
loss token level: tensor(10206.5977, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5840., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4686, 42808])
pred_new.size(): torch.Size([3840, 42808])
lprobs.size(): torch.Size([3408, 42808])
pred_new.size(): torch.Size([3872, 42808])
lprobs.size(): torch.Size([2832, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1980, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3240, 42808])
ter_threshold: 0.48585199999999995
num_accepted / total 43 104
loss token level: tensor(9405.8594, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6044., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.48594
num_accepted / total 135 232
loss token level: tensor(8274.8477, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6476., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.486009
num_accepted / total 37 80
loss token level: tensor(8394.2773, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11504., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([8970, 42808])
ter_threshold: 0.486121
num_accepted / total 18 64
loss token level: tensor(8593.3125, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6552., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.486156
num_accepted / total 90 136
loss token level: tensor(9089.3467, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(15936., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([648, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([4551, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3192, 42808])
ter_threshold: 0.486754
num_accepted / total 15 80
loss token level: tensor(12878.4443, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2560., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.48675599999999997
num_accepted / total 132 272
loss token level: tensor(9454.4199, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6176., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.486912
num_accepted / total 46 104
loss token level: tensor(9051.6367, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6260., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2912, 42808])
ter_threshold: 0.487153
num_accepted / total 92 184
loss token level: tensor(9500.5742, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10688., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5000, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([8322, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([3268, 42808])
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([4396, 42808])
ter_threshold: 0.48749299999999995
num_accepted / total 38 96
loss token level: tensor(8329.4277, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8320., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([3402, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([4625, 42808])
ter_threshold: 0.48777099999999995
num_accepted / total 32 88
loss token level: tensor(9906.9805, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8640., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5166, 42808])
ter_threshold: 0.48846199999999995
num_accepted / total 170 272
loss token level: tensor(7987.7637, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7200., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6858, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([3276, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([6622, 42808])
pred_new.size(): torch.Size([8066, 42808])
pred_new.size(): torch.Size([4370, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([3584, 42808])
ter_threshold: 0.48932299999999995
num_accepted / total 19 40
loss token level: tensor(8013.1147, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11632., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2800, 42808])
ter_threshold: 0.489453
num_accepted / total 23 64
loss token level: tensor(8962.4238, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8880., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([5328, 42808])
pred_new.size(): torch.Size([6900, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.48990599999999995
num_accepted / total 4 24
loss token level: tensor(8442.3242, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2376., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6468, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([4104, 42808])
pred_new.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([4350, 42808])
ter_threshold: 0.490759
num_accepted / total 49 136
loss token level: tensor(8052.3862, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3916., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8502, 42808])
ter_threshold: 0.491035
num_accepted / total 18 72
loss token level: tensor(9912.7344, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4112., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4891, 42808])
ter_threshold: 0.49109
num_accepted / total 51 96
loss token level: tensor(8866.4219, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13296., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2310, 42808])
ter_threshold: 0.491166
num_accepted / total 6 48
loss token level: tensor(10771.7773, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3208., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([5940, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4669, 42808])
pred_new.size(): torch.Size([4788, 42808])
pred_new.size(): torch.Size([7680, 42808])
pred_new.size(): torch.Size([1872, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([3750, 42808])
lprobs.size(): torch.Size([3160, 42808])
lprobs.size(): lprobs.size(): torch.Size([3520, 42808])
2023-09-24 23:16:26 | INFO | train_inner | epoch 022:   2480 / 9060 loss=7.201, nll_loss=3.491, ppl=11.24, wps=3924.8, ups=0.3, wpb=13080.3, bsz=463.7, num_updates=192700, lr=7.20376e-05, gnorm=1.099, loss_scale=4, train_wall=333, gb_free=15.2, wall=390980
lprobs.size(): torch.Size([3280, 42808])
2023-09-24 23:21:40 | INFO | train_inner | epoch 022:   2580 / 9060 loss=7.231, nll_loss=3.565, ppl=11.84, wps=4124, ups=0.32, wpb=12928.8, bsz=435.9, num_updates=192800, lr=7.20189e-05, gnorm=1.146, loss_scale=4, train_wall=313, gb_free=13.3, wall=391293
ter_threshold: 0.492807
num_accepted / total 37 96
loss token level: tensor(9020.1855, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5216., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
2023-09-24 23:26:58 | INFO | train_inner | epoch 022:   2680 / 9060 loss=7.288, nll_loss=3.533, ppl=11.58, wps=4062.4, ups=0.31, wpb=12937, bsz=443.4, num_updates=192900, lr=7.20002e-05, gnorm=1.124, loss_scale=4, train_wall=318, gb_free=14.2, wall=391612
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2499, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([2992, 42808])
2023-09-24 23:32:19 | INFO | train_inner | epoch 022:   2780 / 9060 loss=7.361, nll_loss=3.608, ppl=12.19, wps=4057.4, ups=0.31, wpb=13023, bsz=430.1, num_updates=193000, lr=7.19816e-05, gnorm=1.138, loss_scale=4, train_wall=321, gb_free=13.1, wall=391933
2023-09-24 23:37:51 | INFO | train_inner | epoch 022:   2880 / 9060 loss=7.366, nll_loss=3.627, ppl=12.35, wps=3930.9, ups=0.3, wpb=13035.1, bsz=435.4, num_updates=193100, lr=7.19629e-05, gnorm=1.105, loss_scale=4, train_wall=331, gb_free=13.8, wall=392264
pred_new.size(): torch.Size([2240, 42808])
2023-09-24 23:43:17 | INFO | train_inner | epoch 022:   2980 / 9060 loss=7.272, nll_loss=3.521, ppl=11.48, wps=3991.8, ups=0.31, wpb=12993.1, bsz=427.8, num_updates=193200, lr=7.19443e-05, gnorm=1.101, loss_scale=4, train_wall=325, gb_free=13.4, wall=392590
lprobs.size(): torch.Size([2784, 42808])
2023-09-24 23:48:35 | INFO | train_inner | epoch 022:   3080 / 9060 loss=7.303, nll_loss=3.6, ppl=12.13, wps=4043, ups=0.31, wpb=12872.5, bsz=417.5, num_updates=193300, lr=7.19257e-05, gnorm=1.114, loss_scale=4, train_wall=318, gb_free=12.9, wall=392908
2023-09-24 23:53:55 | INFO | train_inner | epoch 022:   3180 / 9060 loss=7.385, nll_loss=3.619, ppl=12.29, wps=4070.2, ups=0.31, wpb=13033.1, bsz=439.5, num_updates=193400, lr=7.19071e-05, gnorm=1.117, loss_scale=4, train_wall=320, gb_free=13, wall=393229
2023-09-24 23:59:12 | INFO | train_inner | epoch 022:   3280 / 9060 loss=7.279, nll_loss=3.579, ppl=11.95, wps=4085.5, ups=0.32, wpb=12941.1, bsz=400.6, num_updates=193500, lr=7.18885e-05, gnorm=1.122, loss_scale=4, train_wall=316, gb_free=13.7, wall=393545
pred_new.size(): torch.Size([5916, 42808])
ter_threshold: 0.493592
num_accepted / total 16 72
loss token level: tensor(8276.1367, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2604., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 00:04:43 | INFO | train_inner | epoch 022:   3380 / 9060 loss=7.437, nll_loss=3.652, ppl=12.58, wps=3921.6, ups=0.3, wpb=12976.7, bsz=427.1, num_updates=193600, lr=7.18699e-05, gnorm=1.163, loss_scale=4, train_wall=331, gb_free=13.2, wall=393876
2023-09-25 00:10:15 | INFO | train_inner | epoch 022:   3480 / 9060 loss=7.449, nll_loss=3.639, ppl=12.46, wps=3869, ups=0.3, wpb=12872.3, bsz=424.7, num_updates=193700, lr=7.18514e-05, gnorm=1.158, loss_scale=4, train_wall=332, gb_free=13.9, wall=394209
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.493795
num_accepted / total 6 24
loss token level: tensor(7892.0254, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2578., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 00:15:28 | INFO | train_inner | epoch 022:   3580 / 9060 loss=7.44, nll_loss=3.651, ppl=12.56, wps=4143.3, ups=0.32, wpb=12941.5, bsz=429.2, num_updates=193800, lr=7.18329e-05, gnorm=1.174, loss_scale=4, train_wall=312, gb_free=13.3, wall=394521
2023-09-25 00:20:44 | INFO | train_inner | epoch 022:   3680 / 9060 loss=7.446, nll_loss=3.651, ppl=12.56, wps=4110.1, ups=0.32, wpb=13003.2, bsz=427, num_updates=193900, lr=7.18143e-05, gnorm=1.152, loss_scale=4, train_wall=316, gb_free=13.5, wall=394838
ter_threshold: 0.49390999999999996
num_accepted / total 19 112
loss token level: tensor(8817.5449, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1806., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
2023-09-25 00:26:00 | INFO | train_inner | epoch 022:   3780 / 9060 loss=7.24, nll_loss=3.526, ppl=11.52, wps=4127, ups=0.32, wpb=13024.8, bsz=420.1, num_updates=194000, lr=7.17958e-05, gnorm=1.119, loss_scale=4, train_wall=315, gb_free=15.2, wall=395153
pred_new.size(): torch.Size([3105, 42808])
2023-09-25 00:31:10 | INFO | train_inner | epoch 022:   3880 / 9060 loss=7.178, nll_loss=3.53, ppl=11.55, wps=4171.5, ups=0.32, wpb=12943.7, bsz=426.1, num_updates=194100, lr=7.17773e-05, gnorm=1.135, loss_scale=4, train_wall=310, gb_free=13.6, wall=395464
lprobs.size(): torch.Size([3504, 42808])
lprobs.size(): torch.Size([2800, 42808])
2023-09-25 00:36:33 | INFO | train_inner | epoch 022:   3980 / 9060 loss=7.397, nll_loss=3.619, ppl=12.29, wps=4035.6, ups=0.31, wpb=13033.9, bsz=435.1, num_updates=194200, lr=7.17588e-05, gnorm=1.146, loss_scale=4, train_wall=323, gb_free=13.1, wall=395787
pred_new.size(): torch.Size([1404, 42808])
2023-09-25 00:41:48 | INFO | train_inner | epoch 022:   4080 / 9060 loss=7.39, nll_loss=3.596, ppl=12.09, wps=4133.7, ups=0.32, wpb=13013.3, bsz=459.2, num_updates=194300, lr=7.17404e-05, gnorm=1.128, loss_scale=4, train_wall=315, gb_free=13.5, wall=396101
ter_threshold: 0.49436599999999997
num_accepted / total 118 176
loss token level: tensor(8755.5586, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8808., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 00:46:58 | INFO | train_inner | epoch 022:   4180 / 9060 loss=7.462, nll_loss=3.694, ppl=12.95, wps=4186.4, ups=0.32, wpb=12967.1, bsz=420.6, num_updates=194400, lr=7.17219e-05, gnorm=1.129, loss_scale=4, train_wall=309, gb_free=13.4, wall=396411
ter_threshold: 0.494425
num_accepted / total 61 136
loss token level: tensor(7742.3115, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5116., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2940, 42808])
ter_threshold: 0.49447399999999997
num_accepted / total 3 8
loss token level: tensor(4299.5879, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4500., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 00:52:06 | INFO | train_inner | epoch 022:   4280 / 9060 loss=7.111, nll_loss=3.529, ppl=11.54, wps=4154, ups=0.32, wpb=12798.6, bsz=413.8, num_updates=194500, lr=7.17035e-05, gnorm=1.138, loss_scale=4, train_wall=308, gb_free=14, wall=396719
lprobs.size(): torch.Size([3536, 42808])
2023-09-25 00:57:17 | INFO | train_inner | epoch 022:   4380 / 9060 loss=7.382, nll_loss=3.606, ppl=12.17, wps=4169.3, ups=0.32, wpb=12965.4, bsz=437, num_updates=194600, lr=7.1685e-05, gnorm=1.135, loss_scale=4, train_wall=311, gb_free=13.2, wall=397030
pred_new.size(): torch.Size([2100, 42808])
2023-09-25 01:02:34 | INFO | train_inner | epoch 022:   4480 / 9060 loss=7.357, nll_loss=3.608, ppl=12.19, wps=4063.2, ups=0.32, wpb=12873.8, bsz=413.6, num_updates=194700, lr=7.16666e-05, gnorm=1.137, loss_scale=4, train_wall=317, gb_free=13.7, wall=397347
pred_new.size(): torch.Size([4521, 42808])
2023-09-25 01:07:53 | INFO | train_inner | epoch 022:   4580 / 9060 loss=7.268, nll_loss=3.574, ppl=11.91, wps=4087.7, ups=0.31, wpb=13068.7, bsz=425.7, num_updates=194800, lr=7.16482e-05, gnorm=1.106, loss_scale=4, train_wall=319, gb_free=14.6, wall=397667
2023-09-25 01:13:16 | INFO | train_inner | epoch 022:   4680 / 9060 loss=7.447, nll_loss=3.626, ppl=12.35, wps=4035, ups=0.31, wpb=13003.4, bsz=438.7, num_updates=194900, lr=7.16299e-05, gnorm=1.166, loss_scale=4, train_wall=322, gb_free=12.9, wall=397989
2023-09-25 01:18:33 | INFO | train_inner | epoch 022:   4780 / 9060 loss=7.419, nll_loss=3.645, ppl=12.51, wps=4038.6, ups=0.31, wpb=12827.3, bsz=419.7, num_updates=195000, lr=7.16115e-05, gnorm=1.164, loss_scale=4, train_wall=317, gb_free=13.7, wall=398307
lprobs.size(): torch.Size([2592, 42808])
2023-09-25 01:23:51 | INFO | train_inner | epoch 022:   4880 / 9060 loss=7.424, nll_loss=3.635, ppl=12.42, wps=4103.5, ups=0.31, wpb=13027.1, bsz=447.7, num_updates=195100, lr=7.15931e-05, gnorm=1.127, loss_scale=4, train_wall=317, gb_free=13.1, wall=398624
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3040, 42808])
2023-09-25 01:29:09 | INFO | train_inner | epoch 022:   4980 / 9060 loss=7.22, nll_loss=3.535, ppl=11.59, wps=4070.6, ups=0.31, wpb=12978, bsz=414.2, num_updates=195200, lr=7.15748e-05, gnorm=1.104, loss_scale=4, train_wall=319, gb_free=13.4, wall=398943
lprobs.size(): torch.Size([2392, 42808])
2023-09-25 01:34:28 | INFO | train_inner | epoch 022:   5080 / 9060 loss=7.111, nll_loss=3.51, ppl=11.39, wps=4092.9, ups=0.31, wpb=13021.7, bsz=413.5, num_updates=195300, lr=7.15565e-05, gnorm=1.106, loss_scale=4, train_wall=318, gb_free=13.3, wall=399261
2023-09-25 01:39:49 | INFO | train_inner | epoch 022:   5180 / 9060 loss=7.371, nll_loss=3.607, ppl=12.19, wps=4019.1, ups=0.31, wpb=12917, bsz=432.2, num_updates=195400, lr=7.15382e-05, gnorm=1.139, loss_scale=4, train_wall=321, gb_free=13.3, wall=399582
lprobs.size(): torch.Size([3432, 42808])
2023-09-25 01:45:02 | INFO | train_inner | epoch 022:   5280 / 9060 loss=7.33, nll_loss=3.6, ppl=12.13, wps=4148.2, ups=0.32, wpb=12993, bsz=431, num_updates=195500, lr=7.15199e-05, gnorm=1.122, loss_scale=4, train_wall=313, gb_free=13.1, wall=399896
pred_new.size(): torch.Size([2805, 42808])
lprobs.size(): torch.Size([3536, 42808])
2023-09-25 01:50:27 | INFO | train_inner | epoch 022:   5380 / 9060 loss=7.322, nll_loss=3.557, ppl=11.77, wps=3983.7, ups=0.31, wpb=12941.7, bsz=416, num_updates=195600, lr=7.15016e-05, gnorm=1.138, loss_scale=4, train_wall=325, gb_free=12.8, wall=400221
2023-09-25 01:55:47 | INFO | train_inner | epoch 022:   5480 / 9060 loss=7.428, nll_loss=3.628, ppl=12.36, wps=4036.3, ups=0.31, wpb=12914.5, bsz=426.2, num_updates=195700, lr=7.14833e-05, gnorm=1.143, loss_scale=4, train_wall=320, gb_free=12.9, wall=400540
lprobs.size(): torch.Size([3192, 42808])
2023-09-25 02:00:59 | INFO | train_inner | epoch 022:   5580 / 9060 loss=7.436, nll_loss=3.646, ppl=12.52, wps=4164.4, ups=0.32, wpb=12972.2, bsz=430.5, num_updates=195800, lr=7.1465e-05, gnorm=1.151, loss_scale=4, train_wall=311, gb_free=13.8, wall=400852
pred_new.size(): torch.Size([3420, 42808])
pred_new.size(): torch.Size([1472, 42808])
2023-09-25 02:06:10 | INFO | train_inner | epoch 022:   5680 / 9060 loss=7.282, nll_loss=3.607, ppl=12.18, wps=4141.5, ups=0.32, wpb=12901.4, bsz=423.3, num_updates=195900, lr=7.14468e-05, gnorm=1.144, loss_scale=4, train_wall=311, gb_free=14, wall=401163
pred_new.size(): torch.Size([5046, 42808])
pred_new.size(): torch.Size([1863, 42808])
2023-09-25 02:11:34 | INFO | train_inner | epoch 022:   5780 / 9060 loss=7.277, nll_loss=3.548, ppl=11.7, wps=4004.3, ups=0.31, wpb=12954.4, bsz=414.2, num_updates=196000, lr=7.14286e-05, gnorm=1.162, loss_scale=4, train_wall=323, gb_free=13.7, wall=401487
2023-09-25 02:16:56 | INFO | train_inner | epoch 022:   5880 / 9060 loss=7.295, nll_loss=3.603, ppl=12.15, wps=4023.2, ups=0.31, wpb=12979.7, bsz=439.1, num_updates=196100, lr=7.14104e-05, gnorm=1.124, loss_scale=4, train_wall=322, gb_free=14.7, wall=401810
2023-09-25 02:22:22 | INFO | train_inner | epoch 022:   5980 / 9060 loss=7.393, nll_loss=3.618, ppl=12.28, wps=3999, ups=0.31, wpb=13041.9, bsz=450.8, num_updates=196200, lr=7.13922e-05, gnorm=1.138, loss_scale=4, train_wall=326, gb_free=12.8, wall=402136
lprobs.size(): torch.Size([3392, 42808])
2023-09-25 02:27:35 | INFO | train_inner | epoch 022:   6080 / 9060 loss=7.216, nll_loss=3.545, ppl=11.67, wps=4187.6, ups=0.32, wpb=13086.7, bsz=447.2, num_updates=196300, lr=7.1374e-05, gnorm=1.108, loss_scale=8, train_wall=312, gb_free=14.2, wall=402448
pred_new.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([5780, 42808])
2023-09-25 02:32:56 | INFO | train_inner | epoch 022:   6180 / 9060 loss=7.144, nll_loss=3.547, ppl=11.69, wps=4055.8, ups=0.31, wpb=13015, bsz=392.2, num_updates=196400, lr=7.13558e-05, gnorm=1.101, loss_scale=8, train_wall=321, gb_free=13.2, wall=402769
pred_new.size(): torch.Size([516, 42808])
2023-09-25 02:38:13 | INFO | train_inner | epoch 022:   6280 / 9060 loss=7.367, nll_loss=3.625, ppl=12.34, wps=4084.7, ups=0.32, wpb=12947.1, bsz=425.7, num_updates=196500, lr=7.13376e-05, gnorm=1.131, loss_scale=8, train_wall=317, gb_free=13.7, wall=403086
pred_new.size(): torch.Size([5481, 42808])
2023-09-25 02:43:35 | INFO | train_inner | epoch 022:   6380 / 9060 loss=7.411, nll_loss=3.619, ppl=12.28, wps=4039.7, ups=0.31, wpb=13031.7, bsz=449.5, num_updates=196600, lr=7.13195e-05, gnorm=1.141, loss_scale=8, train_wall=322, gb_free=13, wall=403409
lprobs.size(): torch.Size([3200, 42808])
2023-09-25 02:48:58 | INFO | train_inner | epoch 022:   6480 / 9060 loss=7.48, nll_loss=3.655, ppl=12.6, wps=4019.7, ups=0.31, wpb=12977.8, bsz=435.9, num_updates=196700, lr=7.13014e-05, gnorm=1.147, loss_scale=8, train_wall=323, gb_free=14.3, wall=403732
pred_new.size(): torch.Size([6867, 42808])
lprobs.size(): torch.Size([2384, 42808])
2023-09-25 02:54:08 | INFO | train_inner | epoch 022:   6580 / 9060 loss=7.381, nll_loss=3.63, ppl=12.38, wps=4157.4, ups=0.32, wpb=12898.8, bsz=410.1, num_updates=196800, lr=7.12832e-05, gnorm=1.133, loss_scale=8, train_wall=310, gb_free=13.9, wall=404042
2023-09-25 02:59:31 | INFO | train_inner | epoch 022:   6680 / 9060 loss=7.226, nll_loss=3.587, ppl=12.02, wps=4025.8, ups=0.31, wpb=12975.1, bsz=436.6, num_updates=196900, lr=7.12651e-05, gnorm=1.12, loss_scale=8, train_wall=322, gb_free=15.2, wall=404364
torch.Size([3552, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.488125
num_accepted / total 49 144
loss token level: tensor(11179.2656, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7044., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2952, 42808])
ter_threshold: 0.488234
num_accepted / total 237 296
loss token level: tensor(8976.8047, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10048., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([1428, 42808])
ter_threshold: 0.48846199999999995
num_accepted / total 115 272
loss token level: tensor(10158.7861, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5076., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4600, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([2070, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([8774, 42808])
pred_new.size(): torch.Size([1050, 42808])
pred_new.size(): torch.Size([2310, 42808])
pred_new.size(): torch.Size([4840, 42808])
pred_new.size(): torch.Size([3600, 42808])
ter_threshold: 0.489082
num_accepted / total 28 72
loss token level: tensor(10444.1074, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8752., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6916, 42808])
lprobs.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([2904, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([5610, 42808])
pred_new.size(): torch.Size([5040, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1332, 42808])
pred_new.size(): torch.Size([7665, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([6204, 42808])
pred_new.size(): torch.Size([1378, 42808])
ter_threshold: 0.490759
num_accepted / total 59 128
loss token level: tensor(8898.9658, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5956., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5159, 42808])
pred_new.size(): torch.Size([2030, 42808])
pred_new.size(): torch.Size([1500, 42808])
pred_new.size(): torch.Size([1456, 42808])
pred_new.size(): torch.Size([5015, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([4160, 42808])
pred_new.size(): torch.Size([5346, 42808])
pred_new.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2730, 42808])
pred_new.size(): torch.Size([5580, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2624, 42808])
pred_new.size(): torch.Size([6216, 42808])
pred_new.size(): torch.Size([5292, 42808])
pred_new.size(): torch.Size([1320, 42808])
pred_new.size(): torch.Size([1548, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([2352, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.492807
num_accepted / total 74 128
loss token level: tensor(8868.9570, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8156., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.49287499999999995
num_accepted / total 19 64
loss token level: tensor(8614.3281, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4020., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1365, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.493249
num_accepted / total 12 56
loss token level: tensor(7983.4355, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2836., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2040, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.493592
num_accepted / total 41 96
loss token level: tensor(8878.6133, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6032., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5382, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([3510, 42808])
pred_new.size(): torch.Size([2150, 42808])
pred_new.size(): torch.Size([1932, 42808])
ter_threshold: 0.49390999999999996
num_accepted / total 46 112
loss token level: tensor(10300.5811, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6236., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.494004
num_accepted / total 28 88
loss token level: tensor(8950.9492, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4640., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2000, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3588, 42808])
pred_new.size(): torch.Size([6075, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2880, 42808])
ter_threshold: 0.49519199999999997
num_accepted / total 9 48
loss token level: tensor(8875.9502, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2908., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2412, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6880, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.495448
num_accepted / total 41 96
loss token level: tensor(9883.1846, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6332., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([6845, 42808])
pred_new.size(): torch.Size([4620, 42808])
pred_new.size(): torch.Size([4740, 42808])
pred_new.size(): torch.Size([7599, 42808])
ter_threshold: 0.496066
num_accepted / total 46 104
loss token level: tensor(8583.9492, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10256., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5250, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([1456, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3213, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.49678599999999995
num_accepted / total 23 64
loss token level: tensor(10239.9434, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7752., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2528, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([8235, 42808])
ter_threshold: 0.496924
num_accepted / total 61 112
loss token level: tensor(9589.8369, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([5440, 42808])
ter_threshold: 0.496924
num_accepted / total 170 272
loss token level: tensor(7894.0537, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9160., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 03:05:00 | INFO | train_inner | epoch 022:   6780 / 9060 loss=7.474, nll_loss=3.647, ppl=12.53, wps=3911.9, ups=0.3, wpb=12877.6, bsz=429, num_updates=197000, lr=7.1247e-05, gnorm=1.164, loss_scale=8, train_wall=329, gb_free=13.9, wall=404693
2023-09-25 03:10:18 | INFO | train_inner | epoch 022:   6880 / 9060 loss=7.378, nll_loss=3.609, ppl=12.2, wps=4076.7, ups=0.31, wpb=12975.8, bsz=442.7, num_updates=197100, lr=7.1229e-05, gnorm=1.143, loss_scale=8, train_wall=318, gb_free=14.4, wall=405012
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1872, 42808])
2023-09-25 03:15:42 | INFO | train_inner | epoch 022:   6980 / 9060 loss=7.421, nll_loss=3.671, ppl=12.74, wps=3987.2, ups=0.31, wpb=12907.7, bsz=431, num_updates=197200, lr=7.12109e-05, gnorm=1.18, loss_scale=8, train_wall=323, gb_free=14.1, wall=405335
lprobs.size(): torch.Size([3552, 42808])
2023-09-25 03:20:48 | INFO | train_inner | epoch 022:   7080 / 9060 loss=7.273, nll_loss=3.592, ppl=12.06, wps=4259.1, ups=0.33, wpb=13035.3, bsz=454.7, num_updates=197300, lr=7.11929e-05, gnorm=1.115, loss_scale=8, train_wall=306, gb_free=14.2, wall=405641
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([2236, 42808])
pred_new.size(): torch.Size([3196, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4522, 42808])
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([2280, 42808])
ter_threshold: 0.490197
num_accepted / total 57 112
loss token level: tensor(9100.8027, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12440., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([3924, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([7140, 42808])
pred_new.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([800, 42808])
lprobs.size(): torch.Size([2784, 42808])
pred_new.size(): torch.Size([4329, 42808])
ter_threshold: 0.490759
num_accepted / total 136 232
loss token level: tensor(8615.9150, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7008., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6806, 42808])
pred_new.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3861, 42808])
pred_new.size(): torch.Size([5995, 42808])
ter_threshold: 0.49109
num_accepted / total 99 176
loss token level: tensor(7957.8467, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10592., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5760, 42808])
pred_new.size(): torch.Size([2652, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([4095, 42808])
pred_new.size(): torch.Size([5580, 42808])
ter_threshold: 0.491642
num_accepted / total 16 64
loss token level: tensor(9379.2969, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6176., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5112, 42808])
pred_new.size(): torch.Size([5226, 42808])
ter_threshold: 0.49185599999999996
num_accepted / total 59 112
loss token level: tensor(9813.6250, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13024., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3036, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.492073
num_accepted / total 43 88
loss token level: tensor(8870.9336, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5022, 42808])
pred_new.size(): torch.Size([5292, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([1316, 42808])
ter_threshold: 0.49276299999999995
num_accepted / total 7 24
loss token level: tensor(7775.9868, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7124., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.492807
num_accepted / total 37 144
loss token level: tensor(8024.2119, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2484., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([663, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1032, 42808])
lprobs.size(): torch.Size([2560, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4968, 42808])
ter_threshold: 0.493592
num_accepted / total 37 112
loss token level: tensor(9276.6035, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4460., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4080, 42808])
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([1947, 42808])
ter_threshold: 0.49390999999999996
num_accepted / total 49 96
loss token level: tensor(8929.4658, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7768., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3960, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.494004
num_accepted / total 68 208
loss token level: tensor(11635.0410, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4024., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1932, 42808])
pred_new.size(): torch.Size([2754, 42808])
lprobs.size(): torch.Size([3560, 42808])
ter_threshold: 0.49436599999999997
num_accepted / total 92 168
loss token level: tensor(9811.4219, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7872., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([4320, 42808])
pred_new.size(): torch.Size([5124, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([4000, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.49521
num_accepted / total 18 56
loss token level: tensor(9182.9590, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7708., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2652, 42808])
ter_threshold: 0.495448
num_accepted / total 110 176
loss token level: tensor(8879.2490, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7824., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([2376, 42808])
ter_threshold: 0.495989
num_accepted / total 41 80
loss token level: tensor(9329.1553, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7344., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.496066
num_accepted / total 54 104
loss token level: tensor(9208.8936, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14048., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4810, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2704, 42808])
pred_new.size(): torch.Size([2262, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([3159, 42808])
pred_new.size(): torch.Size([3900, 42808])
ter_threshold: 0.496496
num_accepted / total 10 48
loss token level: tensor(8968.6113, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5224., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2084, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.49672099999999997
num_accepted / total 19 56
loss token level: tensor(9126.6064, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5056., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([318, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3904, 42808])
ter_threshold: 0.496924
num_accepted / total 64 160
loss token level: tensor(8205.7041, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6536., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4606, 42808])
ter_threshold: 0.497136
num_accepted / total 24 80
loss token level: tensor(8735.4521, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6072., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2728, 42808])
pred_new.size(): torch.Size([2652, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([1276, 42808])
ter_threshold: pred_new.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([3381, 42808])
2023-09-25 03:26:02 | INFO | train_inner | epoch 022:   7180 / 9060 loss=7.168, nll_loss=3.507, ppl=11.37, wps=4165.9, ups=0.32, wpb=13093, bsz=456.2, num_updates=197400, lr=7.11748e-05, gnorm=1.123, loss_scale=8, train_wall=314, gb_free=14.4, wall=405956
ter_threshold: 0.497407
num_accepted / total 46 96
loss token level: tensor(9410.8047, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6216., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6500, 42808])
pred_new.size(): torch.Size([2000, 42808])
2023-09-25 03:31:13 | INFO | train_inner | epoch 022:   7280 / 9060 loss=7.325, nll_loss=3.589, ppl=12.03, wps=4177.5, ups=0.32, wpb=12995.9, bsz=448.6, num_updates=197500, lr=7.11568e-05, gnorm=1.125, loss_scale=8, train_wall=311, gb_free=14, wall=406267
lprobs.size(): torch.Size([3384, 42808])
2023-09-25 03:36:23 | INFO | train_inner | epoch 022:   7380 / 9060 loss=7.244, nll_loss=3.594, ppl=12.07, wps=4184.8, ups=0.32, wpb=12949.6, bsz=403.5, num_updates=197600, lr=7.11388e-05, gnorm=1.122, loss_scale=8, train_wall=309, gb_free=13.3, wall=406576
2023-09-25 03:41:44 | INFO | train_inner | epoch 022:   7480 / 9060 loss=7.44, nll_loss=3.637, ppl=12.44, wps=4032.8, ups=0.31, wpb=12934.3, bsz=426.6, num_updates=197700, lr=7.11208e-05, gnorm=1.152, loss_scale=8, train_wall=320, gb_free=14, wall=406897
2023-09-25 03:47:00 | INFO | train_inner | epoch 022:   7580 / 9060 loss=7.262, nll_loss=3.614, ppl=12.24, wps=4125.4, ups=0.32, wpb=13045.1, bsz=425.4, num_updates=197800, lr=7.11028e-05, gnorm=1.139, loss_scale=8, train_wall=316, gb_free=14.5, wall=407213
2023-09-25 03:52:23 | INFO | train_inner | epoch 022:   7680 / 9060 loss=7.248, nll_loss=3.535, ppl=11.59, wps=4009.6, ups=0.31, wpb=12943.2, bsz=422.8, num_updates=197900, lr=7.10849e-05, gnorm=1.135, loss_scale=8, train_wall=323, gb_free=13.3, wall=407536
lprobs.size(): torch.Size([3160, 42808])
2023-09-25 03:57:33 | INFO | train_inner | epoch 022:   7780 / 9060 loss=7.363, nll_loss=3.626, ppl=12.34, wps=4191.2, ups=0.32, wpb=12997, bsz=453.8, num_updates=198000, lr=7.10669e-05, gnorm=1.133, loss_scale=8, train_wall=310, gb_free=15.7, wall=407846
lprobs.size(): torch.Size([3584, 42808])
2023-09-25 04:02:48 | INFO | train_inner | epoch 022:   7880 / 9060 loss=7.476, nll_loss=3.685, ppl=12.86, wps=4144.1, ups=0.32, wpb=13052.3, bsz=451.5, num_updates=198100, lr=7.1049e-05, gnorm=1.134, loss_scale=8, train_wall=315, gb_free=14.4, wall=408161
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1870, 42808])
2023-09-25 04:08:01 | INFO | train_inner | epoch 022:   7980 / 9060 loss=7.134, nll_loss=3.504, ppl=11.35, wps=4104.2, ups=0.32, wpb=12868.7, bsz=418.6, num_updates=198200, lr=7.1031e-05, gnorm=1.112, loss_scale=8, train_wall=313, gb_free=13.2, wall=408475
pred_new.size(): torch.Size([2304, 42808])
2023-09-25 04:13:28 | INFO | train_inner | epoch 022:   8080 / 9060 loss=7.312, nll_loss=3.608, ppl=12.2, wps=3982, ups=0.31, wpb=12998.6, bsz=430.2, num_updates=198300, lr=7.10131e-05, gnorm=1.11, loss_scale=8, train_wall=326, gb_free=13.6, wall=408801
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([2400, 42808])
2023-09-25 04:18:59 | INFO | train_inner | epoch 022:   8180 / 9060 loss=7.466, nll_loss=3.668, ppl=12.71, wps=3941.3, ups=0.3, wpb=13043.3, bsz=421.6, num_updates=198400, lr=7.09952e-05, gnorm=1.185, loss_scale=8, train_wall=331, gb_free=14.1, wall=409132
pred_new.size(): torch.Size([3354, 42808])
pred_new.size(): torch.Size([5244, 42808])
2023-09-25 04:24:25 | INFO | train_inner | epoch 022:   8280 / 9060 loss=7.481, nll_loss=3.661, ppl=12.65, wps=3987.6, ups=0.31, wpb=13027.4, bsz=435.1, num_updates=198500, lr=7.09773e-05, gnorm=1.16, loss_scale=8, train_wall=326, gb_free=14.3, wall=409459
2023-09-25 04:27:56 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-25 04:29:45 | INFO | train_inner | epoch 022:   8381 / 9060 loss=7.35, nll_loss=3.599, ppl=12.12, wps=4061.2, ups=0.31, wpb=12987.3, bsz=447.1, num_updates=198600, lr=7.09595e-05, gnorm=1.13, loss_scale=4, train_wall=320, gb_free=13.3, wall=409778
ter_threshold: 0.498612
num_accepted / total 17 56
loss token level: tensor(8653.9697, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4096., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.498646
num_accepted / total 36 112
loss token level: tensor(8964.8174, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4036., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 04:35:06 | INFO | train_inner | epoch 022:   8481 / 9060 loss=7.256, nll_loss=3.552, ppl=11.73, wps=4059.7, ups=0.31, wpb=13018.1, bsz=419, num_updates=198700, lr=7.09416e-05, gnorm=1.122, loss_scale=4, train_wall=320, gb_free=14.2, wall=410099
pred_new.size(): torch.Size([2088, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-25 04:40:25 | INFO | train_inner | epoch 022:   8581 / 9060 loss=7.255, nll_loss=3.578, ppl=11.94, wps=4043.3, ups=0.31, wpb=12895.5, bsz=424.5, num_updates=198800, lr=7.09238e-05, gnorm=1.137, loss_scale=4, train_wall=319, gb_free=15.1, wall=410418
2023-09-25 04:45:53 | INFO | train_inner | epoch 022:   8681 / 9060 loss=7.401, nll_loss=3.634, ppl=12.41, wps=3953.6, ups=0.3, wpb=12985.7, bsz=422.4, num_updates=198900, lr=7.09059e-05, gnorm=1.146, loss_scale=4, train_wall=328, gb_free=14, wall=410747
pred_new.size(): torch.Size([1680, 42808])
pred_new.size(): torch.Size([7224, 42808])
2023-09-25 04:51:13 | INFO | train_inner | epoch 022:   8781 / 9060 loss=7.335, nll_loss=3.637, ppl=12.44, wps=4036.2, ups=0.31, wpb=12907.6, bsz=427.1, num_updates=199000, lr=7.08881e-05, gnorm=1.119, loss_scale=4, train_wall=320, gb_free=14.2, wall=411066
pred_new.size(): torch.Size([6360, 42808])
pred_new.size(): torch.Size([4392, 42808])
2023-09-25 04:56:30 | INFO | train_inner | epoch 022:   8881 / 9060 loss=7.527, nll_loss=3.687, ppl=12.88, wps=4127.2, ups=0.32, wpb=13079.8, bsz=442.7, num_updates=199100, lr=7.08703e-05, gnorm=1.148, loss_scale=4, train_wall=317, gb_free=13.3, wall=411383
lprobs.size(): torch.Size([3496, 42808])
2023-09-25 05:01:45 | INFO | train_inner | epoch 022:   8981 / 9060 loss=7.205, nll_loss=3.567, ppl=11.85, wps=4107.8, ups=0.32, wpb=12969.1, bsz=419.1, num_updates=199200, lr=7.08525e-05, gnorm=1.104, loss_scale=4, train_wall=315, gb_free=13.2, wall=411699
2023-09-25 05:06:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-25 05:06:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-25 05:06:01 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-25 05:06:01 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-25 05:06:02 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-25 05:06:02 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-25 05:06:02 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-25 05:06:02 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-25 05:06:03 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-25 05:06:03 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-25 05:06:03 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-25 05:06:03 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-25 05:06:04 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein voller Erfolg.
2023-09-25 05:06:04 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-25 05:06:04 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-25 05:06:04 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-25 05:06:05 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, was wir respektieren.
2023-09-25 05:06:05 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-25 05:06:05 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatgesprächen.
2023-09-25 05:06:05 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-25 05:06:06 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sich sowohl für Geschäftsreisende als auch für Urlauber gleichermaßen eignen.
2023-09-25 05:06:06 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-25 05:06:06 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-25 05:06:06 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-25 05:06:07 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-25 05:06:07 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-25 05:06:08 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU riesige Mengen an Energie verschwendet.
2023-09-25 05:06:08 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-25 05:06:08 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Ausgabe.
2023-09-25 05:06:08 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-25 05:06:09 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Haltung auch bald im Haushalt der Union widerspiegeln.
2023-09-25 05:06:09 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-25 05:06:09 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-25 05:06:09 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-25 05:06:10 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-25 05:06:10 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-25 05:06:10 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-25 05:06:10 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-25 05:06:11 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie sich gewünscht hätten?
2023-09-25 05:06:11 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-25 05:06:12 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-25 05:06:12 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-25 05:06:12 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-25 05:06:12 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-25 05:06:13 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-25 05:06:13 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-25 05:06:13 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-25 05:06:13 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-25 05:06:14 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potentielle Käufer veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-25 05:06:14 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-25 05:06:15 | INFO | fairseq.tasks.translation | example hypothesis: Da sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-25 05:06:15 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-25 05:06:15 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-25 05:06:15 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-25 05:06:16 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Debatte, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-25 05:06:16 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-25 05:06:16 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Orte im Umkreis von etwa 8 km Entfernung.
2023-09-25 05:06:16 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-25 05:06:17 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Webportal System basiert.
2023-09-25 05:06:17 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-25 05:06:18 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! akustisch, interaktiv oder schriftlich die Realisierung von Klanghandbüchern an.
2023-09-25 05:06:18 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-25 05:06:18 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-25 05:06:18 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-25 05:06:19 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, aber sie kann sich auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu sichern.
2023-09-25 05:06:19 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-25 05:06:19 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Abzug Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-25 05:06:19 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-25 05:06:20 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet die Ascent Ti-Modell als Basis.
2023-09-25 05:06:20 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-25 05:06:21 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine kostenlose Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-25 05:06:21 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-25 05:06:21 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-25 05:06:21 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-25 05:06:22 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind die Thatcher-Vorstellungen von niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv zentrale Teile seiner Agenda.
2023-09-25 05:06:22 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-25 05:06:23 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es richtig funktioniert.
2023-09-25 05:06:23 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-25 05:06:23 | INFO | fairseq.tasks.translation | example hypothesis: Horde und Allianz können Gegenstände nicht gegenseitig kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-25 05:06:23 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-25 05:06:24 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollen.
2023-09-25 05:06:24 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-25 05:06:25 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-25 05:06:25 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-25 05:06:25 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens mit den Vereinigten Staaten abgeben müssen.
2023-09-25 05:06:25 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-25 05:06:26 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderauflage - unser umfangreiches Sortiment an PlastikBabyartikeln überzeugt nicht zuletzt durch seine herausragende Verarbeitung.
2023-09-25 05:06:26 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-25 05:06:27 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-25 05:06:27 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-25 05:06:27 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis Kenntnis Kenntnis von SachSachverhalten, die mit diesen AGB nicht vereinbar sind, zu unterrichten.
2023-09-25 05:06:27 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-25 05:06:28 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz auf dem Gebiet der Außen- und Verteidigungspolitik braucht.
2023-09-25 05:06:28 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-25 05:06:29 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-25 05:06:29 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-25 05:06:29 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die erzielt wurden, wenn wir uns alle Fragen betrachten, die jetzt diskutiert werden, und die etwas betreffen, was gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-25 05:06:29 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-25 05:06:30 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-25 05:06:30 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
lprobs.size(): torch.Size([3552, 42808])
2023-09-25 05:06:31 | INFO | fairseq.tasks.translation | example hypothesis: Der Berichterstatter hat es erneut geschafft, zuweilen unterschiedliche Meinungen und Beiträge zusammenzufassen und sie - würde ich sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-25 05:06:31 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-25 05:06:31 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm trockener elektrostatischer Einsetzer um einen trockenen ESP für den niedrigeren Leistungsbereich.
2023-09-25 05:06:31 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-25 05:06:32 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-25 05:06:32 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-25 05:06:33 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und unseren Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-25 05:06:33 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-25 05:06:33 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich weist ein Handelsdefizit mit der EU auf und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren geführt werden und mit unserer Völkergemeinschaft zusammenhängen.
2023-09-25 05:06:33 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-25 05:06:34 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-25 05:06:34 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-25 05:06:35 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-25 05:06:35 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-25 05:06:35 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Anzahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-25 05:06:35 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-25 05:06:36 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch einen weiteren: die Notsituation für die Kinder, den schwächsten Teil der Bevölkerung, die ohne Familie, ohne Schutz und ohne Staat zurückgelassen wurden.
2023-09-25 05:06:36 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-25 05:06:37 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können...................
2023-09-25 05:06:37 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-25 05:06:38 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, nicht innerhalb des Ersten realisiert wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis befleckt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt................
2023-09-25 05:06:38 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-25 05:06:38 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder aufzunehmen...............
2023-09-25 05:06:38 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-25 05:06:39 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und der Öffentlichkeit muss klar gemacht werden, dass niemand über dem Gesetz steht.......................
2023-09-25 05:06:39 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-25 05:06:40 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-25 05:06:40 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-25 05:06:40 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur klareren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen daher für die Klarstellung des Anhangs.
2023-09-25 05:06:40 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-25 05:06:41 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung grundlegender Arbeitsnormen haben, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt wurden, nicht als unvereinbar mit den WTO-Verträgen betrachtet werden....
2023-09-25 05:06:41 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-25 05:06:42 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über den irischen öffentlich-rechtlichen Rundfunk RTE teilgenommen, mit einer Frau, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-25 05:06:42 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-25 05:06:43 | INFO | fairseq.tasks.translation | example hypothesis: Vor diesem Hintergrund hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer besonnenen Haltung gratulieren.
2023-09-25 05:06:43 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-25 05:06:43 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder etwas so Spezielles wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist...............
2023-09-25 05:06:43 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-25 05:06:44 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist offen für Spieler aller Nationalitäten.
2023-09-25 05:06:44 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-25 05:06:45 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Ich glaube, dass der Bericht, abgesehen von diesen wenigen Vorbehalten, ein nützlicher und relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-25 05:06:45 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-25 05:06:46 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken, hieße, eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen oft die tatsächliche oder wahrgenommene Gefahr, von institutioneller Hegemonie zerschlagen zu werden)!!!!!!!!!!!!!!!
2023-09-25 05:06:46 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-25 05:06:46 | INFO | fairseq.tasks.translation | example hypothesis: In der Gemeinschaftsgerichtsbarkeit zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist.
2023-09-25 05:06:46 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-25 05:06:47 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist einer der lustigsten Autos, der für weniger als 50.000 Dollar fährt, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos ausprobieren.
2023-09-25 05:06:47 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-25 05:06:48 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung dieser Angelegenheit.
2023-09-25 05:06:48 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-25 05:06:49 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrilltes Hecht, Forelle mit Mandeln.
2023-09-25 05:06:49 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-25 05:06:50 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was ein politisches Handeln bedeutet, einen Gesamtüberblick zu geben, der es uns ermöglicht, die verschiedenen Fragen eingehender zu befassen und zu prüfen, welchen Impuls die Europäische Union im Hinblick auf die Zukunft geben kann..................
2023-09-25 05:06:50 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-25 05:06:50 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer von "Scardona Records", Herr Branko Paić, haben sich darauf geeinigt, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-25 05:06:50 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-25 05:06:51 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politik, steuerliche Maßnahmen und Zwänge, die nicht an die gegenwärtige Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-25 05:06:51 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-25 05:06:52 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den die Kommission uns vorlegt, geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text übernommen hat......................
2023-09-25 05:06:52 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-25 05:06:53 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den Rechts- und Rechtsraum, wodurch Norwegen und Island, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen gelten werden, zu den Staaten werden, in denen die gemeinsamen Auslieferungsbestimmungen gelten.
2023-09-25 05:06:53 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-25 05:06:54 | INFO | fairseq.tasks.translation | example hypothesis: Wir gehen mit voller Geschwindigkeit mit einem Schwenkboot hinunter den Mississippi, suchen nach dem großen verborgenen Schatz, verlieben uns in den schönen Becky Thatcher, der rein dynamisch ist, und vor allem werden wir große Freunde sein.......................
2023-09-25 05:06:54 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-25 05:06:54 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der Verschmutzung durch Schiffe, die durch Einzelpersonen oder Rechtspersonen verursacht werden, den Umfang der Reaktion und die Strafbarkeit der Sanktionen, die im Falle von Verletzungen durch Personen verhängt werden können.
2023-09-25 05:06:54 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-25 05:06:55 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falization und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner getan und eine Gruppe von Bergbewohnern gefilmt haben, die seit Jahren von einem autoritären Regime gejagt wurden, das sich über jeden Grundsatz der Demokratie hinwegsetzt.............
2023-09-25 05:06:55 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-25 05:06:56 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseurshop und ein Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Mending und Presseservice, eine Wechselstube, kostenloser Shoeshine und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das Französische Viertel.
2023-09-25 05:06:56 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-25 05:06:57 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, die Frau des Königs D. João II, und bekannt durch ihre international bekannten Keramiken für ihre figurischen und satirischen Werke, ist es auch einen Besuch wert.
2023-09-25 05:06:57 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-25 05:06:58 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es handele sich um einen Fall guter Befürworter des Westens auf der einen Seite und Anhänger des ehemaligen Regimes auf der anderen Seite - das ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-25 05:06:58 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-25 05:06:59 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt werden, und dies ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte........................
2023-09-25 05:06:59 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-25 05:07:00 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär Informationen übermittelt, so sind diese auf Verlangen an einen anderen Aktionär in der Aktionärsversammlung weiterzugeben, auch wenn diese Informationen für eine ordnungsgemäße Prüfung eines Tagesordnungspunktes nicht erforderlich sind.
2023-09-25 05:07:00 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-25 05:07:01 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachfolgende Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die normalerweise in die Taschen verschiedener Diktatoren fließen und ihren schönen Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr elendes Leben führen.
2023-09-25 05:07:01 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-25 05:07:02 | INFO | fairseq.tasks.translation | example hypothesis: Wir bitten die Mitgliedstaaten - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder der NATO an diesem kriegerischen Akt beteiligt gewesen wären -, mit Informationen zu helfen, die es keinen Grund mehr gibt, geheim, versteckt oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen und die ganze Wahrheit sagen können............................
2023-09-25 05:07:02 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-25 05:07:02 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-25 05:07:02 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-25 05:07:03 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, zusammen mit unserer Geschäftseinheit Defence Electronics und Indra in Spanien, wird die Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar sind, die die modernen Off-the-Regf-Plattformen nie erreichen können.....................
2023-09-25 05:07:03 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-25 05:07:04 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir auch in der Lage sein werden, nicht nur für uns, sondern weltweit die Produkte vom Markt zu nehmen, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt eine ernsthafte Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.
2023-09-25 05:07:04 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-25 05:07:05 | INFO | fairseq.tasks.translation | example hypothesis: Unter der einfachen Verschwörung von Moderne und Postmoderne oder dem klaren Gegensatz von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und anhaltende Spannung jener beiden ästhetischen Politik anerkennen, die genau die Formen der Sichtbarkeit und Verständbarkeit mit sich bringt, die die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen............... die die die letztlich zu ihrer eigenen Selbstunterdrückung
2023-09-25 05:07:05 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-25 05:07:06 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir vorgetragen haben und die meine Ausführungen eindeutig weitgehend unterstützen, und auf der Grundlage der vorangegangenen Beschlüsse unsere Aussprachen führen, und bei der Abstimmung, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht um die Feststellung der Beschlußfähigkeit bitten.
2023-09-25 05:07:06 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-25 05:07:07 | INFO | fairseq.tasks.translation | example hypothesis: Angesichts der Tatsache, dass diese Völker nie die Einschränkung des Prinzips des Nationalstaats akzeptiert haben, sind es paradoxerweise gerade sie, die, kaum niemandem bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen......................, aber,
2023-09-25 05:07:07 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-25 05:07:09 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Weise als hybride Form veröffentlicht, die Rezensionen und Artikel der Quartalszeitschrift sind für H-Soz-u-Kult geschrieben und über Mailinglisten sowie die Webseiten des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt................. H-Soz-u-Kult und das Michigan-H-Net
2023-09-25 05:07:09 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-25 05:07:10 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone ihre Federn signifikant aufpoliert, indem sie von einst blutenden Wecker im Taschenformat über polyphon tootende Game Boy-Aspiranten bis hin zu schmal klingenden Mini-PCs mit Stereosound in CD-Qualität: Von nun an konnten sie dank ihrer besonderen Kombination aus Fähigkeiten von den ehemaligen "me-too-Wannabes" zu Trailblazers neuer technologischer Entwicklungen werden.
2023-09-25 05:07:10 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-25 05:07:12 | INFO | fairseq.tasks.translation | example hypothesis: El coronel Quaritch, quien dirige la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen, en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un
2023-09-25 05:07:12 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-25 05:07:12 | INFO | valid | epoch 022 | valid on 'valid' subset | loss 4.119 | nll_loss 2.156 | ppl 4.46 | bleu 28.18 | wps 16519.9 | wpb 12011.9 | bsz 398.1 | num_updates 199279 | best_bleu 29.48
2023-09-25 05:07:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 199279 updates
2023-09-25 05:07:12 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint22.pt
2023-09-25 05:07:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint22.pt
2023-09-25 05:07:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint22.pt (epoch 22 @ 199279 updates, score 28.18) (writing took 10.688400942948647 seconds)
2023-09-25 05:07:23 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2023-09-25 05:07:23 | INFO | train | epoch 022 | loss 7.345 | nll_loss 3.6 | ppl 12.12 | wps 4042.1 | ups 0.31 | wpb 12977.2 | bsz 430.6 | num_updates 199279 | lr 7.08385e-05 | gnorm 1.134 | loss_scale 4 | train_wall 28974 | gb_free 13.5 | wall 412037
2023-09-25 05:07:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-25 05:07:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-25 05:07:23 | INFO | fairseq.trainer | begin training epoch 23
2023-09-25 05:07:23 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-25 05:08:26 | INFO | train_inner | epoch 023:     21 / 9060 loss=7.346, nll_loss=3.617, ppl=12.27, wps=3237.4, ups=0.25, wpb=12960.7, bsz=425.4, num_updates=199300, lr=7.08347e-05, gnorm=1.124, loss_scale=4, train_wall=317, gb_free=13.7, wall=412099
pred_new.size(): torch.Size([3640, 42808])
2023-09-25 05:13:41 | INFO | train_inner | epoch 023:    121 / 9060 loss=7.287, nll_loss=3.556, ppl=11.76, wps=4124.1, ups=0.32, wpb=12991.7, bsz=419.6, num_updates=199400, lr=7.0817e-05, gnorm=1.11, loss_scale=4, train_wall=315, gb_free=13.4, wall=412414
pred_new.size(): torch.Size([6156, 42808])
2023-09-25 05:19:09 | INFO | train_inner | epoch 023:    221 / 9060 loss=7.502, nll_loss=3.613, ppl=12.23, wps=3943.6, ups=0.3, wpb=12943.4, bsz=438.9, num_updates=199500, lr=7.07992e-05, gnorm=1.176, loss_scale=4, train_wall=328, gb_free=14.7, wall=412743
2023-09-25 05:24:28 | INFO | train_inner | epoch 023:    321 / 9060 loss=7.372, nll_loss=3.573, ppl=11.9, wps=4110.5, ups=0.31, wpb=13096.1, bsz=446.6, num_updates=199600, lr=7.07815e-05, gnorm=1.117, loss_scale=4, train_wall=318, gb_free=14.8, wall=413061
lprobs.size(): torch.Size([2480, 42808])
2023-09-25 05:29:47 | INFO | train_inner | epoch 023:    421 / 9060 loss=7.301, nll_loss=3.585, ppl=12, wps=4017.2, ups=0.31, wpb=12844.1, bsz=407.9, num_updates=199700, lr=7.07638e-05, gnorm=1.141, loss_scale=4, train_wall=319, gb_free=13.7, wall=413381
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-25 05:35:10 | INFO | train_inner | epoch 023:    521 / 9060 loss=7.298, nll_loss=3.551, ppl=11.72, wps=4021.4, ups=0.31, wpb=12972.6, bsz=455, num_updates=199800, lr=7.07461e-05, gnorm=1.155, loss_scale=4, train_wall=322, gb_free=12.9, wall=413703
pred_new.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([9408, 42808])
2023-09-25 05:40:29 | INFO | train_inner | epoch 023:    621 / 9060 loss=7.321, nll_loss=3.547, ppl=11.69, wps=4089.3, ups=0.31, wpb=13029.5, bsz=449.6, num_updates=199900, lr=7.07284e-05, gnorm=1.132, loss_scale=4, train_wall=318, gb_free=13.3, wall=414022
2023-09-25 05:45:55 | INFO | train_inner | epoch 023:    721 / 9060 loss=7.296, nll_loss=3.559, ppl=11.78, wps=3963.6, ups=0.31, wpb=12930.5, bsz=422.6, num_updates=200000, lr=7.07107e-05, gnorm=1.135, loss_scale=4, train_wall=326, gb_free=13.4, wall=414348
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3072, 42808])
2023-09-25 05:51:18 | INFO | train_inner | epoch 023:    821 / 9060 loss=7.516, nll_loss=3.672, ppl=12.74, wps=3998.7, ups=0.31, wpb=12925.6, bsz=432.5, num_updates=200100, lr=7.0693e-05, gnorm=1.172, loss_scale=4, train_wall=323, gb_free=15.3, wall=414672
ter_threshold: 0.500194
num_accepted / total 37 112
loss token level: tensor(12088.8730, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4836., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 05:56:48 | INFO | train_inner | epoch 023:    921 / 9060 loss=7.477, nll_loss=3.674, ppl=12.77, wps=3938, ups=0.3, wpb=12993.9, bsz=427.2, num_updates=200200, lr=7.06753e-05, gnorm=1.145, loss_scale=4, train_wall=330, gb_free=13, wall=415001
pred_new.size(): torch.Size([3420, 42808])
pred_new.size(): torch.Size([7040, 42808])
ter_threshold: 0.500248
num_accepted / total 14 56
loss token level: tensor(9676.8525, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6548., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 06:02:20 | INFO | train_inner | epoch 023:   1021 / 9060 loss=7.499, nll_loss=3.627, ppl=12.36, wps=3929.1, ups=0.3, wpb=13050.3, bsz=425.4, num_updates=200300, lr=7.06577e-05, gnorm=1.155, loss_scale=4, train_wall=332, gb_free=14, wall=415334
2023-09-25 06:07:44 | INFO | train_inner | epoch 023:   1121 / 9060 loss=7.383, nll_loss=3.63, ppl=12.38, wps=4018.1, ups=0.31, wpb=13009.8, bsz=440.9, num_updates=200400, lr=7.06401e-05, gnorm=1.149, loss_scale=4, train_wall=324, gb_free=14.8, wall=415657
lprobs.size(): torch.Size([3528, 42808])
2023-09-25 06:13:01 | INFO | train_inner | epoch 023:   1221 / 9060 loss=7.391, nll_loss=3.651, ppl=12.56, wps=4034.5, ups=0.31, wpb=12808.8, bsz=415.8, num_updates=200500, lr=7.06225e-05, gnorm=1.151, loss_scale=4, train_wall=317, gb_free=13.8, wall=415975
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([1692, 42808])
2023-09-25 06:18:14 | INFO | train_inner | epoch 023:   1321 / 9060 loss=7.257, nll_loss=3.558, ppl=11.78, wps=4144.8, ups=0.32, wpb=12951.4, bsz=410.6, num_updates=200600, lr=7.06049e-05, gnorm=1.119, loss_scale=4, train_wall=312, gb_free=15.6, wall=416287
pred_new.size(): torch.Size([4830, 42808])
2023-09-25 06:23:40 | INFO | train_inner | epoch 023:   1421 / 9060 loss=7.484, nll_loss=3.625, ppl=12.34, wps=3971.6, ups=0.31, wpb=12952.5, bsz=434.2, num_updates=200700, lr=7.05873e-05, gnorm=1.143, loss_scale=4, train_wall=326, gb_free=12.9, wall=416614
2023-09-25 06:29:07 | INFO | train_inner | epoch 023:   1521 / 9060 loss=7.386, nll_loss=3.649, ppl=12.54, wps=3966.6, ups=0.31, wpb=12957.2, bsz=402.2, num_updates=200800, lr=7.05697e-05, gnorm=1.146, loss_scale=4, train_wall=326, gb_free=15.4, wall=416940
pred_new.size(): torch.Size([3440, 42808])
2023-09-25 06:34:48 | INFO | train_inner | epoch 023:   1621 / 9060 loss=7.527, nll_loss=3.682, ppl=12.84, wps=3775.4, ups=0.29, wpb=12884.4, bsz=442, num_updates=200900, lr=7.05521e-05, gnorm=1.157, loss_scale=4, train_wall=341, gb_free=15.2, wall=417281
2023-09-25 06:40:15 | INFO | train_inner | epoch 023:   1721 / 9060 loss=7.31, nll_loss=3.565, ppl=11.84, wps=3936.9, ups=0.31, wpb=12891.6, bsz=412.6, num_updates=201000, lr=7.05346e-05, gnorm=1.13, loss_scale=4, train_wall=327, gb_free=14.2, wall=417609
lprobs.size(): torch.Size([3584, 42808])
2023-09-25 06:45:40 | INFO | train_inner | epoch 023:   1821 / 9060 loss=7.313, nll_loss=3.611, ppl=12.22, wps=4006.5, ups=0.31, wpb=13001.1, bsz=433.1, num_updates=201100, lr=7.0517e-05, gnorm=1.13, loss_scale=4, train_wall=324, gb_free=13.8, wall=417933
torch.Size([3320, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3016, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3288, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.4935
num_accepted / total 17 56
loss token level: tensor(8118.3799, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7560., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6734, 42808])
pred_new.size(): torch.Size([435, 42808])
lprobs.size(): torch.Size([2304, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.49364600000000003
num_accepted / total 5 32
loss token level: tensor(8268.7617, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3368., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.49390999999999996
num_accepted / total 28 96
loss token level: tensor(10265.4629, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4304., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2666, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1296, 42808])
ter_threshold: 0.49416499999999997
num_accepted / total 71 144
loss token level: tensor(8027.2285, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5736., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5400, 42808])
ter_threshold: 0.49436599999999997
num_accepted / total 33 96
loss token level: tensor(8289.9053, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4456., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.494425
num_accepted / total 81 168
loss token level: tensor(9014.8477, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6576., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.494429
num_accepted / total 21 64
loss token level: tensor(8384.6172, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4488., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3034, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([756, 42808])
pred_new.size(): torch.Size([3510, 42808])
pred_new.size(): torch.Size([2829, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([5865, 42808])
pred_new.size(): torch.Size([2250, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([1140, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1335, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([5085, 42808])
pred_new.size(): torch.Size([3690, 42808])
ter_threshold: 0.495989
num_accepted / total 24 64
loss token level: tensor(7827.7119, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4720., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3100, 42808])
ter_threshold: 0.496066
num_accepted / total 48 144
loss token level: tensor(11699.6230, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7980., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3852, 42808])
ter_threshold: 0.49629
num_accepted / total 7 56
loss token level: tensor(13502.1484, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1888., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([3483, 42808])
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([884, 42808])
pred_new.size(): torch.Size([7695, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([5772, 42808])
lprobs.size(): torch.Size([3096, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4028, 42808])
ter_threshold: 0.496924
num_accepted / total 53 136
loss token level: tensor(8595.5996, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6540., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2888, 42808])
pred_new.size(): torch.Size([2728, 42808])
ter_threshold: 0.497407
num_accepted / total 150 208
loss token level: tensor(8977.3574, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9784., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5382, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2205, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.497633
num_accepted / total 5 8
loss token level: tensor(9048.7568, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11296., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8184, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4680, 42808])
ter_threshold: 0.498421
num_accepted / total 40 72
loss token level: tensor(8403.3867, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7416., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5917, 42808])
pred_new.size(): torch.Size([1782, 42808])
ter_threshold: 0.498558
num_accepted / total 12 48
loss token level: tensor(9174.1416, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5636., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8220, 42808])
ter_threshold: 0.498646
num_accepted / total 87 208
loss token level: tensor(11645.8125, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5256., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3760, 42808])
lprobs.size(): torch.Size([2996, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([1296, 42808])
ter_threshold: 0.49897
num_accepted / total 126 176
loss token level: tensor(9531.9512, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(14912., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7656, 42808])
pred_new.size(): torch.Size([7668, 42808])
pred_new.size(): torch.Size([1584, 42808])
ter_threshold: 0.499085
num_accepted / total 23 56
loss token level: tensor(9004.2461, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6456., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2560, 42808])
pred_new.size(): torch.Size([366, 42808])
pred_new.size(): torch.Size([5280, 42808])
pred_new.size(): torch.Size([1960, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([3330, 42808])
pred_new.size(): torch.Size([1452, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([1794, 42808])
pred_new.size(): torch.Size([6000, 42808])
pred_new.size(): torch.Size([2268, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([1932, 42808])
ter_threshold: 0.500194
num_accepted / total 26 88
loss token level: tensor(8564.0068, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3508., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4080, 42808])
pred_new.size(): torch.Size([3960, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): pred_new.size(): torch.Size([2964, 42808])
2023-09-25 06:51:06 | INFO | train_inner | epoch 023:   1921 / 9060 loss=7.428, nll_loss=3.641, ppl=12.47, wps=4002.7, ups=0.31, wpb=13038.7, bsz=424.6, num_updates=201200, lr=7.04995e-05, gnorm=1.157, loss_scale=4, train_wall=325, gb_free=13.2, wall=418259
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-25 06:56:36 | INFO | train_inner | epoch 023:   2021 / 9060 loss=7.445, nll_loss=3.61, ppl=12.21, wps=3937.9, ups=0.3, wpb=13008.2, bsz=440.9, num_updates=201300, lr=7.0482e-05, gnorm=1.144, loss_scale=4, train_wall=330, gb_free=14.1, wall=418589
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2592, 42808])
2023-09-25 07:02:07 | INFO | train_inner | epoch 023:   2121 / 9060 loss=7.498, nll_loss=3.681, ppl=12.83, wps=3937.3, ups=0.3, wpb=13031.9, bsz=413.1, num_updates=201400, lr=7.04645e-05, gnorm=1.156, loss_scale=4, train_wall=331, gb_free=15.4, wall=418920
pred_new.size(): torch.Size([2448, 42808])
lprobs.size(): torch.Size([3240, 42808])
2023-09-25 07:07:22 | INFO | train_inner | epoch 023:   2221 / 9060 loss=7.629, nll_loss=3.734, ppl=13.3, wps=4123.4, ups=0.32, wpb=12995.2, bsz=443.6, num_updates=201500, lr=7.0447e-05, gnorm=1.232, loss_scale=4, train_wall=315, gb_free=13.3, wall=419236
2023-09-25 07:12:47 | INFO | train_inner | epoch 023:   2321 / 9060 loss=7.434, nll_loss=3.661, ppl=12.65, wps=4022.5, ups=0.31, wpb=13066.4, bsz=420, num_updates=201600, lr=7.04295e-05, gnorm=1.152, loss_scale=4, train_wall=325, gb_free=13.5, wall=419560
2023-09-25 07:18:13 | INFO | train_inner | epoch 023:   2421 / 9060 loss=7.412, nll_loss=3.615, ppl=12.25, wps=3984.7, ups=0.31, wpb=12993.3, bsz=417.6, num_updates=201700, lr=7.04121e-05, gnorm=1.157, loss_scale=4, train_wall=326, gb_free=15.4, wall=419887
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.501794
num_accepted / total 43 88
loss token level: tensor(8381.7441, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11608., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 07:23:39 | INFO | train_inner | epoch 023:   2521 / 9060 loss=7.287, nll_loss=3.605, ppl=12.17, wps=3991, ups=0.31, wpb=13001.3, bsz=416.1, num_updates=201800, lr=7.03946e-05, gnorm=1.126, loss_scale=4, train_wall=326, gb_free=13.7, wall=420212
2023-09-25 07:29:03 | INFO | train_inner | epoch 023:   2621 / 9060 loss=7.467, nll_loss=3.653, ppl=12.58, wps=4005.8, ups=0.31, wpb=12997.7, bsz=427.4, num_updates=201900, lr=7.03772e-05, gnorm=1.179, loss_scale=4, train_wall=324, gb_free=14.4, wall=420537
2023-09-25 07:34:26 | INFO | train_inner | epoch 023:   2721 / 9060 loss=7.358, nll_loss=3.612, ppl=12.23, wps=4015.5, ups=0.31, wpb=12946.9, bsz=428.2, num_updates=202000, lr=7.03598e-05, gnorm=1.149, loss_scale=4, train_wall=322, gb_free=14.6, wall=420859
2023-09-25 07:39:44 | INFO | train_inner | epoch 023:   2821 / 9060 loss=7.254, nll_loss=3.579, ppl=11.95, wps=4039.5, ups=0.31, wpb=12844.4, bsz=403.2, num_updates=202100, lr=7.03423e-05, gnorm=1.127, loss_scale=4, train_wall=318, gb_free=12.9, wall=421177
pred_new.size(): torch.Size([5850, 42808])
2023-09-25 07:45:15 | INFO | train_inner | epoch 023:   2921 / 9060 loss=7.389, nll_loss=3.591, ppl=12.05, wps=3924.9, ups=0.3, wpb=12999.4, bsz=436.8, num_updates=202200, lr=7.03249e-05, gnorm=1.159, loss_scale=4, train_wall=331, gb_free=13.8, wall=421508
pred_new.size(): torch.Size([8625, 42808])
pred_new.size(): torch.Size([5106, 42808])
2023-09-25 07:50:49 | INFO | train_inner | epoch 023:   3021 / 9060 loss=7.377, nll_loss=3.647, ppl=12.52, wps=3875.1, ups=0.3, wpb=12954.3, bsz=423.4, num_updates=202300, lr=7.03076e-05, gnorm=1.174, loss_scale=4, train_wall=334, gb_free=13.2, wall=421843
pred_new.size(): torch.Size([3000, 42808])
2023-09-25 07:56:17 | INFO | train_inner | epoch 023:   3121 / 9060 loss=7.641, nll_loss=3.717, ppl=13.15, wps=3979.1, ups=0.31, wpb=13028.7, bsz=414.2, num_updates=202400, lr=7.02902e-05, gnorm=1.216, loss_scale=4, train_wall=327, gb_free=13.9, wall=422170
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.502451
num_accepted / total 114 176
loss token level: tensor(8798.6621, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(14224., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 08:01:44 | INFO | train_inner | epoch 023:   3221 / 9060 loss=7.467, nll_loss=3.626, ppl=12.35, wps=3974.1, ups=0.31, wpb=13006.8, bsz=424.7, num_updates=202500, lr=7.02728e-05, gnorm=1.162, loss_scale=4, train_wall=327, gb_free=13.2, wall=422497
2023-09-25 08:07:12 | INFO | train_inner | epoch 023:   3321 / 9060 loss=7.429, nll_loss=3.652, ppl=12.57, wps=3974.9, ups=0.31, wpb=13030.2, bsz=470.5, num_updates=202600, lr=7.02555e-05, gnorm=1.138, loss_scale=4, train_wall=328, gb_free=13, wall=422825
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 08:12:25 | INFO | train_inner | epoch 023:   3421 / 9060 loss=7.528, nll_loss=3.684, ppl=12.85, wps=4119.7, ups=0.32, wpb=12895.4, bsz=439, num_updates=202700, lr=7.02382e-05, gnorm=1.163, loss_scale=8, train_wall=313, gb_free=13, wall=423138
ter_threshold: 0.50275
num_accepted / total 102 160
loss token level: tensor(8717.2754, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8140., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5415, 42808])
lprobs.size(): torch.Size([2856, 42808])
2023-09-25 08:17:39 | INFO | train_inner | epoch 023:   3521 / 9060 loss=7.201, nll_loss=3.525, ppl=11.51, wps=4098.7, ups=0.32, wpb=12894.8, bsz=437.9, num_updates=202800, lr=7.02208e-05, gnorm=1.129, loss_scale=8, train_wall=314, gb_free=12.8, wall=423453
2023-09-25 08:23:14 | INFO | train_inner | epoch 023:   3621 / 9060 loss=7.504, nll_loss=3.693, ppl=12.93, wps=3859.5, ups=0.3, wpb=12900, bsz=412.1, num_updates=202900, lr=7.02035e-05, gnorm=1.2, loss_scale=8, train_wall=334, gb_free=14.4, wall=423787
2023-09-25 08:28:38 | INFO | train_inner | epoch 023:   3721 / 9060 loss=7.401, nll_loss=3.648, ppl=12.53, wps=4006.8, ups=0.31, wpb=13010.4, bsz=423.4, num_updates=203000, lr=7.01862e-05, gnorm=1.165, loss_scale=8, train_wall=324, gb_free=13.3, wall=424112
lprobs.size(): torch.Size([3360, 42808])
2023-09-25 08:34:12 | INFO | train_inner | epoch 023:   3821 / 9060 loss=7.375, nll_loss=3.604, ppl=12.16, wps=3855.1, ups=0.3, wpb=12857.4, bsz=418.5, num_updates=203100, lr=7.0169e-05, gnorm=1.194, loss_scale=8, train_wall=333, gb_free=14.1, wall=424445
2023-09-25 08:34:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
pred_new.size(): torch.Size([3780, 42808])
lprobs.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3384, 42808])
2023-09-25 08:39:53 | INFO | train_inner | epoch 023:   3922 / 9060 loss=7.524, nll_loss=3.664, ppl=12.68, wps=3809.1, ups=0.29, wpb=12991.5, bsz=467.9, num_updates=203200, lr=7.01517e-05, gnorm=1.184, loss_scale=4, train_wall=341, gb_free=13.9, wall=424786
pred_new.size(): torch.Size([648, 42808])
ter_threshold: 0.503278
num_accepted / total 130 192
loss token level: tensor(8579.7637, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8864., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 08:45:23 | INFO | train_inner | epoch 023:   4022 / 9060 loss=7.493, nll_loss=3.674, ppl=12.77, wps=3935.5, ups=0.3, wpb=12984.2, bsz=422.2, num_updates=203300, lr=7.01344e-05, gnorm=1.168, loss_scale=4, train_wall=330, gb_free=15.5, wall=425116
pred_new.size(): torch.Size([5203, 42808])
2023-09-25 08:50:38 | INFO | train_inner | epoch 023:   4122 / 9060 loss=7.405, nll_loss=3.656, ppl=12.6, wps=4110.7, ups=0.32, wpb=12957, bsz=453, num_updates=203400, lr=7.01172e-05, gnorm=1.144, loss_scale=4, train_wall=315, gb_free=13.3, wall=425431
ter_threshold: 0.5034069999999999
num_accepted / total 118 168
loss token level: tensor(8731.7324, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(16752., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 08:55:52 | INFO | train_inner | epoch 023:   4222 / 9060 loss=7.393, nll_loss=3.629, ppl=12.37, wps=4129.9, ups=0.32, wpb=12963.9, bsz=454.2, num_updates=203500, lr=7.01e-05, gnorm=1.183, loss_scale=4, train_wall=314, gb_free=14.6, wall=425745
pred_new.size(): torch.Size([2232, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([4410, 42808])
2023-09-25 09:01:16 | INFO | train_inner | epoch 023:   4322 / 9060 loss=7.459, nll_loss=3.653, ppl=12.58, wps=4016.6, ups=0.31, wpb=13004.9, bsz=427.8, num_updates=203600, lr=7.00827e-05, gnorm=1.179, loss_scale=4, train_wall=324, gb_free=14.2, wall=426069
ter_threshold: 0.503678
num_accepted / total 15 40
loss token level: tensor(8225.7168, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9064., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 09:06:44 | INFO | train_inner | epoch 023:   4422 / 9060 loss=7.479, nll_loss=3.681, ppl=12.82, wps=3933.5, ups=0.3, wpb=12899.9, bsz=396, num_updates=203700, lr=7.00655e-05, gnorm=1.182, loss_scale=4, train_wall=328, gb_free=12.9, wall=426397
lprobs.size(): torch.Size([3432, 42808])
2023-09-25 09:12:09 | INFO | train_inner | epoch 023:   4522 / 9060 loss=7.379, nll_loss=3.65, ppl=12.55, wps=4004.3, ups=0.31, wpb=13028.5, bsz=440, num_updates=203800, lr=7.00484e-05, gnorm=1.128, loss_scale=4, train_wall=325, gb_free=13.5, wall=426722
pred_new.size(): torch.Size([3234, 42808])
pred_new.size(): torch.Size([4160, 42808])
lprobs.size(): torch.Size([3480, 42808])
2023-09-25 09:17:32 | INFO | train_inner | epoch 023:   4622 / 9060 loss=7.386, nll_loss=3.625, ppl=12.34, wps=4059.5, ups=0.31, wpb=13105, bsz=426.4, num_updates=203900, lr=7.00312e-05, gnorm=1.174, loss_scale=4, train_wall=323, gb_free=14.2, wall=427045
pred_new.size(): torch.Size([2142, 42808])
ter_threshold: 0.503934
num_accepted / total 18 64
loss token level: tensor(8860.8809, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6896., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.503967
num_accepted / total 32 64
loss token level: tensor(8753.3418, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7952., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 09:23:01 | INFO | train_inner | epoch 023:   4722 / 9060 loss=7.701, nll_loss=3.783, ppl=13.76, wps=3942.2, ups=0.3, wpb=12976.8, bsz=449, num_updates=204000, lr=7.0014e-05, gnorm=1.19, loss_scale=4, train_wall=329, gb_free=12.7, wall=427374
ter_threshold: 0.5040169999999999
num_accepted / total 33 88
loss token level: tensor(7616.5889, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8240., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 09:28:26 | INFO | train_inner | epoch 023:   4822 / 9060 loss=7.583, nll_loss=3.728, ppl=13.25, wps=3987.3, ups=0.31, wpb=12948.7, bsz=438.8, num_updates=204100, lr=6.99969e-05, gnorm=1.185, loss_scale=4, train_wall=324, gb_free=13.3, wall=427699
lprobs.size(): torch.Size([2840, 42808])
2023-09-25 09:33:51 | INFO | train_inner | epoch 023:   4922 / 9060 loss=7.521, nll_loss=3.636, ppl=12.43, wps=3994.6, ups=0.31, wpb=13005.1, bsz=444.8, num_updates=204200, lr=6.99797e-05, gnorm=1.173, loss_scale=4, train_wall=325, gb_free=13.4, wall=428025
2023-09-25 09:39:24 | INFO | train_inner | epoch 023:   5022 / 9060 loss=7.428, nll_loss=3.664, ppl=12.67, wps=3893.4, ups=0.3, wpb=12949, bsz=410.2, num_updates=204300, lr=6.99626e-05, gnorm=1.147, loss_scale=4, train_wall=332, gb_free=14.4, wall=428357
0.49738899999999997
num_accepted / total 274 392
loss token level: tensor(8610.5859, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11328., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.497407
num_accepted / total 122 184
loss token level: tensor(8044.1206, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7176., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([1778, 42808])
pred_new.size(): torch.Size([9486, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5332, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3302, 42808])
lprobs.size(): torch.Size([3408, 42808])
pred_new.size(): torch.Size([5925, 42808])
pred_new.size(): torch.Size([6264, 42808])
pred_new.size(): torch.Size([4092, 42808])
lprobs.size(): torch.Size([3304, 42808])
ter_threshold: 0.498459
num_accepted / total 27 64
loss token level: tensor(8454.2061, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6664., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6318, 42808])
lprobs.size(): torch.Size([2856, 42808])
ter_threshold: 0.498646
num_accepted / total 15 72
loss token level: tensor(8365.6426, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2464., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([9525, 42808])
pred_new.size(): torch.Size([2924, 42808])
pred_new.size(): torch.Size([3861, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([1456, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6992, 42808])
pred_new.size(): torch.Size([4550, 42808])
pred_new.size(): torch.Size([5035, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([4140, 42808])
ter_threshold: 0.500194
num_accepted / total 61 128
loss token level: tensor(10953.5811, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7008., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([2322, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([6303, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3024, 42808])
ter_threshold: 0.500652
num_accepted / total 12 48
loss token level: tensor(9031.3926, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3752., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3488, 42808])
pred_new.size(): torch.Size([1056, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([4192, 42808])
ter_threshold: 0.501085
num_accepted / total 16 56
loss token level: tensor(9815.1270, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6424., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.501205
num_accepted / total 52 88
loss token level: tensor(8469.5645, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13264., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.5012989999999999
num_accepted / total 123 208
loss token level: tensor(7808.4619, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8016., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([3604, 42808])
pred_new.size(): torch.Size([2992, 42808])
ter_threshold: 0.501497
num_accepted / total 13 72
loss token level: tensor(9739.6533, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3140., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.501521
num_accepted / total 6 48
loss token level: tensor(8739.8027, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2312., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.501549
num_accepted / total 41 96
loss token level: tensor(10284.8613, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5800., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.501568
num_accepted / total 86 136
loss token level: tensor(8812.0127, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8864., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2970, 42808])
pred_new.size(): torch.Size([3450, 42808])
pred_new.size(): torch.Size([1704, 42808])
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.501794
num_accepted / total 74 128
loss token level: tensor(9217.4297, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14464., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.502061
num_accepted / total 38 88
loss token level: tensor(9141.6523, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6136., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7130, 42808])
pred_new.size(): torch.Size([4464, 42808])
lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.50235
num_accepted / total 42 104
loss token level: tensor(9158.6738, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5428., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.502451
num_accepted / total 12 64
loss token level: tensor(8467.7969, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3304., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.50275
num_accepted / total 91 144
loss token level: tensor(8782.1094, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6369, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6240, 42808])
lprobs.size(): torch.Size([2840, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.50308
num_accepted / total 40 88
loss token level: tensor(9220.9434, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11248., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([630, 42808])
pred_new.size(): torch.Size([7470, 42808])
pred_new.size(): torch.Size([4992, 42808])
pred_new.size(): torch.Size([1260, 42808])
ter_threshold: 0.5034069999999999
num_accepted / total 65 112
loss token level: tensor(9740.3164, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14720., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.503553
num_accepted / total 169 272
loss token level: tensor(10227.3467, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10560., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4788, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1372, 42808])
pred_new.size(): torch.Size([6844, 42808])
pred_new.size(): torch.Size([8750, 42808])
ter_threshold: 0.5040169999999999
num_accepted / total 207 296
loss token level: tensor(7728.0586, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11488., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.504199
num_accepted / total 8 64
loss token level: tensor(9243.1807, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3046., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4785, 42808])
2023-09-25 09:44:51 | INFO | train_inner | epoch 023:   5122 / 9060 loss=7.385, nll_loss=3.626, ppl=12.35, wps=3959.2, ups=0.31, wpb=12941.6, bsz=416.6, num_updates=204400, lr=6.99455e-05, gnorm=1.159, loss_scale=4, train_wall=327, gb_free=14.7, wall=428684
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-25 09:50:03 | INFO | train_inner | epoch 023:   5222 / 9060 loss=7.378, nll_loss=3.661, ppl=12.65, wps=4168, ups=0.32, wpb=13027.5, bsz=437.5, num_updates=204500, lr=6.99284e-05, gnorm=1.134, loss_scale=4, train_wall=312, gb_free=13.7, wall=428997
lprobs.size(): torch.Size([3264, 42808])
2023-09-25 09:55:39 | INFO | train_inner | epoch 023:   5322 / 9060 loss=7.535, nll_loss=3.673, ppl=12.75, wps=3868.1, ups=0.3, wpb=12969.3, bsz=449.4, num_updates=204600, lr=6.99113e-05, gnorm=1.183, loss_scale=4, train_wall=335, gb_free=13.8, wall=429332
pred_new.size(): torch.Size([6424, 42808])
2023-09-25 10:01:05 | INFO | train_inner | epoch 023:   5422 / 9060 loss=7.317, nll_loss=3.589, ppl=12.03, wps=4005.3, ups=0.31, wpb=13065.7, bsz=412.3, num_updates=204700, lr=6.98942e-05, gnorm=1.135, loss_scale=4, train_wall=326, gb_free=13.8, wall=429658
2023-09-25 10:06:22 | INFO | train_inner | epoch 023:   5522 / 9060 loss=7.412, nll_loss=3.642, ppl=12.48, wps=4120.7, ups=0.31, wpb=13087.4, bsz=432.4, num_updates=204800, lr=6.98771e-05, gnorm=1.138, loss_scale=4, train_wall=317, gb_free=13.7, wall=429976
lprobs.size(): torch.Size([3416, 42808])
ter_threshold: 0.504876
num_accepted / total 33 88
loss token level: tensor(9009.7842, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8288., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 10:11:41 | INFO | train_inner | epoch 023:   5622 / 9060 loss=7.389, nll_loss=3.636, ppl=12.43, wps=4053.2, ups=0.31, wpb=12910, bsz=424.2, num_updates=204900, lr=6.98601e-05, gnorm=1.187, loss_scale=4, train_wall=318, gb_free=13.6, wall=430294
ter_threshold: 0.504944
num_accepted / total 38 104
loss token level: tensor(11043.2041, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4656., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([3198, 42808])
2023-09-25 10:17:03 | INFO | train_inner | epoch 023:   5722 / 9060 loss=7.421, nll_loss=3.612, ppl=12.22, wps=4019.9, ups=0.31, wpb=12953.3, bsz=439.4, num_updates=205000, lr=6.9843e-05, gnorm=1.142, loss_scale=4, train_wall=322, gb_free=13.8, wall=430617
2023-09-25 10:22:44 | INFO | train_inner | epoch 023:   5822 / 9060 loss=7.58, nll_loss=3.715, ppl=13.13, wps=3817.7, ups=0.29, wpb=13029.8, bsz=432.4, num_updates=205100, lr=6.9826e-05, gnorm=1.167, loss_scale=4, train_wall=341, gb_free=14, wall=430958
pred_new.size(): torch.Size([3775, 42808])
2023-09-25 10:28:16 | INFO | train_inner | epoch 023:   5922 / 9060 loss=7.498, nll_loss=3.691, ppl=12.91, wps=3943.4, ups=0.3, wpb=13059.4, bsz=433, num_updates=205200, lr=6.9809e-05, gnorm=1.173, loss_scale=4, train_wall=331, gb_free=14.3, wall=431289
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3248, 42808])
2023-09-25 10:33:50 | INFO | train_inner | epoch 023:   6022 / 9060 loss=7.596, nll_loss=3.719, ppl=13.17, wps=3912.9, ups=0.3, wpb=13077, bsz=437.6, num_updates=205300, lr=6.9792e-05, gnorm=1.172, loss_scale=4, train_wall=334, gb_free=12.5, wall=431623
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([6708, 42808])
ter_threshold: 0.505366
num_accepted / total 7 48
loss token level: tensor(8934.5391, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1520., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 10:39:20 | INFO | train_inner | epoch 023:   6122 / 9060 loss=7.382, nll_loss=3.635, ppl=12.42, wps=3945.6, ups=0.3, wpb=13017.2, bsz=412.6, num_updates=205400, lr=6.9775e-05, gnorm=1.153, loss_scale=4, train_wall=330, gb_free=13.1, wall=431953
2023-09-25 10:44:53 | INFO | train_inner | epoch 023:   6222 / 9060 loss=7.426, nll_loss=3.642, ppl=12.48, wps=3884.1, ups=0.3, wpb=12942.3, bsz=438.2, num_updates=205500, lr=6.9758e-05, gnorm=1.171, loss_scale=4, train_wall=333, gb_free=12, wall=432286
2023-09-25 10:50:19 | INFO | train_inner | epoch 023:   6322 / 9060 loss=7.499, nll_loss=3.711, ppl=13.1, wps=3908, ups=0.31, wpb=12746, bsz=422.1, num_updates=205600, lr=6.9741e-05, gnorm=1.229, loss_scale=4, train_wall=326, gb_free=14.3, wall=432613
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 10:56:01 | INFO | train_inner | epoch 023:   6422 / 9060 loss=7.79, nll_loss=3.815, ppl=14.07, wps=3818.4, ups=0.29, wpb=13065.4, bsz=452.1, num_updates=205700, lr=6.97241e-05, gnorm=1.196, loss_scale=4, train_wall=342, gb_free=13.6, wall=432955
tensor(13552., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5662, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([2622, 42808])
pred_new.size(): torch.Size([4060, 42808])
pred_new.size(): torch.Size([1344, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2728, 42808])
pred_new.size(): torch.Size([1998, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([640, 42808])
pred_new.size(): torch.Size([5148, 42808])
ter_threshold: 0.498371
num_accepted / total 9 40
loss token level: tensor(8104.3472, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2556., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.498421
num_accepted / total 17 64
loss token level: tensor(9547.0020, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2830., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6222, 42808])
pred_new.size(): torch.Size([7844, 42808])
ter_threshold: 0.498646
num_accepted / total 77 176
loss token level: tensor(7331.5947, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3660., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3780, 42808])
ter_threshold: 0.49897
num_accepted / total 43 96
loss token level: tensor(9770.0371, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10464., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5520, 42808])
pred_new.size(): torch.Size([3042, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([4370, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([6125, 42808])
pred_new.size(): torch.Size([5328, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([6072, 42808])
pred_new.size(): torch.Size([8881, 42808])
pred_new.size(): torch.Size([4704, 42808])
pred_new.size(): torch.Size([6084, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([3384, 42808])
ter_threshold: 0.500194
num_accepted / total 22 80
loss token level: tensor(8162.5537, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3316., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3318, 42808])
pred_new.size(): torch.Size([6156, 42808])
ter_threshold: 0.5003610000000001
num_accepted / total 13 64
loss token level: tensor(9378.7959, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2190., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5382, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([450, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([2016, 42808])
pred_new.size(): torch.Size([1764, 42808])
lprobs.size(): torch.Size([3000, 42808])
ter_threshold: 0.501196
num_accepted / total 9 40
loss token level: tensor(10113.2148, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2626., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.5012989999999999
num_accepted / total 96 144
loss token level: tensor(8153.6616, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13632., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4536, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.501568
num_accepted / total 9 80
loss token level: tensor(8572.2139, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1080., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([10212, 42808])
ter_threshold: 0.501794
num_accepted / total 67 120
loss token level: tensor(8987.3779, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13648., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4550, 42808])
ter_threshold: 0.502061
num_accepted / total 59 104
loss token level: tensor(9053.3711, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8560., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6930, 42808])
pred_new.size(): torch.Size([498, 42808])
pred_new.size(): torch.Size([5130, 42808])
ter_threshold: 0.502394
num_accepted / total 8 32
loss token level: tensor(10154.7168, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3736., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
ter_threshold: 0.502451
num_accepted / total 91 144
loss token level: tensor(8465.2715, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13368., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([4480, 42808])
pred_new.size(): torch.Size([4746, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2460, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.503177
num_accepted / total 5 56
loss token level: tensor(9177.7900, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(1590., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6351, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.503553
num_accepted / total 126 184
loss token level: tensor(7971.8994, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5664, 42808])
pred_new.size(): torch.Size([2838, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4830, 42808])
pred_new.size(): torch.Size([3604, 42808])
pred_new.size(): torch.Size([7645, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([7990, 42808])
pred_new.size(): torch.Size([5180, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([2090, 42808])
pred_new.size(): torch.Size([2646, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([7885, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([8236, 42808])
ter_threshold: 0.505197
num_accepted / total 13 72
loss token level: tensor(8638.9492, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3668., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1939, 42808])
pred_new.size(): torch.Size([5184, 42808])
pred_new.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([2152, 42808])
lprobs.size(): torch.Size([2624, 42808])
ter_threshold: 0.505471
num_accepted / total 17 64
loss token level: tensor(8522.1289, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6336., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3552, 42808])
ter_threshold: 0.50579
num_accepted / total 17 96
loss token level: tensor(8432.8496, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: pred_new.size(): torch.Size([4347, 42808])
ter_threshold: 0.50579
num_accepted / total 34 96
loss token level: tensor(7982.0508, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7380., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 11:01:26 | INFO | train_inner | epoch 023:   6522 / 9060 loss=7.372, nll_loss=3.636, ppl=12.43, wps=3989.4, ups=0.31, wpb=12956, bsz=420.6, num_updates=205800, lr=6.97071e-05, gnorm=1.154, loss_scale=4, train_wall=324, gb_free=14.2, wall=433280
pred_new.size(): torch.Size([5895, 42808])
2023-09-25 11:07:03 | INFO | train_inner | epoch 023:   6622 / 9060 loss=7.563, nll_loss=3.708, ppl=13.07, wps=3846.3, ups=0.3, wpb=12940, bsz=452.3, num_updates=205900, lr=6.96902e-05, gnorm=1.177, loss_scale=4, train_wall=336, gb_free=13.3, wall=433616
2023-09-25 11:12:25 | INFO | train_inner | epoch 023:   6722 / 9060 loss=7.342, nll_loss=3.62, ppl=12.29, wps=4004.1, ups=0.31, wpb=12906.6, bsz=424.2, num_updates=206000, lr=6.96733e-05, gnorm=1.162, loss_scale=4, train_wall=322, gb_free=14.7, wall=433938
2023-09-25 11:17:56 | INFO | train_inner | epoch 023:   6822 / 9060 loss=7.451, nll_loss=3.687, ppl=12.88, wps=3957.7, ups=0.3, wpb=13119.5, bsz=419, num_updates=206100, lr=6.96564e-05, gnorm=1.137, loss_scale=4, train_wall=331, gb_free=13.2, wall=434270
pred_new.size(): torch.Size([3392, 42808])
2023-09-25 11:23:31 | INFO | train_inner | epoch 023:   6922 / 9060 loss=7.499, nll_loss=3.666, ppl=12.7, wps=3889.4, ups=0.3, wpb=13019, bsz=444.5, num_updates=206200, lr=6.96395e-05, gnorm=1.171, loss_scale=4, train_wall=334, gb_free=12.5, wall=434605
2023-09-25 11:29:03 | INFO | train_inner | epoch 023:   7022 / 9060 loss=7.474, nll_loss=3.694, ppl=12.94, wps=3914.3, ups=0.3, wpb=12990.4, bsz=422.8, num_updates=206300, lr=6.96226e-05, gnorm=1.18, loss_scale=4, train_wall=332, gb_free=13.4, wall=434936
pred_new.size(): torch.Size([2800, 42808])
2023-09-25 11:34:22 | INFO | train_inner | epoch 023:   7122 / 9060 loss=7.334, nll_loss=3.641, ppl=12.48, wps=4057.1, ups=0.31, wpb=12938.2, bsz=422.8, num_updates=206400, lr=6.96058e-05, gnorm=1.144, loss_scale=4, train_wall=319, gb_free=13.2, wall=435255
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3552, 42808])
2023-09-25 11:39:59 | INFO | train_inner | epoch 023:   7222 / 9060 loss=7.654, nll_loss=3.748, ppl=13.43, wps=3844.6, ups=0.3, wpb=12961.7, bsz=447.4, num_updates=206500, lr=6.95889e-05, gnorm=1.211, loss_scale=4, train_wall=337, gb_free=14.4, wall=435592
2023-09-25 11:45:27 | INFO | train_inner | epoch 023:   7322 / 9060 loss=7.605, nll_loss=3.701, ppl=13, wps=3942.1, ups=0.3, wpb=12927.3, bsz=423.4, num_updates=206600, lr=6.95721e-05, gnorm=1.184, loss_scale=4, train_wall=328, gb_free=14.6, wall=435920
lprobs.size(): torch.Size([3264, 42808])
2023-09-25 11:51:00 | INFO | train_inner | epoch 023:   7422 / 9060 loss=7.468, nll_loss=3.676, ppl=12.78, wps=3900.4, ups=0.3, wpb=12989.7, bsz=441.4, num_updates=206700, lr=6.95552e-05, gnorm=1.17, loss_scale=4, train_wall=333, gb_free=14.3, wall=436253
2023-09-25 11:56:26 | INFO | train_inner | epoch 023:   7522 / 9060 loss=7.518, nll_loss=3.726, ppl=13.24, wps=4005.3, ups=0.31, wpb=13067.4, bsz=421.3, num_updates=206800, lr=6.95384e-05, gnorm=1.185, loss_scale=4, train_wall=326, gb_free=14.2, wall=436580
pred_new.size(): torch.Size([6750, 42808])
2023-09-25 12:02:00 | INFO | train_inner | epoch 023:   7622 / 9060 loss=7.684, nll_loss=3.794, ppl=13.87, wps=3862, ups=0.3, wpb=12907.1, bsz=443.8, num_updates=206900, lr=6.95216e-05, gnorm=1.215, loss_scale=4, train_wall=334, gb_free=15, wall=436914
ter_threshold: 0.506923
num_accepted / total 68 120
loss token level: tensor(9098.7949, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7896., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 12:07:36 | INFO | train_inner | epoch 023:   7722 / 9060 loss=7.306, nll_loss=3.616, ppl=12.26, wps=3852.2, ups=0.3, wpb=12914.6, bsz=412.9, num_updates=207000, lr=6.95048e-05, gnorm=1.162, loss_scale=4, train_wall=335, gb_free=13.1, wall=437249
2023-09-25 12:13:07 | INFO | train_inner | epoch 023:   7822 / 9060 loss=7.546, nll_loss=3.717, ppl=13.15, wps=3924.4, ups=0.3, wpb=12989.8, bsz=439.5, num_updates=207100, lr=6.9488e-05, gnorm=1.162, loss_scale=4, train_wall=331, gb_free=14.6, wall=437580
2023-09-25 12:18:31 | INFO | train_inner | epoch 023:   7922 / 9060 loss=7.389, nll_loss=3.624, ppl=12.33, wps=3993.4, ups=0.31, wpb=12954.2, bsz=435.9, num_updates=207200, lr=6.94713e-05, gnorm=1.155, loss_scale=8, train_wall=324, gb_free=13.9, wall=437905
pred_new.size(): torch.Size([3276, 42808])
ter_threshold: 0.507266
num_accepted / total 167 272
loss token level: tensor(8104.0322, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7160., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 12:23:54 | INFO | train_inner | epoch 023:   8022 / 9060 loss=7.454, nll_loss=3.676, ppl=12.78, wps=4035.6, ups=0.31, wpb=13033.7, bsz=420.4, num_updates=207300, lr=6.94545e-05, gnorm=1.163, loss_scale=8, train_wall=323, gb_free=14.7, wall=438227
lprobs.size(): torch.Size([2952, 42808])
ter_threshold: 0.507369
num_accepted / total 59 112
loss token level: tensor(7990.0620, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10880., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7930, 42808])
2023-09-25 12:29:19 | INFO | train_inner | epoch 023:   8122 / 9060 loss=7.505, nll_loss=3.701, ppl=13, wps=4001.8, ups=0.31, wpb=13011.4, bsz=437.6, num_updates=207400, lr=6.94377e-05, gnorm=1.15, loss_scale=8, train_wall=325, gb_free=13.5, wall=438553
ter_threshold: 0.507458
num_accepted / total 51 120
loss token level: tensor(8043.5430, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5296., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.507494
num_accepted / total 10 40
loss token level: tensor(8618.9199, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4016., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 12:34:38 | INFO | train_inner | epoch 023:   8222 / 9060 loss=7.386, nll_loss=3.652, ppl=12.57, wps=4088.4, ups=0.31, wpb=13037.7, bsz=428.8, num_updates=207500, lr=6.9421e-05, gnorm=1.14, loss_scale=8, train_wall=319, gb_free=13.4, wall=438872
ter_threshold: 0.507535
num_accepted / total 65 144
loss token level: tensor(8489.7871, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8432., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8700, 42808])
lprobs.size(): torch.Size([3024, 42808])
2023-09-25 12:40:10 | INFO | train_inner | epoch 023:   8322 / 9060 loss=7.405, nll_loss=3.673, ppl=12.76, wps=3936.5, ups=0.3, wpb=13050.1, bsz=434.3, num_updates=207600, lr=6.94043e-05, gnorm=1.138, loss_scale=8, train_wall=331, gb_free=14.5, wall=439203
ter_threshold: 0.507668
num_accepted / total 42 112
loss token level: tensor(8572.3945, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7676., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 12:45:28 | INFO | train_inner | epoch 023:   8422 / 9060 loss=7.439, nll_loss=3.661, ppl=12.65, wps=4078.5, ups=0.31, wpb=12980.9, bsz=441.2, num_updates=207700, lr=6.93876e-05, gnorm=1.167, loss_scale=8, train_wall=318, gb_free=16, wall=439521
lprobs.size(): torch.Size([3360, 42808])
2023-09-25 12:50:58 | INFO | train_inner | epoch 023:   8522 / 9060 loss=7.283, nll_loss=3.622, ppl=12.31, wps=3942.1, ups=0.3, wpb=12997.2, bsz=404.5, num_updates=207800, lr=6.93709e-05, gnorm=1.132, loss_scale=8, train_wall=329, gb_free=13.3, wall=439851
pred_new.size(): torch.Size([2331, 42808])
2023-09-25 12:56:22 | INFO | train_inner | epoch 023:   8622 / 9060 loss=7.314, nll_loss=3.607, ppl=12.19, wps=3984.9, ups=0.31, wpb=12931.2, bsz=426.5, num_updates=207900, lr=6.93542e-05, gnorm=1.156, loss_scale=8, train_wall=324, gb_free=14.8, wall=440176
pred_new.size(): torch.Size([4800, 42808])
pred_new.size(): torch.Size([3800, 42808])
2023-09-25 13:01:47 | INFO | train_inner | epoch 023:   8722 / 9060 loss=7.378, nll_loss=3.647, ppl=12.53, wps=3984.2, ups=0.31, wpb=12936.9, bsz=422.7, num_updates=208000, lr=6.93375e-05, gnorm=1.142, loss_scale=8, train_wall=324, gb_free=13.2, wall=440500
ter_threshold: 0.508019
num_accepted / total 61 96
loss token level: tensor(8975.3184, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8664., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4590, 42808])
2023-09-25 13:07:13 | INFO | train_inner | epoch 023:   8822 / 9060 loss=7.48, nll_loss=3.665, ppl=12.69, wps=3996.3, ups=0.31, wpb=13023, bsz=449.4, num_updates=208100, lr=6.93209e-05, gnorm=1.145, loss_scale=8, train_wall=326, gb_free=14.1, wall=440826
pred_new.size(): torch.Size([2565, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([6678, 42808])
2023-09-25 13:12:45 | INFO | train_inner | epoch 023:   8922 / 9060 loss=7.447, nll_loss=3.638, ppl=12.45, wps=3887.3, ups=0.3, wpb=12926.6, bsz=457.1, num_updates=208200, lr=6.93042e-05, gnorm=1.167, loss_scale=8, train_wall=332, gb_free=13.2, wall=441159
2023-09-25 13:18:21 | INFO | train_inner | epoch 023:   9022 / 9060 loss=7.436, nll_loss=3.644, ppl=12.5, wps=3888.7, ups=0.3, wpb=13051.1, bsz=433.5, num_updates=208300, lr=6.92876e-05, gnorm=1.174, loss_scale=8, train_wall=335, gb_free=13.2, wall=441494
2023-09-25 13:20:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-25 13:20:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-25 13:20:31 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-25 13:20:31 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-25 13:20:31 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-25 13:20:31 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-25 13:20:32 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterbringung.
2023-09-25 13:20:32 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-25 13:20:32 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Dokumente streng vertraulich behandelt.
2023-09-25 13:20:32 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-25 13:20:33 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-25 13:20:33 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-25 13:20:34 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein voller Erfolg.
2023-09-25 13:20:34 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-25 13:20:34 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein gutes neues Jahr für alle und Glückwünsche an unseren Präsidenten.
2023-09-25 13:20:34 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-25 13:20:35 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-25 13:20:35 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-25 13:20:35 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-25 13:20:35 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-25 13:20:36 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Urlaubsreisende ansprechend sind.
2023-09-25 13:20:36 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-25 13:20:36 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstrasse in Richtung Chianciano Terme.
2023-09-25 13:20:36 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-25 13:20:37 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-25 13:20:37 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-25 13:20:38 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU insgesamt riesige Mengen an Energie verschwendet.
2023-09-25 13:20:38 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-25 13:20:38 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Ausgabe.
2023-09-25 13:20:38 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-25 13:20:39 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich der Sinneswandel auch in Kürze im Haushalt der Union widerspiegeln.
2023-09-25 13:20:39 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-25 13:20:39 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-25 13:20:39 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-25 13:20:40 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-25 13:20:40 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-25 13:20:40 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-25 13:20:40 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-25 13:20:41 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-25 13:20:41 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-25 13:20:42 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Sitz und Produktionshallen in Stans.
2023-09-25 13:20:42 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-25 13:20:42 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-25 13:20:42 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-25 13:20:43 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-25 13:20:43 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-25 13:20:44 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-25 13:20:44 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-25 13:20:44 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potenzielle Käufer veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-25 13:20:44 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-25 13:20:45 | INFO | fairseq.tasks.translation | example hypothesis: Während sich die Zentralbanken weiter auf unbekanntes Territorium wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-25 13:20:45 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-25 13:20:45 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten zu einer Einigung kommen könnten.
2023-09-25 13:20:45 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-25 13:20:46 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Aussprache, Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit einzuladen.
2023-09-25 13:20:46 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-25 13:20:47 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte in einem Umkreis von etwa 8 Kilometern vom Strip entfernt.
2023-09-25 13:20:47 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-25 13:20:47 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem bekannten Open Source Php-Nuke Web-Portalsystem basiert.
2023-09-25 13:20:47 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-25 13:20:48 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-25 13:20:48 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-25 13:20:49 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung sowohl für Transferdruck als auch für Direktdruck erhältlich.
2023-09-25 13:20:49 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-25 13:20:49 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, kann sich jedoch auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu gewährleisten.
2023-09-25 13:20:49 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-25 13:20:50 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel dafür ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Ausreise Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-25 13:20:50 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-25 13:20:50 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-25 13:20:50 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-25 13:20:51 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, für einige Formate gibt es leider keine kostenlose Alternative, die auf allen Computerplattformen läuft.
2023-09-25 13:20:51 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-25 13:20:52 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche ist.
2023-09-25 13:20:52 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-25 13:20:52 | INFO | fairseq.tasks.translation | example hypothesis: Noch immer sind die Thatcher-Ideen zu niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-25 13:20:52 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-25 13:20:53 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es richtig funktioniert.
2023-09-25 13:20:53 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-25 13:20:54 | INFO | fairseq.tasks.translation | example hypothesis: Horde und Allianz können sich keine Gegenstände kaufen oder verkaufen, es sei denn, sie benutzen die unten aufgeführten neutralen Auktionshäuser.
2023-09-25 13:20:54 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-25 13:20:54 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollen.
2023-09-25 13:20:54 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-25 13:20:55 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-25 13:20:55 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-25 13:20:55 | INFO | fairseq.tasks.translation | example hypothesis: Nach dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens mit den Vereinigten Staaten vorlegen müssen.
2023-09-25 13:20:55 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-25 13:20:56 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unser breites Sortiment an PlastikBabyartikeln ist beeindruckend, nicht zuletzt wegen seiner herausragenden Verarbeitung.
2023-09-25 13:20:56 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-25 13:20:57 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-25 13:20:57 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-25 13:20:57 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis Kenntnis Kenntnis von Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-25 13:20:57 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-25 13:20:58 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung für notwendig hält.
2023-09-25 13:20:58 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-25 13:20:59 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen erstellt............
2023-09-25 13:20:59 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-25 13:21:00 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die erzielt wurden, wenn wir uns alle Fragen betrachten, die jetzt diskutiert werden und etwas betreffen, was gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-25 13:21:00 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-25 13:21:00 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Dämpfern für erstklassigen Spaß am Rad.
2023-09-25 13:21:00 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-25 13:21:01 | INFO | fairseq.tasks.translation | example hypothesis: Einmal mehr ist es der Berichterstatterin gelungen, zuweilen unterschiedliche Meinungen und Beiträge zusammenzufassen und sie - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-25 13:21:01 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-25 13:21:02 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlagsgeräten um einen trockenen ESP für den niedrigeren Leistungsbereich.
2023-09-25 13:21:02 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-25 13:21:02 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt, befinden Sie sich bereits in einem fremden Land...................
2023-09-25 13:21:02 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-25 13:21:03 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsreichtum verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-25 13:21:03 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-25 13:21:04 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und mit unserem Völkergemeinschaft zusammenhängen.
2023-09-25 13:21:04 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-25 13:21:04 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-25 13:21:04 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-25 13:21:05 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-25 13:21:05 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-25 13:21:06 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-25 13:21:06 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-25 13:21:07 | INFO | fairseq.tasks.translation | example hypothesis: Im Rahmen dieser Notsituation gibt es jedoch noch einen weiteren: die Notsituation der Kinder, des schwächsten Bevölkerungsschichten, die keine Familie, keinen Schutz und keinen Staat mehr haben.
2023-09-25 13:21:07 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-25 13:21:07 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können...................
2023-09-25 13:21:07 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-25 13:21:08 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, innerhalb des ersten nicht verwirklicht wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, solange man sein wahres Selbst nicht kennt.................
2023-09-25 13:21:08 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-25 13:21:09 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in ihrer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Wählerregistrierung wieder aufzunehmen..............
2023-09-25 13:21:09 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-25 13:21:10 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern freie Meinungsäußerung, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-25 13:21:10 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-25 13:21:10 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken, die Plattform und Betriebssystem-Unabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-25 13:21:10 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-25 13:21:11 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur eindeutigeren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen somit für eine Klarstellung des Anhangs.
2023-09-25 13:21:11 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-25 13:21:12 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedsländer eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen haben, und fordert die WTO auf, klar zu erklären, dass von der IAO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen angesehen werden......
2023-09-25 13:21:12 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-25 13:21:12 | INFO | fairseq.tasks.translation | example hypothesis: Kürzlich nahm ich an einer Aussprache über den irischen öffentlich-rechtlichen Rundfunk RTE mit einer Frau teil, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.......... zu....
2023-09-25 13:21:12 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-25 13:21:13 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-25 13:21:13 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-25 13:21:14 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie nach Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Bürgerschaft oder so etwas wie die Senkung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Studenten zugeschnitten ist................
2023-09-25 13:21:14 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-25 13:21:15 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und steht Spielern aller Nationalitäten offen.........................
2023-09-25 13:21:15 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-25 13:21:15 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, abgesehen von diesen wenigen Vorbehalten, einen nützlichen, relevanten Beitrag zur Diskussion über Flexicurity leistet, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-25 13:21:15 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-25 13:21:16 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken, hieße, zu naturalisieren und zu mystifizieren, was eine spezifische Art von Vertragsbeziehung zwischen Einzelpersonen mit gemeinsamen Anliegen ist (unter ihnen ist oft die tatsächliche oder wahrgenommene Bedrohung, von institutioneller Hegemonie zerschlagen zu werden)!!!!!!!!!!!
2023-09-25 13:21:16 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-25 13:21:17 | INFO | fairseq.tasks.translation | example hypothesis: In der Gemeinschaftsgerichtsbarkeit zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder eine einheitliche Auslegung der Konvention erforderlich ist.
2023-09-25 13:21:17 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-25 13:21:18 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist einer der lustigsten Autos für weniger als 50.000 Dollar, und wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren..........................
2023-09-25 13:21:18 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-25 13:21:19 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung der Angelegenheit danken.
2023-09-25 13:21:19 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-25 13:21:19 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrillter Hecht, Forellen mit Mandeln.
2023-09-25 13:21:19 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-25 13:21:20 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was ein politisches Handeln bedeutet, einen Gesamtüberblick zu bieten, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu sehen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann................
2023-09-25 13:21:20 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-25 13:21:21 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Eigentümer von "Scardona Records", Herr Branko Paić, haben sich darauf geeinigt, ein Live-Album "Bodulska balada 2009" zu veröffentlichen..................
2023-09-25 13:21:21 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-25 13:21:22 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politik, steuerliche Maßnahmen und Zwänge, die nicht an die derzeitige Situation vor Ort angepasst sind, schrittweise ausgehöhlt wird.
2023-09-25 13:21:22 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-25 13:21:23 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht im allgemeinen in die gleiche Richtung wie die geltende Verordnung von 1994, zu der das Europäische Parlament mit einem hervorragenden Beispiel der Zusammenarbeit mit dem Rat beigetragen hat, der alle unsere Änderungsanträge in den Text übernommen hat....
2023-09-25 13:21:23 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-25 13:21:23 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus, mit den entsprechenden Folgen für den rechtlichen und justiziellen Bereich, und macht Norwegen und Island zu Ländern, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen gelten werden....................
2023-09-25 13:21:23 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-25 13:21:24 | INFO | fairseq.tasks.translation | example hypothesis: Mit einem Schmiedeboot hinunter den Mississippi werden wir mit voller Geschwindigkeit fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein......................
2023-09-25 13:21:24 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-25 13:21:25 | INFO | fairseq.tasks.translation | example hypothesis: In der Praxis harmonisiert die Richtlinie die Definition der Verschmutzung durch Schiffe, die durch Einzelpersonen oder Rechtspersonen verursacht wird, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die im Falle von Verstößen von Einzelpersonen verhängt werden können.
2023-09-25 13:21:25 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-25 13:21:26 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner erledigt und eine Gruppe von Bergbewohnern gefilmt haben, die seit Jahren von einem autoritären Regime verfolgt werden, das sich über jeden Grundsatz der Demokratie hinwegsetzt...............
2023-09-25 13:21:26 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-25 13:21:27 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeingservice, ein Mending und Presseservice, ein Geldwechsel, kostenfreier Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-25 13:21:27 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-25 13:21:28 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, Ehefrau des Königs D. João II, und bekannt durch ihre international bekannten Keramiken für ihre figurativen und satirischen Werke, ist auch einen Besuch wert.
2023-09-25 13:21:28 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-25 13:21:28 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es handele sich um gute Befürworter des Westens auf der einen Seite und Befürworter des früheren Regimes auf der anderen Seite, ist ebenfalls verwerflich, da die Rolle aller bekannt ist.
2023-09-25 13:21:28 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-25 13:21:29 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die unterschiedslos zwischen Flüssen und dem Meer fahren, nicht auf diese Weise abgedeckt sind, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.......................
2023-09-25 13:21:29 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-25 13:21:30 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Aktionärsversammlung aufgrund seines Status als Aktionär Informationen übermittelt, so sind diese auf Verlangen an andere Aktionäre in der Aktionärsversammlung weiterzugeben, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Beurteilung eines Tagesordnungspunktes zu ermöglichen.
2023-09-25 13:21:30 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-25 13:21:31 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die normalerweise in den Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen Menschen in unseren eigenen Ländern leben, die auch ein sehr elendes Leben führen.
2023-09-25 13:21:31 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-25 13:21:32 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder der NATO an diesem Kriegshandlungen beteiligt gewesen sein könnten -, mit Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, geheim oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen und die ganze Wahrheit erfahren können..........................
2023-09-25 13:21:32 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-25 13:21:33 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit der Bahn vom Stadtzentrum entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet............................
2023-09-25 13:21:33 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-25 13:21:34 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, sowie mit unserer Geschäftseinheit Defence Electronics und Indra in Spanien wird das Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen enthalten, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar sind, die die heutigen Plattformen außerhalb des Regals nie erreichen können.
2023-09-25 13:21:34 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-25 13:21:35 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir nicht nur für uns, sondern weltweit die Produkte vom Markt nehmen können, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt eine große Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt........................, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13
2023-09-25 13:21:35 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-25 13:21:36 | INFO | fairseq.tasks.translation | example hypothesis: Unter der einfachen Verschwörung von Moderne und Postmoderne oder dem klaren Gegensatz von reiner Kunst und engagierter Kunst müssen wir die originale und anhaltende Spannung jener beiden ästhetischen Politik erkennen, die in genau die Formen der Sichtbarkeit und Verständlichkeit verbirgt, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen................., die die letztlich zu ihrer eigenen Selbstunterdrück
2023-09-25 13:21:36 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-25 13:21:37 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Debatten und der Stellungnahmen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Beschlüsse unsere Debatten führen, und bei der Abstimmung, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht um die Feststellung der Beschlussfähigkeit bitten.
2023-09-25 13:21:37 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-25 13:21:38 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips nie akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem nationale Grenzen aufgehoben werden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen...............,,,,,,,,,,,
2023-09-25 13:21:38 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-25 13:21:39 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Form als Hybridform veröffentlicht, die Rezensionen und Artikel der Quartalzeitschrift sind für H-Soz-u-Kult geschrieben und über Mailinglisten sowie über die Websites des Berliner H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt.......... H-Soz-u-Kult und H-Kult sowie das Michigan-Net, wurden
2023-09-25 13:21:39 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-25 13:21:40 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Einführung der neuen Smartphone-Generation haben Handys ihre Federn deutlich verwischt und von einst wehenden Wecker im Taschenformat über polyphonisch tootende Game Boy-Aspirants bis hin zu schlichten Mini-PCs mit knackigem Stereo-Sound in CD-Qualität gegossen: Künftig könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-wannabes zu Trailblazern neuer technologischer Entwicklungen übergehen.
2023-09-25 13:21:40 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-25 13:21:42 | INFO | fairseq.tasks.translation | example hypothesis: En el primero de la base humana en Pandora, el pesar del fin científico del proyecto, el coronel Quaritch, quien dirige la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera requiario rerir a la fuerza para que se marchen., Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un
2023-09-25 13:21:42 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-25 13:21:43 | INFO | valid | epoch 023 | valid on 'valid' subset | loss 4.112 | nll_loss 2.147 | ppl 4.43 | bleu 27.72 | wps 16284.4 | wpb 12011.9 | bsz 398.1 | num_updates 208338 | best_bleu 29.48
2023-09-25 13:21:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 208338 updates
2023-09-25 13:21:43 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint23.pt
2023-09-25 13:21:49 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint23.pt
2023-09-25 13:21:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint23.pt (epoch 23 @ 208338 updates, score 27.72) (writing took 9.487190732965246 seconds)
2023-09-25 13:21:53 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2023-09-25 13:21:53 | INFO | train | epoch 023 | loss 7.44 | nll_loss 3.651 | ppl 12.56 | wps 3962.4 | ups 0.31 | wpb 12977.3 | bsz 430.6 | num_updates 208338 | lr 6.92813e-05 | gnorm 1.161 | loss_scale 8 | train_wall 29562 | gb_free 13.7 | wall 441706
2023-09-25 13:21:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-25 13:21:53 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-25 13:21:53 | INFO | fairseq.trainer | begin training epoch 24
2023-09-25 13:21:53 | INFO | fairseq_cli.train | Start iterating over samples
lprobs.size(): torch.Size([3136, 42808])
2023-09-25 13:25:12 | INFO | train_inner | epoch 024:     62 / 9060 loss=7.519, nll_loss=3.673, ppl=12.75, wps=3165.1, ups=0.24, wpb=13018.8, bsz=427.9, num_updates=208400, lr=6.92709e-05, gnorm=1.176, loss_scale=8, train_wall=328, gb_free=12.9, wall=441906
2023-09-25 13:30:58 | INFO | train_inner | epoch 024:    162 / 9060 loss=7.429, nll_loss=3.615, ppl=12.26, wps=3755.3, ups=0.29, wpb=12975.2, bsz=435.1, num_updates=208500, lr=6.92543e-05, gnorm=1.161, loss_scale=8, train_wall=345, gb_free=15, wall=442251
pred_new.size(): torch.Size([5376, 42808])
pred_new.size(): torch.Size([8100, 42808])
2023-09-25 13:36:27 | INFO | train_inner | epoch 024:    262 / 9060 loss=7.452, nll_loss=3.661, ppl=12.65, wps=3914.1, ups=0.3, wpb=12876.9, bsz=413.5, num_updates=208600, lr=6.92377e-05, gnorm=1.169, loss_scale=8, train_wall=329, gb_free=13.9, wall=442580
pred_new.size(): torch.Size([4386, 42808])
2023-09-25 13:42:02 | INFO | train_inner | epoch 024:    362 / 9060 loss=7.368, nll_loss=3.577, ppl=11.94, wps=3912.4, ups=0.3, wpb=13105.7, bsz=440.5, num_updates=208700, lr=6.92211e-05, gnorm=1.141, loss_scale=8, train_wall=335, gb_free=13.4, wall=442915
lprobs.size(): torch.Size([3456, 42808])
2023-09-25 13:47:27 | INFO | train_inner | epoch 024:    462 / 9060 loss=7.391, nll_loss=3.599, ppl=12.12, wps=3984.1, ups=0.31, wpb=12976.7, bsz=417.1, num_updates=208800, lr=6.92046e-05, gnorm=1.158, loss_scale=8, train_wall=325, gb_free=14.4, wall=443241
pred_new.size(): torch.Size([2624, 42808])
pred_new.size(): torch.Size([2900, 42808])
2023-09-25 13:52:59 | INFO | train_inner | epoch 024:    562 / 9060 loss=7.667, nll_loss=3.752, ppl=13.47, wps=3910.4, ups=0.3, wpb=12980.5, bsz=445.4, num_updates=208900, lr=6.9188e-05, gnorm=1.198, loss_scale=8, train_wall=332, gb_free=14.6, wall=443573
ter_threshold: 0.508996
num_accepted / total 19 56
loss token level: tensor(8622.6064, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8848., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
2023-09-25 13:58:28 | INFO | train_inner | epoch 024:    662 / 9060 loss=7.659, nll_loss=3.722, ppl=13.2, wps=3955.2, ups=0.3, wpb=13013.7, bsz=436.2, num_updates=209000, lr=6.91714e-05, gnorm=1.197, loss_scale=8, train_wall=329, gb_free=14.1, wall=443902
ter_threshold: 0.509098
num_accepted / total 34 72
loss token level: tensor(9509.3184, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11840., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 14:04:06 | INFO | train_inner | epoch 024:    762 / 9060 loss=7.521, nll_loss=3.671, ppl=12.74, wps=3831.3, ups=0.3, wpb=12947.8, bsz=416.9, num_updates=209100, lr=6.91549e-05, gnorm=1.194, loss_scale=8, train_wall=338, gb_free=13, wall=444240
2023-09-25 14:08:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-25 14:09:32 | INFO | train_inner | epoch 024:    863 / 9060 loss=7.663, nll_loss=3.73, ppl=13.27, wps=3996.2, ups=0.31, wpb=13017.6, bsz=440.2, num_updates=209200, lr=6.91384e-05, gnorm=1.201, loss_scale=4, train_wall=325, gb_free=14.2, wall=444565
ter_threshold: 0.509203
num_accepted / total 20 80
loss token level: tensor(7865.2939, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3072., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 14:15:17 | INFO | train_inner | epoch 024:    963 / 9060 loss=7.631, nll_loss=3.711, ppl=13.1, wps=3814.6, ups=0.29, wpb=13165.8, bsz=444.2, num_updates=209300, lr=6.91219e-05, gnorm=1.173, loss_scale=4, train_wall=345, gb_free=13.9, wall=444911
torch.Size([1290, 42808])
ter_threshold: 0.501186
num_accepted / total 22 64
loss token level: tensor(8824.1553, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5012., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2088, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.5012989999999999
num_accepted / total 57 104
loss token level: tensor(9376.3340, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13504., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([2856, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.501521
num_accepted / total 15 56
loss token level: tensor(8185.7124, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5888., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.501646
num_accepted / total 34 72
loss token level: tensor(8707.3086, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6376., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1664, 42808])
ter_threshold: 0.502061
num_accepted / total 74 136
loss token level: tensor(8462.5332, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6400., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([2160, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.50235
num_accepted / total 44 104
loss token level: tensor(9121.9512, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5668., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([5936, 42808])
ter_threshold: 0.50275
num_accepted / total 43 88
loss token level: tensor(8036.5352, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6432., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.50308
num_accepted / total 72 112
loss token level: tensor(8219.7480, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(14832., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3182, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.503278
num_accepted / total 152 208
loss token level: tensor(8767.7158, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9304., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4371, 42808])
pred_new.size(): torch.Size([6195, 42808])
ter_threshold: 0.503521
num_accepted / total 10 48
loss token level: tensor(8476.0166, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2434., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2184, 42808])
pred_new.size(): torch.Size([5658, 42808])
pred_new.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([2310, 42808])
ter_threshold: 0.503678
num_accepted / total 11 40
loss token level: tensor(9400.7480, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6776., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([1474, 42808])
pred_new.size(): torch.Size([3124, 42808])
pred_new.size(): torch.Size([3354, 42808])
ter_threshold: 0.5040169999999999
num_accepted / total 38 96
loss token level: tensor(9398.0127, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9520., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2500, 42808])
pred_new.size(): torch.Size([4332, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([2464, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2679, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5850, 42808])
pred_new.size(): torch.Size([1404, 42808])
lprobs.size(): torch.Size([3400, 42808])
ter_threshold: 0.504944
num_accepted / total 35 88
loss token level: tensor(8758.5635, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5520., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3128, 42808])
pred_new.size(): torch.Size([7490, 42808])
pred_new.size(): torch.Size([3010, 42808])
ter_threshold: 0.505197
num_accepted / total 106 192
loss token level: tensor(7612.4883, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9840., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3648, 42808])
pred_new.size(): torch.Size([5800, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([9240, 42808])
pred_new.size(): torch.Size([2046, 42808])
pred_new.size(): torch.Size([826, 42808])
pred_new.size(): torch.Size([132, 42808])
pred_new.size(): torch.Size([992, 42808])
lprobs.size(): torch.Size([2720, 42808])
ter_threshold: 0.506529
num_accepted / total 350 392
loss token level: tensor(7941.2441, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12528., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3339, 42808])
lprobs.size(): torch.Size([3296, 42808])
pred_new.size(): torch.Size([128, 42808])
ter_threshold: 0.507332
num_accepted / total 21 48
loss token level: tensor(8956.1699, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11344., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6996, 42808])
ter_threshold: 0.507458
num_accepted / total 57 104
loss token level: tensor(9027.3271, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7992., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([2760, 42808])
ter_threshold: 0.507668
num_accepted / total 38 96
loss token level: tensor(11557.7168, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9896., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([8085, 42808])
pred_new.size(): torch.Size([6318, 42808])
pred_new.size(): torch.Size([3638, 42808])
pred_new.size(): torch.Size([1480, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6956, 42808])
pred_new.size(): torch.Size([6930, 42808])
pred_new.size(): torch.Size([2310, 42808])
lprobs.size(): torch.Size([2280, 42808])
ter_threshold: 0.508996
num_accepted / total 8 48
loss token level: tensor(9183.4502, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3740., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.509098
num_accepted / total 35 80
loss token level: tensor(9023.0098, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9776., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.509203
num_accepted / total 42 104
loss token level: tensor(10150.7227, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6008., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.509394
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3280, 42808])
2023-09-25 14:21:02 | INFO | train_inner | epoch 024:   1063 / 9060 loss=7.461, nll_loss=3.626, ppl=12.35, wps=3742.6, ups=0.29, wpb=12918.1, bsz=457.4, num_updates=209400, lr=6.91053e-05, gnorm=1.168, loss_scale=4, train_wall=345, gb_free=14.1, wall=445256
2023-09-25 14:26:36 | INFO | train_inner | epoch 024:   1163 / 9060 loss=7.706, nll_loss=3.773, ppl=13.67, wps=3902.9, ups=0.3, wpb=13042.4, bsz=445.1, num_updates=209500, lr=6.90889e-05, gnorm=1.205, loss_scale=4, train_wall=334, gb_free=14, wall=445590
ter_threshold: 0.5095149999999999
num_accepted / total 38 88
loss token level: tensor(9721.4590, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6288., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 14:28:19 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
ter_threshold: 0.509563
num_accepted / total 59 104
loss token level: tensor(8952.9922, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13552., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 14:32:13 | INFO | train_inner | epoch 024:   1264 / 9060 loss=7.598, nll_loss=3.731, ppl=13.28, wps=3859.2, ups=0.3, wpb=12992.2, bsz=431, num_updates=209600, lr=6.90724e-05, gnorm=1.185, loss_scale=2, train_wall=336, gb_free=13.2, wall=445927
ter_threshold: 0.509626
num_accepted / total 12 40
loss token level: tensor(7493.4282, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6512., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 14:37:50 | INFO | train_inner | epoch 024:   1364 / 9060 loss=7.687, nll_loss=3.716, ppl=13.14, wps=3863.4, ups=0.3, wpb=13024.3, bsz=459.4, num_updates=209700, lr=6.90559e-05, gnorm=1.197, loss_scale=2, train_wall=337, gb_free=13.9, wall=446264
ter_threshold: 0.509713
num_accepted / total 35 96
loss token level: tensor(10166.4062, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8080., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 14:43:28 | INFO | train_inner | epoch 024:   1464 / 9060 loss=7.533, nll_loss=3.706, ppl=13.05, wps=3866.8, ups=0.3, wpb=13046, bsz=409.9, num_updates=209800, lr=6.90394e-05, gnorm=1.203, loss_scale=2, train_wall=337, gb_free=13.8, wall=446601
2023-09-25 14:49:01 | INFO | train_inner | epoch 024:   1564 / 9060 loss=7.657, nll_loss=3.713, ppl=13.11, wps=3929.2, ups=0.3, wpb=13101, bsz=440.9, num_updates=209900, lr=6.9023e-05, gnorm=1.215, loss_scale=2, train_wall=333, gb_free=13.1, wall=446935
pred_new.size(): torch.Size([2835, 42808])
pred_new.size(): torch.Size([8096, 42808])
2023-09-25 14:54:32 | INFO | train_inner | epoch 024:   1664 / 9060 loss=7.497, nll_loss=3.643, ppl=12.49, wps=3914.5, ups=0.3, wpb=12948.2, bsz=440.2, num_updates=210000, lr=6.90066e-05, gnorm=1.179, loss_scale=2, train_wall=330, gb_free=12.8, wall=447265
2023-09-25 15:00:03 | INFO | train_inner | epoch 024:   1764 / 9060 loss=7.483, nll_loss=3.621, ppl=12.3, wps=3923, ups=0.3, wpb=12994.5, bsz=445.4, num_updates=210100, lr=6.89901e-05, gnorm=1.15, loss_scale=2, train_wall=331, gb_free=15.4, wall=447597
ter_threshold: 0.510145
num_accepted / total 22 72
loss token level: tensor(10097.5781, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6472., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 15:05:39 | INFO | train_inner | epoch 024:   1864 / 9060 loss=7.517, nll_loss=3.648, ppl=12.54, wps=3843.8, ups=0.3, wpb=12896.9, bsz=446.8, num_updates=210200, lr=6.89737e-05, gnorm=1.177, loss_scale=2, train_wall=335, gb_free=13.8, wall=447932
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2394, 42808])
lprobs.size(): torch.Size([2976, 42808])
2023-09-25 15:11:13 | INFO | train_inner | epoch 024:   1964 / 9060 loss=7.549, nll_loss=3.711, ppl=13.09, wps=3866.4, ups=0.3, wpb=12924.7, bsz=422.2, num_updates=210300, lr=6.89573e-05, gnorm=1.188, loss_scale=2, train_wall=334, gb_free=13.6, wall=448266
lprobs.size(): torch.Size([3328, 42808])
2023-09-25 15:16:53 | INFO | train_inner | epoch 024:   2064 / 9060 loss=7.522, nll_loss=3.641, ppl=12.48, wps=3836.5, ups=0.29, wpb=13040.4, bsz=448.7, num_updates=210400, lr=6.89409e-05, gnorm=1.184, loss_scale=2, train_wall=340, gb_free=14.6, wall=448606
2023-09-25 15:22:29 | INFO | train_inner | epoch 024:   2164 / 9060 loss=7.513, nll_loss=3.667, ppl=12.71, wps=3854.9, ups=0.3, wpb=12965.5, bsz=437.9, num_updates=210500, lr=6.89246e-05, gnorm=1.167, loss_scale=2, train_wall=336, gb_free=12.7, wall=448943
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.510563
num_accepted / total 41 80
loss token level: tensor(9325.9336, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13264., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([891, 42808])
lprobs.size(): torch.Size([3344, 42808])
2023-09-25 15:28:06 | INFO | train_inner | epoch 024:   2264 / 9060 loss=7.354, nll_loss=3.603, ppl=12.15, wps=3829.7, ups=0.3, wpb=12898.8, bsz=438.8, num_updates=210600, lr=6.89082e-05, gnorm=1.173, loss_scale=2, train_wall=337, gb_free=14.2, wall=449279
pred_new.size(): torch.Size([2121, 42808])
2023-09-25 15:33:43 | INFO | train_inner | epoch 024:   2364 / 9060 loss=7.609, nll_loss=3.727, ppl=13.24, wps=3864, ups=0.3, wpb=13035.8, bsz=441.1, num_updates=210700, lr=6.88918e-05, gnorm=1.182, loss_scale=2, train_wall=337, gb_free=14.1, wall=449617
2023-09-25 15:39:27 | INFO | train_inner | epoch 024:   2464 / 9060 loss=7.869, nll_loss=3.859, ppl=14.51, wps=3777.3, ups=0.29, wpb=12974, bsz=445.5, num_updates=210800, lr=6.88755e-05, gnorm=1.25, loss_scale=2, train_wall=343, gb_free=13.5, wall=449960
ter_threshold: 0.510811
num_accepted / total 31 80
loss token level: tensor(10024.5908, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6068., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 15:45:02 | INFO | train_inner | epoch 024:   2564 / 9060 loss=7.517, nll_loss=3.674, ppl=12.76, wps=3893.7, ups=0.3, wpb=13053.6, bsz=421.9, num_updates=210900, lr=6.88592e-05, gnorm=1.175, loss_scale=2, train_wall=335, gb_free=13.8, wall=450295
lprobs.size(): torch.Size([2784, 42808])
pred_new.size(): torch.Size([6278, 42808])
2023-09-25 15:50:44 | INFO | train_inner | epoch 024:   2664 / 9060 loss=7.438, nll_loss=3.675, ppl=12.77, wps=3785.6, ups=0.29, wpb=12961.5, bsz=429, num_updates=211000, lr=6.88428e-05, gnorm=1.168, loss_scale=2, train_wall=342, gb_free=13.8, wall=450638
2023-09-25 15:56:12 | INFO | train_inner | epoch 024:   2764 / 9060 loss=7.53, nll_loss=3.657, ppl=12.61, wps=3988.5, ups=0.31, wpb=13048.6, bsz=445.7, num_updates=211100, lr=6.88265e-05, gnorm=1.189, loss_scale=2, train_wall=327, gb_free=14.3, wall=450965
pred_new.size(): torch.Size([2418, 42808])
2023-09-25 16:01:39 | INFO | train_inner | epoch 024:   2864 / 9060 loss=7.608, nll_loss=3.735, ppl=13.31, wps=3959.6, ups=0.31, wpb=12961.4, bsz=423.8, num_updates=211200, lr=6.88102e-05, gnorm=1.193, loss_scale=2, train_wall=327, gb_free=13.4, wall=451292
pred_new.size(): torch.Size([580, 42808])
2023-09-25 16:07:11 | INFO | train_inner | epoch 024:   2964 / 9060 loss=7.644, nll_loss=3.737, ppl=13.33, wps=3910.5, ups=0.3, wpb=12999.7, bsz=446.6, num_updates=211300, lr=6.8794e-05, gnorm=1.183, loss_scale=2, train_wall=332, gb_free=13.3, wall=451625
pred_new.size(): torch.Size([3696, 42808])
2023-09-25 16:12:39 | INFO | train_inner | epoch 024:   3064 / 9060 loss=7.366, nll_loss=3.599, ppl=12.12, wps=3917.5, ups=0.31, wpb=12838.6, bsz=415, num_updates=211400, lr=6.87777e-05, gnorm=1.181, loss_scale=2, train_wall=327, gb_free=14.9, wall=451953
ter_threshold: 0.51143
num_accepted / total 27 72
loss token level: tensor(9553.0742, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8800., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6640, 42808])
2023-09-25 16:18:11 | INFO | train_inner | epoch 024:   3164 / 9060 loss=7.501, nll_loss=3.695, ppl=12.96, wps=3916.4, ups=0.3, wpb=13009.8, bsz=417.7, num_updates=211500, lr=6.87614e-05, gnorm=1.179, loss_scale=2, train_wall=332, gb_free=13.8, wall=452285
lprobs.size(): torch.Size([2880, 42808])
2023-09-25 16:23:47 | INFO | train_inner | epoch 024:   3264 / 9060 loss=7.64, nll_loss=3.743, ppl=13.39, wps=3853.3, ups=0.3, wpb=12924.7, bsz=420, num_updates=211600, lr=6.87452e-05, gnorm=1.202, loss_scale=2, train_wall=335, gb_free=13.8, wall=452620
2023-09-25 16:29:17 | INFO | train_inner | epoch 024:   3364 / 9060 loss=7.401, nll_loss=3.623, ppl=12.32, wps=3912.9, ups=0.3, wpb=12944.7, bsz=427.1, num_updates=211700, lr=6.87289e-05, gnorm=1.179, loss_scale=2, train_wall=331, gb_free=13.4, wall=452951
2023-09-25 16:34:40 | INFO | train_inner | epoch 024:   3464 / 9060 loss=7.49, nll_loss=3.659, ppl=12.63, wps=4046.1, ups=0.31, wpb=13033, bsz=427.5, num_updates=211800, lr=6.87127e-05, gnorm=1.162, loss_scale=2, train_wall=322, gb_free=15.5, wall=453273
2023-09-25 16:40:08 | INFO | train_inner | epoch 024:   3564 / 9060 loss=7.613, nll_loss=3.735, ppl=13.32, wps=3977.2, ups=0.3, wpb=13045.8, bsz=435.8, num_updates=211900, lr=6.86965e-05, gnorm=1.194, loss_scale=2, train_wall=328, gb_free=13.9, wall=453601
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([7540, 42808])
2023-09-25 16:45:49 | INFO | train_inner | epoch 024:   3664 / 9060 loss=7.69, nll_loss=3.753, ppl=13.48, wps=3789.4, ups=0.29, wpb=12921, bsz=409.7, num_updates=212000, lr=6.86803e-05, gnorm=1.212, loss_scale=2, train_wall=341, gb_free=14.5, wall=453942
ter_threshold: 0.512011
num_accepted / total 38 88
loss token level: tensor(8244.7227, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5672., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3024, 42808])
2023-09-25 16:51:14 | INFO | train_inner | epoch 024:   3764 / 9060 loss=7.425, nll_loss=3.672, ppl=12.75, wps=3958.2, ups=0.31, wpb=12878.5, bsz=417.4, num_updates=212100, lr=6.86641e-05, gnorm=1.161, loss_scale=2, train_wall=325, gb_free=16.5, wall=454267
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([4284, 42808])
2023-09-25 16:56:48 | INFO | train_inner | epoch 024:   3864 / 9060 loss=7.582, nll_loss=3.711, ppl=13.09, wps=3883.8, ups=0.3, wpb=12982.6, bsz=431.4, num_updates=212200, lr=6.86479e-05, gnorm=1.181, loss_scale=2, train_wall=334, gb_free=13.4, wall=454602
pred_new.size(): torch.Size([4940, 42808])
2023-09-25 17:02:15 | INFO | train_inner | epoch 024:   3964 / 9060 loss=7.563, nll_loss=3.69, ppl=12.9, wps=3992.6, ups=0.31, wpb=13055.4, bsz=427.7, num_updates=212300, lr=6.86317e-05, gnorm=1.169, loss_scale=2, train_wall=327, gb_free=12.6, wall=454929
ter_threshold: 0.512377
num_accepted / total 73 144
loss token level: tensor(8299.1338, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10448., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 17:07:50 | INFO | train_inner | epoch 024:   4064 / 9060 loss=7.332, nll_loss=3.606, ppl=12.18, wps=3867.1, ups=0.3, wpb=12927.9, bsz=418, num_updates=212400, lr=6.86156e-05, gnorm=1.158, loss_scale=2, train_wall=334, gb_free=13.1, wall=455263
2023-09-25 17:13:21 | INFO | train_inner | epoch 024:   4164 / 9060 loss=7.549, nll_loss=3.68, ppl=12.82, wps=3913.7, ups=0.3, wpb=12979.8, bsz=422.6, num_updates=212500, lr=6.85994e-05, gnorm=1.181, loss_scale=2, train_wall=331, gb_free=14, wall=455595
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.504477
num_accepted / total 19 48
loss token level: tensor(8255.2832, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6068., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.504944
num_accepted / total 101 176
loss token level: tensor(9448.6211, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7476., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5049509999999999
num_accepted / total 27 56
loss token level: tensor(8272.1113, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6832., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3660, 42808])
pred_new.size(): torch.Size([8395, 42808])
lprobs.size(): torch.Size([3120, 42808])
ter_threshold: 0.505197
num_accepted / total 71 144
loss token level: tensor(9077.2324, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5712, 42808])
pred_new.size(): torch.Size([2816, 42808])
ter_threshold: 0.5055810000000001
num_accepted / total 12 32
loss token level: tensor(8075.7192, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8856., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.50579
num_accepted / total 37 120
loss token level: tensor(8429.8730, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6144., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([868, 42808])
pred_new.size(): torch.Size([1416, 42808])
pred_new.size(): torch.Size([7000, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4110, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.506529
num_accepted / total 87 144
loss token level: tensor(9492.4473, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12976., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1950, 42808])
ter_threshold: 0.506719
num_accepted / total 37 80
loss token level: tensor(9120.0254, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5856., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.506783
num_accepted / total 7 48
loss token level: tensor(9053.5449, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1812., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1224, 42808])
ter_threshold: 0.507204
num_accepted / total 90 192
loss token level: tensor(9670.1621, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9296., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4104, 42808])
ter_threshold: 0.507369
num_accepted / total 60 112
loss token level: tensor(9626.2754, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13840., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.507458
num_accepted / total 37 88
loss token level: tensor(8446.7988, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5596., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.507535
num_accepted / total 173 224
loss token level: tensor(8587.2207, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(17152., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7605, 42808])
lprobs.size(): torch.Size([2560, 42808])
ter_threshold: 0.507668
num_accepted / total 43 96
loss token level: tensor(10216.4756, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5304, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([2368, 42808])
pred_new.size(): torch.Size([3626, 42808])
pred_new.size(): torch.Size([4626, 42808])
pred_new.size(): torch.Size([432, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([9540, 42808])
pred_new.size(): torch.Size([6696, 42808])
pred_new.size(): torch.Size([4664, 42808])
pred_new.size(): torch.Size([4392, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([3872, 42808])
lprobs.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([3402, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([5688, 42808])
pred_new.size(): torch.Size([2292, 42808])
ter_threshold: 0.5095149999999999
num_accepted / total 123 168
loss token level: tensor(8855.8799, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9808., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.509563
num_accepted / total 54 104
loss token level: tensor(9575.2559, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.509773
num_accepted / total 23 72
loss token level: tensor(8256.1123, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3986., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5099009999999999
num_accepted / total 24 80
loss token level: tensor(10534.0049, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6936., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2088, 42808])
pred_new.size(): torch.Size([970, 42808])
pred_new.size(): torch.Size([1950, 42808])
pred_new.size(): torch.Size([8100, 42808])
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([6375, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([1232, 42808])
ter_threshold: 0.511014
num_accepted / total 14 40
loss token level: tensor(7519.4946, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4752., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.511082
num_accepted / total 24 64
loss token level: tensor(8840.0830, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5208., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4773, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1134, 42808])
ter_threshold: 0.511736
num_accepted / total 183 272
loss token level: tensor(8642.2363, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8357, 42808])
ter_threshold: 0.512011
num_accepted / total 78 128
loss token level: tensor(8835.3984, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8400., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([2808, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5607, 42808])
pred_new.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([6664, 42808])
ter_threshold: 0.512377
num_accepted / total 75 168
loss token level: tensor(8068.3301, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8584., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([642, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.512563
num_accepted / total 86 144
loss token level: 2023-09-25 17:18:59 | INFO | train_inner | epoch 024:   4264 / 9060 loss=7.623, nll_loss=3.727, ppl=13.24, wps=3799.2, ups=0.3, wpb=12847.6, bsz=432.8, num_updates=212600, lr=6.85833e-05, gnorm=1.218, loss_scale=2, train_wall=338, gb_free=13.2, wall=455933
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 17:24:21 | INFO | train_inner | epoch 024:   4364 / 9060 loss=7.528, nll_loss=3.676, ppl=12.78, wps=4019.8, ups=0.31, wpb=12931, bsz=447.1, num_updates=212700, lr=6.85672e-05, gnorm=1.177, loss_scale=2, train_wall=321, gb_free=13.5, wall=456254
2023-09-25 17:30:01 | INFO | train_inner | epoch 024:   4464 / 9060 loss=7.331, nll_loss=3.633, ppl=12.4, wps=3808, ups=0.29, wpb=12929.1, bsz=418.6, num_updates=212800, lr=6.85511e-05, gnorm=1.184, loss_scale=2, train_wall=339, gb_free=14.9, wall=456594
2023-09-25 17:35:28 | INFO | train_inner | epoch 024:   4564 / 9060 loss=7.397, nll_loss=3.66, ppl=12.64, wps=3921, ups=0.3, wpb=12856.6, bsz=421.1, num_updates=212900, lr=6.8535e-05, gnorm=1.218, loss_scale=2, train_wall=328, gb_free=12.8, wall=456922
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.512967
num_accepted / total 9 48
loss token level: tensor(9443.9736, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4432., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 17:40:47 | INFO | train_inner | epoch 024:   4664 / 9060 loss=7.425, nll_loss=3.664, ppl=12.67, wps=4032.1, ups=0.31, wpb=12841.5, bsz=435.9, num_updates=213000, lr=6.85189e-05, gnorm=1.161, loss_scale=2, train_wall=318, gb_free=13.3, wall=457240
tensor(3204., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5058929999999999
num_accepted / total 16 64
loss token level: tensor(10112.3623, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5936., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.505904
num_accepted / total 7 32
loss token level: tensor(9059.5508, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2688., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4836, 42808])
pred_new.size(): torch.Size([2304, 42808])
lprobs.size(): torch.Size([3160, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([6600, 42808])
lprobs.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([5670, 42808])
ter_threshold: 0.506923
num_accepted / total 60 112
loss token level: tensor(8943.7861, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7304., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.5071399999999999
num_accepted / total 38 80
loss token level: tensor(9472.5703, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11984., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.507204
num_accepted / total 89 144
loss token level: tensor(8924.5791, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13920., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([848, 42808])
ter_threshold: 0.507266
num_accepted / total 126 256
loss token level: tensor(10384.8926, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5792., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.507369
num_accepted / total 56 112
loss token level: tensor(8845.4219, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10544., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2024, 42808])
ter_threshold: 0.507535
num_accepted / total 70 160
loss token level: tensor(11642.2705, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9840., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4788, 42808])
ter_threshold: 0.507578
num_accepted / total 35 80
loss token level: tensor(8914.0020, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9728., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.507668
num_accepted / total 82 136
loss token level: tensor(9410.6299, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14920., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4788, 42808])
lprobs.size(): torch.Size([2768, 42808])
pred_new.size(): torch.Size([3852, 42808])
pred_new.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3008, 42808])
pred_new.size(): torch.Size([6307, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5220, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([4216, 42808])
pred_new.size(): torch.Size([2790, 42808])
pred_new.size(): torch.Size([4386, 42808])
pred_new.size(): torch.Size([4158, 42808])
lprobs.size(): torch.Size([2552, 42808])
ter_threshold: 0.509174
num_accepted / total 12 48
loss token level: tensor(10158.2686, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3928., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.509203
num_accepted / total 84 136
loss token level: tensor(8990.0664, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8944., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.509394
num_accepted / total 63 176
loss token level: tensor(11759.9971, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7792., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.50946
num_accepted / total 9 56
loss token level: tensor(7632.6968, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3564., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.5095149999999999
num_accepted / total 29 88
loss token level: tensor(8699.7988, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4188., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.509563
num_accepted / total 41 88
loss token level: tensor(9295.1641, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11376., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([2720, 42808])
ter_threshold: 0.510145
num_accepted / total 17 64
loss token level: tensor(8599.9785, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6368., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.510301
num_accepted / total 31 72
loss token level: tensor(8804.2236, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9664., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([9200, 42808])
ter_threshold: 0.510347
num_accepted / total 25 56
loss token level: tensor(8320.9492, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3100, 42808])
lprobs.size(): torch.Size([2496, 42808])
pred_new.size(): torch.Size([441, 42808])
pred_new.size(): torch.Size([4218, 42808])
lprobs.size(): torch.Size([2848, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.510802
num_accepted / total 16 40
loss token level: tensor(9197.4766, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6208., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2664, 42808])
pred_new.size(): torch.Size([2204, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([6120, 42808])
pred_new.size(): torch.Size([532, 42808])
ter_threshold: 0.511736
num_accepted / total 43 120
loss token level: tensor(11127.8340, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4564., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.511756
num_accepted / total 20 48
loss token level: tensor(9155.4961, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10768., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.512011
num_accepted / total 67 152
loss token level: tensor(7745.6113, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4140., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1700, 42808])
pred_new.size(): torch.Size([5655, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2376, 42808])
ter_threshold: 0.512859
num_accepted / total 86 152
loss token level: tensor(9099.4580, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7360., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.512878
num_accepted / total 23 64
loss token level: tensor(7637.3252, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4512., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([6912, 42808])
2023-09-25 17:46:17 | INFO | train_inner | epoch 024:   4764 / 9060 loss=7.523, nll_loss=3.725, ppl=13.22, wps=3911.3, ups=0.3, wpb=12895, bsz=412, num_updates=213100, lr=6.85028e-05, gnorm=1.189, loss_scale=2, train_wall=329, gb_free=15.8, wall=457570
pred_new.size(): torch.Size([5250, 42808])
2023-09-25 17:51:56 | INFO | train_inner | epoch 024:   4864 / 9060 loss=7.704, nll_loss=3.767, ppl=13.62, wps=3839.6, ups=0.29, wpb=13047.2, bsz=435.7, num_updates=213200, lr=6.84867e-05, gnorm=1.19, loss_scale=2, train_wall=340, gb_free=13.2, wall=457910
pred_new.size(): torch.Size([7735, 42808])
2023-09-25 17:57:30 | INFO | train_inner | epoch 024:   4964 / 9060 loss=7.63, nll_loss=3.747, ppl=13.42, wps=3888.2, ups=0.3, wpb=12951.8, bsz=421.4, num_updates=213300, lr=6.84707e-05, gnorm=1.212, loss_scale=2, train_wall=333, gb_free=13.7, wall=458243
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1120, 42808])
pred_new.size(): torch.Size([1800, 42808])
2023-09-25 18:03:04 | INFO | train_inner | epoch 024:   5064 / 9060 loss=7.548, nll_loss=3.708, ppl=13.07, wps=3876.1, ups=0.3, wpb=12949.7, bsz=448.5, num_updates=213400, lr=6.84546e-05, gnorm=1.174, loss_scale=2, train_wall=334, gb_free=14.5, wall=458577
ter_threshold: 0.513401
num_accepted / total 21 72
loss token level: tensor(8072.4883, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3596., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 18:08:31 | INFO | train_inner | epoch 024:   5164 / 9060 loss=7.42, nll_loss=3.692, ppl=12.93, wps=3897.5, ups=0.31, wpb=12751.2, bsz=419.3, num_updates=213500, lr=6.84386e-05, gnorm=1.182, loss_scale=2, train_wall=327, gb_free=12.9, wall=458904
pred_new.size(): torch.Size([6210, 42808])
2023-09-25 18:14:14 | INFO | train_inner | epoch 024:   5264 / 9060 loss=7.527, nll_loss=3.689, ppl=12.9, wps=3769.8, ups=0.29, wpb=12955, bsz=429.8, num_updates=213600, lr=6.84226e-05, gnorm=1.189, loss_scale=2, train_wall=343, gb_free=14.4, wall=459248
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([3660, 42808])
pred_new.size(): torch.Size([2871, 42808])
2023-09-25 18:19:43 | INFO | train_inner | epoch 024:   5364 / 9060 loss=7.47, nll_loss=3.684, ppl=12.86, wps=3940.8, ups=0.3, wpb=12953.1, bsz=419.8, num_updates=213700, lr=6.84066e-05, gnorm=1.17, loss_scale=4, train_wall=328, gb_free=15.4, wall=459577
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3916, 42808])
2023-09-25 18:25:25 | INFO | train_inner | epoch 024:   5464 / 9060 loss=7.52, nll_loss=3.7, ppl=13, wps=3797.2, ups=0.29, wpb=12969.5, bsz=408.2, num_updates=213800, lr=6.83906e-05, gnorm=1.191, loss_scale=4, train_wall=341, gb_free=14.7, wall=459918
pred_new.size(): torch.Size([7068, 42808])
2023-09-25 18:31:02 | INFO | train_inner | epoch 024:   5564 / 9060 loss=7.505, nll_loss=3.685, ppl=12.86, wps=3859.4, ups=0.3, wpb=13034.3, bsz=400.9, num_updates=213900, lr=6.83746e-05, gnorm=1.176, loss_scale=4, train_wall=337, gb_free=13.2, wall=460256
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3472, 42808])
2023-09-25 18:36:29 | INFO | train_inner | epoch 024:   5664 / 9060 loss=7.331, nll_loss=3.628, ppl=12.36, wps=4000.2, ups=0.31, wpb=13077.2, bsz=451.9, num_updates=214000, lr=6.83586e-05, gnorm=1.14, loss_scale=4, train_wall=327, gb_free=15.8, wall=460583
2023-09-25 18:41:55 | INFO | train_inner | epoch 024:   5764 / 9060 loss=7.46, nll_loss=3.697, ppl=12.97, wps=4022.6, ups=0.31, wpb=13084.4, bsz=438, num_updates=214100, lr=6.83426e-05, gnorm=1.159, loss_scale=4, train_wall=325, gb_free=14.6, wall=460908
ter_threshold: 0.514138
num_accepted / total 9 72
loss token level: tensor(9072.8193, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2096., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([7375, 42808])
ter_threshold: 0.514157
num_accepted / total 151 256
loss token level: tensor(9158.2773, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7608., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5141709999999999
num_accepted / total 37 112
loss token level: tensor(8251.1543, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6472., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 18:47:34 | INFO | train_inner | epoch 024:   5864 / 9060 loss=7.498, nll_loss=3.691, ppl=12.91, wps=3834.9, ups=0.29, wpb=13008.4, bsz=435, num_updates=214200, lr=6.83267e-05, gnorm=1.179, loss_scale=4, train_wall=339, gb_free=13.8, wall=461247
2023-09-25 18:53:12 | INFO | train_inner | epoch 024:   5964 / 9060 loss=7.461, nll_loss=3.672, ppl=12.75, wps=3839, ups=0.3, wpb=12992.2, bsz=405.3, num_updates=214300, lr=6.83107e-05, gnorm=1.217, loss_scale=4, train_wall=338, gb_free=14.1, wall=461586
2023-09-25 18:58:46 | INFO | train_inner | epoch 024:   6064 / 9060 loss=7.494, nll_loss=3.697, ppl=12.97, wps=3857.6, ups=0.3, wpb=12859.9, bsz=430.7, num_updates=214400, lr=6.82948e-05, gnorm=1.185, loss_scale=4, train_wall=333, gb_free=13.5, wall=461919
pred_new.size(): torch.Size([1575, 42808])
2023-09-25 19:04:24 | INFO | train_inner | epoch 024:   6164 / 9060 loss=7.473, nll_loss=3.64, ppl=12.47, wps=3836.2, ups=0.3, wpb=12969.8, bsz=459.1, num_updates=214500, lr=6.82789e-05, gnorm=1.183, loss_scale=4, train_wall=338, gb_free=15.7, wall=462257
2023-09-25 19:10:02 | INFO | train_inner | epoch 024:   6264 / 9060 loss=7.529, nll_loss=3.692, ppl=12.93, wps=3833.7, ups=0.3, wpb=12981.6, bsz=441.6, num_updates=214600, lr=6.8263e-05, gnorm=1.192, loss_scale=4, train_wall=338, gb_free=14.2, wall=462596
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2552, 42808])
2023-09-25 19:15:32 | INFO | train_inner | epoch 024:   6364 / 9060 loss=7.258, nll_loss=3.577, ppl=11.94, wps=3932.9, ups=0.3, wpb=12985.3, bsz=421.1, num_updates=214700, lr=6.82471e-05, gnorm=1.145, loss_scale=4, train_wall=330, gb_free=14.5, wall=462926
ter_threshold: 0.514787
num_accepted / total 47 96
loss token level: tensor(9247.7607, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11680., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 19:21:02 | INFO | train_inner | epoch 024:   6464 / 9060 loss=7.442, nll_loss=3.64, ppl=12.47, wps=3949.9, ups=0.3, wpb=13021.6, bsz=439.4, num_updates=214800, lr=6.82312e-05, gnorm=1.186, loss_scale=4, train_wall=329, gb_free=14.5, wall=463256
pred_new.size(): torch.Size([270, 42808])
lprobs.size(): torch.Size([3040, 42808])
2023-09-25 19:26:36 | INFO | train_inner | epoch 024:   6564 / 9060 loss=7.593, nll_loss=3.731, ppl=13.28, wps=3872.2, ups=0.3, wpb=12944.1, bsz=415.5, num_updates=214900, lr=6.82153e-05, gnorm=1.196, loss_scale=4, train_wall=334, gb_free=13.3, wall=463590
ter_threshold: 0.51499
num_accepted / total 5 32
loss token level: tensor(10545.9707, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2380., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 19:32:15 | INFO | train_inner | epoch 024:   6664 / 9060 loss=7.493, nll_loss=3.68, ppl=12.82, wps=3821.9, ups=0.3, wpb=12949.6, bsz=428.8, num_updates=215000, lr=6.81994e-05, gnorm=1.208, loss_scale=4, train_wall=339, gb_free=13.3, wall=463929
pred_new.size(): torch.Size([3816, 42808])
2023-09-25 19:37:40 | INFO | train_inner | epoch 024:   6764 / 9060 loss=7.393, nll_loss=3.64, ppl=12.47, wps=3994.6, ups=0.31, wpb=12977, bsz=405.6, num_updates=215100, lr=6.81836e-05, gnorm=1.159, loss_scale=4, train_wall=325, gb_free=13, wall=464254
ter_threshold: 0.515152
num_accepted / total 84 144
loss token level: tensor(9358.6523, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13296., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 19:43:09 | INFO | train_inner | epoch 024:   6864 / 9060 loss=7.509, nll_loss=3.685, ppl=12.86, wps=3972.4, ups=0.3, wpb=13049.8, bsz=431.4, num_updates=215200, lr=6.81677e-05, gnorm=1.186, loss_scale=4, train_wall=328, gb_free=14.9, wall=464582
2023-09-25 19:48:42 | INFO | train_inner | epoch 024:   6964 / 9060 loss=7.57, nll_loss=3.719, ppl=13.17, wps=3894.8, ups=0.3, wpb=12979.6, bsz=420.4, num_updates=215300, lr=6.81519e-05, gnorm=1.19, loss_scale=4, train_wall=333, gb_free=13.8, wall=464915
pred_new.size(): torch.Size([5684, 42808])
2023-09-25 19:54:17 | INFO | train_inner | epoch 024:   7064 / 9060 loss=7.507, nll_loss=3.684, ppl=12.85, wps=3874.9, ups=0.3, wpb=13000.8, bsz=432.2, num_updates=215400, lr=6.81361e-05, gnorm=1.173, loss_scale=4, train_wall=335, gb_free=14.6, wall=465251
pred_new.size(): torch.Size([2240, 42808])
2023-09-25 19:59:52 | INFO | train_inner | epoch 024:   7164 / 9060 loss=7.438, nll_loss=3.652, ppl=12.57, wps=3867, ups=0.3, wpb=12925.8, bsz=446.2, num_updates=215500, lr=6.81203e-05, gnorm=1.182, loss_scale=4, train_wall=334, gb_free=13.2, wall=465585
2023-09-25 20:05:34 | INFO | train_inner | epoch 024:   7264 / 9060 loss=7.554, nll_loss=3.706, ppl=13.05, wps=3798.2, ups=0.29, wpb=12994.7, bsz=450.6, num_updates=215600, lr=6.81045e-05, gnorm=1.162, loss_scale=4, train_wall=342, gb_free=13.7, wall=465927
2023-09-25 20:11:04 | INFO | train_inner | epoch 024:   7364 / 9060 loss=7.336, nll_loss=3.619, ppl=12.28, wps=3914.4, ups=0.3, wpb=12941, bsz=407.5, num_updates=215700, lr=6.80887e-05, gnorm=1.15, loss_scale=4, train_wall=330, gb_free=14.9, wall=466258
ter_threshold: 0.515759
num_accepted / total 23 48
loss token level: tensor(8023.4956, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6684., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 20:16:27 | INFO | train_inner | epoch 024:   7464 / 9060 loss=7.371, nll_loss=3.648, ppl=12.53, wps=4026.1, ups=0.31, wpb=12977.3, bsz=426.3, num_updates=215800, lr=6.80729e-05, gnorm=1.216, loss_scale=4, train_wall=322, gb_free=13.8, wall=466580
pred_new.size(): torch.Size([2250, 42808])
2023-09-25 20:21:52 | INFO | train_inner | epoch 024:   7564 / 9060 loss=7.481, nll_loss=3.659, ppl=12.63, wps=4019.4, ups=0.31, wpb=13062.5, bsz=432.8, num_updates=215900, lr=6.80571e-05, gnorm=1.179, loss_scale=4, train_wall=325, gb_free=13.6, wall=466905
ter_threshold: 0.515919
num_accepted / total 124 192
loss token level: tensor(7924.1182, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11968., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-25 20:27:25 | INFO | train_inner | epoch 024:   7664 / 9060 loss=7.491, nll_loss=3.669, ppl=12.72, wps=3943.9, ups=0.3, wpb=13139.2, bsz=442.8, num_updates=216000, lr=6.80414e-05, gnorm=1.179, loss_scale=4, train_wall=333, gb_free=14.1, wall=467238
2023-09-25 20:33:04 | INFO | train_inner | epoch 024:   7764 / 9060 loss=7.639, nll_loss=3.751, ppl=13.47, wps=3785.3, ups=0.3, wpb=12829.9, bsz=416.3, num_updates=216100, lr=6.80256e-05, gnorm=1.204, loss_scale=4, train_wall=339, gb_free=13.9, wall=467577
pred_new.size(): torch.Size([8305, 42808])
pred_new.size(): torch.Size([2480, 42808])
2023-09-25 20:38:42 | INFO | train_inner | epoch 024:   7864 / 9060 loss=7.534, nll_loss=3.68, ppl=12.82, wps=3864.1, ups=0.3, wpb=13055.4, bsz=434.9, num_updates=216200, lr=6.80099e-05, gnorm=1.184, loss_scale=4, train_wall=338, gb_free=13.4, wall=467915
lprobs.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([2142, 42808])
2023-09-25 20:44:13 | INFO | train_inner | epoch 024:   7964 / 9060 loss=7.533, nll_loss=3.683, ppl=12.84, wps=3928.6, ups=0.3, wpb=13026.6, bsz=445.7, num_updates=216300, lr=6.79942e-05, gnorm=1.187, loss_scale=4, train_wall=331, gb_free=14.7, wall=468247
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 20:49:55 | INFO | train_inner | epoch 024:   8064 / 9060 loss=7.402, nll_loss=3.631, ppl=12.39, wps=3803.7, ups=0.29, wpb=12982.1, bsz=417.6, num_updates=216400, lr=6.79785e-05, gnorm=1.155, loss_scale=4, train_wall=341, gb_free=13.5, wall=468588
pred_new.size(): torch.Size([9185, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-25 20:55:32 | INFO | train_inner | epoch 024:   8164 / 9060 loss=7.561, nll_loss=3.742, ppl=13.38, wps=3832.4, ups=0.3, wpb=12922.7, bsz=417, num_updates=216500, lr=6.79628e-05, gnorm=1.216, loss_scale=4, train_wall=337, gb_free=13.3, wall=468925
lprobs.size(): torch.Size([3160, 42808])
2023-09-25 21:01:00 | INFO | train_inner | epoch 024:   8264 / 9060 loss=7.446, nll_loss=3.651, ppl=12.57, wps=3963.6, ups=0.3, wpb=13020.1, bsz=441.2, num_updates=216600, lr=6.79471e-05, gnorm=1.166, loss_scale=4, train_wall=328, gb_free=13.8, wall=469254
pred_new.size(): torch.Size([4680, 42808])
pred_new.size(): torch.Size([2890, 42808])
2023-09-25 21:06:41 | INFO | train_inner | epoch 024:   8364 / 9060 loss=7.537, nll_loss=3.73, ppl=13.26, wps=3806.4, ups=0.29, wpb=12985.1, bsz=426.8, num_updates=216700, lr=6.79314e-05, gnorm=1.203, loss_scale=4, train_wall=341, gb_free=14.4, wall=469595
ter_threshold: 0.516775
num_accepted / total 162 232
loss token level: tensor(8822.0195, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(14624., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1625, 42808])
pred_new.size(): torch.Size([3640, 42808])
lprobs.size(): torch.Size([3584, 42808])
2023-09-25 21:12:07 | INFO | train_inner | epoch 024:   8464 / 9060 loss=7.4, nll_loss=3.655, ppl=12.6, wps=3989.2, ups=0.31, wpb=13002, bsz=415.6, num_updates=216800, lr=6.79157e-05, gnorm=1.176, loss_scale=4, train_wall=326, gb_free=13.7, wall=469921
lprobs.size(): torch.Size([2816, 42808])
2023-09-25 21:17:44 | INFO | train_inner | epoch 024:   8564 / 9060 loss=7.418, nll_loss=3.64, ppl=12.47, wps=3844.4, ups=0.3, wpb=12958.1, bsz=401.8, num_updates=216900, lr=6.79001e-05, gnorm=1.187, loss_scale=4, train_wall=337, gb_free=12.8, wall=470258
2023-09-25 21:23:29 | INFO | train_inner | epoch 024:   8664 / 9060 loss=7.532, nll_loss=3.725, ppl=13.23, wps=3758, ups=0.29, wpb=12956.6, bsz=439.4, num_updates=217000, lr=6.78844e-05, gnorm=1.196, loss_scale=4, train_wall=345, gb_free=13.5, wall=470603
lprobs.size(): torch.Size([2624, 42808])
2023-09-25 21:28:56 | INFO | train_inner | epoch 024:   8764 / 9060 loss=7.362, nll_loss=3.633, ppl=12.4, wps=3961, ups=0.31, wpb=12965.4, bsz=436.2, num_updates=217100, lr=6.78688e-05, gnorm=1.158, loss_scale=4, train_wall=327, gb_free=13.8, wall=470930
2023-09-25 21:34:41 | INFO | train_inner | epoch 024:   8864 / 9060 loss=7.329, nll_loss=3.598, ppl=12.11, wps=3757.6, ups=0.29, wpb=12963.1, bsz=438, num_updates=217200, lr=6.78532e-05, gnorm=1.179, loss_scale=4, train_wall=345, gb_free=13.4, wall=471275
pred_new.size(): torch.Size([2916, 42808])
2023-09-25 21:40:11 | INFO | train_inner | epoch 024:   8964 / 9060 loss=7.511, nll_loss=3.688, ppl=12.89, wps=3957.6, ups=0.3, wpb=13042.2, bsz=447.8, num_updates=217300, lr=6.78375e-05, gnorm=1.186, loss_scale=4, train_wall=329, gb_free=12.8, wall=471604
lprobs.size(): torch.Size([3328, 42808])
2023-09-25 21:45:40 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-25 21:45:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-25 21:45:41 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-25 21:45:41 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-25 21:45:41 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-25 21:45:41 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-25 21:45:42 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-25 21:45:42 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-25 21:45:42 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-25 21:45:42 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-25 21:45:43 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-25 21:45:43 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-25 21:45:43 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein voller Erfolg.
2023-09-25 21:45:43 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-25 21:45:44 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein glückliches neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-25 21:45:44 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-25 21:45:44 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-25 21:45:44 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-25 21:45:45 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chat-Diskussionen.
2023-09-25 21:45:45 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-25 21:45:45 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Urlaubsreisende ansprechend sind.
2023-09-25 21:45:45 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-25 21:45:46 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-25 21:45:46 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-25 21:45:46 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-25 21:45:46 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-25 21:45:47 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der gesamten EU riesige Mengen an Energie verschwendet.
2023-09-25 21:45:47 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-25 21:45:48 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner neuesten Nummer veröffentlicht.
2023-09-25 21:45:48 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-25 21:45:48 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich auch die veränderte Einstellung bald im Haushalt der Union widerspiegeln.
2023-09-25 21:45:48 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-25 21:45:49 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-25 21:45:49 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-25 21:45:49 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-25 21:45:49 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-25 21:45:50 | INFO | fairseq.tasks.translation | example hypothesis: Ich darf Sie daran erinnern, dass eines der Hauptziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-25 21:45:50 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-25 21:45:50 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-25 21:45:50 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-25 21:45:51 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Sitz und Produktionshallen in Stans.
2023-09-25 21:45:51 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-25 21:45:52 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-25 21:45:52 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-25 21:45:52 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-25 21:45:52 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-25 21:45:53 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionale Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-25 21:45:53 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-25 21:45:53 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potenzielle Käufer veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-25 21:45:53 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-25 21:45:54 | INFO | fairseq.tasks.translation | example hypothesis: Während sich die Zentralbanken weiter auf unbekanntes Territorium wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten würden.
2023-09-25 21:45:54 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-25 21:45:55 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-25 21:45:55 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-25 21:45:55 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Aussprache, Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-25 21:45:55 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-25 21:45:56 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Orte im Umkreis von etwa 8 km vom Strip entfernt.
2023-09-25 21:45:56 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-25 21:45:57 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Webportal System basiert.
2023-09-25 21:45:57 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-25 21:45:57 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-25 21:45:57 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-25 21:45:58 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-25 21:45:58 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-25 21:45:58 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer internen Unterstützung aufbauen, aber sie kann sich zur Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-25 21:45:58 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-25 21:45:59 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Ausreise Zugang zu dem von ihnen gezahlten Geld in die europäischen Sozialversicherungssysteme haben.
2023-09-25 21:45:59 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-25 21:46:00 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-25 21:46:00 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-25 21:46:00 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, für einige Formate gibt es leider keine freie Alternative, die auf jeder Computerplattform läuft.
2023-09-25 21:46:00 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-25 21:46:01 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer wird auch wissen, wie man Ihnen helfen, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-25 21:46:01 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-25 21:46:02 | INFO | fairseq.tasks.translation | example hypothesis: Dennoch sind die Thatcher-Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-25 21:46:02 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-25 21:46:02 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils-Benutzer müssen splashutils erneut emergen, damit es korrekt funktioniert.
2023-09-25 21:46:02 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-25 21:46:03 | INFO | fairseq.tasks.translation | example hypothesis: Spieler von Horde und Allianz können sich keine Gegenstände kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser benutzen.
2023-09-25 21:46:03 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-25 21:46:03 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollen.
2023-09-25 21:46:03 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-25 21:46:04 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-25 21:46:04 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-25 21:46:05 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens grundsätzlich mit den Vereinigten Staaten abgeben müssen.
2023-09-25 21:46:05 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-25 21:46:06 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - unser breites Sortiment an PlastikBabyartikeln überzeugt nicht zuletzt durch ihre herausragende Verarbeitung.
2023-09-25 21:46:06 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-25 21:46:06 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-25 21:46:06 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-25 21:46:07 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Bekanntwerden dieser AGB von Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-25 21:46:07 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-25 21:46:08 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung sieht.
2023-09-25 21:46:08 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-25 21:46:08 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-25 21:46:08 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-25 21:46:09 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die erzielt wurden, wenn wir uns alle Fragen betrachten, die jetzt diskutiert werden und etwas betreffen, das gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-25 21:46:09 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-25 21:46:10 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-25 21:46:10 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-25 21:46:10 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es der Berichterstatterin gelungen, bisweilen unterschiedliche Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-25 21:46:10 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-25 21:46:11 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Einläufern um einen trockenen ESP für den unteren Leistungsbereich.
2023-09-25 21:46:11 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-25 21:46:12 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.
2023-09-25 21:46:12 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-25 21:46:12 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-25 21:46:12 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-25 21:46:13 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und verlässt sich auf Verhandlungen mit Drittländern, von denen viele seit Jahren bestehen und mit unserer Völkergemeinschaft in Verbindung stehen.
2023-09-25 21:46:13 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-25 21:46:14 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-25 21:46:14 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-25 21:46:15 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-25 21:46:15 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-25 21:46:15 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-25 21:46:15 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-25 21:46:16 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch einen weiteren: die Notsituation der Kinder, des schwächsten BevölkerungsBevölkerung, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-25 21:46:16 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-25 21:46:17 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Flossen seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen. Das heißt, dass Haie nicht nur für ihre Flossen gefangen werden dürfen...
2023-09-25 21:46:17 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-25 21:46:17 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht befreit ist, nicht innerhalb des ersten verwirklicht wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich wissen, bis man sein wahres Selbst kennt..................
2023-09-25 21:46:17 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-25 21:46:18 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher entscheidend, dass wir weiterhin internationalen Druck auf die Regierung ausüben, um alles in unserer Macht Stehende zu tun, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu eröffnen.............
2023-09-25 21:46:18 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-25 21:46:19 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Versammlungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht......................
2023-09-25 21:46:19 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-25 21:46:19 | INFO | fairseq.tasks.translation | example hypothesis: System ist in der Programmiersprache Java mit J2EE-Techniken implementiert, was die Plattform- und Betriebssystem-Unabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-25 21:46:19 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-25 21:46:20 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur klareren und flexibleren Koordinierung der europäischen sozialen Sicherheit ab und stimmen somit für die Klärung des Anhangs.
2023-09-25 21:46:20 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-25 21:46:21 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden...
2023-09-25 21:46:21 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-25 21:46:22 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Aussprache über den irischen öffentlich-rechtlichen Rundfunk RTE mit einer Frau teilgenommen, die sehr besorgt darüber war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen............ zu kürzen, die
2023-09-25 21:46:22 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-25 21:46:22 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-25 21:46:22 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-25 21:46:23 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist...............
2023-09-25 21:46:23 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-25 21:46:24 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und steht Spielern aller Nationalitäten offen.........................
2023-09-25 21:46:24 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-25 21:46:25 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Ich glaube, dass der Bericht, abgesehen von diesen wenigen Vorbehalten, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-25 21:46:25 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-25 21:46:25 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken, hieße, zu naturalisieren und zu mystifizieren, was eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen ist (darunter oft die tatsächliche oder wahrgenommene Bedrohung, von der institutionellen Hegemonie zerschlagen zu werden)!!!!!!!!!!!!
2023-09-25 21:46:25 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-25 21:46:26 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder eine einheitliche Auslegung der Konvention erforderlich ist.
2023-09-25 21:46:26 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-25 21:46:27 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist einer der lustigsten Autos für weniger als 50.000 Dollar. Wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos ausprobieren.
2023-09-25 21:46:27 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-25 21:46:28 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung dieser Angelegenheit.
2023-09-25 21:46:28 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-25 21:46:29 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten Pörkölt (Eintopf) und die ausgezeichneten Süßwasserfische: gegrillter Hecht, Forelle mit Mandeln.
2023-09-25 21:46:29 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-25 21:46:29 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, wäre es vielleicht besser, einen Gesamtüberblick zu bieten, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu überlegen, welchen Impuls die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-25 21:46:29 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-25 21:46:30 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Besitzer der "Scardona Records", Herr Branko Paić, haben sich darauf geeinigt, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-25 21:46:30 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-25 21:46:31 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar gefährdet sind und die Wettbewerbsfähigkeit aufgrund der makroökonomischen Politik, der steuerlichen Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-25 21:46:31 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-25 21:46:32 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die geltende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, beigetragen hat.
2023-09-25 21:46:32 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-25 21:46:33 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geographischen Grenzen Europas hinaus mit den entsprechenden Konsequenzen für den Rechts- und Rechtsraum, wodurch Norwegen und Island, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstandes Anwendung finden werden, Norwegen und Island gelten..................
2023-09-25 21:46:33 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-25 21:46:34 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit einem Schlauchboot den Mississippi hinunter fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und mehr als alles andere werden wir große Freunde sein.......................
2023-09-25 21:46:34 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-25 21:46:34 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Personen oder juristische Personen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion darauf und die Strafbarkeit der Sanktionen, die im Falle solcher von Einzelpersonen begangenen Verstöße angewendet werden können.
2023-09-25 21:46:34 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-25 21:46:35 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihrer Arbeit als Journalisten und Kameramänner nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren von einem autoritären Regime verfolgt werden, das sich über jeden Grundsatz der Demokratie hinwegsetzt.
2023-09-25 21:46:35 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-25 21:46:36 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeingdesk, ein Bank- und Push-Service, eine Wechselstube, kostenfreie Schuhputze und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das französische Viertel.
2023-09-25 21:46:36 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-25 21:46:37 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, die Frau des Königs D. João II, geliebt wurde und durch ihre international bekannten Keramiken für ihre bildhaften und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-25 21:46:37 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-25 21:46:38 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es sei ein Fall von guten Pro-Western auf der einen Seite und Anhängern des früheren Regimes auf der anderen Seite - das ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-25 21:46:38 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-25 21:46:39 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die unterschiedslos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie behandelt werden sollte.......................,
2023-09-25 21:46:39 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-25 21:46:40 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden Informationen außerhalb einer Hauptversammlung einem Aktionär aufgrund seines Status als Aktionär zur Verfügung gestellt, so sind diese Informationen auf Verlangen an einen anderen Aktionär in der Hauptversammlung zu übermitteln, auch wenn diese Informationen nicht erforderlich sind, um eine ordnungsgemäße Bewertung eines Tagesordnungspunktes zu ermöglichen.
2023-09-25 21:46:40 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-25 21:46:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachher die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die in der Regel in den Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen Menschen in unseren eigenen Ländern leben, die ebenfalls ein sehr elendes Leben führen................ leben, die auch ein sehr elendes Leben führen, gleichzeitig
2023-09-25 21:46:41 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-25 21:46:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder der NATO an diesem Kriegsakt beteiligt gewesen sein könnten -, bei Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, geheim oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit erzählt werden kann............. können die ganze Wahrheit ans Licht bringen und die ganze Wahrheit
2023-09-25 21:46:41 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-25 21:46:42 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Minuten mit dem Zug von der Innenstadt entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.................. Die komfortable Zimmer der Pension Nomaden sind im charman
2023-09-25 21:46:42 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-25 21:46:43 | INFO | fairseq.tasks.translation | example hypothesis: "Zusammen mit unseren Partnern für das Radar, das von Thales in Frankreich, sowie unserer Business Unit Defence Electronics und Indra in Spanien, wird das Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen beinhalten, die für nachhaltige und zuverlässige ISTAR-Missionen, die die heutige außerhalb der Regalplattformen nie erfüllen können, von entscheidender Bedeutung sind, die die heutigen außerhalb der Regalplattformen nie erfüllen können.
2023-09-25 21:46:43 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-25 21:46:44 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen unmissverständlich klarstellen, dass wir nicht nur für uns, sondern weltweit die Produkte aus dem Markt nehmen können, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt eine ernste Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt........................, wie Frau González Álvarez in ihrem neuen Änderungsantrag
2023-09-25 21:46:44 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-25 21:46:45 | INFO | fairseq.tasks.translation | example hypothesis: Unter der direkten Verschwörung von Moderne und Postmoderne oder dem klaren Gegensatz von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und anhaltende Spannung jener beiden ästhetischen Politik erkennen, die in die Formen der Sichtbarkeit und Verständlichkeit verwickelt ist, die Kunst als solche identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen................, die die letztlich zu ihrer eigenen Selbstunterdrückung geführt werden,
2023-09-25 21:46:45 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-25 21:46:46 | INFO | fairseq.tasks.translation | example hypothesis: Doch was den heutigen Tag betrifft, so werde ich angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir gegeben haben, die ich eindeutig weitgehend unterstützen, und auf der Grundlage der vorangegangenen Beschlüsse unsere Debatten führen, und bei der Abstimmung, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht um die Prüfung der Beschlussfähigkeit beantragen............, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht um die Prüfung der Beschlussfähigkeit bitten, wenn die vierzig Petenten nicht
2023-09-25 21:46:46 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-25 21:46:47 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips nie akzeptiert haben, so sind es paradoxerweise gerade sie, die nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen aufgehoben wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung der ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen................, aber ohne das Ziel, eine einheitliche Kultur zu schaffen, aber,
2023-09-25 21:46:47 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-25 21:46:49 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder vielmehr ihr Inhalt - wurde bis 2008 in mehrfacher Form als hybride Form veröffentlicht, für H-Soz-u-Kult geschrieben und über Mailing-Listen sowie die Websites des H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt.
2023-09-25 21:46:49 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-25 21:46:50 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit dem Eintreffen der neuen Smartphone-Generation haben Handys ihre Federn deutlich verwischt und von einst schleichenden Taschenwecker über polyphonen Tootling Game Boy-Wecker zu schlichten Mini-PCs mit klarem Stereo-Sound in CD-Qualität ausgegossen: Künftig könnten sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu Wegfahrern neuer technologischer Entwicklungen werden.
2023-09-25 21:46:50 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-25 21:46:52 | INFO | fairseq.tasks.translation | example hypothesis: En la pandora, el pesar del fin científico del proyecto, el coronel Quaritch, quien dirige la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen. Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un konflito mado; en l édeberá decidir de qué lado está.
2023-09-25 21:46:52 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-25 21:46:53 | INFO | valid | epoch 024 | valid on 'valid' subset | loss 4.115 | nll_loss 2.15 | ppl 4.44 | bleu 27.7 | wps 16375.8 | wpb 12011.9 | bsz 398.1 | num_updates 217396 | best_bleu 29.48
2023-09-25 21:46:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 217396 updates
2023-09-25 21:46:53 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint24.pt
2023-09-25 21:46:58 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint24.pt
2023-09-25 21:47:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint24.pt (epoch 24 @ 217396 updates, score 27.7) (writing took 9.885191048961133 seconds)
2023-09-25 21:47:02 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2023-09-25 21:47:02 | INFO | train | epoch 024 | loss 7.508 | nll_loss 3.681 | ppl 12.83 | wps 3878.2 | ups 0.3 | wpb 12977.1 | bsz 430.5 | num_updates 217396 | lr 6.78226e-05 | gnorm 1.183 | loss_scale 4 | train_wall 30203 | gb_free 13.7 | wall 472016
2023-09-25 21:47:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-25 21:47:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-25 21:47:03 | INFO | fairseq.trainer | begin training epoch 25
2023-09-25 21:47:03 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-25 21:47:15 | INFO | train_inner | epoch 025:      4 / 9060 loss=7.419, nll_loss=3.657, ppl=12.62, wps=3032.5, ups=0.24, wpb=12854.6, bsz=410.2, num_updates=217400, lr=6.78219e-05, gnorm=1.181, loss_scale=4, train_wall=341, gb_free=14.7, wall=472028
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([8200, 42808])
2023-09-25 21:52:59 | INFO | train_inner | epoch 025:    104 / 9060 loss=7.428, nll_loss=3.621, ppl=12.31, wps=3797.1, ups=0.29, wpb=13066.4, bsz=407.1, num_updates=217500, lr=6.78064e-05, gnorm=1.169, loss_scale=4, train_wall=344, gb_free=13.1, wall=472372
lprobs.size(): torch.Size([3584, 42808])
2023-09-25 21:58:45 | INFO | train_inner | epoch 025:    204 / 9060 loss=7.505, nll_loss=3.636, ppl=12.43, wps=3774.7, ups=0.29, wpb=13062.6, bsz=426.4, num_updates=217600, lr=6.77908e-05, gnorm=1.202, loss_scale=4, train_wall=346, gb_free=12.9, wall=472719
pred_new.size(): torch.Size([5400, 42808])
2023-09-25 22:04:24 | INFO | train_inner | epoch 025:    304 / 9060 loss=7.633, nll_loss=3.722, ppl=13.2, wps=3831.4, ups=0.29, wpb=13000.3, bsz=433.5, num_updates=217700, lr=6.77752e-05, gnorm=1.216, loss_scale=4, train_wall=339, gb_free=14.5, wall=473058
pred_new.size(): torch.Size([3036, 42808])
pred_new.size(): torch.Size([4620, 42808])
2023-09-25 22:10:06 | INFO | train_inner | epoch 025:    404 / 9060 loss=7.55, nll_loss=3.68, ppl=12.81, wps=3795.4, ups=0.29, wpb=12970.6, bsz=396.6, num_updates=217800, lr=6.77596e-05, gnorm=1.202, loss_scale=8, train_wall=341, gb_free=13.9, wall=473400
ter_threshold: 0.517837
num_accepted / total 60 112
loss token level: tensor(8186.1758, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10880., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3564, 42808])
2023-09-25 22:15:52 | INFO | train_inner | epoch 025:    504 / 9060 loss=7.535, nll_loss=3.702, ppl=13.01, wps=3735.9, ups=0.29, wpb=12907.9, bsz=417.1, num_updates=217900, lr=6.77441e-05, gnorm=1.214, loss_scale=8, train_wall=345, gb_free=13.6, wall=473745
pred_new.size(): torch.Size([2016, 42808])
pred_new.size(): torch.Size([6510, 42808])
2023-09-25 22:21:14 | INFO | train_inner | epoch 025:    604 / 9060 loss=7.629, nll_loss=3.708, ppl=13.07, wps=4024.8, ups=0.31, wpb=12969.6, bsz=449.2, num_updates=218000, lr=6.77285e-05, gnorm=1.201, loss_scale=8, train_wall=322, gb_free=13.3, wall=474067
2023-09-25 22:26:50 | INFO | train_inner | epoch 025:    704 / 9060 loss=7.486, nll_loss=3.633, ppl=12.41, wps=3863.8, ups=0.3, wpb=12975, bsz=441.6, num_updates=218100, lr=6.7713e-05, gnorm=1.189, loss_scale=8, train_wall=336, gb_free=13, wall=474403
2023-09-25 22:32:36 | INFO | train_inner | epoch 025:    804 / 9060 loss=7.702, nll_loss=3.733, ppl=13.29, wps=3753.9, ups=0.29, wpb=12999.5, bsz=448.8, num_updates=218200, lr=6.76975e-05, gnorm=1.233, loss_scale=8, train_wall=346, gb_free=13.6, wall=474749
pred_new.size(): torch.Size([3800, 42808])
2023-09-25 22:34:23 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-25 22:38:28 | INFO | train_inner | epoch 025:    905 / 9060 loss=7.559, nll_loss=3.674, ppl=12.77, wps=3695.9, ups=0.28, wpb=13010, bsz=445, num_updates=218300, lr=6.7682e-05, gnorm=1.197, loss_scale=4, train_wall=352, gb_free=14.3, wall=475101
lprobs.size(): torch.Size([2816, 42808])
2023-09-25 22:44:13 | INFO | train_inner | epoch 025:   1005 / 9060 loss=7.561, nll_loss=3.691, ppl=12.92, wps=3758.9, ups=0.29, wpb=12986.3, bsz=411.5, num_updates=218400, lr=6.76665e-05, gnorm=1.207, loss_scale=4, train_wall=345, gb_free=15.4, wall=475447
lprobs.size(): torch.Size([2640, 42808])
2023-09-25 22:49:44 | INFO | train_inner | epoch 025:   1105 / 9060 loss=7.492, nll_loss=3.665, ppl=12.68, wps=3938.1, ups=0.3, wpb=13012.1, bsz=429.2, num_updates=218500, lr=6.7651e-05, gnorm=1.176, loss_scale=4, train_wall=330, gb_free=13.1, wall=475777
pred_new.size(): torch.Size([2592, 42808])
2023-09-25 22:55:31 | INFO | train_inner | epoch 025:   1205 / 9060 loss=7.473, nll_loss=3.652, ppl=12.57, wps=3747.9, ups=0.29, wpb=13019.3, bsz=420.9, num_updates=218600, lr=6.76355e-05, gnorm=1.197, loss_scale=4, train_wall=347, gb_free=13.7, wall=476125
2023-09-25 23:01:10 | INFO | train_inner | epoch 025:   1305 / 9060 loss=7.564, nll_loss=3.67, ppl=12.72, wps=3808.2, ups=0.3, wpb=12893, bsz=415, num_updates=218700, lr=6.76201e-05, gnorm=1.21, loss_scale=4, train_wall=338, gb_free=14.5, wall=476463
2023-09-25 23:06:52 | INFO | train_inner | epoch 025:   1405 / 9060 loss=7.635, nll_loss=3.728, ppl=13.25, wps=3775.1, ups=0.29, wpb=12913, bsz=426.5, num_updates=218800, lr=6.76046e-05, gnorm=1.236, loss_scale=4, train_wall=342, gb_free=15.1, wall=476805
2023-09-25 23:10:50 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
lprobs.size(): torch.Size([3584, 42808])
2023-09-25 23:12:29 | INFO | train_inner | epoch 025:   1506 / 9060 loss=7.567, nll_loss=3.677, ppl=12.79, wps=3863.3, ups=0.3, wpb=13015.6, bsz=447, num_updates=218900, lr=6.75892e-05, gnorm=1.193, loss_scale=2, train_wall=337, gb_free=13.1, wall=477142
num_accepted / total 88 160
loss token level: tensor(8492.4482, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11712., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6578, 42808])
ter_threshold: 0.509563
num_accepted / total 64 128
loss token level: tensor(9030.9844, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(11632., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3280, 42808])
ter_threshold: 0.509773
num_accepted / total 18 64
loss token level: tensor(7775.3511, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3300., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2720, 42808])
pred_new.size(): torch.Size([2304, 42808])
lprobs.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([5644, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([276, 42808])
lprobs.size(): torch.Size([3096, 42808])
pred_new.size(): torch.Size([8050, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1344, 42808])
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([2700, 42808])
lprobs.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([5082, 42808])
ter_threshold: 0.510811
num_accepted / total 30 72
loss token level: tensor(9172.0205, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6624., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6720, 42808])
ter_threshold: 0.511388
num_accepted / total 9 72
loss token level: tensor(13794.9111, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2632., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8575, 42808])
pred_new.size(): torch.Size([5304, 42808])
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([8374, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.512011
num_accepted / total 24 72
loss token level: tensor(7694.0430, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4032., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([1216, 42808])
ter_threshold: 0.512119
num_accepted / total 60 96
loss token level: tensor(8051.0449, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8496., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5088, 42808])
pred_new.size(): torch.Size([6655, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2592, 42808])
ter_threshold: 0.512377
num_accepted / total 71 152
loss token level: tensor(9922.7285, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10000., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1780, 42808])
lprobs.size(): torch.Size([3168, 42808])
ter_threshold: 0.512563
num_accepted / total 52 96
loss token level: tensor(9720.3496, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8360., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1296, 42808])
pred_new.size(): torch.Size([2704, 42808])
pred_new.size(): torch.Size([5544, 42808])
pred_new.size(): torch.Size([2952, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.513091
num_accepted / total 113 184
loss token level: tensor(9709.4473, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7868., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1080, 42808])
pred_new.size(): torch.Size([6804, 42808])
pred_new.size(): torch.Size([1920, 42808])
pred_new.size(): torch.Size([2842, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([3034, 42808])
ter_threshold: 0.514138
num_accepted / total 51 112
loss token level: tensor(8574.4492, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10200., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5376, 42808])
ter_threshold: 0.5141709999999999
num_accepted / total 116 192
loss token level: tensor(8479.1309, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12304., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.514212
num_accepted / total 51 96
loss token level: tensor(9630.8555, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8408., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4576, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6762, 42808])
ter_threshold: 0.514526
num_accepted / total 138 208
loss token level: tensor(8481.2285, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13984., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([820, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2408, 42808])
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3770, 42808])
pred_new.size(): torch.Size([4576, 42808])
pred_new.size(): torch.Size([900, 42808])
pred_new.size(): torch.Size([6355, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([2436, 42808])
ter_threshold: 0.515576
num_accepted / total 9 72
loss token level: tensor(10972.8643, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1888., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1768, 42808])
pred_new.size(): torch.Size([5265, 42808])
ter_threshold: 0.515919
num_accepted / total 35 88
loss token level: tensor(8958.1875, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9984., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2938, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([8349, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([2958, 42808])
ter_threshold: 0.516775
num_accepted / total 76 160
loss token level: tensor(8743.5342, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9400., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.5168889999999999
num_accepted / total 82 136
loss token level: tensor(9209.7246, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8720., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4992, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2912, 42808])
pred_new.size(): torch.Size([4032, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([1180, 42808])
pred_new.size(): torch.Size([3774, 42808])
lprobs.size(): torch.Size([2680, 42808])
pred_new.size(): torch.Size([7665, 42808])
pred_new.size(): torch.Size([1650, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2769, 42808])
pred_new.size(): torch.Size([1872, 42808])
pred_new.size(): torch.Size([1984, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.518919
num_accepted / total 114 184
loss token level: tensor(7957.6572, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: ter_threshold: 0.518919
num_accepted / total 89 136
loss token level: tensor(8797.1240, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9040., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1800, 42808])
pred_new.size(): torch.Size([5460, 42808])
2023-09-25 23:17:59 | INFO | train_inner | epoch 025:   1606 / 9060 loss=7.438, nll_loss=3.652, ppl=12.57, wps=3913.2, ups=0.3, wpb=12908.1, bsz=411.4, num_updates=219000, lr=6.75737e-05, gnorm=1.196, loss_scale=2, train_wall=330, gb_free=12.6, wall=477472
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([5460, 42808])
2023-09-25 23:23:34 | INFO | train_inner | epoch 025:   1706 / 9060 loss=7.663, nll_loss=3.765, ppl=13.59, wps=3859.2, ups=0.3, wpb=12959.3, bsz=439.2, num_updates=219100, lr=6.75583e-05, gnorm=1.224, loss_scale=2, train_wall=336, gb_free=14.7, wall=477808
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([6345, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-25 23:29:19 | INFO | train_inner | epoch 025:   1806 / 9060 loss=7.699, nll_loss=3.737, ppl=13.34, wps=3744.4, ups=0.29, wpb=12894.4, bsz=442.2, num_updates=219200, lr=6.75429e-05, gnorm=1.243, loss_scale=2, train_wall=344, gb_free=12.7, wall=478152
2023-09-25 23:35:02 | INFO | train_inner | epoch 025:   1906 / 9060 loss=7.476, nll_loss=3.667, ppl=12.7, wps=3743.2, ups=0.29, wpb=12853.2, bsz=423.4, num_updates=219300, lr=6.75275e-05, gnorm=1.21, loss_scale=2, train_wall=343, gb_free=13.4, wall=478496
pred_new.size(): torch.Size([6460, 42808])
2023-09-25 23:40:34 | INFO | train_inner | epoch 025:   2006 / 9060 loss=7.453, nll_loss=3.628, ppl=12.37, wps=3896.8, ups=0.3, wpb=12944.9, bsz=426.7, num_updates=219400, lr=6.75121e-05, gnorm=1.175, loss_scale=2, train_wall=332, gb_free=15.6, wall=478828
pred_new.size(): torch.Size([4256, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-25 23:46:22 | INFO | train_inner | epoch 025:   2106 / 9060 loss=7.969, nll_loss=3.856, ppl=14.48, wps=3803.4, ups=0.29, wpb=13202.3, bsz=452.7, num_updates=219500, lr=6.74967e-05, gnorm=1.242, loss_scale=2, train_wall=347, gb_free=12.8, wall=479175
pred_new.size(): torch.Size([4648, 42808])
2023-09-25 23:51:57 | INFO | train_inner | epoch 025:   2206 / 9060 loss=7.737, nll_loss=3.768, ppl=13.63, wps=3873.6, ups=0.3, wpb=13010.6, bsz=432.8, num_updates=219600, lr=6.74814e-05, gnorm=1.236, loss_scale=2, train_wall=336, gb_free=13.5, wall=479511
2023-09-25 23:57:26 | INFO | train_inner | epoch 025:   2306 / 9060 loss=7.492, nll_loss=3.641, ppl=12.47, wps=3924.2, ups=0.3, wpb=12882.6, bsz=446, num_updates=219700, lr=6.7466e-05, gnorm=1.217, loss_scale=2, train_wall=328, gb_free=13.1, wall=479839
pred_new.size(): torch.Size([7800, 42808])
2023-09-26 00:03:01 | INFO | train_inner | epoch 025:   2406 / 9060 loss=7.664, nll_loss=3.723, ppl=13.21, wps=3885.5, ups=0.3, wpb=13033.8, bsz=446.7, num_updates=219800, lr=6.74507e-05, gnorm=1.217, loss_scale=2, train_wall=335, gb_free=13.3, wall=480175
pred_new.size(): torch.Size([1098, 42808])
2023-09-26 00:08:31 | INFO | train_inner | epoch 025:   2506 / 9060 loss=7.41, nll_loss=3.62, ppl=12.29, wps=3910.5, ups=0.3, wpb=12917.6, bsz=422, num_updates=219900, lr=6.74353e-05, gnorm=1.181, loss_scale=2, train_wall=330, gb_free=12.6, wall=480505
lprobs.size(): torch.Size([3536, 42808])
2023-09-26 00:14:02 | INFO | train_inner | epoch 025:   2606 / 9060 loss=7.846, nll_loss=3.828, ppl=14.2, wps=3946.4, ups=0.3, wpb=13038.9, bsz=435.9, num_updates=220000, lr=6.742e-05, gnorm=1.231, loss_scale=2, train_wall=330, gb_free=13.3, wall=480835
2023-09-26 00:19:41 | INFO | train_inner | epoch 025:   2706 / 9060 loss=7.566, nll_loss=3.7, ppl=12.99, wps=3848.2, ups=0.3, wpb=13032.7, bsz=407, num_updates=220100, lr=6.74047e-05, gnorm=1.188, loss_scale=2, train_wall=338, gb_free=13.8, wall=481174
2023-09-26 00:25:05 | INFO | train_inner | epoch 025:   2806 / 9060 loss=7.496, nll_loss=3.67, ppl=12.73, wps=4030.4, ups=0.31, wpb=13096.4, bsz=435.3, num_updates=220200, lr=6.73894e-05, gnorm=1.195, loss_scale=2, train_wall=325, gb_free=13.3, wall=481499
2023-09-26 00:30:42 | INFO | train_inner | epoch 025:   2906 / 9060 loss=7.558, nll_loss=3.678, ppl=12.8, wps=3853.9, ups=0.3, wpb=12984, bsz=449.6, num_updates=220300, lr=6.73741e-05, gnorm=1.204, loss_scale=2, train_wall=337, gb_free=12.7, wall=481836
lprobs.size(): torch.Size([3312, 42808])
2023-09-26 00:36:34 | INFO | train_inner | epoch 025:   3006 / 9060 loss=7.475, nll_loss=3.687, ppl=12.88, wps=3667.5, ups=0.28, wpb=12889, bsz=412, num_updates=220400, lr=6.73588e-05, gnorm=1.255, loss_scale=2, train_wall=351, gb_free=13.9, wall=482187
pred_new.size(): torch.Size([2574, 42808])
2023-09-26 00:42:07 | INFO | train_inner | epoch 025:   3106 / 9060 loss=7.596, nll_loss=3.72, ppl=13.17, wps=3886.8, ups=0.3, wpb=12950, bsz=422.2, num_updates=220500, lr=6.73435e-05, gnorm=1.206, loss_scale=2, train_wall=333, gb_free=13.8, wall=482520
ter_threshold: 0.520524
num_accepted / total 23 80
loss token level: tensor(8119.3740, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6508., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([1400, 42808])
2023-09-26 00:47:34 | INFO | train_inner | epoch 025:   3206 / 9060 loss=7.422, nll_loss=3.653, ppl=12.58, wps=3936.7, ups=0.31, wpb=12887.4, bsz=428.3, num_updates=220600, lr=6.73282e-05, gnorm=1.178, loss_scale=2, train_wall=327, gb_free=15.9, wall=482848
lprobs.size(): torch.Size([3528, 42808])
2023-09-26 00:53:11 | INFO | train_inner | epoch 025:   3306 / 9060 loss=7.492, nll_loss=3.664, ppl=12.68, wps=3841.4, ups=0.3, wpb=12943.3, bsz=411.2, num_updates=220700, lr=6.7313e-05, gnorm=1.204, loss_scale=2, train_wall=337, gb_free=14.5, wall=483185
pred_new.size(): torch.Size([1550, 42808])
2023-09-26 00:58:53 | INFO | train_inner | epoch 025:   3406 / 9060 loss=7.427, nll_loss=3.667, ppl=12.7, wps=3781.8, ups=0.29, wpb=12935.6, bsz=409.4, num_updates=220800, lr=6.72977e-05, gnorm=1.205, loss_scale=2, train_wall=342, gb_free=14.4, wall=483527
2023-09-26 01:04:22 | INFO | train_inner | epoch 025:   3506 / 9060 loss=7.462, nll_loss=3.65, ppl=12.55, wps=3946.3, ups=0.3, wpb=12963.6, bsz=436.2, num_updates=220900, lr=6.72825e-05, gnorm=1.192, loss_scale=2, train_wall=328, gb_free=13.7, wall=483855
pred_new.size(): torch.Size([2880, 42808])
2023-09-26 01:09:59 | INFO | train_inner | epoch 025:   3606 / 9060 loss=7.468, nll_loss=3.645, ppl=12.51, wps=3833.6, ups=0.3, wpb=12940.8, bsz=408, num_updates=221000, lr=6.72673e-05, gnorm=1.215, loss_scale=2, train_wall=337, gb_free=13.9, wall=484193
pred_new.size(): torch.Size([4560, 42808])
2023-09-26 01:15:49 | INFO | train_inner | epoch 025:   3706 / 9060 loss=7.742, nll_loss=3.779, ppl=13.73, wps=3699.9, ups=0.29, wpb=12917.3, bsz=435.2, num_updates=221100, lr=6.72521e-05, gnorm=1.264, loss_scale=2, train_wall=349, gb_free=14, wall=484542
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([3710, 42808])
2023-09-26 01:21:24 | INFO | train_inner | epoch 025:   3806 / 9060 loss=7.743, nll_loss=3.776, ppl=13.7, wps=3870.4, ups=0.3, wpb=12998.8, bsz=438.5, num_updates=221200, lr=6.72369e-05, gnorm=1.22, loss_scale=2, train_wall=336, gb_free=14.5, wall=484878
2023-09-26 01:26:56 | INFO | train_inner | epoch 025:   3906 / 9060 loss=7.427, nll_loss=3.639, ppl=12.46, wps=3906.6, ups=0.3, wpb=12938.4, bsz=417, num_updates=221300, lr=6.72217e-05, gnorm=1.207, loss_scale=2, train_wall=331, gb_free=13.2, wall=485209
2023-09-26 01:32:27 | INFO | train_inner | epoch 025:   4006 / 9060 loss=7.541, nll_loss=3.694, ppl=12.94, wps=3956.9, ups=0.3, wpb=13106, bsz=438.6, num_updates=221400, lr=6.72065e-05, gnorm=1.195, loss_scale=2, train_wall=331, gb_free=12.9, wall=485540
pred_new.size(): torch.Size([10028, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 01:38:03 | INFO | train_inner | epoch 025:   4106 / 9060 loss=7.676, nll_loss=3.757, ppl=13.52, wps=3865.9, ups=0.3, wpb=13008.6, bsz=433.5, num_updates=221500, lr=6.71913e-05, gnorm=1.243, loss_scale=2, train_wall=336, gb_free=13.7, wall=485877
ter_threshold: 0.5215719999999999
num_accepted / total 43 72
loss token level: tensor(7903.1270, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8704., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
2023-09-26 01:43:37 | INFO | train_inner | epoch 025:   4206 / 9060 loss=7.408, nll_loss=3.616, ppl=12.26, wps=3908.6, ups=0.3, wpb=13030.1, bsz=440, num_updates=221600, lr=6.71762e-05, gnorm=1.244, loss_scale=2, train_wall=333, gb_free=14, wall=486210
2023-09-26 01:49:23 | INFO | train_inner | epoch 025:   4306 / 9060 loss=7.466, nll_loss=3.671, ppl=12.73, wps=3777.9, ups=0.29, wpb=13069.8, bsz=446.6, num_updates=221700, lr=6.7161e-05, gnorm=1.188, loss_scale=2, train_wall=346, gb_free=14.2, wall=486556
tensor(9913.0029, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8704., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3060, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([3375, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([5100, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.513091
num_accepted / total 118 224
loss token level: tensor(8036.7207, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5200., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3304, 42808])
pred_new.size(): torch.Size([4592, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.513401
num_accepted / total 11 72
loss token level: tensor(8778.3027, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2144., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([780, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([4617, 42808])
pred_new.size(): torch.Size([3074, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4500, 42808])
pred_new.size(): torch.Size([3276, 42808])
pred_new.size(): torch.Size([2548, 42808])
pred_new.size(): torch.Size([4698, 42808])
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([7062, 42808])
ter_threshold: 0.514526
num_accepted / total 107 168
loss token level: tensor(8633.1152, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14056., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6752, 42808])
pred_new.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([7332, 42808])
pred_new.size(): torch.Size([1532, 42808])
pred_new.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2960, 42808])
pred_new.size(): torch.Size([588, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.515576
num_accepted / total 42 80
loss token level: tensor(8875.9180, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7728., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3192, 42808])
ter_threshold: 0.515919
num_accepted / total 40 128
loss token level: tensor(11924.8438, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7784., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([2156, 42808])
lprobs.size(): torch.Size([2592, 42808])
pred_new.size(): torch.Size([3444, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([4220, 42808])
ter_threshold: 0.516775
num_accepted / total 78 136
loss token level: tensor(9365.7949, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13880., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2754, 42808])
pred_new.size(): torch.Size([3976, 42808])
lprobs.size(): torch.Size([2720, 42808])
lprobs.size(): torch.Size([2880, 42808])
ter_threshold: 0.5168889999999999
num_accepted / total 55 120
loss token level: tensor(8501.8115, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5272., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6192, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([3136, 42808])
ter_threshold: 0.5170509999999999
num_accepted / total 16 64
loss token level: tensor(8273.2168, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3088., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([4425, 42808])
ter_threshold: 0.517259
num_accepted / total 29 64
loss token level: tensor(9067.1777, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6456., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.517411
num_accepted / total 6 40
loss token level: tensor(8834.0264, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2066., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([4560, 42808])
ter_threshold: 0.517645
num_accepted / total 14 48
loss token level: tensor(9599.3672, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4704., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([10295, 42808])
ter_threshold: 0.517837
num_accepted / total 49 96
loss token level: tensor(8945.3340, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13016., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3816, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([9409, 42808])
pred_new.size(): torch.Size([176, 42808])
pred_new.size(): torch.Size([4180, 42808])
ter_threshold: 0.518226
num_accepted / total 39 80
loss token level: tensor(8202.9092, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11360., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.518285
num_accepted / total 25 72
loss token level: tensor(8485.3320, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(4444., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4455, 42808])
pred_new.size(): torch.Size([2052, 42808])
pred_new.size(): torch.Size([4185, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1620, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([5976, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([5904, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([9920, 42808])
pred_new.size(): torch.Size([2728, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([2494, 42808])
pred_new.size(): torch.Size([3525, 42808])
pred_new.size(): torch.Size([3914, 42808])
ter_threshold: 0.519606
num_accepted / total 12 56
loss token level: tensor(9256.1992, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5132., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6232, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.520121
num_accepted / total 11 40
loss token level: tensor(8715.8643, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6820., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2945, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.520524
num_accepted / total 53 112
loss token level: tensor(10792.2832, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12448., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5980, 42808])
pred_new.size(): torch.Size([4704, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5044, 42808])
pred_new.size(): torch.Size([4464, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2295, 42808])
pred_new.size(): torch.Size([6480, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([5208, 42808])
pred_new.size(): torch.Size([9006, 42808])
lprobs.size(): torch.Size([2496, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3264, 42808])
ter_threshold: 0.521763
pred_new.size(): torch.Size([6450, 42808])
ter_threshold: 0.521763
num_accepted / total 53 112
loss token level: tensor(10407.0029, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10960., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 01:54:55 | INFO | train_inner | epoch 025:   4406 / 9060 loss=7.423, nll_loss=3.641, ppl=12.48, wps=3939, ups=0.3, wpb=13073.9, bsz=436.8, num_updates=221800, lr=6.71459e-05, gnorm=1.173, loss_scale=2, train_wall=332, gb_free=13.5, wall=486888
2023-09-26 02:00:20 | INFO | train_inner | epoch 025:   4506 / 9060 loss=7.523, nll_loss=3.699, ppl=12.99, wps=3956.7, ups=0.31, wpb=12880.8, bsz=428, num_updates=221900, lr=6.71307e-05, gnorm=1.218, loss_scale=2, train_wall=325, gb_free=13.5, wall=487214
2023-09-26 02:05:47 | INFO | train_inner | epoch 025:   4606 / 9060 loss=7.69, nll_loss=3.778, ppl=13.72, wps=3960.6, ups=0.31, wpb=12931.6, bsz=470.7, num_updates=222000, lr=6.71156e-05, gnorm=1.227, loss_scale=2, train_wall=326, gb_free=13.9, wall=487540
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.522051
num_accepted / total 19 48
loss token level: tensor(8706.9385, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9384., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 02:11:36 | INFO | train_inner | epoch 025:   4706 / 9060 loss=7.686, nll_loss=3.784, ppl=13.77, wps=3707.7, ups=0.29, wpb=12969.9, bsz=418.3, num_updates=222100, lr=6.71005e-05, gnorm=1.225, loss_scale=2, train_wall=350, gb_free=13.6, wall=487890
pred_new.size(): torch.Size([7535, 42808])
2023-09-26 02:17:12 | INFO | train_inner | epoch 025:   4806 / 9060 loss=7.559, nll_loss=3.697, ppl=12.97, wps=3866, ups=0.3, wpb=12965.5, bsz=445, num_updates=222200, lr=6.70854e-05, gnorm=1.23, loss_scale=2, train_wall=335, gb_free=13.4, wall=488225
ter_threshold: 0.522222
num_accepted / total 26 72
loss token level: tensor(9124.4941, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8552., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 02:22:49 | INFO | train_inner | epoch 025:   4906 / 9060 loss=7.319, nll_loss=3.599, ppl=12.12, wps=3846.8, ups=0.3, wpb=12966.5, bsz=458.9, num_updates=222300, lr=6.70703e-05, gnorm=1.161, loss_scale=2, train_wall=337, gb_free=14.6, wall=488562
ter_threshold: 0.513091
num_accepted / total 34 128
loss token level: tensor(8705.5879, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2912., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5100, 42808])
lprobs.size(): torch.Size([2416, 42808])
pred_new.size(): torch.Size([4860, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4108, 42808])
pred_new.size(): torch.Size([2144, 42808])
pred_new.size(): torch.Size([6270, 42808])
pred_new.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([7470, 42808])
lprobs.size(): torch.Size([3560, 42808])
pred_new.size(): torch.Size([2288, 42808])
ter_threshold: 0.514138
num_accepted / total 55 112
loss token level: tensor(9364.5918, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10816., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([5292, 42808])
ter_threshold: 0.5141709999999999
num_accepted / total 100 160
loss token level: tensor(9054.8574, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14936., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.514212
num_accepted / total 70 128
loss token level: tensor(9763.3262, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7208., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3360, 42808])
ter_threshold: 0.514437
num_accepted / total 6 8
loss token level: tensor(4913.4912, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10832., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5508, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6534, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([3042, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4680, 42808])
pred_new.size(): torch.Size([3618, 42808])
pred_new.size(): torch.Size([2436, 42808])
ter_threshold: 0.515224
num_accepted / total 11 64
loss token level: tensor(8599.8174, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2134., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5075, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1140, 42808])
ter_threshold: 0.515919
num_accepted / total 48 96
loss token level: tensor(9139.0781, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12080., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5597, 42808])
pred_new.size(): torch.Size([3306, 42808])
lprobs.size(): torch.Size([2608, 42808])
pred_new.size(): torch.Size([6510, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6955, 42808])
pred_new.size(): torch.Size([6305, 42808])
pred_new.size(): torch.Size([3488, 42808])
pred_new.size(): torch.Size([1120, 42808])
ter_threshold: 0.516775
num_accepted / total 65 112
loss token level: tensor(9517.0986, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14992., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([3393, 42808])
pred_new.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1536, 42808])
pred_new.size(): torch.Size([5520, 42808])
pred_new.size(): torch.Size([8424, 42808])
pred_new.size(): torch.Size([2272, 42808])
pred_new.size(): torch.Size([6072, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([6372, 42808])
ter_threshold: 0.517837
num_accepted / total 58 112
loss token level: tensor(9487.1211, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11248., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4112, 42808])
pred_new.size(): torch.Size([7371, 42808])
pred_new.size(): torch.Size([6498, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([3306, 42808])
ter_threshold: 0.518226
num_accepted / total 29 80
loss token level: tensor(10310.1406, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8816., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2288, 42808])
lprobs.size(): torch.Size([2728, 42808])
pred_new.size(): torch.Size([1218, 42808])
ter_threshold: 0.518919
num_accepted / total 301 352
loss token level: tensor(7546.7295, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8728., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6424, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([2940, 42808])
pred_new.size(): torch.Size([6579, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([1920, 42808])
pred_new.size(): torch.Size([4693, 42808])
pred_new.size(): torch.Size([3795, 42808])
pred_new.size(): torch.Size([2964, 42808])
pred_new.size(): torch.Size([1927, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([5535, 42808])
ter_threshold: 0.520524
num_accepted / total 41 112
loss token level: tensor(8480.9668, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7768., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.520537
num_accepted / total 71 128
loss token level: tensor(9422.0332, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(12656., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([2684, 42808])
pred_new.size(): torch.Size([5925, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([6976, 42808])
pred_new.size(): torch.Size([5546, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3248, 42808])
ter_threshold: 0.521593
num_accepted / total 29 64
loss token level: tensor(8564.0791, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6832., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.5216879999999999
num_accepted / total 65 104
loss token level: tensor(9079.4180, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8160., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.521763
num_accepted / total 59 96
loss token level: tensor(8593.5674, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14864., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.521809
num_accepted / total 19 64
loss token level: tensor(8861.5977, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7344., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([2992, 42808])
ter_threshold: 0.522321
num_accepted / total 60 112
loss token level: tensor(8949.6211, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(13328., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.522358
num_accepted / total 64 112
loss token level: tensor(9892.5791, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14408., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.522321
num_accepted / total 72 136
loss token level: tensor(8480.9736, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10672., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 02:28:24 | INFO | train_inner | epoch 025:   5006 / 9060 loss=7.55, nll_loss=3.708, ppl=13.07, wps=3893.3, ups=0.3, wpb=13049.8, bsz=440.4, num_updates=222400, lr=6.70552e-05, gnorm=1.205, loss_scale=2, train_wall=335, gb_free=14.2, wall=488898
ter_threshold: 0.522465
num_accepted / total 12 40
loss token level: tensor(8217.5000, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6088., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 02:34:07 | INFO | train_inner | epoch 025:   5106 / 9060 loss=7.534, nll_loss=3.704, ppl=13.04, wps=3794.7, ups=0.29, wpb=13026.2, bsz=426.4, num_updates=222500, lr=6.70402e-05, gnorm=1.215, loss_scale=2, train_wall=343, gb_free=13.4, wall=489241
lprobs.size(): torch.Size([3104, 42808])
2023-09-26 02:39:51 | INFO | train_inner | epoch 025:   5206 / 9060 loss=7.511, nll_loss=3.671, ppl=12.74, wps=3765.4, ups=0.29, wpb=12941.1, bsz=436.6, num_updates=222600, lr=6.70251e-05, gnorm=1.199, loss_scale=2, train_wall=343, gb_free=13.9, wall=489584
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([670, 42808])
2023-09-26 02:45:37 | INFO | train_inner | epoch 025:   5306 / 9060 loss=7.405, nll_loss=3.626, ppl=12.35, wps=3742.3, ups=0.29, wpb=12948.1, bsz=414.2, num_updates=222700, lr=6.701e-05, gnorm=1.176, loss_scale=2, train_wall=346, gb_free=13.1, wall=489930
2023-09-26 02:51:12 | INFO | train_inner | epoch 025:   5406 / 9060 loss=7.431, nll_loss=3.663, ppl=12.67, wps=3878.1, ups=0.3, wpb=12979.4, bsz=447.7, num_updates=222800, lr=6.6995e-05, gnorm=1.176, loss_scale=2, train_wall=334, gb_free=14.7, wall=490265
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 02:56:41 | INFO | train_inner | epoch 025:   5506 / 9060 loss=7.297, nll_loss=3.598, ppl=12.11, wps=3914.6, ups=0.3, wpb=12909.4, bsz=416.8, num_updates=222900, lr=6.698e-05, gnorm=1.191, loss_scale=2, train_wall=330, gb_free=13.7, wall=490595
2023-09-26 03:02:25 | INFO | train_inner | epoch 025:   5606 / 9060 loss=7.624, nll_loss=3.745, ppl=13.4, wps=3777.2, ups=0.29, wpb=12979.6, bsz=442.2, num_updates=223000, lr=6.6965e-05, gnorm=1.218, loss_scale=4, train_wall=343, gb_free=13.9, wall=490939
ter_threshold: 0.523067
num_accepted / total 24 64
loss token level: tensor(9023.0264, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9488., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 03:08:19 | INFO | train_inner | epoch 025:   5706 / 9060 loss=7.506, nll_loss=3.698, ppl=12.98, wps=3666.8, ups=0.28, wpb=12960.5, bsz=417.8, num_updates=223100, lr=6.69499e-05, gnorm=1.196, loss_scale=4, train_wall=353, gb_free=13, wall=491292
lprobs.size(): torch.Size([3264, 42808])
2023-09-26 03:13:58 | INFO | train_inner | epoch 025:   5806 / 9060 loss=7.56, nll_loss=3.704, ppl=13.03, wps=3815, ups=0.29, wpb=12955.9, bsz=448.4, num_updates=223200, lr=6.69349e-05, gnorm=1.195, loss_scale=4, train_wall=339, gb_free=13.7, wall=491632
lprobs.size(): torch.Size([3200, 42808])
2023-09-26 03:19:37 | INFO | train_inner | epoch 025:   5906 / 9060 loss=7.601, nll_loss=3.723, ppl=13.2, wps=3829.8, ups=0.29, wpb=12992.5, bsz=437.5, num_updates=223300, lr=6.692e-05, gnorm=1.207, loss_scale=4, train_wall=339, gb_free=13.6, wall=491971
pred_new.size(): torch.Size([4240, 42808])
2023-09-26 03:25:17 | INFO | train_inner | epoch 025:   6006 / 9060 loss=7.53, nll_loss=3.695, ppl=12.95, wps=3841.1, ups=0.29, wpb=13057, bsz=403.4, num_updates=223400, lr=6.6905e-05, gnorm=1.21, loss_scale=4, train_wall=340, gb_free=13.3, wall=492311
lprobs.size(): torch.Size([3264, 42808])
2023-09-26 03:31:03 | INFO | train_inner | epoch 025:   6106 / 9060 loss=7.431, nll_loss=3.666, ppl=12.7, wps=3747.8, ups=0.29, wpb=12960.1, bsz=403.7, num_updates=223500, lr=6.689e-05, gnorm=1.203, loss_scale=4, train_wall=346, gb_free=14.6, wall=492657
ter_threshold: 0.523533
num_accepted / total 33 80
loss token level: tensor(9126.0723, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(10544., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 03:36:39 | INFO | train_inner | epoch 025:   6206 / 9060 loss=7.437, nll_loss=3.663, ppl=12.67, wps=3840.3, ups=0.3, wpb=12906.6, bsz=428.6, num_updates=223600, lr=6.6875e-05, gnorm=1.203, loss_scale=4, train_wall=336, gb_free=13.6, wall=492993
lprobs.size(): torch.Size([3344, 42808])
2023-09-26 03:42:23 | INFO | train_inner | epoch 025:   6306 / 9060 loss=7.452, nll_loss=3.651, ppl=12.56, wps=3760.7, ups=0.29, wpb=12936.8, bsz=411.4, num_updates=223700, lr=6.68601e-05, gnorm=1.224, loss_scale=4, train_wall=344, gb_free=13.6, wall=493337
pred_new.size(): torch.Size([5746, 42808])
2023-09-26 03:48:05 | INFO | train_inner | epoch 025:   6406 / 9060 loss=7.687, nll_loss=3.766, ppl=13.6, wps=3797.9, ups=0.29, wpb=12972.5, bsz=421.8, num_updates=223800, lr=6.68452e-05, gnorm=1.221, loss_scale=4, train_wall=341, gb_free=12.6, wall=493678
2023-09-26 03:53:54 | INFO | train_inner | epoch 025:   6506 / 9060 loss=7.532, nll_loss=3.702, ppl=13.01, wps=3683.6, ups=0.29, wpb=12862.5, bsz=435.2, num_updates=223900, lr=6.68302e-05, gnorm=1.209, loss_scale=4, train_wall=349, gb_free=14.4, wall=494027
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 03:59:43 | INFO | train_inner | epoch 025:   6606 / 9060 loss=7.494, nll_loss=3.676, ppl=12.78, wps=3743.1, ups=0.29, wpb=13053.4, bsz=432.8, num_updates=224000, lr=6.68153e-05, gnorm=1.207, loss_scale=4, train_wall=348, gb_free=14.2, wall=494376
pred_new.size(): torch.Size([6664, 42808])
2023-09-26 04:05:21 | INFO | train_inner | epoch 025:   6706 / 9060 loss=7.522, nll_loss=3.664, ppl=12.68, wps=3822.1, ups=0.3, wpb=12939.2, bsz=444.6, num_updates=224100, lr=6.68004e-05, gnorm=1.2, loss_scale=4, train_wall=338, gb_free=12.9, wall=494715
2023-09-26 04:10:58 | INFO | train_inner | epoch 025:   6806 / 9060 loss=7.573, nll_loss=3.731, ppl=13.28, wps=3813.5, ups=0.3, wpb=12854, bsz=434.9, num_updates=224200, lr=6.67855e-05, gnorm=1.218, loss_scale=4, train_wall=337, gb_free=14, wall=495052
pred_new.size(): torch.Size([8800, 42808])
2023-09-26 04:16:33 | INFO | train_inner | epoch 025:   6906 / 9060 loss=7.657, nll_loss=3.763, ppl=13.58, wps=3873.6, ups=0.3, wpb=12980.3, bsz=446.1, num_updates=224300, lr=6.67706e-05, gnorm=1.21, loss_scale=4, train_wall=335, gb_free=12.9, wall=495387
2023-09-26 04:22:14 | INFO | train_inner | epoch 025:   7006 / 9060 loss=7.735, nll_loss=3.84, ppl=14.32, wps=3799.3, ups=0.29, wpb=12959.4, bsz=433.4, num_updates=224400, lr=6.67557e-05, gnorm=1.239, loss_scale=4, train_wall=341, gb_free=14.5, wall=495728
2023-09-26 04:27:58 | INFO | train_inner | epoch 025:   7106 / 9060 loss=7.742, nll_loss=3.827, ppl=14.19, wps=3777.9, ups=0.29, wpb=12991.6, bsz=436.3, num_updates=224500, lr=6.67409e-05, gnorm=1.241, loss_scale=4, train_wall=344, gb_free=14.1, wall=496072
2023-09-26 04:33:30 | INFO | train_inner | epoch 025:   7206 / 9060 loss=7.497, nll_loss=3.677, ppl=12.79, wps=3919.7, ups=0.3, wpb=13012.8, bsz=449.4, num_updates=224600, lr=6.6726e-05, gnorm=1.198, loss_scale=4, train_wall=332, gb_free=13.4, wall=496404
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 04:39:03 | INFO | train_inner | epoch 025:   7306 / 9060 loss=7.478, nll_loss=3.684, ppl=12.85, wps=3942.7, ups=0.3, wpb=13120.3, bsz=426.1, num_updates=224700, lr=6.67112e-05, gnorm=1.212, loss_scale=4, train_wall=333, gb_free=13.5, wall=496737
pred_new.size(): torch.Size([2288, 42808])
2023-09-26 04:44:39 | INFO | train_inner | epoch 025:   7406 / 9060 loss=7.567, nll_loss=3.702, ppl=13.02, wps=3882.6, ups=0.3, wpb=13052.3, bsz=421, num_updates=224800, lr=6.66963e-05, gnorm=1.235, loss_scale=4, train_wall=336, gb_free=12.8, wall=497073
2023-09-26 04:50:11 | INFO | train_inner | epoch 025:   7506 / 9060 loss=7.686, nll_loss=3.839, ppl=14.31, wps=3895.8, ups=0.3, wpb=12907.2, bsz=421.4, num_updates=224900, lr=6.66815e-05, gnorm=1.216, loss_scale=4, train_wall=331, gb_free=13.3, wall=497404
pred_new.size(): torch.Size([4998, 42808])
lprobs.size(): torch.Size([3344, 42808])
ter_threshold: 0.524986
num_accepted / total 65 120
loss token level: tensor(9151.1602, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13320., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 04:55:56 | INFO | train_inner | epoch 025:   7606 / 9060 loss=7.707, nll_loss=3.793, ppl=13.86, wps=3763, ups=0.29, wpb=12998.2, bsz=425.3, num_updates=225000, lr=6.66667e-05, gnorm=1.221, loss_scale=4, train_wall=345, gb_free=13.5, wall=497749
2023-09-26 05:01:26 | INFO | train_inner | epoch 025:   7706 / 9060 loss=7.522, nll_loss=3.698, ppl=12.98, wps=3937.3, ups=0.3, wpb=12975.9, bsz=442.8, num_updates=225100, lr=6.66519e-05, gnorm=1.192, loss_scale=4, train_wall=329, gb_free=14, wall=498079
lprobs.size(): torch.Size([3520, 42808])
2023-09-26 05:07:06 | INFO | train_inner | epoch 025:   7806 / 9060 loss=7.548, nll_loss=3.688, ppl=12.89, wps=3822.8, ups=0.29, wpb=12999, bsz=454.2, num_updates=225200, lr=6.66371e-05, gnorm=1.19, loss_scale=4, train_wall=340, gb_free=13.4, wall=498419
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3894, 42808])
2023-09-26 05:12:36 | INFO | train_inner | epoch 025:   7906 / 9060 loss=7.529, nll_loss=3.693, ppl=12.94, wps=3930.3, ups=0.3, wpb=12971.9, bsz=428, num_updates=225300, lr=6.66223e-05, gnorm=1.208, loss_scale=4, train_wall=330, gb_free=14, wall=498749
2023-09-26 05:13:01 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2480, 42808])
2023-09-26 05:18:06 | INFO | train_inner | epoch 025:   8007 / 9060 loss=7.521, nll_loss=3.707, ppl=13.06, wps=3918.5, ups=0.3, wpb=12946.6, bsz=412.8, num_updates=225400, lr=6.66075e-05, gnorm=1.191, loss_scale=2, train_wall=330, gb_free=13.6, wall=499080
2023-09-26 05:23:45 | INFO | train_inner | epoch 025:   8107 / 9060 loss=7.399, nll_loss=3.646, ppl=12.52, wps=3833, ups=0.3, wpb=12987, bsz=426.6, num_updates=225500, lr=6.65927e-05, gnorm=1.18, loss_scale=2, train_wall=339, gb_free=13.8, wall=499418
pred_new.size(): torch.Size([8001, 42808])
2023-09-26 05:29:16 | INFO | train_inner | epoch 025:   8207 / 9060 loss=7.44, nll_loss=3.68, ppl=12.82, wps=3923.4, ups=0.3, wpb=12994.4, bsz=432.3, num_updates=225600, lr=6.6578e-05, gnorm=1.195, loss_scale=2, train_wall=331, gb_free=13.9, wall=499750
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.5256609999999999
num_accepted / total 66 152
loss token level: tensor(8422.4004, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7668., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 05:35:00 | INFO | train_inner | epoch 025:   8307 / 9060 loss=7.571, nll_loss=3.719, ppl=13.17, wps=3764.9, ups=0.29, wpb=12944.4, bsz=447.4, num_updates=225700, lr=6.65632e-05, gnorm=1.205, loss_scale=2, train_wall=344, gb_free=13.6, wall=500093
pred_new.size(): torch.Size([2142, 42808])
2023-09-26 05:40:37 | INFO | train_inner | epoch 025:   8407 / 9060 loss=7.642, nll_loss=3.713, ppl=13.12, wps=3882, ups=0.3, wpb=13086.3, bsz=435.2, num_updates=225800, lr=6.65485e-05, gnorm=1.213, loss_scale=2, train_wall=337, gb_free=14.4, wall=500430
pred_new.size(): torch.Size([3648, 42808])
2023-09-26 05:46:04 | INFO | train_inner | epoch 025:   8507 / 9060 loss=7.62, nll_loss=3.761, ppl=13.56, wps=3950.8, ups=0.31, wpb=12937.2, bsz=442.6, num_updates=225900, lr=6.65337e-05, gnorm=1.208, loss_scale=2, train_wall=327, gb_free=13.5, wall=500758
pred_new.size(): torch.Size([6161, 42808])
pred_new.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([2592, 42808])
2023-09-26 05:51:43 | INFO | train_inner | epoch 025:   8607 / 9060 loss=7.536, nll_loss=3.717, ppl=13.15, wps=3844.4, ups=0.3, wpb=13001.8, bsz=420.2, num_updates=226000, lr=6.6519e-05, gnorm=1.21, loss_scale=2, train_wall=338, gb_free=13.9, wall=501096
pred_new.size(): torch.Size([2604, 42808])
pred_new.size(): torch.Size([2800, 42808])
2023-09-26 05:57:19 | INFO | train_inner | epoch 025:   8707 / 9060 loss=7.408, nll_loss=3.648, ppl=12.53, wps=3884.2, ups=0.3, wpb=13059.4, bsz=421.1, num_updates=226100, lr=6.65043e-05, gnorm=1.173, loss_scale=2, train_wall=336, gb_free=13, wall=501432
ter_threshold: 0.526123
num_accepted / total 36 80
loss token level: tensor(9251.6670, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6788., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
2023-09-26 06:02:54 | INFO | train_inner | epoch 025:   8807 / 9060 loss=7.55, nll_loss=3.743, ppl=13.39, wps=3874.1, ups=0.3, wpb=12969.3, bsz=427.7, num_updates=226200, lr=6.64896e-05, gnorm=1.222, loss_scale=2, train_wall=335, gb_free=14.1, wall=501767
lprobs.size(): torch.Size([3168, 42808])
2023-09-26 06:08:39 | INFO | train_inner | epoch 025:   8907 / 9060 loss=7.716, nll_loss=3.792, ppl=13.85, wps=3755.3, ups=0.29, wpb=12959.7, bsz=439.8, num_updates=226300, lr=6.64749e-05, gnorm=1.221, loss_scale=2, train_wall=345, gb_free=15.1, wall=502112
2023-09-26 06:14:25 | INFO | train_inner | epoch 025:   9007 / 9060 loss=7.43, nll_loss=3.64, ppl=12.47, wps=3763, ups=0.29, wpb=13013.2, bsz=416.4, num_updates=226400, lr=6.64602e-05, gnorm=1.198, loss_scale=2, train_wall=346, gb_free=12.3, wall=502458
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 06:17:30 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-26 06:17:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-26 06:17:30 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-26 06:17:30 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-26 06:17:31 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-26 06:17:31 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-26 06:17:32 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-26 06:17:32 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-26 06:17:32 | INFO | fairseq.tasks.translation | example hypothesis: Ihre Dokumente werden selbstverständlich streng vertraulich behandelt.
2023-09-26 06:17:32 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-26 06:17:33 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-26 06:17:33 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-26 06:17:33 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und es war ein voller Erfolg.
2023-09-26 06:17:33 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-26 06:17:34 | INFO | fairseq.tasks.translation | example hypothesis: (EN) Herr Präsident! Frohes neues Jahr für alle und Glückwünsche an unseren Präsidenten.
2023-09-26 06:17:34 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-26 06:17:35 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Initiativmonopol, das wir respektieren.
2023-09-26 06:17:35 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-26 06:17:35 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatdiskussionen.
2023-09-26 06:17:35 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-26 06:17:36 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer verfügen über digitales TV und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende gleichermaßen geeignet sind.
2023-09-26 06:17:36 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-26 06:17:37 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-26 06:17:37 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-26 06:17:37 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-26 06:17:37 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-26 06:17:38 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU insgesamt riesige Mengen an Energie verschwendet.
2023-09-26 06:17:38 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-26 06:17:39 | INFO | fairseq.tasks.translation | example hypothesis: Das Deutsche Linux Magazin hat einen Artikel von Gentoo Entwickler Michael Kohl in seiner neuesten Nummer.
2023-09-26 06:17:39 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-26 06:17:39 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellung auch in Kürze im Haushalt der Union niederschlagen.
2023-09-26 06:17:39 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-26 06:17:40 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-26 06:17:40 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-26 06:17:41 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-26 06:17:41 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-26 06:17:41 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-26 06:17:41 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-26 06:17:42 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-26 06:17:42 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-26 06:17:43 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-26 06:17:43 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-26 06:17:43 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-26 06:17:43 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-26 06:17:44 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-26 06:17:44 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-26 06:17:45 | INFO | fairseq.tasks.translation | example hypothesis: Das funktionelle Bindeglied dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-26 06:17:45 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-26 06:17:46 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potenzielle Käufer veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-26 06:17:46 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-26 06:17:46 | INFO | fairseq.tasks.translation | example hypothesis: Während sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-26 06:17:46 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-26 06:17:47 | INFO | fairseq.tasks.translation | example hypothesis: Er fügte hinzu, dass er bereit sei, die notwendigen Vorschläge zu unterbreiten, falls es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-26 06:17:47 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-26 06:17:48 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die in dieser Aussprache gebotene Gelegenheit, Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-26 06:17:48 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-26 06:17:48 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Orte im Umkreis von etwa 8 km vom Strip entfernt.
2023-09-26 06:17:48 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-26 06:17:49 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem berühmten Open Source Php-Nuke Web-Portalsystem basiert.
2023-09-26 06:17:49 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-26 06:17:50 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Tonhandbüchern an.
2023-09-26 06:17:50 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-26 06:17:51 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-26 06:17:51 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-26 06:17:51 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, kann sich aber bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-26 06:17:51 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-26 06:17:52 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrer Ausreise Zugang zu dem von ihnen bezahlten Geld in die europäischen Sozialversicherungssysteme haben.
2023-09-26 06:17:52 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-26 06:17:53 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-26 06:17:53 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-26 06:17:54 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie - leider gibt es für einige Formate keine kostenlose Alternative, die auf jeder Computerplattform läuft.
2023-09-26 06:17:54 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-26 06:17:54 | INFO | fairseq.tasks.translation | example hypothesis: Der Pfarrer weiß auch, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind..............
2023-09-26 06:17:54 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-26 06:17:55 | INFO | fairseq.tasks.translation | example hypothesis: Trotzdem sind Thatcher-Ideen über niedrigere und transparentere Steuerstrukturen und eine zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-26 06:17:55 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-26 06:17:56 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils-Benutzer müssen splashutils neu emergen, damit es korrekt funktioniert.
2023-09-26 06:17:56 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-26 06:17:57 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können Gegenstände nicht gegenseitig kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser nutzen...................
2023-09-26 06:17:57 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-26 06:17:57 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten....................
2023-09-26 06:17:57 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-26 06:17:58 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-26 06:17:58 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-26 06:17:59 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten Details des Abkommens im Prinzip mit den Vereinigten Staaten abgeben müssen.
2023-09-26 06:17:59 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-26 06:18:00 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unser umfangreiches Sortiment an PlastikBabyartikeln ist nicht zuletzt durch seine hervorragende Verarbeitung beeindruckend, nicht zuletzt durch seine hervorragende Verarbeitung.
2023-09-26 06:18:00 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-26 06:18:00 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-26 06:18:00 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-26 06:18:01 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis Kenntnis Kenntnis von Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-26 06:18:01 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-26 06:18:02 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und die Notwendigkeit institutioneller Veränderungen erkannt hat, die im Bereich der Außenpolitik und Verteidigung eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung benötigt.
2023-09-26 06:18:02 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-26 06:18:03 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-26 06:18:03 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-26 06:18:04 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die bei der Prüfung aller Fragen, die jetzt diskutiert werden, zu etwas, das gerade einmal zwei Jahre alt ist, nämlich die neue transatlantische Agenda, erzielt wurden, die neue transatlantische Agenda.....
2023-09-26 06:18:04 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-26 06:18:04 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus gesunkenen Federn und Stoßdämpfern für erstklassigen Fahrspaß.
2023-09-26 06:18:04 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-26 06:18:05 | INFO | fairseq.tasks.translation | example hypothesis: Erneut ist es dem Berichterstatter gelungen, gelegentlich abweichende Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-26 06:18:05 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-26 06:18:06 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT T-Modell unser Programm an trockenen elektrostatischen Einläufern um einen trockenen ESP für den unteren Leistungsbereich.
2023-09-26 06:18:06 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-26 06:18:07 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt, befinden Sie sich bereits in einem fremden Land...................
2023-09-26 06:18:07 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-26 06:18:08 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-26 06:18:08 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-26 06:18:08 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und mit unserer Völkergemeinschaft zu tun haben.
2023-09-26 06:18:08 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-26 06:18:09 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-26 06:18:09 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-26 06:18:10 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-26 06:18:10 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-26 06:18:11 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die wachsende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-26 06:18:11 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-26 06:18:12 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine andere: die Notsituation der Kinder, des schwächsten BevölkerungsBevölkerung, die ohne Familie, ohne Schutz und ohne Staat zurückgelassen wurde.
2023-09-26 06:18:12 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-26 06:18:13 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Abtrennens seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden dürfen..................
2023-09-26 06:18:13 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-26 06:18:14 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, erst nicht verwirklicht ist, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, bis man sein wahres Selbst kennt.................., ohne
2023-09-26 06:18:14 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-26 06:18:14 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in unserer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder aufzunehmen..............
2023-09-26 06:18:14 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-26 06:18:15 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die die Bürger mit Meinungsfreiheit, freien und unabhängigen Wahlen und Vereinigungsfreiheit stärken, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.....................
2023-09-26 06:18:15 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-26 06:18:16 | INFO | fairseq.tasks.translation | example hypothesis: System wird in Java Programmiersprache mit J2EE-Techniken implementiert, die Plattform- und Betriebssystem-Unabhängigkeit garantieren (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-26 06:18:16 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-26 06:18:17 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Sehr geehrte Damen und Herren! Wir stimmen heute über einen Vorschlag zur klareren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen somit für die Klärung des Anhangs.
2023-09-26 06:18:17 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-26 06:18:18 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Auffassung, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt wurden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden...
2023-09-26 06:18:18 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-26 06:18:19 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Aussprache über das irische Radio RTÉ teilgenommen, mit einer Frau, die sehr besorgt war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen.
2023-09-26 06:18:19 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-26 06:18:20 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und ich möchte der Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.
2023-09-26 06:18:20 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-26 06:18:21 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder etwas so Spezielles wie die Reduzierung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.............
2023-09-26 06:18:21 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-26 06:18:21 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Jahreszeit der Griechischen Poker Tour (2010-2011), findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen........................
2023-09-26 06:18:21 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-26 06:18:23 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher, relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament nochmals dafür danken.
2023-09-26 06:18:23 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-26 06:18:23 | INFO | fairseq.tasks.translation | example hypothesis: Anderenfalls zu denken, hieße, eine bestimmte Art von Vertragsbeziehung zwischen Individuen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (darunter oft die tatsächliche oder wahrgenommene Bedrohung, von institutioneller Hegemonie zerschlagen zu werden)!!!!!!!!!!!!!!!!
2023-09-26 06:18:23 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-26 06:18:24 | INFO | fairseq.tasks.translation | example hypothesis: In der Zuständigkeit der Gemeinschaft für ein Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder wenn eine einheitliche Auslegung des Übereinkommens erforderlich ist...........................
2023-09-26 06:18:24 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-26 06:18:25 | INFO | fairseq.tasks.translation | example hypothesis: Die BMW 3er Serie ist eines der lustigsten Autos mit weniger als 50.000 Dollar. Wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos ausprobieren.
2023-09-26 06:18:25 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-26 06:18:26 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung des Themas danken...................... - Herr Präsident, Herr Präsident!
2023-09-26 06:18:26 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-26 06:18:27 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrillter Hecht, Forelle mit Mandeln..........................
2023-09-26 06:18:27 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-26 06:18:28 | INFO | fairseq.tasks.translation | example hypothesis: Anstatt sich daran zu erinnern, was ein politisches Handeln bedeutet, wäre es vielleicht besser, einen Gesamtüberblick zu bieten, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu überlegen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann................
2023-09-26 06:18:28 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-26 06:18:29 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber der "Scardona Records", Herr Branko Paić, haben sich darauf geeinigt, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-26 06:18:29 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-26 06:18:30 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo die bestehenden Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politik, steuerliche Maßnahmen und Zwänge, die nicht an die derzeitige Situation vor Ort angepasst sind, allmählich ausgehöhlt wird. die nicht an die derzeitige Situation vor Ort angepasst sind, die nicht an die derzeitige Lage vor Ort
2023-09-26 06:18:30 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-26 06:18:31 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein ausgezeichnetes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, beigetragen hat. der alle unsere Änderungsanträge in den Text übernommen hat..........
2023-09-26 06:18:31 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-26 06:18:32 | INFO | fairseq.tasks.translation | example hypothesis: Somit erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus mit den entsprechenden Konsequenzen für den Rechts- und Rechtsbereich, wodurch Norwegen und Island, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen Anwendung finden werden, in Norwegen und Island, in denen die gemeinsamen Auslieferungsbestimmungen gelten........
2023-09-26 06:18:32 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-26 06:18:33 | INFO | fairseq.tasks.translation | example hypothesis: Wir fahren mit voller Geschwindigkeit in einem Schmiedeboot hinunter den Mississippi, suchen nach dem großen verborgenen Schatz, verlieben uns in den wunderschönen Becky Thatcher, der reiner Dynamit ist, und vor allem werden wir große Freunde sein.....................
2023-09-26 06:18:33 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-26 06:18:34 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Personen oder Rechtspersonen verursachten Meeresverschmutzung durch Schiffe, den Umfang der Reaktion und die Strafbarkeit der Sanktionen, die im Falle solcher Verstöße von Personen verhängt werden können.
2023-09-26 06:18:34 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-26 06:18:35 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner verrichtet und eine Gruppe von Bergbewohnern gefilmt haben, die jahrelang von einem autoritären Regime gejagt wurden, das sich über jedes Prinzip der Demokratie hinwegsetzt.............
2023-09-26 06:18:35 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-26 06:18:36 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Umkleidekabine, ein Geldwechsel, kostenfreier Schuhputzservice und WLAN-Internetzugang. Die 346 Zimmer und Suiten des Omni Royal Orleans bieten Blick auf den Innenhof und das Französische Viertel.
2023-09-26 06:18:36 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-26 06:18:37 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der von Königin D. Leonor, der Frau von König D. João II, geliebten Thermalquelle verdankt und durch ihre international bekannten Keramiken für ihre gegenständlichen und satirischen Werke bekannt ist, ist ebenfalls einen Besuch wert.
2023-09-26 06:18:37 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-26 06:18:38 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, es handele sich um gute Befürworter des Westens auf der einen und Anhänger des früheren Regimes auf der anderen Seite - das ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-26 06:18:38 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-26 06:18:39 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und dem Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte.................., der irgendwie irgendwie abgedeckt werden
2023-09-26 06:18:39 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-26 06:18:40 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Hauptversammlung aufgrund seines Status als Aktionär Informationen zur Verfügung gestellt, so sind diese auf Verlangen an andere Aktionäre in der Hauptversammlung weiterzugeben, auch wenn diese Informationen für eine angemessene Bewertung eines Tagesordnungspunktes nicht erforderlich sind.
2023-09-26 06:18:40 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-26 06:18:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die normalerweise in den Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen Menschen in unseren eigenen Ländern leben, die auch ein sehr elendes Leben führen................, die auch ein sehr elendes Leben führen, die auch ein sehr elendes
2023-09-26 06:18:41 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-26 06:18:42 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder der NATO an diesem Kriegshandlung beteiligt gewesen sein könnten -, mit Informationen zu helfen, die es keinen Grund mehr gibt, geheim, geheim oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit gesagt werden kann................, damit die ganze Wahrheit ans Licht
2023-09-26 06:18:42 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-26 06:18:43 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug von der Innenstadt entfernt.Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-26 06:18:43 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-26 06:18:44 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, sowie unserer Business Unit Defence Electronics und Indra in Spanien wird der Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen umfassen, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die heutigen Plattformen außerhalb der Regale nie erreichen können....................., die die moderne Plattformen
2023-09-26 06:18:44 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-26 06:18:46 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir nicht nur für uns, sondern weltweit die Produkte, die nicht nur für den Inlandsverbrauch, sondern auch für den globalen Markt eine ernste Gefahr darstellen, vom Markt nehmen können, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt.................., wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 in ihrem neuen Änderungsantrag
2023-09-26 06:18:46 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-26 06:18:47 | INFO | fairseq.tasks.translation | example hypothesis: Unter der einfachen Verschwörung von Moderne und Postmoderne oder dem klaren Gegensatz von reiner Kunst und engagierter Kunst müssen wir die originelle und dauerhafte Spannung jener beiden ästhetischen Politik erkennen, die in genau die Formen der Sichtbarkeit und Verständlichkeit verbirgt, die Kunst als solche für uns identifizierbar machen - jene beiden Politiken, die letztlich zu ihrer eigenen Selbstunterdrückung führen............... die, die, die letztlich zu ihrer eigenen Selbstunterdrück
2023-09-26 06:18:47 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-26 06:18:48 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute betrifft, so werde ich angesichts der Bedeutung der Debatten und angesichts der Meinungen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Beschlüsse unsere Debatten führen, und bei der Abstimmung, falls die vierzig Petenten nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-26 06:18:48 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-26 06:18:49 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips nie akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem die nationalen Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung der ethnischen, religiösen, sprachlichen und kulturellen Vielfalt zu ermöglichen................, aber ohne das Ziel, eine einheitliche Kultur zu
2023-09-26 06:18:49 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-26 06:18:50 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Form als Hybridform veröffentlicht, die Rezensionen und Artikel der Quartalszeitschrift für H-Soz-u-Kult geschrieben und über Mailinglisten sowie über die Websites der H-Soz-u-Kult und des Michigan-basierten H-Net an ihre Abonnenten verteilt............... H-Soz-Kult und H-Kult und das Michigan-Net
2023-09-26 06:18:50 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-26 06:18:52 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Handys ihre Federn deutlich verfeinert und von einst wackeligen Wecker im Taschenformat über polyphonisch tootende Game Boy-Aspiranten zu Mini-PCs mit knackigem Stereo-Sound in CD-Qualität: Zukünftig könnten sie dank ihrer besonderen Kombination aus Fähigkeiten von den ehemaligen I-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen werden................., könnten, dank ihrer besonderen Kombination von Fähigkeiten, von den ehemaligen me-too-Wannabes zu Trailbla
2023-09-26 06:18:52 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-26 06:18:54 | INFO | fairseq.tasks.translation | example hypothesis: La piel de la base humana en Pandora, conocido a Jake para que le proportionación información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen; en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un konflito armado; en l deberá dedir de qué lado está está.
2023-09-26 06:18:54 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-26 06:18:54 | INFO | valid | epoch 025 | valid on 'valid' subset | loss 4.119 | nll_loss 2.158 | ppl 4.46 | bleu 26.38 | wps 14057.2 | wpb 12011.9 | bsz 398.1 | num_updates 226453 | best_bleu 29.48
2023-09-26 06:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 226453 updates
2023-09-26 06:18:54 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint25.pt
2023-09-26 06:19:01 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint25.pt
2023-09-26 06:19:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint25.pt (epoch 25 @ 226453 updates, score 26.38) (writing took 10.609564348007552 seconds)
2023-09-26 06:19:05 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2023-09-26 06:19:05 | INFO | train | epoch 025 | loss 7.55 | nll_loss 3.7 | ppl 12.99 | wps 3825.8 | ups 0.29 | wpb 12977.5 | bsz 430.6 | num_updates 226453 | lr 6.64524e-05 | gnorm 1.208 | loss_scale 2 | train_wall 30603 | gb_free 14.2 | wall 502738
2023-09-26 06:19:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-26 06:19:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-26 06:19:05 | INFO | fairseq.trainer | begin training epoch 26
2023-09-26 06:19:05 | INFO | fairseq_cli.train | Start iterating over samples
2023-09-26 06:21:34 | INFO | train_inner | epoch 026:     47 / 9060 loss=7.396, nll_loss=3.647, ppl=12.53, wps=3003.8, ups=0.23, wpb=12901.8, bsz=415.8, num_updates=226500, lr=6.64455e-05, gnorm=1.188, loss_scale=2, train_wall=334, gb_free=14.1, wall=502888
pred_new.size(): torch.Size([8505, 42808])
2023-09-26 06:27:23 | INFO | train_inner | epoch 026:    147 / 9060 loss=7.584, nll_loss=3.656, ppl=12.61, wps=3747.3, ups=0.29, wpb=13071.9, bsz=436.6, num_updates=226600, lr=6.64309e-05, gnorm=1.22, loss_scale=2, train_wall=349, gb_free=14.4, wall=503236
pred_new.size(): torch.Size([5612, 42808])
2023-09-26 06:33:08 | INFO | train_inner | epoch 026:    247 / 9060 loss=7.454, nll_loss=3.62, ppl=12.3, wps=3779.7, ups=0.29, wpb=13047.3, bsz=410.9, num_updates=226700, lr=6.64162e-05, gnorm=1.215, loss_scale=2, train_wall=345, gb_free=12.9, wall=503582
2023-09-26 06:38:43 | INFO | train_inner | epoch 026:    347 / 9060 loss=7.555, nll_loss=3.688, ppl=12.89, wps=3824.5, ups=0.3, wpb=12814.8, bsz=423.8, num_updates=226800, lr=6.64016e-05, gnorm=1.224, loss_scale=2, train_wall=335, gb_free=13.7, wall=503917
2023-09-26 06:44:18 | INFO | train_inner | epoch 026:    447 / 9060 loss=7.672, nll_loss=3.733, ppl=13.3, wps=3861.2, ups=0.3, wpb=12940.7, bsz=449.4, num_updates=226900, lr=6.6387e-05, gnorm=1.22, loss_scale=2, train_wall=335, gb_free=14, wall=504252
2023-09-26 06:49:54 | INFO | train_inner | epoch 026:    547 / 9060 loss=7.544, nll_loss=3.656, ppl=12.6, wps=3888.7, ups=0.3, wpb=13065.4, bsz=434.2, num_updates=227000, lr=6.63723e-05, gnorm=1.194, loss_scale=2, train_wall=336, gb_free=14, wall=504588
pred_new.size(): torch.Size([4806, 42808])
pred_new.size(): torch.Size([4380, 42808])
2023-09-26 06:55:32 | INFO | train_inner | epoch 026:    647 / 9060 loss=7.459, nll_loss=3.628, ppl=12.36, wps=3848.8, ups=0.3, wpb=12989.3, bsz=437.3, num_updates=227100, lr=6.63577e-05, gnorm=1.194, loss_scale=2, train_wall=337, gb_free=14.4, wall=504925
lprobs.size(): torch.Size([2712, 42808])
2023-09-26 07:01:18 | INFO | train_inner | epoch 026:    747 / 9060 loss=7.614, nll_loss=3.685, ppl=12.87, wps=3768.8, ups=0.29, wpb=13055.6, bsz=419.8, num_updates=227200, lr=6.63431e-05, gnorm=1.22, loss_scale=2, train_wall=346, gb_free=15.6, wall=505272
2023-09-26 07:07:06 | INFO | train_inner | epoch 026:    847 / 9060 loss=7.69, nll_loss=3.735, ppl=13.31, wps=3743.7, ups=0.29, wpb=13031.6, bsz=429.1, num_updates=227300, lr=6.63285e-05, gnorm=1.238, loss_scale=2, train_wall=348, gb_free=14.7, wall=505620
lprobs.size(): torch.Size([3480, 42808])
2023-09-26 07:12:47 | INFO | train_inner | epoch 026:    947 / 9060 loss=7.474, nll_loss=3.647, ppl=12.53, wps=3811.8, ups=0.29, wpb=12993.3, bsz=432.1, num_updates=227400, lr=6.63139e-05, gnorm=1.216, loss_scale=2, train_wall=341, gb_free=13, wall=505961
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 07:18:23 | INFO | train_inner | epoch 026:   1047 / 9060 loss=7.488, nll_loss=3.668, ppl=12.71, wps=3865.8, ups=0.3, wpb=12964.2, bsz=435.3, num_updates=227500, lr=6.62994e-05, gnorm=1.199, loss_scale=2, train_wall=335, gb_free=14.4, wall=506296
ter_threshold: 0.52759
num_accepted / total 39 144
loss token level: tensor(8413.4844, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2656., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 07:23:55 | INFO | train_inner | epoch 026:   1147 / 9060 loss=7.622, nll_loss=3.717, ppl=13.15, wps=3875.5, ups=0.3, wpb=12895.6, bsz=444.8, num_updates=227600, lr=6.62848e-05, gnorm=1.225, loss_scale=2, train_wall=332, gb_free=13.2, wall=506629
2023-09-26 07:29:34 | INFO | train_inner | epoch 026:   1247 / 9060 loss=7.718, nll_loss=3.77, ppl=13.64, wps=3800.1, ups=0.29, wpb=12883.1, bsz=416.8, num_updates=227700, lr=6.62702e-05, gnorm=1.242, loss_scale=2, train_wall=339, gb_free=13.1, wall=506968
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3560, 42808])
2023-09-26 07:35:17 | INFO | train_inner | epoch 026:   1347 / 9060 loss=7.825, nll_loss=3.801, ppl=13.94, wps=3805.1, ups=0.29, wpb=13049.6, bsz=460.1, num_updates=227800, lr=6.62557e-05, gnorm=1.257, loss_scale=2, train_wall=343, gb_free=13.4, wall=507311
2023-09-26 07:40:57 | INFO | train_inner | epoch 026:   1447 / 9060 loss=7.49, nll_loss=3.678, ppl=12.8, wps=3836.3, ups=0.29, wpb=13041.4, bsz=425.6, num_updates=227900, lr=6.62411e-05, gnorm=1.205, loss_scale=2, train_wall=340, gb_free=13, wall=507651
2023-09-26 07:46:50 | INFO | train_inner | epoch 026:   1547 / 9060 loss=7.555, nll_loss=3.678, ppl=12.8, wps=3698.1, ups=0.28, wpb=13044.1, bsz=440.8, num_updates=228000, lr=6.62266e-05, gnorm=1.219, loss_scale=2, train_wall=352, gb_free=14.6, wall=508003
2023-09-26 07:52:47 | INFO | train_inner | epoch 026:   1647 / 9060 loss=7.6, nll_loss=3.683, ppl=12.84, wps=3659.2, ups=0.28, wpb=13050.1, bsz=417.2, num_updates=228100, lr=6.62121e-05, gnorm=1.214, loss_scale=2, train_wall=356, gb_free=14.4, wall=508360
pred_new.size(): torch.Size([4182, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([5766, 42808])
ter_threshold: 0.5281819999999999
num_accepted / total 5 32
loss token level: tensor(11381.6641, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2362., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.528183
num_accepted / total 47 96
loss token level: tensor(9327.9629, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11472., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.528187
num_accepted / total 98 144
loss token level: tensor(10097.8984, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(15576., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 07:58:27 | INFO | train_inner | epoch 026:   1747 / 9060 loss=7.812, nll_loss=3.8, ppl=13.93, wps=3801.4, ups=0.29, wpb=12933, bsz=430.3, num_updates=228200, lr=6.61976e-05, gnorm=1.25, loss_scale=2, train_wall=340, gb_free=13.5, wall=508700
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3496, 42808])
2023-09-26 08:04:02 | INFO | train_inner | epoch 026:   1847 / 9060 loss=7.743, nll_loss=3.767, ppl=13.61, wps=3846.7, ups=0.3, wpb=12894.5, bsz=445.8, num_updates=228300, lr=6.61831e-05, gnorm=1.246, loss_scale=2, train_wall=335, gb_free=14, wall=509036
lprobs.size(): torch.Size([3584, 42808])
2023-09-26 08:09:41 | INFO | train_inner | epoch 026:   1947 / 9060 loss=7.528, nll_loss=3.661, ppl=12.65, wps=3832.7, ups=0.29, wpb=12993.7, bsz=432.8, num_updates=228400, lr=6.61686e-05, gnorm=1.227, loss_scale=2, train_wall=339, gb_free=14.7, wall=509375
pred_new.size(): torch.Size([2248, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([990, 42808])
2023-09-26 08:15:36 | INFO | train_inner | epoch 026:   2047 / 9060 loss=7.382, nll_loss=3.573, ppl=11.9, wps=3681.6, ups=0.28, wpb=13072.6, bsz=443.5, num_updates=228500, lr=6.61541e-05, gnorm=1.198, loss_scale=2, train_wall=355, gb_free=15.3, wall=509730
lprobs.size(): torch.Size([3344, 42808])
2023-09-26 08:21:05 | INFO | train_inner | epoch 026:   2147 / 9060 loss=7.415, nll_loss=3.655, ppl=12.6, wps=3932.5, ups=0.3, wpb=12918.8, bsz=443.9, num_updates=228600, lr=6.61396e-05, gnorm=1.197, loss_scale=2, train_wall=328, gb_free=13.9, wall=510058
pred_new.size(): torch.Size([10160, 42808])
2023-09-26 08:26:37 | INFO | train_inner | epoch 026:   2247 / 9060 loss=7.714, nll_loss=3.782, ppl=13.75, wps=3953.8, ups=0.3, wpb=13130, bsz=439.8, num_updates=228700, lr=6.61252e-05, gnorm=1.213, loss_scale=2, train_wall=332, gb_free=14.3, wall=510390
pred_new.size(): torch.Size([2700, 42808])
ter_threshold: 0.528753
num_accepted / total 36 72
loss token level: tensor(8156.8672, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6828., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 08:32:08 | INFO | train_inner | epoch 026:   2347 / 9060 loss=7.502, nll_loss=3.655, ppl=12.6, wps=3927.5, ups=0.3, wpb=13024.7, bsz=433.4, num_updates=228800, lr=6.61107e-05, gnorm=1.184, loss_scale=2, train_wall=331, gb_free=15.7, wall=510722
pred_new.size(): torch.Size([6760, 42808])
2023-09-26 08:37:56 | INFO | train_inner | epoch 026:   2447 / 9060 loss=7.507, nll_loss=3.706, ppl=13.05, wps=3744.7, ups=0.29, wpb=13000.4, bsz=425, num_updates=228900, lr=6.60963e-05, gnorm=1.209, loss_scale=2, train_wall=347, gb_free=12.7, wall=511069
pred_new.size(): torch.Size([3744, 42808])
2023-09-26 08:43:31 | INFO | train_inner | epoch 026:   2547 / 9060 loss=7.602, nll_loss=3.712, ppl=13.11, wps=3876.9, ups=0.3, wpb=13011.3, bsz=436.5, num_updates=229000, lr=6.60819e-05, gnorm=1.235, loss_scale=2, train_wall=335, gb_free=12.7, wall=511405
tensor(6696., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2244, 42808])
pred_new.size(): torch.Size([1581, 42808])
pred_new.size(): torch.Size([7200, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.519369
num_accepted / total 131 232
loss token level: tensor(9554.8516, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7056., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4590, 42808])
pred_new.size(): torch.Size([2744, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([5125, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2656, 42808])
pred_new.size(): torch.Size([7644, 42808])
ter_threshold: 0.519938
num_accepted / total 10 40
loss token level: tensor(8405.6504, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3804., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([6987, 42808])
pred_new.size(): torch.Size([1728, 42808])
pred_new.size(): torch.Size([3577, 42808])
ter_threshold: 0.520524
num_accepted / total 63 144
loss token level: tensor(9674.5879, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10336., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6728, 42808])
ter_threshold: 0.520688
num_accepted / total 46 80
loss token level: tensor(9579.0801, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(14144., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4559, 42808])
pred_new.size(): torch.Size([4654, 42808])
pred_new.size(): torch.Size([5304, 42808])
pred_new.size(): torch.Size([7189, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.52132
num_accepted / total 14 56
loss token level: tensor(9686.7578, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4052., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6039, 42808])
pred_new.size(): torch.Size([9309, 42808])
ter_threshold: 0.5216879999999999
num_accepted / total 115 184
loss token level: tensor(8110.8477, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7196., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1960, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.522045
num_accepted / total 11 40
loss token level: tensor(7615.4878, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3560., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.522096
num_accepted / total 97 160
loss token level: tensor(9092.5527, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13296., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3220, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2992, 42808])
pred_new.size(): torch.Size([6336, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2100, 42808])
ter_threshold: 0.522842
num_accepted / total 10 40
loss token level: tensor(8050.0254, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6068., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.522904
num_accepted / total 13 64
loss token level: tensor(11449.7305, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4976., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4611, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([4608, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([378, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([1269, 42808])
pred_new.size(): torch.Size([2592, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6954, 42808])
pred_new.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([2448, 42808])
pred_new.size(): torch.Size([5548, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([4089, 42808])
pred_new.size(): torch.Size([2320, 42808])
pred_new.size(): torch.Size([7840, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([2376, 42808])
pred_new.size(): torch.Size([8906, 42808])
lprobs.size(): torch.Size([2720, 42808])
ter_threshold: 0.5256609999999999
num_accepted / total 248 296
loss token level: tensor(8400.4775, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(14824., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7020, 42808])
pred_new.size(): torch.Size([2236, 42808])
pred_new.size(): torch.Size([2223, 42808])
pred_new.size(): torch.Size([4060, 42808])
pred_new.size(): torch.Size([1236, 42808])
pred_new.size(): torch.Size([4588, 42808])
pred_new.size(): torch.Size([1960, 42808])
pred_new.size(): torch.Size([3744, 42808])
pred_new.size(): torch.Size([2436, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([7410, 42808])
ter_threshold: 0.526562
num_accepted / total 50 88
loss token level: tensor(8612.1484, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13784., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([680, 42808])
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.5270159999999999
num_accepted / total 61 112
loss token level: tensor(9618.4268, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13280., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6720, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2944, 42808])
pred_new.size(): torch.Size([840, 42808])
ter_threshold: 0.527816
num_accepted / total 107 144
loss token level: tensor(9263.6016, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(15552., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.5280009999999999
num_accepted / total 67 112
loss token level: tensor(8172.3281, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12200., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3612, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2992, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([2640, 42808])
pred_new.size(): torch.Size([2400, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([3840, 42808])
pred_new.size(): torch.Size([5964, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.529025
num_accepted / total 19 64
loss token level: lprobs.size(): torch.Size([3344, 42808])
2023-09-26 08:49:00 | INFO | train_inner | epoch 026:   2647 / 9060 loss=7.483, nll_loss=3.66, ppl=12.64, wps=3945.7, ups=0.3, wpb=12982.4, bsz=413.7, num_updates=229100, lr=6.60674e-05, gnorm=1.199, loss_scale=2, train_wall=329, gb_free=14.9, wall=511734
2023-09-26 08:54:39 | INFO | train_inner | epoch 026:   2747 / 9060 loss=7.614, nll_loss=3.721, ppl=13.19, wps=3798.5, ups=0.3, wpb=12857.7, bsz=427.9, num_updates=229200, lr=6.6053e-05, gnorm=1.246, loss_scale=2, train_wall=338, gb_free=15.1, wall=512072
pred_new.size(): torch.Size([4264, 42808])
pred_new.size(): torch.Size([2706, 42808])
2023-09-26 09:00:15 | INFO | train_inner | epoch 026:   2847 / 9060 loss=7.446, nll_loss=3.623, ppl=12.32, wps=3834.1, ups=0.3, wpb=12877, bsz=425.5, num_updates=229300, lr=6.60386e-05, gnorm=1.203, loss_scale=2, train_wall=336, gb_free=13.1, wall=512408
ter_threshold: 0.5293129999999999
num_accepted / total 33 112
loss token level: tensor(8448.6230, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3352., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4998, 42808])
lprobs.size(): torch.Size([2640, 42808])
2023-09-26 09:05:52 | INFO | train_inner | epoch 026:   2947 / 9060 loss=7.647, nll_loss=3.734, ppl=13.3, wps=3836.9, ups=0.3, wpb=12953.2, bsz=427.6, num_updates=229400, lr=6.60242e-05, gnorm=1.244, loss_scale=2, train_wall=337, gb_free=13.5, wall=512746
2023-09-26 09:11:21 | INFO | train_inner | epoch 026:   3047 / 9060 loss=7.333, nll_loss=3.58, ppl=11.95, wps=3947.7, ups=0.3, wpb=12972.6, bsz=423.4, num_updates=229500, lr=6.60098e-05, gnorm=1.197, loss_scale=4, train_wall=328, gb_free=15.6, wall=513074
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([3036, 42808])
pred_new.size(): torch.Size([1900, 42808])
2023-09-26 09:17:04 | INFO | train_inner | epoch 026:   3147 / 9060 loss=7.477, nll_loss=3.661, ppl=12.65, wps=3792.5, ups=0.29, wpb=13007.6, bsz=423.7, num_updates=229600, lr=6.59955e-05, gnorm=1.204, loss_scale=4, train_wall=343, gb_free=12.6, wall=513417
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3264, 42808])
2023-09-26 09:22:48 | INFO | train_inner | epoch 026:   3247 / 9060 loss=7.549, nll_loss=3.72, ppl=13.18, wps=3734.7, ups=0.29, wpb=12872.6, bsz=417.8, num_updates=229700, lr=6.59811e-05, gnorm=1.219, loss_scale=4, train_wall=344, gb_free=12.8, wall=513762
2023-09-26 09:28:25 | INFO | train_inner | epoch 026:   3347 / 9060 loss=7.593, nll_loss=3.686, ppl=12.87, wps=3895.2, ups=0.3, wpb=13100.6, bsz=429.8, num_updates=229800, lr=6.59667e-05, gnorm=1.206, loss_scale=4, train_wall=336, gb_free=12.9, wall=514098
lprobs.size(): torch.Size([3584, 42808])
2023-09-26 09:33:52 | INFO | train_inner | epoch 026:   3447 / 9060 loss=7.377, nll_loss=3.614, ppl=12.24, wps=3954.1, ups=0.31, wpb=12932.7, bsz=412.3, num_updates=229900, lr=6.59524e-05, gnorm=1.223, loss_scale=4, train_wall=327, gb_free=14, wall=514425
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([5568, 42808])
lprobs.size(): torch.Size([2296, 42808])
2023-09-26 09:39:35 | INFO | train_inner | epoch 026:   3547 / 9060 loss=7.691, nll_loss=3.76, ppl=13.55, wps=3770.5, ups=0.29, wpb=12937.2, bsz=420.8, num_updates=230000, lr=6.5938e-05, gnorm=1.242, loss_scale=4, train_wall=343, gb_free=13.3, wall=514768
ter_threshold: 0.530029
num_accepted / total 370 392
loss token level: tensor(8519.0342, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13952., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 09:44:15 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
pred_new.size(): torch.Size([5984, 42808])
2023-09-26 09:45:16 | INFO | train_inner | epoch 026:   3648 / 9060 loss=7.577, nll_loss=3.7, ppl=12.99, wps=3791.5, ups=0.29, wpb=12922.8, bsz=439, num_updates=230100, lr=6.59237e-05, gnorm=1.226, loss_scale=2, train_wall=341, gb_free=14.1, wall=515109
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 09:50:48 | INFO | train_inner | epoch 026:   3748 / 9060 loss=7.502, nll_loss=3.65, ppl=12.55, wps=3914.5, ups=0.3, wpb=12995.2, bsz=426.6, num_updates=230200, lr=6.59094e-05, gnorm=1.222, loss_scale=2, train_wall=332, gb_free=14.2, wall=515441
num_accepted / total 93 144
loss token level: tensor(9811.5469, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(15680., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2646, 42808])
pred_new.size(): torch.Size([3450, 42808])
lprobs.size(): torch.Size([3024, 42808])
ter_threshold: 0.522096
num_accepted / total 90 168
loss token level: tensor(9361.8398, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11920., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7875, 42808])
pred_new.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.522321
num_accepted / total 42 96
loss token level: tensor(8497.9062, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9360., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.522594
num_accepted / total 61 112
loss token level: tensor(9257.0742, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7960., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([3741, 42808])
pred_new.size(): torch.Size([4498, 42808])
pred_new.size(): torch.Size([6501, 42808])
ter_threshold: 0.523067
num_accepted / total 12 56
loss token level: tensor(8179.5205, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5100., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.523123
num_accepted / total 9 40
loss token level: tensor(9476.4082, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5908., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3618, 42808])
pred_new.size(): torch.Size([5208, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([1568, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([2236, 42808])
ter_threshold: 0.52338
num_accepted / total 23 56
loss token level: tensor(8371.3389, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10512., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([2232, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([1480, 42808])
lprobs.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5950, 42808])
pred_new.size(): torch.Size([7020, 42808])
lprobs.size(): torch.Size([2856, 42808])
pred_new.size(): torch.Size([4032, 42808])
lprobs.size(): torch.Size([2784, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([2268, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5820, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([3180, 42808])
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([7392, 42808])
pred_new.size(): torch.Size([2156, 42808])
pred_new.size(): torch.Size([1260, 42808])
pred_new.size(): torch.Size([3589, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3160, 42808])
lprobs.size(): torch.Size([2904, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3978, 42808])
pred_new.size(): torch.Size([7221, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([8122, 42808])
ter_threshold: 0.526607
num_accepted / total 7 56
loss token level: tensor(8532.7090, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2976., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5267569999999999
num_accepted / total 28 56
loss token level: tensor(8430.6230, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7820., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.527003
num_accepted / total 15 64
loss token level: tensor(8481.2646, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3250., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5270159999999999
num_accepted / total 184 232
loss token level: tensor(8821.3545, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(16592., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5183, 42808])
pred_new.size(): torch.Size([6240, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.527495
num_accepted / total 10 56
loss token level: tensor(12216.6914, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2716., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.527816
num_accepted / total 62 112
loss token level: tensor(9870.8057, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11232., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2632, 42808])
pred_new.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2912, 42808])
ter_threshold: 0.528187
num_accepted / total 51 136
loss token level: tensor(7888.8540, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6104., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([6695, 42808])
ter_threshold: 0.52871
num_accepted / total 32 80
loss token level: tensor(8795.7920, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6240., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2886, 42808])
pred_new.size(): torch.Size([6210, 42808])
pred_new.size(): torch.Size([4800, 42808])
pred_new.size(): torch.Size([2697, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.529025
num_accepted / total 22 64
loss token level: tensor(8745.5967, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8848., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4026, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4352, 42808])
ter_threshold: 0.529588
num_accepted / total 14 64
loss token level: tensor(9462.2754, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2976, 42808])
pred_new.size(): torch.Size([2068, 42808])
pred_new.size(): torch.Size([3876, 42808])
lprobs.size(): torch.Size([2872, 42808])
ter_threshold: 0.529883
num_accepted / total 30 72
loss token level: tensor(8156.7764, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5744., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([9095, 42808])
ter_threshold: 0.530029
num_accepted / total 51 96
loss token level: tensor(9124.9912, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12992., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([5568, 42808])
ter_threshold: 0.5302439999999999
ter_threshold: 0.5302439999999999
num_accepted / total 36 96
loss token level: tensor(9062.5938, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8992., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.530248
num_accepted / total 28 88
loss token level: tensor(9936.9844, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(7432., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 09:56:14 | INFO | train_inner | epoch 026:   3848 / 9060 loss=7.408, nll_loss=3.664, ppl=12.67, wps=3968.8, ups=0.31, wpb=12964.4, bsz=433.5, num_updates=230300, lr=6.58951e-05, gnorm=1.377, loss_scale=2, train_wall=326, gb_free=15.8, wall=515768
ter_threshold: 0.530392
num_accepted / total 112 160
loss token level: tensor(8767.2646, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9160., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 10:02:04 | INFO | train_inner | epoch 026:   3948 / 9060 loss=7.555, nll_loss=3.666, ppl=12.69, wps=3724.7, ups=0.29, wpb=13010.1, bsz=410.6, num_updates=230400, lr=6.58808e-05, gnorm=1.224, loss_scale=2, train_wall=349, gb_free=14.4, wall=516117
2023-09-26 10:07:41 | INFO | train_inner | epoch 026:   4048 / 9060 loss=7.613, nll_loss=3.71, ppl=13.09, wps=3836.2, ups=0.3, wpb=12957.8, bsz=413, num_updates=230500, lr=6.58665e-05, gnorm=1.238, loss_scale=2, train_wall=337, gb_free=14.8, wall=516455
pred_new.size(): torch.Size([2703, 42808])
pred_new.size(): torch.Size([4446, 42808])
2023-09-26 10:13:14 | INFO | train_inner | epoch 026:   4148 / 9060 loss=7.53, nll_loss=3.675, ppl=12.77, wps=3880.1, ups=0.3, wpb=12898.9, bsz=427.4, num_updates=230600, lr=6.58522e-05, gnorm=1.227, loss_scale=2, train_wall=332, gb_free=12.8, wall=516787
2023-09-26 10:18:52 | INFO | train_inner | epoch 026:   4248 / 9060 loss=7.598, nll_loss=3.715, ppl=13.13, wps=3837.2, ups=0.3, wpb=12959.9, bsz=459.3, num_updates=230700, lr=6.58379e-05, gnorm=1.213, loss_scale=2, train_wall=337, gb_free=12.4, wall=517125
2023-09-26 10:24:35 | INFO | train_inner | epoch 026:   4348 / 9060 loss=7.806, nll_loss=3.765, ppl=13.59, wps=3790.8, ups=0.29, wpb=13003.6, bsz=446.6, num_updates=230800, lr=6.58237e-05, gnorm=1.244, loss_scale=2, train_wall=343, gb_free=13.8, wall=517468
2023-09-26 10:30:21 | INFO | train_inner | epoch 026:   4448 / 9060 loss=7.712, nll_loss=3.776, ppl=13.7, wps=3770.8, ups=0.29, wpb=13042.2, bsz=445.4, num_updates=230900, lr=6.58094e-05, gnorm=1.228, loss_scale=2, train_wall=346, gb_free=13.6, wall=517814
ter_threshold: 0.530946
num_accepted / total 27 72
loss token level: tensor(10221.3047, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8752., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5916, 42808])
2023-09-26 10:35:54 | INFO | train_inner | epoch 026:   4548 / 9060 loss=7.682, nll_loss=3.783, ppl=13.77, wps=3908.8, ups=0.3, wpb=13020.9, bsz=417.8, num_updates=231000, lr=6.57952e-05, gnorm=1.244, loss_scale=2, train_wall=333, gb_free=13.9, wall=518147
2023-09-26 10:41:21 | INFO | train_inner | epoch 026:   4648 / 9060 loss=7.678, nll_loss=3.762, ppl=13.57, wps=3982.7, ups=0.31, wpb=13016.8, bsz=424.9, num_updates=231100, lr=6.57809e-05, gnorm=1.238, loss_scale=2, train_wall=327, gb_free=14.1, wall=518474
lprobs.size(): torch.Size([2400, 42808])
2023-09-26 10:46:56 | INFO | train_inner | epoch 026:   4748 / 9060 loss=7.563, nll_loss=3.715, ppl=13.13, wps=3871.3, ups=0.3, wpb=13006.7, bsz=413.8, num_updates=231200, lr=6.57667e-05, gnorm=1.22, loss_scale=2, train_wall=336, gb_free=13.7, wall=518810
lprobs.size(): torch.Size([3584, 42808])
2023-09-26 10:52:37 | INFO | train_inner | epoch 026:   4848 / 9060 loss=7.466, nll_loss=3.686, ppl=12.87, wps=3830.3, ups=0.29, wpb=13042.6, bsz=436.3, num_updates=231300, lr=6.57525e-05, gnorm=1.225, loss_scale=2, train_wall=340, gb_free=13.8, wall=519150
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([2684, 42808])
2023-09-26 10:58:11 | INFO | train_inner | epoch 026:   4948 / 9060 loss=7.493, nll_loss=3.715, ppl=13.13, wps=3863.7, ups=0.3, wpb=12896.5, bsz=432.6, num_updates=231400, lr=6.57383e-05, gnorm=1.222, loss_scale=2, train_wall=334, gb_free=15.9, wall=519484
lprobs.size(): torch.Size([3400, 42808])
2023-09-26 11:03:43 | INFO | train_inner | epoch 026:   5048 / 9060 loss=7.558, nll_loss=3.709, ppl=13.08, wps=3911.1, ups=0.3, wpb=13006.5, bsz=441.8, num_updates=231500, lr=6.57241e-05, gnorm=1.221, loss_scale=2, train_wall=332, gb_free=13.4, wall=519817
2023-09-26 11:09:19 | INFO | train_inner | epoch 026:   5148 / 9060 loss=7.504, nll_loss=3.684, ppl=12.85, wps=3866.5, ups=0.3, wpb=12994.9, bsz=434.4, num_updates=231600, lr=6.57099e-05, gnorm=1.244, loss_scale=2, train_wall=336, gb_free=13, wall=520153
pred_new.size(): torch.Size([5226, 42808])
2023-09-26 11:14:59 | INFO | train_inner | epoch 026:   5248 / 9060 loss=7.714, nll_loss=3.783, ppl=13.76, wps=3817.4, ups=0.29, wpb=12979.8, bsz=451.2, num_updates=231700, lr=6.56957e-05, gnorm=1.27, loss_scale=2, train_wall=340, gb_free=13.1, wall=520493
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3000, 42808])
2023-09-26 11:20:43 | INFO | train_inner | epoch 026:   5348 / 9060 loss=7.678, nll_loss=3.788, ppl=13.82, wps=3772.7, ups=0.29, wpb=12946, bsz=436.9, num_updates=231800, lr=6.56815e-05, gnorm=1.261, loss_scale=2, train_wall=343, gb_free=13.8, wall=520836
2023-09-26 11:26:18 | INFO | train_inner | epoch 026:   5448 / 9060 loss=7.481, nll_loss=3.696, ppl=12.96, wps=3862, ups=0.3, wpb=12949.1, bsz=418.2, num_updates=231900, lr=6.56674e-05, gnorm=1.206, loss_scale=2, train_wall=335, gb_free=14.6, wall=521171
pred_new.size(): torch.Size([1836, 42808])
pred_new.size(): torch.Size([5480, 42808])
2023-09-26 11:31:51 | INFO | train_inner | epoch 026:   5548 / 9060 loss=7.643, nll_loss=3.746, ppl=13.42, wps=3876.2, ups=0.3, wpb=12931.3, bsz=428.3, num_updates=232000, lr=6.56532e-05, gnorm=1.229, loss_scale=2, train_wall=333, gb_free=13.5, wall=521505
pred_new.size(): torch.Size([8680, 42808])
lprobs.size(): torch.Size([3496, 42808])
2023-09-26 11:37:31 | INFO | train_inner | epoch 026:   5648 / 9060 loss=7.651, nll_loss=3.708, ppl=13.07, wps=3823.8, ups=0.29, wpb=12989.4, bsz=453.2, num_updates=232100, lr=6.56391e-05, gnorm=1.219, loss_scale=2, train_wall=339, gb_free=14.1, wall=521845
pred_new.size(): torch.Size([714, 42808])
lprobs.size(): torch.Size([3120, 42808])
ter_threshold: 0.522594
num_accepted / total 71 128
loss token level: tensor(8747.2617, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7232., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.522676
num_accepted / total 20 56
loss token level: tensor(9776.5703, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4976., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.522715
num_accepted / total 17 56
loss token level: tensor(9475.6631, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4736., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6570, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([6480, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4532, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1664, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6110, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([4050, 42808])
lprobs.size(): torch.Size([3240, 42808])
lprobs.size(): torch.Size([3344, 42808])
pred_new.size(): torch.Size([3648, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([9798, 42808])
ter_threshold: 0.5252049999999999
num_accepted / total 36 72
loss token level: tensor(9175.2520, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7256., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5481, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1872, 42808])
pred_new.size(): torch.Size([3780, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.5256609999999999
num_accepted / total 94 128
loss token level: tensor(8777.3467, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(16344., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3318, 42808])
pred_new.size(): torch.Size([4902, 42808])
lprobs.size(): torch.Size([2816, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([8610, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3072, 42808])
lprobs.size(): torch.Size([3328, 42808])
pred_new.size(): torch.Size([8349, 42808])
ter_threshold: 0.526753
num_accepted / total 43 104
loss token level: tensor(8863.9746, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5496., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1830, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([5202, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.527816
num_accepted / total 36 88
loss token level: tensor(8181.5200, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7136., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3224, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.528187
num_accepted / total 39 112
loss token level: tensor(12553.6562, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(8616., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.528256
num_accepted / total 24 56
loss token level: tensor(8680.7920, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11200., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2304, 42808])
pred_new.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([2750, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2184, 42808])
pred_new.size(): torch.Size([3960, 42808])
ter_threshold: 0.528753
num_accepted / total 33 72
loss token level: tensor(9115.8594, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6472., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2370, 42808])
pred_new.size(): torch.Size([7968, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.529025
num_accepted / total 19 56
loss token level: tensor(7684.6318, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7792., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.5293129999999999
num_accepted / total 22 72
loss token level: tensor(8031.5220, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3624., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6948, 42808])
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.5296989999999999
num_accepted / total 41 80
loss token level: tensor(9213.1631, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(11616., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.529883
num_accepted / total 52 88
loss token level: tensor(8841.2344, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9152., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([6720, 42808])
ter_threshold: 0.530029
num_accepted / total 132 176
loss token level: tensor(8415.6279, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(14816., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2760, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.5302439999999999
num_accepted / total 79 160
loss token level: tensor(10844.1738, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10144., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.530248
num_accepted / total 25 80
loss token level: tensor(8285.4727, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7020., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6365, 42808])
pred_new.size(): torch.Size([1908, 42808])
lprobs.size(): torch.Size([3016, 42808])
pred_new.size(): torch.Size([3150, 42808])
pred_new.size(): torch.Size([2480, 42808])
pred_new.size(): torch.Size([10260, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([3675, 42808])
ter_threshold: 0.531193
num_accepted / total 12 64
loss token level: tensor(9707.5410, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5024., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3429, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([2772, 42808])
pred_new.size(): torch.Size([1022, 42808])
pred_new.size(): torch.Size([3528, 42808])
ter_threshold: 0.531547
num_accepted / total 7 24
loss token level: tensor(10352.5508, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4568., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8736, 42808])
pred_new.size(): torch.Size([6372, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([2064, 42808])
pred_new.size(): torch.Size([4200, 42808])
pred_new.size(): torch.Size([9088, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3420, 42808])
pred_new.size(): torch.Size([9230, 42808])
2023-09-26 11:43:14 | INFO | train_inner | epoch 026:   5748 / 9060 loss=7.333, nll_loss=3.615, ppl=12.25, wps=3756.2, ups=0.29, wpb=12886.1, bsz=401.8, num_updates=232200, lr=6.56249e-05, gnorm=1.199, loss_scale=2, train_wall=343, gb_free=15.3, wall=522188
2023-09-26 11:48:56 | INFO | train_inner | epoch 026:   5848 / 9060 loss=7.635, nll_loss=3.743, ppl=13.39, wps=3810.4, ups=0.29, wpb=13008.8, bsz=428.9, num_updates=232300, lr=6.56108e-05, gnorm=1.249, loss_scale=2, train_wall=341, gb_free=12.4, wall=522529
pred_new.size(): torch.Size([2184, 42808])
2023-09-26 11:54:46 | INFO | train_inner | epoch 026:   5948 / 9060 loss=7.689, nll_loss=3.734, ppl=13.31, wps=3727.1, ups=0.29, wpb=13047.7, bsz=443.1, num_updates=232400, lr=6.55967e-05, gnorm=1.241, loss_scale=2, train_wall=350, gb_free=13.4, wall=522879
ter_threshold: 0.532482
num_accepted / total 131 176
loss token level: tensor(8074.3711, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9024., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 12:00:15 | INFO | train_inner | epoch 026:   6048 / 9060 loss=7.601, nll_loss=3.711, ppl=13.09, wps=3962, ups=0.3, wpb=13043.4, bsz=443.8, num_updates=232500, lr=6.55826e-05, gnorm=1.215, loss_scale=2, train_wall=329, gb_free=13.4, wall=523208
2023-09-26 12:05:59 | INFO | train_inner | epoch 026:   6148 / 9060 loss=7.645, nll_loss=3.75, ppl=13.46, wps=3737.9, ups=0.29, wpb=12878.4, bsz=435.2, num_updates=232600, lr=6.55685e-05, gnorm=1.227, loss_scale=2, train_wall=344, gb_free=15.5, wall=523553
2023-09-26 12:11:36 | INFO | train_inner | epoch 026:   6248 / 9060 loss=7.597, nll_loss=3.731, ppl=13.28, wps=3880.6, ups=0.3, wpb=13067.2, bsz=453.6, num_updates=232700, lr=6.55544e-05, gnorm=1.205, loss_scale=2, train_wall=336, gb_free=13.8, wall=523890
2023-09-26 12:17:25 | INFO | train_inner | epoch 026:   6348 / 9060 loss=7.573, nll_loss=3.715, ppl=13.13, wps=3702.9, ups=0.29, wpb=12911.3, bsz=416.8, num_updates=232800, lr=6.55403e-05, gnorm=1.236, loss_scale=2, train_wall=348, gb_free=12.8, wall=524238
2023-09-26 12:23:28 | INFO | train_inner | epoch 026:   6448 / 9060 loss=7.654, nll_loss=3.714, ppl=13.12, wps=3574, ups=0.28, wpb=12986, bsz=449.1, num_updates=232900, lr=6.55262e-05, gnorm=1.237, loss_scale=2, train_wall=363, gb_free=12.8, wall=524602
lprobs.size(): torch.Size([3584, 42808])
2023-09-26 12:29:05 | INFO | train_inner | epoch 026:   6548 / 9060 loss=7.595, nll_loss=3.745, ppl=13.41, wps=3828.5, ups=0.3, wpb=12905.8, bsz=419.6, num_updates=233000, lr=6.55122e-05, gnorm=1.241, loss_scale=2, train_wall=337, gb_free=15.1, wall=524939
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 12:34:48 | INFO | train_inner | epoch 026:   6648 / 9060 loss=7.628, nll_loss=3.721, ppl=13.19, wps=3788.5, ups=0.29, wpb=12973.4, bsz=423.2, num_updates=233100, lr=6.54981e-05, gnorm=1.213, loss_scale=2, train_wall=342, gb_free=14, wall=525281
ter_threshold: 0.5331049999999999
num_accepted / total 24 80
loss token level: tensor(8351.0938, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3828., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
2023-09-26 12:40:28 | INFO | train_inner | epoch 026:   6748 / 9060 loss=7.603, nll_loss=3.749, ppl=13.45, wps=3810.7, ups=0.29, wpb=12953.5, bsz=421, num_updates=233200, lr=6.54841e-05, gnorm=1.251, loss_scale=2, train_wall=340, gb_free=13.1, wall=525621
lprobs.size(): torch.Size([3472, 42808])
2023-09-26 12:46:10 | INFO | train_inner | epoch 026:   6848 / 9060 loss=7.409, nll_loss=3.649, ppl=12.55, wps=3808.6, ups=0.29, wpb=13025.3, bsz=397, num_updates=233300, lr=6.547e-05, gnorm=1.182, loss_scale=2, train_wall=342, gb_free=13.2, wall=525963
2023-09-26 12:51:52 | INFO | train_inner | epoch 026:   6948 / 9060 loss=7.612, nll_loss=3.763, ppl=13.58, wps=3804.2, ups=0.29, wpb=13038, bsz=413.4, num_updates=233400, lr=6.5456e-05, gnorm=1.233, loss_scale=2, train_wall=342, gb_free=14.6, wall=526306
lprobs.size(): torch.Size([3160, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 12:57:44 | INFO | train_inner | epoch 026:   7048 / 9060 loss=7.568, nll_loss=3.747, ppl=13.43, wps=3677, ups=0.28, wpb=12941.5, bsz=420.8, num_updates=233500, lr=6.5442e-05, gnorm=1.267, loss_scale=2, train_wall=352, gb_free=12.1, wall=526658
pred_new.size(): torch.Size([5460, 42808])
2023-09-26 13:03:19 | INFO | train_inner | epoch 026:   7148 / 9060 loss=7.639, nll_loss=3.751, ppl=13.46, wps=3883.4, ups=0.3, wpb=12977, bsz=427.9, num_updates=233600, lr=6.5428e-05, gnorm=1.225, loss_scale=2, train_wall=334, gb_free=14.3, wall=526992
lprobs.size(): torch.Size([2448, 42808])
2023-09-26 13:08:58 | INFO | train_inner | epoch 026:   7248 / 9060 loss=7.559, nll_loss=3.757, ppl=13.52, wps=3793.9, ups=0.29, wpb=12892.1, bsz=406.4, num_updates=233700, lr=6.5414e-05, gnorm=1.225, loss_scale=2, train_wall=340, gb_free=14.9, wall=527332
lprobs.size(): torch.Size([2952, 42808])
pred_new.size(): torch.Size([5508, 42808])
2023-09-26 13:14:50 | INFO | train_inner | epoch 026:   7348 / 9060 loss=7.727, nll_loss=3.775, ppl=13.69, wps=3661.4, ups=0.28, wpb=12873.5, bsz=428.2, num_updates=233800, lr=6.54e-05, gnorm=1.257, loss_scale=2, train_wall=351, gb_free=13.9, wall=527683
ter_threshold: 0.533872
num_accepted / total 63 128
loss token level: tensor(8275.2969, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6448., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 13:20:40 | INFO | train_inner | epoch 026:   7448 / 9060 loss=7.628, nll_loss=3.739, ppl=13.36, wps=3708.4, ups=0.29, wpb=12986.6, bsz=414.4, num_updates=233900, lr=6.5386e-05, gnorm=1.238, loss_scale=2, train_wall=350, gb_free=13.6, wall=528034
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 13:26:17 | INFO | train_inner | epoch 026:   7548 / 9060 loss=7.583, nll_loss=3.711, ppl=13.09, wps=3869.3, ups=0.3, wpb=13024.8, bsz=442.7, num_updates=234000, lr=6.5372e-05, gnorm=1.243, loss_scale=2, train_wall=336, gb_free=14.6, wall=528370
2023-09-26 13:31:56 | INFO | train_inner | epoch 026:   7648 / 9060 loss=7.835, nll_loss=3.886, ppl=14.79, wps=3805.1, ups=0.29, wpb=12908.4, bsz=452.5, num_updates=234100, lr=6.53581e-05, gnorm=1.272, loss_scale=2, train_wall=339, gb_free=13.4, wall=528709
2023-09-26 13:37:39 | INFO | train_inner | epoch 026:   7748 / 9060 loss=7.595, nll_loss=3.74, ppl=13.36, wps=3792.6, ups=0.29, wpb=13000.2, bsz=414, num_updates=234200, lr=6.53441e-05, gnorm=1.215, loss_scale=4, train_wall=343, gb_free=12.6, wall=529052
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-26 13:43:14 | INFO | train_inner | epoch 026:   7848 / 9060 loss=7.496, nll_loss=3.713, ppl=13.11, wps=3888.4, ups=0.3, wpb=13024.9, bsz=418.9, num_updates=234300, lr=6.53302e-05, gnorm=1.221, loss_scale=4, train_wall=335, gb_free=14.7, wall=529387
pred_new.size(): torch.Size([4524, 42808])
lprobs.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([3120, 42808])
2023-09-26 13:48:54 | INFO | train_inner | epoch 026:   7948 / 9060 loss=7.465, nll_loss=3.719, ppl=13.17, wps=3803.4, ups=0.29, wpb=12940.3, bsz=436.6, num_updates=234400, lr=6.53162e-05, gnorm=1.198, loss_scale=4, train_wall=340, gb_free=13.4, wall=529727
pred_new.size(): torch.Size([2736, 42808])
2023-09-26 13:54:31 | INFO | train_inner | epoch 026:   8048 / 9060 loss=7.42, nll_loss=3.66, ppl=12.64, wps=3838.9, ups=0.3, wpb=12941.5, bsz=413.8, num_updates=234500, lr=6.53023e-05, gnorm=1.194, loss_scale=4, train_wall=337, gb_free=14.5, wall=530065
pred_new.size(): torch.Size([6006, 42808])
pred_new.size(): torch.Size([9353, 42808])
2023-09-26 14:00:07 | INFO | train_inner | epoch 026:   8148 / 9060 loss=7.48, nll_loss=3.667, ppl=12.7, wps=3866.5, ups=0.3, wpb=12992.8, bsz=459.5, num_updates=234600, lr=6.52884e-05, gnorm=1.191, loss_scale=4, train_wall=336, gb_free=14.4, wall=530401
lprobs.size(): torch.Size([3520, 42808])
2023-09-26 14:05:48 | INFO | train_inner | epoch 026:   8248 / 9060 loss=7.728, nll_loss=3.771, ppl=13.65, wps=3803, ups=0.29, wpb=12980.1, bsz=440.6, num_updates=234700, lr=6.52745e-05, gnorm=1.254, loss_scale=4, train_wall=341, gb_free=14.9, wall=530742
lprobs.size(): torch.Size([3400, 42808])
2023-09-26 14:11:42 | INFO | train_inner | epoch 026:   8348 / 9060 loss=7.645, nll_loss=3.765, ppl=13.6, wps=3678.6, ups=0.28, wpb=13016.8, bsz=449, num_updates=234800, lr=6.52606e-05, gnorm=1.222, loss_scale=4, train_wall=354, gb_free=14, wall=531096
2023-09-26 14:17:37 | INFO | train_inner | epoch 026:   8448 / 9060 loss=7.577, nll_loss=3.704, ppl=13.03, wps=3632.8, ups=0.28, wpb=12892.4, bsz=418.9, num_updates=234900, lr=6.52467e-05, gnorm=1.255, loss_scale=4, train_wall=355, gb_free=14.5, wall=531451
2023-09-26 14:23:12 | INFO | train_inner | epoch 026:   8548 / 9060 loss=7.61, nll_loss=3.738, ppl=13.34, wps=3901.1, ups=0.3, wpb=13047.6, bsz=438.2, num_updates=235000, lr=6.52328e-05, gnorm=1.242, loss_scale=4, train_wall=334, gb_free=15.7, wall=531785
pred_new.size(): torch.Size([3472, 42808])
2023-09-26 14:29:03 | INFO | train_inner | epoch 026:   8648 / 9060 loss=7.698, nll_loss=3.781, ppl=13.75, wps=3696.6, ups=0.28, wpb=12982.8, bsz=423.6, num_updates=235100, lr=6.52189e-05, gnorm=1.237, loss_scale=4, train_wall=351, gb_free=13.7, wall=532136
2023-09-26 14:34:41 | INFO | train_inner | epoch 026:   8748 / 9060 loss=7.661, nll_loss=3.751, ppl=13.46, wps=3842.8, ups=0.3, wpb=12992.8, bsz=433, num_updates=235200, lr=6.52051e-05, gnorm=1.222, loss_scale=4, train_wall=338, gb_free=14.2, wall=532474
ter_threshold: 0.535221
num_accepted / total 27 96
loss token level: tensor(8657.8154, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5736., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3480, 42808])
pred_new.size(): torch.Size([6032, 42808])
2023-09-26 14:40:39 | INFO | train_inner | epoch 026:   8848 / 9060 loss=7.811, nll_loss=3.838, ppl=14.3, wps=3616.3, ups=0.28, wpb=12950.6, bsz=431, num_updates=235300, lr=6.51912e-05, gnorm=1.256, loss_scale=4, train_wall=358, gb_free=12.9, wall=532833
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3200, 42808])
2023-09-26 14:46:15 | INFO | train_inner | epoch 026:   8948 / 9060 loss=7.441, nll_loss=3.682, ppl=12.84, wps=3847.5, ups=0.3, wpb=12932.9, bsz=436.3, num_updates=235400, lr=6.51774e-05, gnorm=1.189, loss_scale=4, train_wall=336, gb_free=13.9, wall=533169
2023-09-26 14:51:55 | INFO | train_inner | epoch 026:   9048 / 9060 loss=7.601, nll_loss=3.727, ppl=13.24, wps=3831.9, ups=0.29, wpb=13028.6, bsz=448.9, num_updates=235500, lr=6.51635e-05, gnorm=1.224, loss_scale=4, train_wall=340, gb_free=13.6, wall=533509
2023-09-26 14:52:41 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-26 14:52:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-26 14:52:42 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-26 14:52:42 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-26 14:52:42 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher völlig gerechtfertigt.
2023-09-26 14:52:42 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-26 14:52:43 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-26 14:52:43 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-26 14:52:43 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-26 14:52:43 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-26 14:52:44 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-26 14:52:44 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-26 14:52:44 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und war ein voller Erfolg.
2023-09-26 14:52:44 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-26 14:52:45 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ein gutes neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-26 14:52:45 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-26 14:52:45 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Initiativmonopol, das wir respektieren.
2023-09-26 14:52:45 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-26 14:52:46 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chatgesprächen.
2023-09-26 14:52:46 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-26 14:52:46 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten digitales TV und Internetzugang, die sowohl für Geschäftsreisende als auch für Urlauber gleichermaßen geeignet sind.
2023-09-26 14:52:46 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-26 14:52:47 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-26 14:52:47 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-26 14:52:47 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-26 14:52:47 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-26 14:52:48 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU insgesamt riesige Mengen an Energie verschwendet.
2023-09-26 14:52:48 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-26 14:52:49 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin enthält einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner aktuellen Nummer.
2023-09-26 14:52:49 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-26 14:52:49 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellung auch in Kürze im Haushalt der Union niederschlagen.
2023-09-26 14:52:49 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-26 14:52:50 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsnormen sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-26 14:52:50 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-26 14:52:51 | INFO | fairseq.tasks.translation | example hypothesis: Hier ist ein konkretes Beispiel: die weithin bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-26 14:52:51 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-26 14:52:51 | INFO | fairseq.tasks.translation | example hypothesis: Darf ich Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-26 14:52:51 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-26 14:52:52 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie sich gewünscht hätten?
2023-09-26 14:52:52 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-26 14:52:52 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Hauptsitz und Produktionshallen in Stans.
2023-09-26 14:52:52 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-26 14:52:53 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-26 14:52:53 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-26 14:52:54 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jeder von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-26 14:52:54 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-26 14:52:54 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution bestehen.
2023-09-26 14:52:54 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-26 14:52:55 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potentielle Käufer veranlassen, sich über die Qualität Ihrer Dienstleistungen und Produkte zu informieren.
2023-09-26 14:52:55 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-26 14:52:55 | INFO | fairseq.tasks.translation | example hypothesis: Während sich die Zentralbanken weiter in unbekanntes Gebiet wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-26 14:52:55 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-26 14:52:56 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-26 14:52:56 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-26 14:52:57 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze diese Aussprache auch, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzufordern.
2023-09-26 14:52:57 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-26 14:52:57 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte im Umkreis von etwa 8 km vom Strip entfernt.
2023-09-26 14:52:57 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-26 14:52:58 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem bekannten Open Source Php-Nuke Web Portal System basiert.
2023-09-26 14:52:58 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-26 14:52:58 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Realisierung von Klanghandbüchern an.
2023-09-26 14:52:58 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-26 14:52:59 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck und Direktdruck erhältlich.
2023-09-26 14:52:59 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-26 14:53:00 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, kann sich aber bei der Sicherung der Stabilität des Landes auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen.
2023-09-26 14:53:00 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-26 14:53:00 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Abzug Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme eingezahlt haben.
2023-09-26 14:53:00 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-26 14:53:01 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) verwendet das Ascent Ti-Modell als Basis.
2023-09-26 14:53:01 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-26 14:53:02 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine kostenlose Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-26 14:53:02 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-26 14:53:02 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind.
2023-09-26 14:53:02 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-26 14:53:03 | INFO | fairseq.tasks.translation | example hypothesis: Noch immer sind die Thatcher-Ideen zu niedrigeren und transparenteren Steuerstrukturen und einer zentralen Kontrolle der Haushaltsausgaben definitiv Schlüsselbestandteile seiner Agenda.
2023-09-26 14:53:03 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-26 14:53:04 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer müssen splashutils erneut emergen, damit es richtig funktioniert.
2023-09-26 14:53:04 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-26 14:53:04 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können keine Gegenstände kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser nutzen.
2023-09-26 14:53:04 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-26 14:53:05 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum diese Kriterien nur innerhalb der Grenzen Europas gelten sollten.
2023-09-26 14:53:05 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-26 14:53:06 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994.
2023-09-26 14:53:06 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-26 14:53:06 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu bestimmten grundsätzlichen Details des Abkommens mit den Vereinigten Staaten vorlegen müssen.
2023-09-26 14:53:06 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-26 14:53:07 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderauflage - unser breites Sortiment an PlastikBabyartikeln überzeugt nicht zuletzt durch seine hervorragende Verarbeitung.
2023-09-26 14:53:07 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-26 14:53:08 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-26 14:53:08 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-26 14:53:08 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnis Kenntnis von Sachverhalten zu informieren, die mit diesen AGB nicht vereinbar sind.
2023-09-26 14:53:08 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-26 14:53:09 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht und erkannt hat, dass institutionelle Veränderungen notwendig sind, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung benötigt.
2023-09-26 14:53:09 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-26 14:53:10 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog als Informationsportal für unsere Kunden konzipiert, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-26 14:53:10 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-26 14:53:10 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die erzielt wurden, wenn wir all die Themen betrachten, die derzeit diskutiert werden, und die etwas betreffen, was gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-26 14:53:10 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-26 14:53:11 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Dämpfern für erstklassigen Fahrspaß.
2023-09-26 14:53:11 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-26 14:53:12 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal ist es dem Berichterstatter gelungen, die zuweilen unterschiedlichen Meinungen und Beiträge zusammenzufassen und - wie ich sagen würde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-26 14:53:12 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-26 14:53:12 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlägen mit einem trockenen ESP für den unteren Leistungsbereich.
2023-09-26 14:53:12 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-26 14:53:13 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt, befinden Sie sich bereits in einem fremden Land.
2023-09-26 14:53:13 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-26 14:53:14 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-26 14:53:14 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-26 14:53:14 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und mit unserer Staatengemeinschaft zu tun haben.
2023-09-26 14:53:14 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-26 14:53:15 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restanten qui se battront pour leur part de 32 000 $.
2023-09-26 14:53:15 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-26 14:53:16 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit real sein soll, dann ist eine einfache, schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-26 14:53:16 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-26 14:53:16 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Stoffe nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-26 14:53:16 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-26 14:53:17 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine andere: die Notsituation der Kinder, des schwächsten Bevölkerungsschichten, die keine Familie, keinen Schutz und keinen Staat mehr haben.
2023-09-26 14:53:17 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-26 14:53:18 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Abtrennens seit 2003 von der EU geregelt ist, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können.
2023-09-26 14:53:18 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-26 14:53:18 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, nicht innerhalb des Ersten erkannt wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, solange man sein wahres Selbst nicht kennt..........., ohne eigenes wahres Selbst
2023-09-26 14:53:18 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-26 14:53:19 | INFO | fairseq.tasks.translation | example hypothesis: Es ist daher wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in unserer Macht Stehende tut, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Wählerregistrierung wieder zu eröffnen.............
2023-09-26 14:53:19 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-26 14:53:20 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern Meinungsfreiheit, freie und unabhängige Wahlen und Versammlungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und der Öffentlichkeit muss klar gemacht werden, dass niemand über dem Gesetz steht.
2023-09-26 14:53:20 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-26 14:53:21 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java-Programmiersprache mit J2EE-Techniken implementiert, was Plattform- und Betriebssystem-Unabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-26 14:53:21 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-26 14:53:21 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatter. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur deutlicheren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen daher für eine Klärung des Anhangs.
2023-09-26 14:53:21 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-26 14:53:22 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung grundlegender Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt wurden, nicht als unvereinbar mit den WTO-Verträgen angesehen werden.
2023-09-26 14:53:22 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-26 14:53:23 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische öffentlich-rechtliche Radio RTE mit einer Frau teilgenommen, die sehr besorgt war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für die Entwicklungshilfe zu kürzen.......... zu kürzen, die Ausgaben für Entwicklungshilfe
2023-09-26 14:53:23 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-26 14:53:24 | INFO | fairseq.tasks.translation | example hypothesis: In diesem Sinne hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte der Kommission nochmals zu ihrer besonnenen Haltung gratulieren.
2023-09-26 14:53:24 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-26 14:53:24 | INFO | fairseq.tasks.translation | example hypothesis: Ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas Besonderes wie die Senkung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist.
2023-09-26 14:53:24 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-26 14:53:25 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Saison der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und steht Spielern aller Nationalitäten offen.
2023-09-26 14:53:25 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-26 14:53:26 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident, ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher und relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-26 14:53:26 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-26 14:53:27 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken hieße, eine bestimmte Art von Vertragsbeziehung zwischen Personen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen oft die tatsächliche oder wahrgenommene Gefahr, von institutioneller Hegemonie zerschlagen zu werden)!
2023-09-26 14:53:27 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-26 14:53:27 | INFO | fairseq.tasks.translation | example hypothesis: In der gemeinschaftlichen Rechtsprechung zu einem Thema, das personenbezogene Daten betrifft, sollten das Gericht und das Gericht erster Instanz eingreifen können, wenn beispielsweise Bürger Ansprüche erheben oder eine einheitliche Auslegung der Konvention erforderlich ist.
2023-09-26 14:53:27 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-26 14:53:28 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist eines der lustigsten Autos unter 50.000 US-Dollar. Wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren. Wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Lineup kostenlos ausprobieren.
2023-09-26 14:53:28 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-26 14:53:29 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung dieser Angelegenheit.
2023-09-26 14:53:29 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-26 14:53:30 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen guten hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrillter Hecht, Forelle mit Mandeln.
2023-09-26 14:53:30 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-26 14:53:30 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, einen Gesamtüberblick zu bieten, der es uns ermöglicht, die verschiedenen Fragen eingehender zu behandeln und zu prüfen, welche Impulse die Europäische Union im Hinblick auf die Zukunft geben kann.
2023-09-26 14:53:30 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-26 14:53:31 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber der "Scardona Records", Herr Branko Paić, haben sich darauf geeinigt, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-26 14:53:31 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-26 14:53:32 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wenn Arbeitslosigkeit herrscht, wenn die bestehenden Arbeitsplätze unmittelbar gefährdet sind und die Wettbewerbsfähigkeit durch makroökonomische Strategien, steuerliche Maßnahmen und Zwänge, die nicht an die derzeitige Situation vor Ort angepasst sind, allmählich ausgehöhlt wird.
2023-09-26 14:53:32 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-26 14:53:33 | INFO | fairseq.tasks.translation | example hypothesis: Der Vorschlag für eine Verordnung, den uns die Kommission vorlegt, geht in die gleiche allgemeine Richtung wie die geltende Verordnung von 1994, zu der das Europäische Parlament durch ein hervorragendes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, einen Beitrag geleistet hat.
2023-09-26 14:53:33 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-26 14:53:34 | INFO | fairseq.tasks.translation | example hypothesis: So erweitert diese schwedische Initiative den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Konsequenzen für den Rechts- und Rechtsbereich, wodurch Norwegen und Island, in denen die im Schengen-Besitzstand enthaltenen gemeinsamen Auslieferungsbestimmungen gelten werden, zu Norwegen und Island werden, in denen die gemeinsamen Auslieferungsbestimmungen Anwendung finden werden.
2023-09-26 14:53:34 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-26 14:53:34 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schmiedeboot den Mississippi hinunter fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der rein dynamisch ist, und vor allem werden wir große Freunde sein........., und vor allem, wir werden große Freunde sein...
2023-09-26 14:53:34 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-26 14:53:35 | INFO | fairseq.tasks.translation | example hypothesis: Konkret harmonisiert die Richtlinie die Definition der durch Personen oder Rechtspersonen verursachten Verschmutzung durch Schiffe, den Umfang der Reaktion darauf und den Strafbarkeit der Sanktionen, die im Falle von Verstößen gegen Personen verhängt werden können.
2023-09-26 14:53:35 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-26 14:53:36 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner verübten und eine Gruppe von Bergleuten filmen, die seit Jahren von einem autoritären Regime verfolgt werden, das sich über jedes Prinzip der Demokratie hinwegsetzt.
2023-09-26 14:53:36 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-26 14:53:37 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseurshop und ein Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Umkleidekabine, eine Wechselstube, kostenfreie Schuhputzmaschine und WLAN-Internetzugang. Die 346 Zimmer und Suiten des Omni Royal Orleans bieten Blick auf den Innenhof und das französische Viertel.
2023-09-26 14:53:37 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-26 14:53:38 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der Thermalquelle verdankt, die Königin D. Leonor, die Frau des Königs D. João II, geliebt und durch ihre international bekannten Keramiken für ihre figürlichen und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-26 14:53:38 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-26 14:53:39 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute Befürworter des Westens auf der einen Seite und Anhänger des früheren Regimes auf der anderen Seite handelt, ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-26 14:53:39 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-26 14:53:40 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir dessen bewusst, lassen Sie mich das sagen, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die wahllos zwischen Flüssen und Meer fahren, nicht auf diese Weise abgedeckt werden, und das ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte......., der irgendwie irgendwie abgedeckt werden sollte, und das ist ein Punkt, der
2023-09-26 14:53:40 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-26 14:53:41 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Hauptversammlung aufgrund seines Status als Aktionär Informationen zur Verfügung gestellt, so sind diese auf Verlangen an jeden anderen Aktionär in der Hauptversammlung zu übermitteln, auch wenn diese Informationen für eine angemessene Auswertung eines Tagesordnungspunktes nicht erforderlich sind.
2023-09-26 14:53:41 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-26 14:53:41 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch nachträglich kontrollieren, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die normalerweise in den Taschen verschiedener Diktatoren landen und ihren guten Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen Menschen in unseren eigenen Ländern leben, die auch ein sehr elendes Leben führen.
2023-09-26 14:53:41 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-26 14:53:42 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - weil sie sagen, dass Flugzeuge aus einem der Mitgliedstaaten oder der NATO an diesem Kriegsakt beteiligt gewesen sein könnten -, mit Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, verschwiegen oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen und die ganze Wahrheit sagen können...... können wir die Fakten wirklich ans Licht bringen und die ganze Wahrheit sagen können.....
2023-09-26 14:53:42 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-26 14:53:43 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Bezirk Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug von der Innenstadt entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet. Die komfortable Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet..... Die komfortable Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet und sind im charmanten Landhaus
2023-09-26 14:53:43 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-26 14:53:44 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich sowie mit unserem Geschäftsbereich Defence Electronics und Indra in Spanien wird der Advanced UAV die modernsten, modularen Sensorsuite und Datenverbindungen integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die moderne, außerhalb der Regalplattformen nie erreichen können........., die für nachhaltige und zuverlässige ISTAR-Missionen, die moderne, außerhalb der Regal
2023-09-26 14:53:44 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-26 14:53:45 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz deutlich machen, dass wir nicht nur für uns, sondern weltweit auch die Produkte vom Markt nehmen können, die nicht nur für den Inlandsverbrauch, sondern auch auf dem Weltmarkt eine ernste Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt......., wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt, weil diese Produkte leicht recycelt werden können, wie Frau González Á
2023-09-26 14:53:45 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-26 14:53:46 | INFO | fairseq.tasks.translation | example hypothesis: Unter der direkten Verschwörung von Modernität und Postmoderne oder dem klaren Gegensatz von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und dauerhafte Spannung jener beiden Ästhetik-Politik anerkennen, die in den Formen der Sichtbarkeit und Verständlichkeit verbirgt, die Kunst als solche für uns identifizierbar machen - jener beiden Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führt......, die letztlich zu ihrer eigenen Selbstunterdrückung führt, die Kunst als solche identifizierbar macht
2023-09-26 14:53:46 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-26 14:53:47 | INFO | fairseq.tasks.translation | example hypothesis: Doch was den heutigen Tag betrifft, so werde ich angesichts der Bedeutung der Aussprachen und der Stellungnahmen, die Sie mir gegeben haben und die meine Ausführungen eindeutig weitgehend unterstützen, und auf der Grundlage der vorangegangenen Beschlüsse unsere Aussprachen führen, und bei der Abstimmung, wenn die vierzig Petenten nicht anwesend sind, werde ich nicht darum bitten, die Beschlußfähigkeit zu prüfen.....
2023-09-26 14:53:47 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-26 14:53:48 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips nie akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein künftiges Europa ebnen, in dem nationale Grenzen beseitigt wurden, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen......., jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern die Entwicklung einer ethnischen, religiösen
2023-09-26 14:53:48 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-26 14:53:49 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 auf vielfältige Weise als hybride Form veröffentlicht, die Rezensionen und Artikel der Quartalszeitschrift für H-Soz-u-Kult geschrieben und über Mailinglisten sowie auf den Webseiten des H-Soz-u-Kult und des Michigan-basierten H-Net an seine Abonnenten verteilt......., H-Kult und das H-Net mit Michigan-Basis H-Net in Michigan, Michigan, H
2023-09-26 14:53:49 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-26 14:53:51 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Einführung der neuen Smartphone-Generation haben Handys ihre Federn deutlich verfeinert, indem sie von einstigen Wecker-Uhren im Taschenformat über polyphonisch tootende Game Boy-Aspiranten bis hin zu Mini-PCs mit knackigem Stereo-Sound in CD-Qualität: Künftig können sie dank ihrer besonderen Kombination von Fähigkeiten von den ehemaligen me-too-Wannabes zu wegweisenden High-Tech-PCs mit neuen technologischen Entwicklungen übergehen.
2023-09-26 14:53:51 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-26 14:53:53 | INFO | fairseq.tasks.translation | example hypothesis: La defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera requiario decirir a la fuerza para que se marchen; en un principio, Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un konflito armado; en l deberá dir de qué lado está.
2023-09-26 14:53:53 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-26 14:53:53 | INFO | valid | epoch 026 | valid on 'valid' subset | loss 4.117 | nll_loss 2.148 | ppl 4.43 | bleu 28.99 | wps 16432.8 | wpb 12011.9 | bsz 398.1 | num_updates 235512 | best_bleu 29.48
2023-09-26 14:53:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 235512 updates
2023-09-26 14:53:53 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint26.pt
2023-09-26 14:53:59 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint26.pt
2023-09-26 14:54:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint26.pt (epoch 26 @ 235512 updates, score 28.99) (writing took 10.292149779037572 seconds)
2023-09-26 14:54:04 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2023-09-26 14:54:04 | INFO | train | epoch 026 | loss 7.582 | nll_loss 3.712 | ppl 13.11 | wps 3804.7 | ups 0.29 | wpb 12977.2 | bsz 430.6 | num_updates 235512 | lr 6.51619e-05 | gnorm 1.227 | loss_scale 4 | train_wall 30791 | gb_free 13.7 | wall 533637
2023-09-26 14:54:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-26 14:54:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-26 14:54:04 | INFO | fairseq.trainer | begin training epoch 27
2023-09-26 14:54:04 | INFO | fairseq_cli.train | Start iterating over samples
lprobs.size(): torch.Size([3304, 42808])
2023-09-26 14:58:58 | INFO | train_inner | epoch 027:     88 / 9060 loss=7.664, nll_loss=3.746, ppl=13.41, wps=3049.3, ups=0.24, wpb=12900.9, bsz=433.8, num_updates=235600, lr=6.51497e-05, gnorm=1.235, loss_scale=4, train_wall=340, gb_free=13.6, wall=533932
2023-09-26 15:04:50 | INFO | train_inner | epoch 027:    188 / 9060 loss=7.88, nll_loss=3.796, ppl=13.89, wps=3669.8, ups=0.28, wpb=12898.6, bsz=432.4, num_updates=235700, lr=6.51359e-05, gnorm=1.27, loss_scale=4, train_wall=351, gb_free=12.8, wall=534283
pred_new.size(): torch.Size([7600, 42808])
pred_new.size(): torch.Size([8670, 42808])
ter_threshold: 0.535783
num_accepted / total 67 112
loss token level: tensor(10430.1934, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13376., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2688, 42808])
2023-09-26 15:10:38 | INFO | train_inner | epoch 027:    288 / 9060 loss=7.705, nll_loss=3.748, ppl=13.44, wps=3738.2, ups=0.29, wpb=13013.1, bsz=424.1, num_updates=235800, lr=6.51221e-05, gnorm=1.236, loss_scale=4, train_wall=348, gb_free=14.5, wall=534631
ter_threshold: 0.5358229999999999
num_accepted / total 13 112
loss token level: tensor(8812.2881, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1812., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1710, 42808])
pred_new.size(): torch.Size([4092, 42808])
2023-09-26 15:16:28 | INFO | train_inner | epoch 027:    388 / 9060 loss=7.733, nll_loss=3.751, ppl=13.46, wps=3728.4, ups=0.29, wpb=13045.7, bsz=439.9, num_updates=235900, lr=6.51083e-05, gnorm=1.241, loss_scale=4, train_wall=350, gb_free=13.8, wall=534981
lprobs.size(): torch.Size([3024, 42808])
ter_threshold: 0.535984
num_accepted / total 7 8
loss token level: tensor(4465.9849, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(12144., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 15:22:05 | INFO | train_inner | epoch 027:    488 / 9060 loss=7.582, nll_loss=3.716, ppl=13.14, wps=3827.3, ups=0.3, wpb=12918.9, bsz=420.5, num_updates=236000, lr=6.50945e-05, gnorm=1.224, loss_scale=4, train_wall=337, gb_free=13.5, wall=535319
2023-09-26 15:27:51 | INFO | train_inner | epoch 027:    588 / 9060 loss=7.594, nll_loss=3.691, ppl=12.92, wps=3759, ups=0.29, wpb=13012.4, bsz=412.4, num_updates=236100, lr=6.50807e-05, gnorm=1.226, loss_scale=4, train_wall=346, gb_free=14.3, wall=535665
pred_new.size(): torch.Size([4788, 42808])
2023-09-26 15:33:35 | INFO | train_inner | epoch 027:    688 / 9060 loss=7.765, nll_loss=3.794, ppl=13.87, wps=3772.6, ups=0.29, wpb=12970.2, bsz=439.9, num_updates=236200, lr=6.50669e-05, gnorm=1.262, loss_scale=4, train_wall=344, gb_free=14.5, wall=536009
2023-09-26 15:39:13 | INFO | train_inner | epoch 027:    788 / 9060 loss=7.601, nll_loss=3.7, ppl=12.99, wps=3872.4, ups=0.3, wpb=13068.3, bsz=438.4, num_updates=236300, lr=6.50531e-05, gnorm=1.223, loss_scale=4, train_wall=337, gb_free=14.2, wall=536346
lprobs.size(): torch.Size([3024, 42808])
2023-09-26 15:44:57 | INFO | train_inner | epoch 027:    888 / 9060 loss=7.552, nll_loss=3.669, ppl=12.72, wps=3802.2, ups=0.29, wpb=13077.7, bsz=422.2, num_updates=236400, lr=6.50394e-05, gnorm=1.222, loss_scale=4, train_wall=344, gb_free=14.4, wall=536690
ter_threshold: 0.536442
num_accepted / total 14 40
loss token level: tensor(8125.4697, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5592., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.536458
num_accepted / total 20 56
loss token level: tensor(8581.6582, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5472., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 15:50:46 | INFO | train_inner | epoch 027:    988 / 9060 loss=7.787, nll_loss=3.77, ppl=13.64, wps=3713.2, ups=0.29, wpb=12980.9, bsz=433.5, num_updates=236500, lr=6.50256e-05, gnorm=1.257, loss_scale=4, train_wall=349, gb_free=13.1, wall=537040
2023-09-26 15:56:22 | INFO | train_inner | epoch 027:   1088 / 9060 loss=7.564, nll_loss=3.691, ppl=12.92, wps=3835.7, ups=0.3, wpb=12879.9, bsz=432.4, num_updates=236600, lr=6.50119e-05, gnorm=1.235, loss_scale=4, train_wall=336, gb_free=12.5, wall=537376
pred_new.size(): torch.Size([1920, 42808])
2023-09-26 16:02:06 | INFO | train_inner | epoch 027:   1188 / 9060 loss=7.559, nll_loss=3.661, ppl=12.65, wps=3788.9, ups=0.29, wpb=13018.3, bsz=425.9, num_updates=236700, lr=6.49981e-05, gnorm=1.24, loss_scale=4, train_wall=343, gb_free=14.5, wall=537719
lprobs.size(): torch.Size([3304, 42808])
2023-09-26 16:07:46 | INFO | train_inner | epoch 027:   1288 / 9060 loss=7.469, nll_loss=3.651, ppl=12.56, wps=3828.4, ups=0.29, wpb=13032, bsz=434.6, num_updates=236800, lr=6.49844e-05, gnorm=1.222, loss_scale=4, train_wall=340, gb_free=13.6, wall=538060
2023-09-26 16:13:34 | INFO | train_inner | epoch 027:   1388 / 9060 loss=7.657, nll_loss=3.757, ppl=13.52, wps=3717.7, ups=0.29, wpb=12925.6, bsz=424.3, num_updates=236900, lr=6.49707e-05, gnorm=1.25, loss_scale=4, train_wall=347, gb_free=13.2, wall=538407
2023-09-26 16:19:14 | INFO | train_inner | epoch 027:   1488 / 9060 loss=7.617, nll_loss=3.74, ppl=13.36, wps=3790.7, ups=0.29, wpb=12912.4, bsz=423.6, num_updates=237000, lr=6.4957e-05, gnorm=1.249, loss_scale=4, train_wall=340, gb_free=13.3, wall=538748
2023-09-26 16:24:54 | INFO | train_inner | epoch 027:   1588 / 9060 loss=7.53, nll_loss=3.687, ppl=12.88, wps=3767.6, ups=0.29, wpb=12797.3, bsz=432.5, num_updates=237100, lr=6.49433e-05, gnorm=1.221, loss_scale=4, train_wall=339, gb_free=15, wall=539088
pred_new.size(): torch.Size([1485, 42808])
lprobs.size(): torch.Size([2688, 42808])
2023-09-26 16:30:22 | INFO | train_inner | epoch 027:   1688 / 9060 loss=7.407, nll_loss=3.62, ppl=12.3, wps=3960.2, ups=0.3, wpb=12988.4, bsz=433.4, num_updates=237200, lr=6.49296e-05, gnorm=1.221, loss_scale=4, train_wall=328, gb_free=13.6, wall=539416
pred_new.size(): torch.Size([1296, 42808])
2023-09-26 16:36:02 | INFO | train_inner | epoch 027:   1788 / 9060 loss=7.533, nll_loss=3.721, ppl=13.19, wps=3808.4, ups=0.29, wpb=12954.8, bsz=418.6, num_updates=237300, lr=6.49159e-05, gnorm=1.238, loss_scale=4, train_wall=340, gb_free=14.3, wall=539756
2023-09-26 16:42:15 | INFO | train_inner | epoch 027:   1888 / 9060 loss=7.788, nll_loss=3.788, ppl=13.82, wps=3493.4, ups=0.27, wpb=13020.6, bsz=430.2, num_updates=237400, lr=6.49022e-05, gnorm=1.253, loss_scale=4, train_wall=372, gb_free=14, wall=540128
pred_new.size(): torch.Size([2262, 42808])
pred_new.size(): torch.Size([6552, 42808])
pred_new.size(): torch.Size([7854, 42808])
2023-09-26 16:48:04 | INFO | train_inner | epoch 027:   1988 / 9060 loss=7.587, nll_loss=3.689, ppl=12.9, wps=3691.7, ups=0.29, wpb=12884.1, bsz=434.4, num_updates=237500, lr=6.48886e-05, gnorm=1.247, loss_scale=4, train_wall=349, gb_free=13.1, wall=540477
lprobs.size(): torch.Size([2664, 42808])
2023-09-26 16:53:57 | INFO | train_inner | epoch 027:   2088 / 9060 loss=7.746, nll_loss=3.803, ppl=13.95, wps=3654.4, ups=0.28, wpb=12908.6, bsz=435.8, num_updates=237600, lr=6.48749e-05, gnorm=1.265, loss_scale=4, train_wall=353, gb_free=13.1, wall=540831
ter_threshold: 0.537632
num_accepted / total 10 48
loss token level: tensor(10338.0938, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3360., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.537644
num_accepted / total 36 80
loss token level: tensor(8958.9229, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6568., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7052, 42808])
2023-09-26 16:59:40 | INFO | train_inner | epoch 027:   2188 / 9060 loss=7.492, nll_loss=3.661, ppl=12.65, wps=3763.1, ups=0.29, wpb=12904.1, bsz=436, num_updates=237700, lr=6.48613e-05, gnorm=1.255, loss_scale=4, train_wall=343, gb_free=13.3, wall=541174
ter_threshold: 0.537727
num_accepted / total 26 80
loss token level: tensor(10358.9258, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4632., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4386, 42808])
2023-09-26 17:05:13 | INFO | train_inner | epoch 027:   2288 / 9060 loss=7.435, nll_loss=3.642, ppl=12.48, wps=3882.6, ups=0.3, wpb=12929.3, bsz=407.5, num_updates=237800, lr=6.48476e-05, gnorm=1.22, loss_scale=4, train_wall=333, gb_free=14.8, wall=541507
pred_new.size(): torch.Size([5265, 42808])
lprobs.size(): torch.Size([3280, 42808])
pred_new.size(): torch.Size([4324, 42808])
2023-09-26 17:10:58 | INFO | train_inner | epoch 027:   2388 / 9060 loss=7.767, nll_loss=3.803, ppl=13.96, wps=3759.1, ups=0.29, wpb=12963.9, bsz=456.2, num_updates=237900, lr=6.4834e-05, gnorm=1.246, loss_scale=4, train_wall=345, gb_free=15.5, wall=541851
pred_new.size(): torch.Size([5537, 42808])
2023-09-26 17:16:40 | INFO | train_inner | epoch 027:   2488 / 9060 loss=7.527, nll_loss=3.719, ppl=13.16, wps=3765.5, ups=0.29, wpb=12861.4, bsz=417.8, num_updates=238000, lr=6.48204e-05, gnorm=1.236, loss_scale=4, train_wall=341, gb_free=13.6, wall=542193
2023-09-26 17:22:22 | INFO | train_inner | epoch 027:   2588 / 9060 loss=7.545, nll_loss=3.698, ppl=12.98, wps=3778.9, ups=0.29, wpb=12952.2, bsz=424.9, num_updates=238100, lr=6.48068e-05, gnorm=1.246, loss_scale=4, train_wall=343, gb_free=13.1, wall=542536
tensor(10179.1797, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8056., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.529273
num_accepted / total 5 56
loss token level: tensor(9245.8311, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1660., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5293129999999999
num_accepted / total 9 96
loss token level: tensor(9201.1523, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(1062., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3024, 42808])
pred_new.size(): torch.Size([3720, 42808])
lprobs.size(): torch.Size([3472, 42808])
pred_new.size(): torch.Size([9844, 42808])
ter_threshold: 0.530029
num_accepted / total 82 152
loss token level: tensor(8156.4258, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10000., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.530034
num_accepted / total 20 80
loss token level: tensor(8524.7705, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4876., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([5166, 42808])
pred_new.size(): torch.Size([2808, 42808])
lprobs.size(): torch.Size([2784, 42808])
ter_threshold: 0.5302439999999999
num_accepted / total 36 96
loss token level: tensor(10470.6006, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7556., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.530248
num_accepted / total 108 184
loss token level: tensor(8952.0156, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13120., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7920, 42808])
lprobs.size(): torch.Size([3072, 42808])
pred_new.size(): torch.Size([5040, 42808])
ter_threshold: 0.530686
num_accepted / total 19 64
loss token level: tensor(10373.0488, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4848., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([3936, 42808])
pred_new.size(): torch.Size([2574, 42808])
pred_new.size(): torch.Size([6300, 42808])
pred_new.size(): torch.Size([3818, 42808])
pred_new.size(): torch.Size([7820, 42808])
pred_new.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([3078, 42808])
pred_new.size(): torch.Size([5664, 42808])
pred_new.size(): torch.Size([2838, 42808])
pred_new.size(): torch.Size([3381, 42808])
pred_new.size(): torch.Size([10412, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([9711, 42808])
lprobs.size(): torch.Size([3080, 42808])
pred_new.size(): torch.Size([3402, 42808])
lprobs.size(): torch.Size([3480, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.5331049999999999
num_accepted / total 77 112
loss token level: tensor(9031.5098, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8960., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([2736, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([936, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.533579
num_accepted / total 115 160
loss token level: tensor(8848.8174, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9520., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6264, 42808])
pred_new.size(): torch.Size([897, 42808])
ter_threshold: 0.5338
num_accepted / total 9 56
loss token level: tensor(11717.9453, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3416., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.533872
num_accepted / total 112 168
loss token level: tensor(8136.5342, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8592., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.5339389999999999
num_accepted / total 21 56
loss token level: tensor(8198.4961, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9112., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3216, 42808])
pred_new.size(): torch.Size([7105, 42808])
pred_new.size(): torch.Size([3772, 42808])
pred_new.size(): torch.Size([2750, 42808])
pred_new.size(): torch.Size([3300, 42808])
pred_new.size(): torch.Size([7750, 42808])
ter_threshold: 0.534606
num_accepted / total 50 88
loss token level: tensor(9527.0625, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7884., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([8645, 42808])
pred_new.size(): torch.Size([2664, 42808])
pred_new.size(): torch.Size([8401, 42808])
pred_new.size(): torch.Size([3082, 42808])
ter_threshold: 0.535169
num_accepted / total 70 128
loss token level: tensor(10042.5078, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8208., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3040, 42808])
ter_threshold: 0.535488
num_accepted / total 16 56
loss token level: tensor(10518.2588, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6616., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5358229999999999
num_accepted / total 41 96
loss token level: tensor(9768.6982, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(10160., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6290, 42808])
lprobs.size(): torch.Size([3408, 42808])
pred_new.size(): torch.Size([6630, 42808])
pred_new.size(): torch.Size([1431, 42808])
ter_threshold: 0.536214
num_accepted / total 9 40
loss token level: tensor(9697.3135, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3202., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([2720, 42808])
ter_threshold: 0.5364519999999999
num_accepted / total 17 64
loss token level: tensor(8357.9746, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3304., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7068, 42808])
ter_threshold: 0.5366949999999999
num_accepted / total 12 56
loss token level: tensor(9187.0098, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4720., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3392, 42808])
ter_threshold: 0.5367649999999999
num_accepted / total 113 184
loss token level: tensor(9222.9082, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(12816., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([5130, 42808])
pred_new.size(): torch.Size([1824, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.537289
num_accepted / total 16 64
loss token level: tensor(10438.0703, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(6412., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([6636, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([8475, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.538095
num_accepted / total 22 80
loss token level: tensor(9507.9004, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3938., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): 2023-09-26 17:27:58 | INFO | train_inner | epoch 027:   2688 / 9060 loss=7.711, nll_loss=3.785, ppl=13.79, wps=3867.9, ups=0.3, wpb=12974.1, bsz=439.8, num_updates=238200, lr=6.47932e-05, gnorm=1.237, loss_scale=4, train_wall=335, gb_free=12.5, wall=542871
2023-09-26 17:33:38 | INFO | train_inner | epoch 027:   2788 / 9060 loss=7.53, nll_loss=3.676, ppl=12.78, wps=3807.2, ups=0.29, wpb=12961, bsz=419.3, num_updates=238300, lr=6.47796e-05, gnorm=1.247, loss_scale=8, train_wall=340, gb_free=13.1, wall=543212
lprobs.size(): torch.Size([3192, 42808])
2023-09-26 17:39:27 | INFO | train_inner | epoch 027:   2888 / 9060 loss=7.678, nll_loss=3.775, ppl=13.69, wps=3717.4, ups=0.29, wpb=12964.9, bsz=423.5, num_updates=238400, lr=6.4766e-05, gnorm=1.265, loss_scale=8, train_wall=349, gb_free=13, wall=543560
lprobs.size(): torch.Size([2432, 42808])
pred_new.size(): torch.Size([6588, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2920, 42808])
2023-09-26 17:45:09 | INFO | train_inner | epoch 027:   2988 / 9060 loss=7.764, nll_loss=3.778, ppl=13.71, wps=3805.1, ups=0.29, wpb=13010.8, bsz=452, num_updates=238500, lr=6.47524e-05, gnorm=1.248, loss_scale=8, train_wall=342, gb_free=12.4, wall=543902
2023-09-26 17:50:51 | INFO | train_inner | epoch 027:   3088 / 9060 loss=7.745, nll_loss=3.783, ppl=13.77, wps=3787.7, ups=0.29, wpb=12977, bsz=447.3, num_updates=238600, lr=6.47388e-05, gnorm=1.249, loss_scale=8, train_wall=342, gb_free=13.3, wall=544245
2023-09-26 17:56:33 | INFO | train_inner | epoch 027:   3188 / 9060 loss=7.635, nll_loss=3.738, ppl=13.35, wps=3796.1, ups=0.29, wpb=12955.6, bsz=433.4, num_updates=238700, lr=6.47253e-05, gnorm=1.236, loss_scale=8, train_wall=341, gb_free=13, wall=544586
pred_new.size(): torch.Size([5015, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 18:02:36 | INFO | train_inner | epoch 027:   3288 / 9060 loss=7.678, nll_loss=3.749, ppl=13.45, wps=3596.3, ups=0.28, wpb=13065.3, bsz=436.4, num_updates=238800, lr=6.47117e-05, gnorm=1.252, loss_scale=8, train_wall=363, gb_free=13.9, wall=544950
lprobs.size(): torch.Size([3360, 42808])
2023-09-26 18:08:04 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-26 18:08:21 | INFO | train_inner | epoch 027:   3389 / 9060 loss=7.687, nll_loss=3.757, ppl=13.52, wps=3776.1, ups=0.29, wpb=13008.2, bsz=425.4, num_updates=238900, lr=6.46982e-05, gnorm=1.248, loss_scale=4, train_wall=344, gb_free=14, wall=545294
ter_threshold: 0.538917
num_accepted / total 40 96
loss token level: tensor(8721.4570, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5248., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
2023-09-26 18:14:15 | INFO | train_inner | epoch 027:   3489 / 9060 loss=7.769, nll_loss=3.835, ppl=14.27, wps=3641.5, ups=0.28, wpb=12919.2, bsz=431.2, num_updates=239000, lr=6.46846e-05, gnorm=1.266, loss_scale=4, train_wall=355, gb_free=14.1, wall=545649
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 18:20:01 | INFO | train_inner | epoch 027:   3589 / 9060 loss=7.496, nll_loss=3.662, ppl=12.66, wps=3739.8, ups=0.29, wpb=12933.7, bsz=422.6, num_updates=239100, lr=6.46711e-05, gnorm=1.254, loss_scale=4, train_wall=346, gb_free=14.7, wall=545995
2023-09-26 18:25:45 | INFO | train_inner | epoch 027:   3689 / 9060 loss=7.631, nll_loss=3.747, ppl=13.43, wps=3793.3, ups=0.29, wpb=13033.5, bsz=429.5, num_updates=239200, lr=6.46576e-05, gnorm=1.26, loss_scale=4, train_wall=343, gb_free=13.3, wall=546338
ter_threshold: 0.539288
num_accepted / total 26 80
loss token level: tensor(8494.7324, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4140., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5392939999999999
num_accepted / total 6 24
loss token level: tensor(7878.2847, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(2746., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 18:31:31 | INFO | train_inner | epoch 027:   3789 / 9060 loss=7.551, nll_loss=3.664, ppl=12.68, wps=3770.7, ups=0.29, wpb=13046.7, bsz=434.4, num_updates=239300, lr=6.46441e-05, gnorm=1.23, loss_scale=4, train_wall=346, gb_free=16.3, wall=546684
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([8091, 42808])
2023-09-26 18:37:12 | INFO | train_inner | epoch 027:   3889 / 9060 loss=7.572, nll_loss=3.708, ppl=13.07, wps=3806.2, ups=0.29, wpb=12995, bsz=411.1, num_updates=239400, lr=6.46306e-05, gnorm=1.233, loss_scale=4, train_wall=341, gb_free=13.8, wall=547026
2023-09-26 18:43:07 | INFO | train_inner | epoch 027:   3989 / 9060 loss=7.681, nll_loss=3.734, ppl=13.31, wps=3680.1, ups=0.28, wpb=13064.4, bsz=436.3, num_updates=239500, lr=6.46171e-05, gnorm=1.238, loss_scale=4, train_wall=355, gb_free=13.9, wall=547381
lprobs.size(): torch.Size([2688, 42808])
lprobs.size(): torch.Size([3344, 42808])
2023-09-26 18:48:57 | INFO | train_inner | epoch 027:   4089 / 9060 loss=7.683, nll_loss=3.763, ppl=13.57, wps=3728.6, ups=0.29, wpb=13036.4, bsz=445.7, num_updates=239600, lr=6.46036e-05, gnorm=1.256, loss_scale=4, train_wall=349, gb_free=12.6, wall=547730
pred_new.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([1377, 42808])
2023-09-26 18:54:38 | INFO | train_inner | epoch 027:   4189 / 9060 loss=7.499, nll_loss=3.701, ppl=13.01, wps=3818.1, ups=0.29, wpb=13029.7, bsz=402.7, num_updates=239700, lr=6.45901e-05, gnorm=1.228, loss_scale=4, train_wall=341, gb_free=13.9, wall=548072
ter_threshold: 0.539722
num_accepted / total 37 88
loss token level: tensor(8547.9258, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5476., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 19:00:31 | INFO | train_inner | epoch 027:   4289 / 9060 loss=7.831, nll_loss=3.821, ppl=14.14, wps=3656.9, ups=0.28, wpb=12907.2, bsz=439.3, num_updates=239800, lr=6.45766e-05, gnorm=1.266, loss_scale=4, train_wall=353, gb_free=13.7, wall=548424
pred_new.size(): torch.Size([2814, 42808])
lprobs.size(): torch.Size([3344, 42808])
2023-09-26 19:06:14 | INFO | train_inner | epoch 027:   4389 / 9060 loss=7.764, nll_loss=3.781, ppl=13.75, wps=3801.9, ups=0.29, wpb=13040.5, bsz=437.2, num_updates=239900, lr=6.45632e-05, gnorm=1.245, loss_scale=4, train_wall=343, gb_free=13.9, wall=548767
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([9240, 42808])
2023-09-26 19:12:08 | INFO | train_inner | epoch 027:   4489 / 9060 loss=7.75, nll_loss=3.799, ppl=13.92, wps=3661.2, ups=0.28, wpb=12946.7, bsz=431.2, num_updates=240000, lr=6.45497e-05, gnorm=1.282, loss_scale=4, train_wall=353, gb_free=13.5, wall=549121
pred_new.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3408, 42808])
2023-09-26 19:17:51 | INFO | train_inner | epoch 027:   4589 / 9060 loss=7.702, nll_loss=3.828, ppl=14.2, wps=3768.6, ups=0.29, wpb=12936.8, bsz=418.7, num_updates=240100, lr=6.45363e-05, gnorm=1.251, loss_scale=4, train_wall=343, gb_free=13.9, wall=549464
pred_new.size(): torch.Size([5404, 42808])
2023-09-26 19:23:34 | INFO | train_inner | epoch 027:   4689 / 9060 loss=7.451, nll_loss=3.648, ppl=12.53, wps=3789.3, ups=0.29, wpb=12994, bsz=414.7, num_updates=240200, lr=6.45228e-05, gnorm=1.235, loss_scale=4, train_wall=343, gb_free=13.5, wall=549807
2023-09-26 19:29:19 | INFO | train_inner | epoch 027:   4789 / 9060 loss=7.665, nll_loss=3.784, ppl=13.78, wps=3766.2, ups=0.29, wpb=12991.1, bsz=425.8, num_updates=240300, lr=6.45094e-05, gnorm=1.249, loss_scale=4, train_wall=345, gb_free=14.3, wall=550152
lprobs.size(): torch.Size([2560, 42808])
2023-09-26 19:35:06 | INFO | train_inner | epoch 027:   4889 / 9060 loss=7.699, nll_loss=3.768, ppl=13.62, wps=3735.3, ups=0.29, wpb=12982.7, bsz=433.9, num_updates=240400, lr=6.4496e-05, gnorm=1.25, loss_scale=4, train_wall=347, gb_free=14.7, wall=550500
lprobs.size(): torch.Size([2496, 42808])
pred_new.size(): torch.Size([164, 42808])
ter_threshold: 0.540483
num_accepted / total 24 72
loss token level: tensor(8373.6787, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4086., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
2023-09-26 19:41:06 | INFO | train_inner | epoch 027:   4989 / 9060 loss=7.537, nll_loss=3.676, ppl=12.78, wps=3616.3, ups=0.28, wpb=13001.1, bsz=410.6, num_updates=240500, lr=6.44826e-05, gnorm=1.259, loss_scale=4, train_wall=359, gb_free=13.4, wall=550859
lprobs.size(): torch.Size([3120, 42808])
2023-09-26 19:46:35 | INFO | train_inner | epoch 027:   5089 / 9060 loss=7.456, nll_loss=3.667, ppl=12.7, wps=3915, ups=0.3, wpb=12879.1, bsz=427.7, num_updates=240600, lr=6.44692e-05, gnorm=1.223, loss_scale=4, train_wall=329, gb_free=13.7, wall=551188
2023-09-26 19:52:17 | INFO | train_inner | epoch 027:   5189 / 9060 loss=7.679, nll_loss=3.749, ppl=13.45, wps=3823.1, ups=0.29, wpb=13089.4, bsz=445.1, num_updates=240700, lr=6.44558e-05, gnorm=1.232, loss_scale=4, train_wall=342, gb_free=14.6, wall=551531
lprobs.size(): torch.Size([3520, 42808])
2023-09-26 19:57:59 | INFO | train_inner | epoch 027:   5289 / 9060 loss=7.634, nll_loss=3.728, ppl=13.25, wps=3811.5, ups=0.29, wpb=13036, bsz=445.4, num_updates=240800, lr=6.44424e-05, gnorm=1.284, loss_scale=4, train_wall=342, gb_free=13, wall=551873
pred_new.size(): torch.Size([8910, 42808])
2023-09-26 20:03:54 | INFO | train_inner | epoch 027:   5389 / 9060 loss=7.921, nll_loss=3.911, ppl=15.04, wps=3639.4, ups=0.28, wpb=12896.5, bsz=408.2, num_updates=240900, lr=6.4429e-05, gnorm=1.302, loss_scale=4, train_wall=354, gb_free=12.5, wall=552227
num_accepted / total 86 152
loss token level: tensor(8853.5322, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(12528., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6665, 42808])
lprobs.size(): torch.Size([3312, 42808])
ter_threshold: 0.530392
num_accepted / total 48 96
loss token level: tensor(10011.8643, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6552., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3400, 42808])
pred_new.size(): torch.Size([4212, 42808])
lprobs.size(): torch.Size([3392, 42808])
pred_new.size(): torch.Size([1920, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([2310, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([4875, 42808])
pred_new.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([9180, 42808])
pred_new.size(): torch.Size([3792, 42808])
pred_new.size(): torch.Size([1896, 42808])
pred_new.size(): torch.Size([4050, 42808])
pred_new.size(): torch.Size([7154, 42808])
pred_new.size(): torch.Size([6171, 42808])
pred_new.size(): torch.Size([4482, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([2464, 42808])
pred_new.size(): torch.Size([2332, 42808])
pred_new.size(): torch.Size([6783, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([504, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3192, 42808])
lprobs.size(): torch.Size([3096, 42808])
pred_new.size(): torch.Size([6832, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1794, 42808])
lprobs.size(): torch.Size([3384, 42808])
ter_threshold: 0.533733
num_accepted / total 80 128
loss token level: tensor(9806.9746, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9480., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4590, 42808])
ter_threshold: 0.533872
num_accepted / total 56 112
loss token level: tensor(9418.4238, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6240., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([8874, 42808])
pred_new.size(): torch.Size([6105, 42808])
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3224, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([1701, 42808])
pred_new.size(): torch.Size([4246, 42808])
ter_threshold: 0.534606
num_accepted / total 12 56
loss token level: tensor(7658.6343, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2094., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3256, 42808])
pred_new.size(): torch.Size([3375, 42808])
pred_new.size(): torch.Size([4743, 42808])
pred_new.size(): torch.Size([6600, 42808])
ter_threshold: 0.535221
num_accepted / total 36 80
loss token level: tensor(8634.2285, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9888., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([3534, 42808])
pred_new.size(): torch.Size([2520, 42808])
pred_new.size(): torch.Size([2385, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.535648
num_accepted / total 9 56
loss token level: tensor(12613.4082, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(2568., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.535783
num_accepted / total 63 112
loss token level: tensor(8066.9854, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(11032., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5357879999999999
num_accepted / total 13 48
loss token level: tensor(7627.3203, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3314., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.535812
num_accepted / total 10 40
loss token level: tensor(8951.8105, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6200., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5358229999999999
num_accepted / total 43 96
loss token level: tensor(9044.6445, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10376., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
pred_new.size(): torch.Size([9048, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([7182, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([3690, 42808])
lprobs.size(): torch.Size([3384, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([7600, 42808])
ter_threshold: 0.5366949999999999
num_accepted / total 26 64
loss token level: tensor(8239.8340, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9952., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4556, 42808])
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4655, 42808])
pred_new.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5148, 42808])
pred_new.size(): torch.Size([3776, 42808])
pred_new.size(): torch.Size([9048, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.538095
num_accepted / total 16 72
loss token level: tensor(8876.9131, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3356., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3196, 42808])
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([2262, 42808])
lprobs.size(): torch.Size([2816, 42808])
ter_threshold: 0.538646
num_accepted / total 132 168
loss token level: tensor(8759.6777, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(17600., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([1140, 42808])
ter_threshold: 0.538917
num_accepted / total 87 136
loss token level: tensor(9030.6035, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8272., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([3942, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.539123
num_accepted / total 50 104
loss token level: tensor(9325.1445, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6788., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3384, 42808])
ter_threshold: 0.539288
num_accepted / total 62 112
loss token level: tensor(9342.2109, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7960., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3504, 42808])
lprobs.size(): torch.Size([3248, 42808])
pred_new.size(): torch.Size([1422, 42808])
pred_new.size(): torch.Size([3648, 42808])
lprobs.size(): torch.Size([3256, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([8648, 42808])
pred_new.size(): torch.Size([6210, 42808])
pred_new.size(): torch.Size([6576, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.540413
num_accepted / total 29 64
loss token level: tensor(8353.5010, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6368., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3384, 42808])
pred_new.size(): torch.Size([4785, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([3657, 42808])
ter_threshold: 0.540947
num_accepted / total 32 72
2023-09-26 20:09:40 | INFO | train_inner | epoch 027:   5489 / 9060 loss=7.67, nll_loss=3.741, ppl=13.37, wps=3739.6, ups=0.29, wpb=12973.9, bsz=421, num_updates=241000, lr=6.44157e-05, gnorm=1.305, loss_scale=4, train_wall=347, gb_free=14.4, wall=552574
ter_threshold: 0.541044
num_accepted / total 60 96
loss token level: tensor(9399.3174, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(13104., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-26 20:15:32 | INFO | train_inner | epoch 027:   5589 / 9060 loss=7.755, nll_loss=3.809, ppl=14.01, wps=3664.9, ups=0.28, wpb=12878.5, bsz=419.8, num_updates=241100, lr=6.44023e-05, gnorm=1.274, loss_scale=4, train_wall=351, gb_free=13.2, wall=552925
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 20:21:15 | INFO | train_inner | epoch 027:   5689 / 9060 loss=7.744, nll_loss=3.796, ppl=13.89, wps=3791.8, ups=0.29, wpb=12996.2, bsz=434.9, num_updates=241200, lr=6.4389e-05, gnorm=1.254, loss_scale=4, train_wall=342, gb_free=13.7, wall=553268
lprobs.size(): torch.Size([2592, 42808])
2023-09-26 20:26:59 | INFO | train_inner | epoch 027:   5789 / 9060 loss=7.601, nll_loss=3.734, ppl=13.31, wps=3793.5, ups=0.29, wpb=13066.5, bsz=428.6, num_updates=241300, lr=6.43756e-05, gnorm=1.231, loss_scale=4, train_wall=344, gb_free=14.9, wall=553613
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([2880, 42808])
2023-09-26 20:32:39 | INFO | train_inner | epoch 027:   5889 / 9060 loss=7.656, nll_loss=3.771, ppl=13.65, wps=3814.6, ups=0.29, wpb=12978.1, bsz=452.2, num_updates=241400, lr=6.43623e-05, gnorm=1.233, loss_scale=4, train_wall=340, gb_free=13.4, wall=553953
2023-09-26 20:38:20 | INFO | train_inner | epoch 027:   5989 / 9060 loss=7.668, nll_loss=3.756, ppl=13.51, wps=3823.5, ups=0.29, wpb=13044.8, bsz=418.1, num_updates=241500, lr=6.43489e-05, gnorm=1.257, loss_scale=4, train_wall=341, gb_free=14.2, wall=554294
pred_new.size(): torch.Size([1050, 42808])
2023-09-26 20:44:16 | INFO | train_inner | epoch 027:   6089 / 9060 loss=7.783, nll_loss=3.81, ppl=14.03, wps=3648.5, ups=0.28, wpb=12966.6, bsz=422.1, num_updates=241600, lr=6.43356e-05, gnorm=1.275, loss_scale=4, train_wall=355, gb_free=14.3, wall=554649
2023-09-26 20:49:59 | INFO | train_inner | epoch 027:   6189 / 9060 loss=7.829, nll_loss=3.837, ppl=14.29, wps=3795.6, ups=0.29, wpb=13011.7, bsz=448, num_updates=241700, lr=6.43223e-05, gnorm=1.266, loss_scale=4, train_wall=343, gb_free=15.6, wall=554992
2023-09-26 20:55:40 | INFO | train_inner | epoch 027:   6289 / 9060 loss=7.739, nll_loss=3.816, ppl=14.08, wps=3793.9, ups=0.29, wpb=12938.4, bsz=425.9, num_updates=241800, lr=6.4309e-05, gnorm=1.247, loss_scale=4, train_wall=341, gb_free=15.3, wall=555333
2023-09-26 21:01:25 | INFO | train_inner | epoch 027:   6389 / 9060 loss=7.395, nll_loss=3.617, ppl=12.27, wps=3758.2, ups=0.29, wpb=12973.3, bsz=437.4, num_updates=241900, lr=6.42957e-05, gnorm=1.209, loss_scale=4, train_wall=345, gb_free=14.7, wall=555678
pred_new.size(): torch.Size([5754, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-26 21:07:11 | INFO | train_inner | epoch 027:   6489 / 9060 loss=7.629, nll_loss=3.75, ppl=13.45, wps=3735.2, ups=0.29, wpb=12936.1, bsz=420.3, num_updates=242000, lr=6.42824e-05, gnorm=1.264, loss_scale=4, train_wall=346, gb_free=13.9, wall=556025
lprobs.size(): torch.Size([3536, 42808])
2023-09-26 21:12:54 | INFO | train_inner | epoch 027:   6589 / 9060 loss=7.764, nll_loss=3.818, ppl=14.1, wps=3791, ups=0.29, wpb=12986.3, bsz=437.6, num_updates=242100, lr=6.42692e-05, gnorm=1.301, loss_scale=4, train_wall=342, gb_free=14.5, wall=556367
pred_new.size(): torch.Size([7750, 42808])
2023-09-26 21:18:41 | INFO | train_inner | epoch 027:   6689 / 9060 loss=7.739, nll_loss=3.803, ppl=13.96, wps=3734.1, ups=0.29, wpb=12968.2, bsz=441.4, num_updates=242200, lr=6.42559e-05, gnorm=1.253, loss_scale=4, train_wall=347, gb_free=13.7, wall=556715
2023-09-26 21:24:28 | INFO | train_inner | epoch 027:   6789 / 9060 loss=7.539, nll_loss=3.71, ppl=13.09, wps=3746.8, ups=0.29, wpb=12994.8, bsz=450.2, num_updates=242300, lr=6.42426e-05, gnorm=1.241, loss_scale=4, train_wall=347, gb_free=13.2, wall=557061
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3096, 42808])
ter_threshold: 0.532482
num_accepted / total 159 208
loss token level: tensor(9549.5732, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9472., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4788, 42808])
pred_new.size(): torch.Size([1881, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([1680, 42808])
ter_threshold: 0.5331049999999999
num_accepted / total 123 168
loss token level: tensor(8798.5918, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9912., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.533733
num_accepted / total 35 112
loss token level: tensor(11356.0947, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4464., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4029, 42808])
ter_threshold: 0.5338
num_accepted / total 20 64
loss token level: tensor(9716.9766, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7808., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([3900, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([4356, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([8435, 42808])
pred_new.size(): torch.Size([4608, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3325, 42808])
ter_threshold: 0.535221
num_accepted / total 251 296
loss token level: tensor(8297.6631, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(16256., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2346, 42808])
lprobs.size(): torch.Size([3200, 42808])
ter_threshold: 0.535308
num_accepted / total 31 72
loss token level: tensor(8287.4102, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6064., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3059, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([906, 42808])
lprobs.size(): torch.Size([2816, 42808])
pred_new.size(): torch.Size([3915, 42808])
ter_threshold: 0.535783
num_accepted / total 94 136
loss token level: tensor(8703.1465, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(15184., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5358229999999999
num_accepted / total 60 112
loss token level: tensor(8017.2148, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(10752., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4950, 42808])
pred_new.size(): torch.Size([3933, 42808])
pred_new.size(): torch.Size([6800, 42808])
pred_new.size(): torch.Size([3003, 42808])
pred_new.size(): torch.Size([1818, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([3956, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([3924, 42808])
pred_new.size(): torch.Size([5202, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3128, 42808])
ter_threshold: 0.537733
num_accepted / total 12 64
loss token level: tensor(8125.1084, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(4240., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4050, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.538108
num_accepted / total 13 56
loss token level: tensor(8683.3135, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(5832., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3560, 42808])
pred_new.size(): torch.Size([1656, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.538646
num_accepted / total 55 128
loss token level: tensor(8172.9062, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6812., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5387
num_accepted / total 23 64
loss token level: tensor(8925.2441, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(7832., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5168, 42808])
lprobs.size(): torch.Size([3584, 42808])
ter_threshold: 0.5388539999999999
num_accepted / total 9 56
loss token level: tensor(9758.9873, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3072., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.538917
num_accepted / total 31 112
loss token level: tensor(12984.9980, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3156., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.539123
num_accepted / total 79 112
loss token level: tensor(8748.4395, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9248., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.539131
num_accepted / total 11 56
loss token level: tensor(11053.2363, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(3054., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3416, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3024, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([4536, 42808])
pred_new.size(): torch.Size([7700, 42808])
pred_new.size(): torch.Size([6789, 42808])
pred_new.size(): torch.Size([2976, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([424, 42808])
ter_threshold: 0.540483
num_accepted / total 38 72
loss token level: tensor(7941.1411, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(6976., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3224, 42808])
pred_new.size(): torch.Size([2400, 42808])
pred_new.size(): torch.Size([8840, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3328, 42808])
ter_threshold: 0.541146
num_accepted / total 37 56
loss token level: tensor(7784.6084, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(9224., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.541252
num_accepted / total 95 136
loss token level: tensor(9091.0889, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(16912., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([4025, 42808])
ter_threshold: 0.541539
num_accepted / total 10 56
loss token level: tensor(10683.1143, device='cuda:2', grad_fn=<AddBackward0>)
loss seque level: tensor(2160., device='cuda:2', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5265, 42808])
lprobs.size(): torch.Size([2904, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3120, 42808])
pred_new.size(): torch.Size([7150, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([5670, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): lprobs.size(): torch.Size([3496, 42808])
2023-09-26 21:30:08 | INFO | train_inner | epoch 027:   6889 / 9060 loss=7.623, nll_loss=3.753, ppl=13.48, wps=3805, ups=0.29, wpb=12934, bsz=402.1, num_updates=242400, lr=6.42294e-05, gnorm=1.249, loss_scale=4, train_wall=340, gb_free=13.2, wall=557401
pred_new.size(): torch.Size([2886, 42808])
ter_threshold: 0.542422
num_accepted / total 62 152
loss token level: tensor(11706.1777, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9296., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3536, 42808])
2023-09-26 21:35:50 | INFO | train_inner | epoch 027:   6989 / 9060 loss=7.755, nll_loss=3.824, ppl=14.16, wps=3827, ups=0.29, wpb=13085.1, bsz=448.7, num_updates=242500, lr=6.42161e-05, gnorm=1.264, loss_scale=4, train_wall=342, gb_free=13.2, wall=557743
2023-09-26 21:41:50 | INFO | train_inner | epoch 027:   7089 / 9060 loss=7.622, nll_loss=3.713, ppl=13.11, wps=3592.1, ups=0.28, wpb=12933.8, bsz=420, num_updates=242600, lr=6.42029e-05, gnorm=1.261, loss_scale=4, train_wall=360, gb_free=15.7, wall=558103
lprobs.size(): torch.Size([2520, 42808])
lprobs.size(): torch.Size([3096, 42808])
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 21:47:32 | INFO | train_inner | epoch 027:   7189 / 9060 loss=7.675, nll_loss=3.733, ppl=13.29, wps=3798.5, ups=0.29, wpb=12999.2, bsz=441.3, num_updates=242700, lr=6.41897e-05, gnorm=1.246, loss_scale=4, train_wall=342, gb_free=12.9, wall=558446
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([2352, 42808])
pred_new.size(): torch.Size([2145, 42808])
2023-09-26 21:53:17 | INFO | train_inner | epoch 027:   7289 / 9060 loss=7.592, nll_loss=3.758, ppl=13.53, wps=3763.4, ups=0.29, wpb=12970.3, bsz=420.9, num_updates=242800, lr=6.41764e-05, gnorm=1.25, loss_scale=4, train_wall=344, gb_free=14.1, wall=558790
lprobs.size(): torch.Size([2320, 42808])
pred_new.size(): torch.Size([6006, 42808])
2023-09-26 21:59:11 | INFO | train_inner | epoch 027:   7389 / 9060 loss=7.5, nll_loss=3.708, ppl=13.07, wps=3670.2, ups=0.28, wpb=12996.2, bsz=437.3, num_updates=242900, lr=6.41632e-05, gnorm=1.217, loss_scale=4, train_wall=354, gb_free=14.2, wall=559144
pred_new.size(): torch.Size([6837, 42808])
2023-09-26 22:04:54 | INFO | train_inner | epoch 027:   7489 / 9060 loss=7.664, nll_loss=3.79, ppl=13.83, wps=3791.3, ups=0.29, wpb=13027.2, bsz=427.8, num_updates=243000, lr=6.415e-05, gnorm=1.238, loss_scale=8, train_wall=343, gb_free=14, wall=559488
2023-09-26 22:09:38 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
pred_new.size(): torch.Size([4532, 42808])
2023-09-26 22:11:04 | INFO | train_inner | epoch 027:   7590 / 9060 loss=7.854, nll_loss=3.87, ppl=14.62, wps=3504.9, ups=0.27, wpb=12949.5, bsz=430.2, num_updates=243100, lr=6.41368e-05, gnorm=1.28, loss_scale=4, train_wall=369, gb_free=14.4, wall=559857
2023-09-26 22:16:51 | INFO | train_inner | epoch 027:   7690 / 9060 loss=7.813, nll_loss=3.839, ppl=14.31, wps=3727.9, ups=0.29, wpb=12928.3, bsz=430.9, num_updates=243200, lr=6.41236e-05, gnorm=1.298, loss_scale=4, train_wall=347, gb_free=12.6, wall=560204
2023-09-26 22:22:31 | INFO | train_inner | epoch 027:   7790 / 9060 loss=7.62, nll_loss=3.757, ppl=13.52, wps=3840.7, ups=0.29, wpb=13066.7, bsz=420, num_updates=243300, lr=6.41105e-05, gnorm=1.248, loss_scale=4, train_wall=340, gb_free=14.1, wall=560544
lprobs.size(): torch.Size([2760, 42808])
2023-09-26 22:28:17 | INFO | train_inner | epoch 027:   7890 / 9060 loss=7.765, nll_loss=3.841, ppl=14.33, wps=3742.4, ups=0.29, wpb=12963.4, bsz=444.9, num_updates=243400, lr=6.40973e-05, gnorm=1.286, loss_scale=4, train_wall=346, gb_free=12.8, wall=560891
lprobs.size(): torch.Size([3168, 42808])
lprobs.size(): torch.Size([3496, 42808])
lprobs.size(): torch.Size([2912, 42808])
2023-09-26 22:34:10 | INFO | train_inner | epoch 027:   7990 / 9060 loss=7.906, nll_loss=3.89, ppl=14.83, wps=3662.3, ups=0.28, wpb=12912.9, bsz=421.5, num_updates=243500, lr=6.40841e-05, gnorm=1.303, loss_scale=4, train_wall=352, gb_free=14.5, wall=561243
ter_threshold: 0.543513
num_accepted / total 18 56
loss token level: tensor(8851.2188, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4768., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([216, 42808])
pred_new.size(): torch.Size([1900, 42808])
2023-09-26 22:39:51 | INFO | train_inner | epoch 027:   8090 / 9060 loss=7.607, nll_loss=3.76, ppl=13.55, wps=3782.1, ups=0.29, wpb=12918.5, bsz=414.6, num_updates=243600, lr=6.4071e-05, gnorm=1.237, loss_scale=4, train_wall=341, gb_free=13.5, wall=561585
lprobs.size(): torch.Size([3520, 42808])
2023-09-26 22:45:44 | INFO | train_inner | epoch 027:   8190 / 9060 loss=7.598, nll_loss=3.721, ppl=13.19, wps=3678.2, ups=0.28, wpb=12967.4, bsz=425.8, num_updates=243700, lr=6.40578e-05, gnorm=1.252, loss_scale=4, train_wall=352, gb_free=13.7, wall=561937
pred_new.size(): torch.Size([2000, 42808])
2023-09-26 22:51:30 | INFO | train_inner | epoch 027:   8290 / 9060 loss=7.515, nll_loss=3.714, ppl=13.13, wps=3717.6, ups=0.29, wpb=12864.2, bsz=440.5, num_updates=243800, lr=6.40447e-05, gnorm=1.217, loss_scale=4, train_wall=346, gb_free=14.2, wall=562283
2023-09-26 22:57:06 | INFO | train_inner | epoch 027:   8390 / 9060 loss=7.704, nll_loss=3.81, ppl=14.03, wps=3852.3, ups=0.3, wpb=12931.8, bsz=431.6, num_updates=243900, lr=6.40316e-05, gnorm=1.258, loss_scale=4, train_wall=335, gb_free=15.8, wall=562619
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([6935, 42808])
pred_new.size(): torch.Size([5760, 42808])
2023-09-26 23:03:03 | INFO | train_inner | epoch 027:   8490 / 9060 loss=7.645, nll_loss=3.791, ppl=13.85, wps=3643.1, ups=0.28, wpb=13025.3, bsz=427.8, num_updates=244000, lr=6.40184e-05, gnorm=1.248, loss_scale=4, train_wall=357, gb_free=12.7, wall=562977
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-26 23:08:46 | INFO | train_inner | epoch 027:   8590 / 9060 loss=7.563, nll_loss=3.695, ppl=12.95, wps=3798, ups=0.29, wpb=13007.2, bsz=445.8, num_updates=244100, lr=6.40053e-05, gnorm=1.243, loss_scale=4, train_wall=342, gb_free=14.8, wall=563319
pred_new.size(): torch.Size([6270, 42808])
lprobs.size(): torch.Size([3400, 42808])
2023-09-26 23:14:39 | INFO | train_inner | epoch 027:   8690 / 9060 loss=7.787, nll_loss=3.814, ppl=14.07, wps=3675.8, ups=0.28, wpb=12991.9, bsz=436.4, num_updates=244200, lr=6.39922e-05, gnorm=1.42, loss_scale=4, train_wall=353, gb_free=13.9, wall=563673
lprobs.size(): torch.Size([2992, 42808])
2023-09-26 23:20:20 | INFO | train_inner | epoch 027:   8790 / 9060 loss=7.584, nll_loss=3.779, ppl=13.73, wps=3834.1, ups=0.29, wpb=13056.3, bsz=423.4, num_updates=244300, lr=6.39791e-05, gnorm=1.22, loss_scale=4, train_wall=340, gb_free=13.7, wall=564013
2023-09-26 23:26:14 | INFO | train_inner | epoch 027:   8890 / 9060 loss=7.905, nll_loss=3.899, ppl=14.92, wps=3698, ups=0.28, wpb=13100.7, bsz=447.8, num_updates=244400, lr=6.3966e-05, gnorm=1.272, loss_scale=4, train_wall=354, gb_free=13.5, wall=564367
2023-09-26 23:31:53 | INFO | train_inner | epoch 027:   8990 / 9060 loss=7.76, nll_loss=3.8, ppl=13.93, wps=3839.6, ups=0.29, wpb=13026.3, bsz=458.1, num_updates=244500, lr=6.39529e-05, gnorm=1.302, loss_scale=4, train_wall=339, gb_free=14.3, wall=564707
lprobs.size(): torch.Size([3456, 42808])
2023-09-26 23:36:00 | INFO | fairseq_cli.train | begin validation on "valid" subset
2023-09-26 23:36:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-26 23:36:00 | INFO | fairseq.tasks.translation | example hypothesis: Vielen Dank, Herr Präsident.
2023-09-26 23:36:00 | INFO | fairseq.tasks.translation | example reference: Vielen Dank, Herr Präsident.
2023-09-26 23:36:01 | INFO | fairseq.tasks.translation | example hypothesis: Der Aufruf zum Handeln ist daher vollkommen gerechtfertigt.
2023-09-26 23:36:01 | INFO | fairseq.tasks.translation | example reference: Somit ist der Handlungsappell vollkommen berechtigt.
2023-09-26 23:36:01 | INFO | fairseq.tasks.translation | example hypothesis: Danach besteht kein Anspruch auf Unterkunft.
2023-09-26 23:36:01 | INFO | fairseq.tasks.translation | example reference: Danach besteht kein Anspruch auf die Beherbergungsleistung mehr.
2023-09-26 23:36:02 | INFO | fairseq.tasks.translation | example hypothesis: Selbstverständlich werden Ihre Unterlagen streng vertraulich behandelt.
2023-09-26 23:36:02 | INFO | fairseq.tasks.translation | example reference: Ihre Daten behandeln wir selbstverständlich streng vertraulich.
2023-09-26 23:36:02 | INFO | fairseq.tasks.translation | example hypothesis: Meiner Meinung nach sollte die Namensfrage nicht an erster Stelle stehen.
2023-09-26 23:36:02 | INFO | fairseq.tasks.translation | example reference: Meiner Meinung nach sollte der Konflikt um die Namensgebung nicht an erster Stelle stehen.
2023-09-26 23:36:03 | INFO | fairseq.tasks.translation | example hypothesis: Das Portal hat zusätzliche Inhalte hinzugefügt und es war ein Erfolg.
2023-09-26 23:36:03 | INFO | fairseq.tasks.translation | example reference: Das Portal wurde mit ergänzenden Inhalten ausgebaut. Es wurde ein voller Erfolg.
2023-09-26 23:36:04 | INFO | fairseq.tasks.translation | example hypothesis: (EN) Herr Präsident! Frohes Neues Jahr für alle und herzlichen Glückwunsch an unseren Präsidenten.
2023-09-26 23:36:04 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich wünsche allen ein gutes neues Jahr und gratuliere unserem Präsidenten.
2023-09-26 23:36:04 | INFO | fairseq.tasks.translation | example hypothesis: Die Kommission hat ein Monopol auf das Initiativrecht, das wir respektieren.
2023-09-26 23:36:04 | INFO | fairseq.tasks.translation | example reference: Die Kommission hat das Monopol des Initiativrechts, das wir respektieren.
2023-09-26 23:36:05 | INFO | fairseq.tasks.translation | example hypothesis: Das Chat-Modul enthält eine Reihe von Funktionen zur Verwaltung und Überprüfung von Chat-Diskussionen.
2023-09-26 23:36:05 | INFO | fairseq.tasks.translation | example reference: Das Chat-Modul enthält eine Anzahl von Funktionen, um die Diskussionen zu verwalten und nachzubereiten.
2023-09-26 23:36:06 | INFO | fairseq.tasks.translation | example hypothesis: Alle Zimmer bieten digitales Fernsehen und Internetzugang, die sowohl für Geschäfts- als auch für Freizeitreisende ansprechend sind.
2023-09-26 23:36:06 | INFO | fairseq.tasks.translation | example reference: In allen Zimmern ist Digitalfernsehen und Internetzugang für sowohl Geschäftsreisende als auch Urlauber erhältlich.
2023-09-26 23:36:06 | INFO | fairseq.tasks.translation | example hypothesis: Von Montepulciano aus nehmen Sie die Staatsstraße in Richtung Chianciano Terme.
2023-09-26 23:36:06 | INFO | fairseq.tasks.translation | example reference: Dann in Richtung Chianciano Terme abbiegen. Nach ca.
2023-09-26 23:36:07 | INFO | fairseq.tasks.translation | example hypothesis: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-26 23:36:07 | INFO | fairseq.tasks.translation | example reference: This page was last modified 15: 41, 21. Jul 2008 by Red _ marquis.
2023-09-26 23:36:07 | INFO | fairseq.tasks.translation | example hypothesis: Generell werden in der EU als Ganzes riesige Mengen an Energie verschwendet.
2023-09-26 23:36:07 | INFO | fairseq.tasks.translation | example reference: Die Energieverschwendung ist allgemein in der gesamten EU gigantisch.
2023-09-26 23:36:08 | INFO | fairseq.tasks.translation | example hypothesis: Das deutsche Linux Magazin hat einen Artikel des Gentoo-Entwicklers Michael Kohl in seiner aktuellen Nummer.
2023-09-26 23:36:08 | INFO | fairseq.tasks.translation | example reference: Das deutsche Linux Magazin veröffentlichte einen Artikel des Gentoo Entwicklers Michael Kohl in der letzen Ausgabe.
2023-09-26 23:36:08 | INFO | fairseq.tasks.translation | example hypothesis: Hoffentlich wird sich die Änderung der Einstellung auch in Kürze im Haushalt der Union niederschlagen.
2023-09-26 23:36:08 | INFO | fairseq.tasks.translation | example reference: Hoffentlich kommt diese veränderte Haltung bald auch bei den Haushaltsentscheidungen der Union zum Tragen.
2023-09-26 23:36:09 | INFO | fairseq.tasks.translation | example hypothesis: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards sowohl für Kleinerzeuger als auch für die Agrarindustrie ist inakzeptabel.
2023-09-26 23:36:09 | INFO | fairseq.tasks.translation | example reference: Die Anwendung harmonisierter Produktions- und Vermarktungsstandards für kleine Erzeuger und die Agrarindustrie gleichermaßen ist inakzeptabel.
2023-09-26 23:36:10 | INFO | fairseq.tasks.translation | example hypothesis: Hier ein konkretes Beispiel: die allgemein bekannte und regelmäßige Verletzung der Menschenrechte in Belarus und Russland.
2023-09-26 23:36:10 | INFO | fairseq.tasks.translation | example reference: Ein konkretes Beispiel dafür sind die allgemein bekannten und regelmäßigen Menschenrechtsverletzungen in Belarus und Russland.
2023-09-26 23:36:11 | INFO | fairseq.tasks.translation | example hypothesis: Ich möchte Sie daran erinnern, dass eines der grundlegenden Ziele der Beschäftigungsstrategie die Integration älterer Menschen ist.
2023-09-26 23:36:11 | INFO | fairseq.tasks.translation | example reference: Ich möchte daran erinnern, dass die Integration der Älteren in den Arbeitsmarkt ein grundlegendes Ziel der Beschäftigungsstrategie darstellt.
2023-09-26 23:36:11 | INFO | fairseq.tasks.translation | example hypothesis: Wie viele von ihnen waren gezwungen, sich mehr Zeit für ihr Berufsleben zu widmen, als sie es sich gewünscht hätten?
2023-09-26 23:36:11 | INFO | fairseq.tasks.translation | example reference: Wie viele sind gezwungen, für ihren Beruf mehr Zeit aufzuwenden als sie wünschen?
2023-09-26 23:36:12 | INFO | fairseq.tasks.translation | example hypothesis: Der grösste Schweizer Flugzeughersteller Pilatus Aircraft hat seinen Sitz und Produktionshallen in Stans.
2023-09-26 23:36:12 | INFO | fairseq.tasks.translation | example reference: In Stans ist unter anderem der grösste schweizerische Flugzeughersteller Pilatus Aircraft beheimatet.
2023-09-26 23:36:12 | INFO | fairseq.tasks.translation | example hypothesis: - Ein Vergütungsausschuss, dessen Vorsitzender stets Vorsitzender des Aufsichtsrats ist.
2023-09-26 23:36:12 | INFO | fairseq.tasks.translation | example reference: - ein Vergütungsausschuss, dessen Vorsitzender stets der Aufsichtsratsvorsitzende ist.
2023-09-26 23:36:13 | INFO | fairseq.tasks.translation | example hypothesis: Nicht alle hatten realistische Chancen, aber jede von ihnen hatte die Unterstützung einer bestimmten politischen Kraft.
2023-09-26 23:36:13 | INFO | fairseq.tasks.translation | example reference: Nicht alle von ihnen hatte eine realistische Chance, aber jeder Einzelne besaß die Unterstützung einer spezifischen politischen Kraft.
2023-09-26 23:36:14 | INFO | fairseq.tasks.translation | example hypothesis: Die funktionelle Verbindung dieses Gremiums sollte ausschließlich mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution sein.
2023-09-26 23:36:14 | INFO | fairseq.tasks.translation | example reference: Darauf beziehen sich die Änderungsanträge 20 und 26. Diese Einrichtung sollte funktionell mit den europäischen Institutionen und unter keinen Umständen mit einer nationalen Institution verbunden sein.
2023-09-26 23:36:14 | INFO | fairseq.tasks.translation | example hypothesis: Eine fehlerhafte Anzeige kann potentielle Käufer dazu veranlassen, sich über die Qualität Ihrer Dienstleistung und Produkte zu informieren.
2023-09-26 23:36:14 | INFO | fairseq.tasks.translation | example reference: Vor diesem Zeitpunkt erfolgte die Auswertung nur teilweise und sollte deshalb nicht als Anhaltspunkt für Optimierungen dienen.
2023-09-26 23:36:15 | INFO | fairseq.tasks.translation | example hypothesis: Während sich die Zentralbanken weiter auf unbekanntes Territorium wagen, argumentieren die Befürworter, dass sie schlimmstenfalls keinen Schaden anrichten werden.
2023-09-26 23:36:15 | INFO | fairseq.tasks.translation | example reference: Während sich Zentralbanken weiter in unbekanntes Terrain vorwagen, behaupten ihre Fürsprecher, dass schlimmstenfalls kein Schaden drohe.
2023-09-26 23:36:15 | INFO | fairseq.tasks.translation | example hypothesis: Sie fügte hinzu, dass sie bereit sei, die notwendigen Vorschläge zu machen, wenn es Anzeichen dafür gäbe, dass die Mitgliedstaaten eine Einigung erzielen könnten.
2023-09-26 23:36:15 | INFO | fairseq.tasks.translation | example reference: Sie erklärte sich bereit, die notwendigen Vorschläge vorzulegen, sofern es zwischen den Mitgliedstaaten zu einer Einigung kommen sollte.
2023-09-26 23:36:16 | INFO | fairseq.tasks.translation | example hypothesis: Ich nutze auch die Gelegenheit dieser Aussprache, um Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-26 23:36:16 | INFO | fairseq.tasks.translation | example reference: Des Weiteren möchte ich die Gelegenheit dieser Aussprache nutzen, um die Vertreter des Rates und der Kommission zu einer besseren interinstitutionellen Zusammenarbeit aufzurufen.
2023-09-26 23:36:17 | INFO | fairseq.tasks.translation | example hypothesis: Wal-Mart hat zwei Standorte im Umkreis von etwa 8 km vom Strip entfernt.
2023-09-26 23:36:17 | INFO | fairseq.tasks.translation | example reference: Wal-Mart ist im Umkreis von 8 Kilometern vom Strip gleich zweimal vertreten.
2023-09-26 23:36:17 | INFO | fairseq.tasks.translation | example hypothesis: Cyberdiritto ist das erste Web Legal Portal, das auf dem bekannten Open Source Php-Nuke Web-Portalsystem basiert.
2023-09-26 23:36:17 | INFO | fairseq.tasks.translation | example reference: Cyberdiritto ist das erste Rechtswebportal, basierend auf dem bekannten Php-Nuke Webportalsystem.
2023-09-26 23:36:18 | INFO | fairseq.tasks.translation | example hypothesis: Deshalb bietet HearDis! die akustische, interaktive oder schriftliche Umsetzung von Klanghandbüchern an.
2023-09-26 23:36:18 | INFO | fairseq.tasks.translation | example reference: Bei komplexen und langfristigen Projekten ist es meist sinnvoll, eine Dokumentation der akustischen Maßnahmen in einem Sound Manual auf schriftliche, auditive oder interaktive Weise zu erstellen.
2023-09-26 23:36:18 | INFO | fairseq.tasks.translation | example hypothesis: Unser bekannter DECOTEX-Artikel ist mit der neuen Lotos-Beschichtung für Transferdruck sowie Direktdruck erhältlich.
2023-09-26 23:36:18 | INFO | fairseq.tasks.translation | example reference: Unser bekannter DEKOTEX Artikel ist mit der neuen Lotos Ausrüstung für den Transfer- und Direktdruck gleichermaßen geeignet.
2023-09-26 23:36:19 | INFO | fairseq.tasks.translation | example hypothesis: Sie muss auf ihrer innenpolitischen Unterstützung aufbauen, kann sich jedoch auf die wirtschaftliche und sicherheitspolitische Zusammenarbeit mit Amerika verlassen, um die Stabilität des Landes zu sichern.
2023-09-26 23:36:19 | INFO | fairseq.tasks.translation | example reference: Sie muss ihre Unterstützung im eigenen Land weiter ausbauen, könnte sich aber auf die Wirtschafts- und Sicherheitszusammenarbeit mit Amerika verlassen, um Pakistans Stabilität zu gewährleisten.
2023-09-26 23:36:20 | INFO | fairseq.tasks.translation | example hypothesis: Ein Beispiel ist die Notwendigkeit, dass Wirtschaftsmigranten nach ihrem Abzug Zugang zu dem Geld haben, das sie in die europäischen Sozialversicherungssysteme einzahlen.
2023-09-26 23:36:20 | INFO | fairseq.tasks.translation | example reference: Ich verweise hier beispielsweise auf den notwendigen Zugang von Rückkehrern zu den in europäische Sozialsysteme eingezahlten Mitteln.
2023-09-26 23:36:20 | INFO | fairseq.tasks.translation | example hypothesis: Alle bisherigen Modelle von Ferrari (Ferrari I, Ferrari II, Ferrari III) benutzten das Ascent Ti-Modell als Basis.
2023-09-26 23:36:20 | INFO | fairseq.tasks.translation | example reference: Alle bisherigen Modelle von Ferrari (Ferrari I, II Ferrari, Ferrari-III), die die Ascent T1-Modell als Basis.
2023-09-26 23:36:21 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind immer auf der Suche nach freien Dateiformaten für Sie, leider gibt es für einige Formate keine kostenlose Alternative, die auf beliebigen Computerplattformen läuft.
2023-09-26 23:36:21 | INFO | fairseq.tasks.translation | example reference: Sie können es aber als Anhaltspunkt für weitere Recherchen über die Firma Rohloff benutzen.
2023-09-26 23:36:22 | INFO | fairseq.tasks.translation | example hypothesis: Der Pastor wird auch wissen, wie man Ihnen helfen kann, qualifizierte Fachleute zu finden, die die besten Lösungen finden, wenn es Ihre Bedürfnisse und Wünsche sind..... finden, wenn es Ihre Bedürfnisse und Wünsche
2023-09-26 23:36:22 | INFO | fairseq.tasks.translation | example reference: Der Prediger kann Ihnen helfen, qualifizierte Fachleute zu finden, die für Sie die besten Lösungen suchen, wenn dies Ihrem Bedürfnis und Ihrem Wunsch entspricht.
2023-09-26 23:36:22 | INFO | fairseq.tasks.translation | example hypothesis: Trotzdem sind die Thatcher-Ideen über niedrigere und transparentere Steuerstrukturen und die zentrale Kontrolle der Haushaltsausgaben definitiv Schlüsselelemente seiner Agenda.
2023-09-26 23:36:22 | INFO | fairseq.tasks.translation | example reference: Und doch ist die Putinsche Tagesordnung von Thatcheristischem Gedankengut geprägt - niedrigere Steuern, ein transparenteres Steuersystem und die zentrale Steuerung der Haushalts-Ausgaben.
2023-09-26 23:36:23 | INFO | fairseq.tasks.translation | example hypothesis: media-gfx / splashutils Benutzer werden splashutils erneut emergen müssen, damit es korrekt funktioniert.
2023-09-26 23:36:23 | INFO | fairseq.tasks.translation | example reference: media-gfx / splashutils User müssen splashutils nochmal installieren, damit es richtig läuft.
2023-09-26 23:36:24 | INFO | fairseq.tasks.translation | example hypothesis: Spieler der Horde und der Allianz können ihre Gegenstände nicht gegenseitig kaufen oder verkaufen, wenn sie nicht die unten aufgeführten neutralen Auktionshäuser nutzen.
2023-09-26 23:36:24 | INFO | fairseq.tasks.translation | example reference: Die drei Auktionshäuser der Horde und der Allianz sind jeweils untereinander verbunden, so dass dieselben Auktionen in Eisenschmiede und in Darnassus gefunden werden.
2023-09-26 23:36:24 | INFO | fairseq.tasks.translation | example hypothesis: Wir wollen auch, dass China die Kopenhagener Kriterien erfüllt, und es gibt keinen Grund, warum sich diese Kriterien auf die Anwendung nur innerhalb der Grenzen Europas beschränken sollten.
2023-09-26 23:36:24 | INFO | fairseq.tasks.translation | example reference: Wir wünschen, dass China auch die Kopenhagener Kriterien erfüllt; es gibt keinen Grund, diese Kriterien nur innerhalb der europäischen Grenzen anzuwenden.
2023-09-26 23:36:25 | INFO | fairseq.tasks.translation | example hypothesis: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage eines Berichts von Herrn Wynn, der Kommission die Entlastung für den Gesamthaushaltsplan der Gemeinschaft für 1994 zu erteilen.
2023-09-26 23:36:25 | INFO | fairseq.tasks.translation | example reference: Der Ausschuß für Haushaltskontrolle empfiehlt auf der Grundlage des Berichts von Herrn Wynn, der Kommission im Hinblick auf den Gesamthaushaltsplan für das Haushaltsjahr 1994 Entlastung zu gewähren.
2023-09-26 23:36:26 | INFO | fairseq.tasks.translation | example hypothesis: Gemäß dem Vorschlag der Kommission wird der Rat formelle Standpunkte zu einigen grundsätzlichen Details des Abkommens mit den Vereinigten Staaten vorlegen müssen.
2023-09-26 23:36:26 | INFO | fairseq.tasks.translation | example reference: Nach dem Vorschlag der Kommission muss der Rat zu bestimmten Einzelheiten der grundsätzlichen Einigung mit den USA formelle Kommentare abgeben.
2023-09-26 23:36:26 | INFO | fairseq.tasks.translation | example hypothesis: Trendige oder klassische Farben, zeitloses Design oder Sonderausgabe - unser breites Sortiment an PlastikBabyartikeln überzeugt nicht zuletzt durch seine herausragende Verarbeitung.
2023-09-26 23:36:26 | INFO | fairseq.tasks.translation | example reference: Trendige oder klassische Farben, zeitloses Design oder Sonderausführung - die Babyartikel aus Kunststoff überzeugen in ihrer Vielseitigkeit und vor allem dank hervorragender Verarbeitung.
2023-09-26 23:36:27 | INFO | fairseq.tasks.translation | example hypothesis: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourist"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-26 23:36:27 | INFO | fairseq.tasks.translation | example reference: Ratschlag: Wegen der riesigen Liste von mit..... verbundenen "... medical tourism"... Seiten mit Schlusselwortern, die auf dieser Homepage aufgezahlt sind, verwende "Finde in der Site" die Funktion unten.
2023-09-26 23:36:28 | INFO | fairseq.tasks.translation | example hypothesis: Der Kunde ist jedoch verpflichtet, picturemaxx unverzüglich nach Kenntnisnahme Kenntnis von SachSachSachverhalten zu informieren, die mit diesen AGB nicht kompatibel sind.
2023-09-26 23:36:28 | INFO | fairseq.tasks.translation | example reference: Der Kunde ist allerdings unverzüglich nach Kenntniserlangung verpflichtet, picturemaxx solche Sachverhalte anzuzeigen, die mit diesen AGB nicht im Einklang stehen.
2023-09-26 23:36:28 | INFO | fairseq.tasks.translation | example hypothesis: Wir sind eine Union, die Fortschritte gemacht hat und die die Notwendigkeit institutioneller Veränderungen erkannt hat, die eine stärkere Präsenz im Bereich der Außenpolitik und Verteidigung notwendig macht.
2023-09-26 23:36:28 | INFO | fairseq.tasks.translation | example reference: Wir sind eine Union, die sich weiter entwickelt und die die Notwendigkeit von institutionellen Veränderungen realisiert hat, die sieht, dass sie im Bereich der Außenpolitik und der Verteidigung eine stärke Präsenz braucht.
2023-09-26 23:36:29 | INFO | fairseq.tasks.translation | example hypothesis: Zusätzlich zu unserem Shop-Angebot haben wir ein Blog erstellt, das als Informationsportal für unsere Kunden gedacht ist, mit Produktneuheiten und Informationen aus allen Kategorien in zwei Sprachen.
2023-09-26 23:36:29 | INFO | fairseq.tasks.translation | example reference: Zusätzlich zu unserem Shop-Angebot bieten wir Ihnen unser Blog als Informationsportal mit interessanten Produktinformationen und Neuheiten aus allen Produktkategorien an.
2023-09-26 23:36:30 | INFO | fairseq.tasks.translation | example hypothesis: Wir können die bedeutenden Fortschritte erkennen, die erzielt wurden, wenn wir uns alle Fragen ansehen, die jetzt diskutiert werden und die etwas betreffen, was gerade einmal zwei Jahre alt ist, die neue transatlantische Agenda.
2023-09-26 23:36:30 | INFO | fairseq.tasks.translation | example reference: Wir können die entscheidenden Fortschritte erkennen, wenn wir uns all die Themen ansehen, die im Augenblick im Rahmen der transatlantischen Agenda - die ja kaum zwei Jahre alt ist - diskutiert werden.
2023-09-26 23:36:30 | INFO | fairseq.tasks.translation | example hypothesis: Bilstein B12 BTK: Für optimale Fahrdynamik - die ideale Mischung aus reduzierten Federn und Stoßdämpfern für erstklassigen Spaß am Rad.
2023-09-26 23:36:30 | INFO | fairseq.tasks.translation | example reference: Bilstein B14 PSS: Das Gewindefahrwerk (Dämpfer und Federn) mit individueller Tieferlegung.
2023-09-26 23:36:31 | INFO | fairseq.tasks.translation | example hypothesis: Wieder einmal war der Berichterstatter in der Lage, die zuweilen unterschiedlichen Meinungen und Beiträge zusammenzufassen und - ich würde sagen - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-26 23:36:31 | INFO | fairseq.tasks.translation | example reference: Erneut war der Berichterstatter in der Lage, zusammenzubringen, was mitunter verschiedene Ansichten und Beiträge waren, und diese - wie ich finde - in einem äußerst ausgewogenen Text zusammenzufassen.
2023-09-26 23:36:32 | INFO | fairseq.tasks.translation | example hypothesis: Mit der gleichen hochwertigen Technologie ergänzt unser COMPACT-Modell unser Programm an trockenen elektrostatischen Niederschlagsgeräten mit einem trockenen ESP für den unteren Leistungsbereich............., für den unteren Leistungs
2023-09-26 23:36:32 | INFO | fairseq.tasks.translation | example reference: Mit der gleichen hochwertigen Technologie ergänzt die Variante COMPACT unser Trocken-Elektrofilter-Programm für den unteren Leistungsbereich.
2023-09-26 23:36:32 | INFO | fairseq.tasks.translation | example hypothesis: San Marino 750 Meter hoch, im ältesten und kleinsten souveränen Staat der Welt, der seine Freiheit und Unabhängigkeit seit Jahrhunderten verteidigt hat, befinden Sie sich bereits in einem fremden Land.........., die sich bereits in einem fremden Land
2023-09-26 23:36:32 | INFO | fairseq.tasks.translation | example reference: San Marino In 750 Meter Höhe, im antiksten und kleinsten souveränen Staat der Welt, welcher seit Jahrhunderten seine Freiheit und Unabhängigkeit bewahrt, ist man bereits im Ausland.
2023-09-26 23:36:33 | INFO | fairseq.tasks.translation | example hypothesis: In einer Zeit, in der viele unserer traditionellen Industrien nach China und in den Fernen Osten abwandern, müssen wir uns auf unsere Innovation und Erfindungsgabe verlassen, um unseren Lebensunterhalt zu verdienen.
2023-09-26 23:36:33 | INFO | fairseq.tasks.translation | example reference: In einer Zeit, in der viele unserer traditionellen Branchen nach China und in den Fernen Osten abwandern, müssen wir uns, um unseren Lebensunterhalt zu sichern, auf unsere Innovationsfähigkeit und Erfindungsgabe verlassen.
2023-09-26 23:36:34 | INFO | fairseq.tasks.translation | example hypothesis: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Verhandlungen mit Drittländern angewiesen, von denen viele seit Jahren bestehen und mit unserer Völkergemeinschaft zu tun haben.
2023-09-26 23:36:34 | INFO | fairseq.tasks.translation | example reference: Das Vereinigte Königreich hat ein Handelsdefizit mit der EU und ist auf Vereinbarungen mit Drittstaaten angewiesen, von denen viele seit Jahren bestehen und in Verbindung mit unserem Commonwealth stehen.
2023-09-26 23:36:34 | INFO | fairseq.tasks.translation | example hypothesis: La finale des WSOP a lieu le 9 novembre avec les neufs joueurs restant qui se battront pour leur part de 32 000 $.
2023-09-26 23:36:34 | INFO | fairseq.tasks.translation | example reference: La mesa final WSOP tendrá lugar el día 9 de noviembre con los nueve jugadores restantes luchando por 32 millones de dólares.
2023-09-26 23:36:35 | INFO | fairseq.tasks.translation | example hypothesis: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit Wirklichkeit werden soll, dann ist eine einfache, schnelle Kodifizierung dieses Raums des Gemeinschaftsrechts längst überfällig.
2023-09-26 23:36:35 | INFO | fairseq.tasks.translation | example reference: Wenn wir an unsere Bürger appellieren und das Grundrecht auf Freizügigkeit in die Praxis umsetzen wollen, ist die einfache und schnelle Kodifizierung dieses Bereichs des Gemeinschaftsrechts längst überfällig.
2023-09-26 23:36:36 | INFO | fairseq.tasks.translation | example hypothesis: Das Kompromisspaket wird sicherstellen, dass die steigende Zahl von Patienten in Europa, die mit menschlichen Geweben und Zellen behandelt werden, darauf vertrauen können, dass diese Substanzen nicht nur sicher, sondern auch von guter Qualität sind.
2023-09-26 23:36:36 | INFO | fairseq.tasks.translation | example reference: Durch das Kompromisspaket wird sichergestellt, dass die steigende Anzahl an mit menschlichem Gewebe und Zellen behandelten Patienten in Europa darauf vertrauen kann, dass diese Substanzen nicht nur sicher, sondern auch qualitativ hochwertig sind.
2023-09-26 23:36:37 | INFO | fairseq.tasks.translation | example hypothesis: In dieser Notsituation gibt es jedoch noch eine andere: die Notsituation der Kinder, des schwächsten BevölkerungsBevölkerung, die ohne Familie, ohne Schutz und ohne Staat zurückgelassen wurde.
2023-09-26 23:36:37 | INFO | fairseq.tasks.translation | example reference: Inmitten dieser Notlage gibt jedoch noch eine weitere: die Notlage der Kinder, der schwächsten Bevölkerungsgruppe, die ohne Familie, ohne Schutz und ohne Staat dastehen.
2023-09-26 23:36:37 | INFO | fairseq.tasks.translation | example hypothesis: Zuallererst sollte klargestellt und hervorgehoben werden, dass die Praxis des Abtrennens seit 2003 von der EU geregelt wird, was bedeutet, dass Haie nicht nur für ihre Flossen gefangen werden können..... gefangen werden können nicht nur für ihre Flossen gefangen werden können.
2023-09-26 23:36:37 | INFO | fairseq.tasks.translation | example reference: In erster Linie muss man klarstellen und betonen, dass die Praxis des Flossenabtrennens von der EU seit 2003 reguliert wird. Das heißt, Haie dürfen nicht allein wegen ihrer Flossen gefangen werden.
2023-09-26 23:36:38 | INFO | fairseq.tasks.translation | example hypothesis: Wenn das Selbst nicht frei ist, nicht erst in der ersten Welt verwirklicht wird, dann bleiben alle äußeren Beziehungen von diesem Mangel an Erkenntnis geprägt, und man kann niemanden wirklich kennen, bis man sein wahres Selbst kennt.
2023-09-26 23:36:38 | INFO | fairseq.tasks.translation | example reference: Wenn andererseits jeder einzelne bereit ist sich rückzubesinnen, auf die "Kunst der höheren Unterscheidungsfähigkeit", dann kann der Leidensweg beendet werden.
2023-09-26 23:36:39 | INFO | fairseq.tasks.translation | example hypothesis: Daher ist es wichtig, dass wir weiterhin internationalen Druck auf die Regierung ausüben, damit sie alles in unserer Macht Stehende unternimmt, um vor den Wahlen eine gewaltfreie Zeit zu schaffen und das Verfahren für die Registrierung der Wähler wieder zu öffnen........, die Verfahren für die
2023-09-26 23:36:39 | INFO | fairseq.tasks.translation | example reference: Aus diesem Grunde ist es essenziell wichtig, weiterhin international auf die Regierung Druck auszuüben, um alles zu unternehmen, um eine gewaltfreie Periode im Vorfeld der Wahlen zu schaffen und den Prozess der Wählerregistrierung erneut aufzunehmen.
2023-09-26 23:36:39 | INFO | fairseq.tasks.translation | example hypothesis: Rechtsvorschriften, die den Bürgern freie Meinungsäußerung, freie und unabhängige Wahlen und Vereinigungsfreiheit ermöglichen, sind von entscheidender Bedeutung, und es muss der Öffentlichkeit klar gemacht werden, dass niemand über dem Gesetz steht.....
2023-09-26 23:36:39 | INFO | fairseq.tasks.translation | example reference: Eine Gesetzgebung, die den Bürgern Redefreiheit, unabhängige Wahlen und Versammlungsfreiheit gewährleistet, ist unabdingbar, genauso wie allen klar sein muss, dass sich niemand über das Gesetz stellen kann.
2023-09-26 23:36:40 | INFO | fairseq.tasks.translation | example hypothesis: System ist in Java Programmiersprache mit J2EE-Techniken implementiert, die die Plattform- und Betriebssystem-Unabhängigkeit garantiert (Anwendung wurde unter Linux, Sun Solaris und Windows NT / 2000 getestet).
2023-09-26 23:36:40 | INFO | fairseq.tasks.translation | example reference: Die derzeitige Version unseres Systems unterstützt die Verwaltung durch die Technologie WebServices. Die neue Version, die wir unseren Kunden im Juni 2003 vorzulegen planen, wird vollständig durch die Technologie WebServices geleitet, was die Integration mit verschiedenen Zusätzen bedeutend erleichtert.
2023-09-26 23:36:41 | INFO | fairseq.tasks.translation | example hypothesis: Berichterstatterin. - (NL) Meine Damen und Herren! Wir stimmen heute über einen Vorschlag zur besseren und flexibleren Koordinierung der europäischen Sozialversicherung ab und stimmen somit für die Klärung des Anhangs.
2023-09-26 23:36:41 | INFO | fairseq.tasks.translation | example reference: Berichterstatterin. - (NL) Sehr geehrte Damen und Herren! Heute stimmen wir über eine klarere und flexiblere Koordinierung der sozialen Sicherheit in Europa und insofern für eine Präzisierung des Anhangs ab.
2023-09-26 23:36:42 | INFO | fairseq.tasks.translation | example hypothesis: Unser Ausschuss ist außerdem der Ansicht, dass die WTO-Mitgliedstaaten eine besondere Verantwortung für die Einhaltung der grundlegenden Arbeitsnormen tragen, und fordert die WTO auf, klar zu erklären, dass Sanktionen, die von der IAO verhängt werden, nicht als unvereinbar mit den WTO-Abkommen angesehen werden...
2023-09-26 23:36:42 | INFO | fairseq.tasks.translation | example reference: Nach Meinung unseres Ausschusses sind die Länder, die der Welthandelsorganisation angehören, besonders dazu verpflichtet, die grundlegenden Arbeitsnormen einzuhalten. Deshalb fordert er die WTO auf klarzustellen, dass derartige, gemäß einem Beschluss der ILO verhängte Sanktionen nicht als unvereinbar mit den WTO-Verträgen gelten dürfen.
2023-09-26 23:36:42 | INFO | fairseq.tasks.translation | example hypothesis: Ich habe kürzlich an einer Debatte über das irische öffentlich-rechtliche Radio RTE mit einer Frau teilgenommen, die sehr besorgt war, dass wir die Gesundheitsausgaben kürzen und nicht genug tun, um die Ausgaben für Entwicklungshilfe zu kürzen......, die wir sehr besorgt waren, weil wir die Ausgaben für
2023-09-26 23:36:42 | INFO | fairseq.tasks.translation | example reference: Kürzlich nahm ich im irischen öffentlichen-rechtlichen Radiosender RTÉ an einer Diskussion teil, bei der sich eine Dame besorgt zeigte, dass die Gesundheitsausgaben gekürzt werden und wir uns nicht ausreichend dafür einsetzen, die Entwicklungshilfe einzuschränken.
2023-09-26 23:36:43 | INFO | fairseq.tasks.translation | example hypothesis: Vor diesem Hintergrund hoffe ich, dass der Bericht von Herrn Parish, der gute Arbeit geleistet hat, morgen angenommen wird, und möchte die Kommission nochmals zu ihrer besonnenen Haltung beglückwünschen.... beglückwünschen... beglückwünschen möchte der Kommission nochmals zu ihrer besonnenen Haltung... beglückwünschen, die sie
2023-09-26 23:36:43 | INFO | fairseq.tasks.translation | example reference: In diesem Sinne hoffe ich, dass der Bericht Parish - der Kollege hat eine gute Arbeit geleistet - morgen angenommen wird, und ich möchte der Kommission nochmals ausdrücklich zu ihrer besonnenen Haltung gratulieren.
2023-09-26 23:36:44 | INFO | fairseq.tasks.translation | example hypothesis: Egal, ob Sie Inspiration für Ihren Unterricht oder konkrete Informationen über die europäische Geschichte, Staatsbürgerschaft oder so etwas Spezielles wie die Senkung des individuellen Energieverbrauchs suchen, Sie sollten etwas Nützliches finden, das auf die Altersgruppe Ihrer Schüler zugeschnitten ist...
2023-09-26 23:36:44 | INFO | fairseq.tasks.translation | example reference: Ob Sie nun gute Ideen für Ihren Unterricht oder konkrete Informationen über die Geschichte Europas, die EU-Bürger oder Dokumentation zu speziellen Fragen suchen, beispielsweise über die Möglichkeiten des Einzelnen, Energie zu sparen: Hier finden Sie zweifellos nützliche und gezielte Angaben und Hinweise für die Altersgruppe Ihrer Schüler.
2023-09-26 23:36:45 | INFO | fairseq.tasks.translation | example hypothesis: Die vierte Staffel der Griechischen Poker Tour (2010-2011) findet in der Hauptstadt Österreichs, im schönen Wien und im bekannten Concord Card Casino statt und ist für Spieler aller Nationalitäten offen........ offen für Spieler aller Nationalitäten aller Nationalitäten offen für Spieler aller Nationalitäten.
2023-09-26 23:36:45 | INFO | fairseq.tasks.translation | example reference: Greek Poker Tour (GPT), ist die erste und groesste griechische Poker Veranstaltung in Europa, eine Idee die zu Leben erwacht wurde durch das Pokerunion Team (www.pokerunion.gr).
2023-09-26 23:36:46 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Ich glaube, dass der Bericht, mit Ausnahme dieser wenigen Vorbehalte, ein nützlicher und relevanter Beitrag zur Diskussion über Flexicurity ist, und ich möchte dem Europäischen Parlament dafür danken.
2023-09-26 23:36:46 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, ich halte den Bericht mit Ausnahme dieser wenigen Einwände für einen nützlichen, sachdienlichen Beitrag zur Diskussion über Flexicurity, und ich möchte dem Europäischen Parlament noch einmal dafür danken.
2023-09-26 23:36:46 | INFO | fairseq.tasks.translation | example hypothesis: Etwas anderes zu denken, hieße, eine bestimmte Art von Vertragsbeziehung zwischen Einzelpersonen mit gemeinsamen Anliegen zu naturalisieren und zu mystifizieren (unter ihnen häufig die tatsächliche oder wahrgenommene Bedrohung, von der institutionellen Hegemonie zerschlagen zu werden)!!!!!!!!!!!!!!
2023-09-26 23:36:46 | INFO | fairseq.tasks.translation | example reference: Jede andere Vorstellung hieße, als "natürlich" auszugeben und zu mystifizieren, was eigentlich ein Vereinbarungsverhältnis ist zwischen Individuen mit gemeinsamen Anliegen (zu denen oft die tatsächliche oder wahrgenommene Bedrohung gehört, durch die institutionelle Hegemonie zerstört zu werden).
2023-09-26 23:36:47 | INFO | fairseq.tasks.translation | example hypothesis: In der Rechtsprechung der Gemeinschaft zu einem Thema, das personenbezogene Daten betrifft, sollten der Gerichtshof und das Gericht erster Instanz intervenieren können, wenn beispielsweise Bürger Forderungen stellen oder wenn eine einheitliche Auslegung der Konvention erforderlich ist......, wenn eine einheitliche Auslegung der Konvention erforderlich ist, wenn zum Beispiel die Bürger Ansprüche erheben, oder wenn
2023-09-26 23:36:47 | INFO | fairseq.tasks.translation | example reference: Und bei einer gemeinschaftlichen Rechtssprechung, bei der es um personenbezogene Daten geht, müßte auch der Gerichtshof und das Gericht erster Instanz Mitspracherecht haben, wenn es zum Beispiel um Beschwerden von Bürgern oder um eine einheitliche Auslegung dieses Übereinkommens geht.
2023-09-26 23:36:48 | INFO | fairseq.tasks.translation | example hypothesis: Der BMW 3er ist eines der unterhaltsamsten Autos für unter 50.000 $. Wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke kostenlos ausprobieren.........., wenn Sie in der Nähe von Toronto, Montreal oder Vancouver wohnen, können Sie die gesamte Strecke
2023-09-26 23:36:48 | INFO | fairseq.tasks.translation | example reference: Der 335i (behauptete) 300 PS, 3,0-Liter-Twin-Turbo sechs bleiben, ebenso wie der 328i-230 PS, 3,0-Liter-Inline-sechs.
2023-09-26 23:36:49 | INFO | fairseq.tasks.translation | example hypothesis: Herr Präsident! Zunächst möchte ich dem Berichterstatter, Herrn Swoboda, für einen ausgezeichneten Bericht danken, ebenso wie dem Ausschuss für auswärtige Angelegenheiten, Menschenrechte, gemeinsame Sicherheit und Verteidigungspolitik für die realistische Darstellung dieser Angelegenheit.
2023-09-26 23:36:49 | INFO | fairseq.tasks.translation | example reference: Herr Präsident, gestatten Sie mir zunächst, dem Berichterstatter, Herrn Swoboda, für seinen guten Bericht und gleichzeitig dem Ausschuss für auswärtige Angelegenheiten für seine sachgemäße Stellungnahme zu danken.
2023-09-26 23:36:50 | INFO | fairseq.tasks.translation | example hypothesis: Probieren Sie Fischsuppe, Hühnerpaprika, einen hausgemachten Pörkölt und die ausgezeichneten Süßwasserfische: gegrillter Hecht, Forelle mit Mandeln.
2023-09-26 23:36:50 | INFO | fairseq.tasks.translation | example reference: Sie müssen die Fischsuppe, das Hühnerpaprika und das gute hausgemachte Pörkölt (Eintopf) kosten, aber auch die köstlichen Süsswasser Fischsorten: den gegrillten Zander, oder die Forelle mit Mandeln.
2023-09-26 23:36:50 | INFO | fairseq.tasks.translation | example hypothesis: Vielleicht wäre es besser, anstatt sich daran zu erinnern, was eine politische Aktion bedeutet, einen Gesamtüberblick zu bieten, der es uns ermöglicht, uns eingehender mit den verschiedenen Fragen zu befassen und zu sehen, welche Impulse die Europäische Union mit Blick auf die Zukunft geben kann....., die Europäische Union mit Blick auf die Zukunft geben kann
2023-09-26 23:36:50 | INFO | fairseq.tasks.translation | example reference: Statt daran zu erinnern, was eine politische Aktion bedeutet, wäre es wohl besser gewesen, diese Gesamtvision zu bieten, die es uns erlauben würde, auf die verschiedenen Themen näher einzugehen und zu sehen, welchen Impuls die Europäische Union in der Vorausschau auf die Zukunft erhalten kann.
2023-09-26 23:36:51 | INFO | fairseq.tasks.translation | example hypothesis: Der Direktor der Bodulska balada, Herr Ivan Lambaša, und der Inhaber von "Scardona Records", Herr Branko Paić, stimmten überein, ein Live-Album "Bodulska balada 2009" zu veröffentlichen.
2023-09-26 23:36:51 | INFO | fairseq.tasks.translation | example reference: Der Direktor der Bodulska balada - Herr Ivan Lambaša, und der Besitzer von "Scardona" Records, Herr Branko Paić, haben sich über die Veröffentlichung der Live-Ausgabe der "Bodulska balada 2009" geeinigt.
2023-09-26 23:36:52 | INFO | fairseq.tasks.translation | example hypothesis: Es gibt keine soziale Stabilität und keinen wirklichen Wohlstand, wo Arbeitslosigkeit herrscht, wo unmittelbare Gefahren für die bestehenden Arbeitsplätze bestehen und die Wettbewerbsfähigkeit aufgrund makroökonomischer Strategien, fiskalischer Maßnahmen und Zwänge, die nicht an die bestehende Situation vor Ort angepasst sind, allmählich ausgehöhlt wird. die nicht an die bestehende Situation vor Ort angepasst sind, die nicht an die
2023-09-26 23:36:52 | INFO | fairseq.tasks.translation | example reference: Soziale Stabilität und echten Wohlstand kann es nicht geben, solange es Arbeitslosigkeit gibt, solange vorhandene Arbeitsplätze unmittelbar bedroht sind und die Wettbewerbsfähigkeit durch makroökonomische Politiken, fiskalpolitische Maßnahmen und Zwänge, die sich nicht an den tatsächlichen Bedingungen orientieren, allmählich unterhöhlt wird.
2023-09-26 23:36:53 | INFO | fairseq.tasks.translation | example hypothesis: Der uns von der Kommission vorgelegte Vorschlag für eine Verordnung geht in die gleiche allgemeine Richtung wie die bestehende Verordnung von 1994, zu der das Europäische Parlament durch ein ausgezeichnetes Beispiel der Zusammenarbeit mit dem Rat, der alle unsere Änderungsanträge in den Text übernommen hat, beigetragen hat, indem es alle unsere Änderungsanträge in den Text übernommen hat, beigetragen hat.. der alle unsere Änderungsanträge in den
2023-09-26 23:36:53 | INFO | fairseq.tasks.translation | example reference: Der Verordnungsvorschlag, den uns die Kommission präsentiert, folgt den allgemeinen Linien der Verordnung, die seit 1994 in Kraft ist und an deren Ausarbeitung das Europäische Parlament mitgewirkt hat, in einer ausgezeichneten Zusammenarbeit mit dem Rat, der alle Änderungsvorschläge unserer Versammlung in den Text einbrachte.
2023-09-26 23:36:54 | INFO | fairseq.tasks.translation | example hypothesis: Diese schwedische Initiative erweitert somit den Raum der Freizügigkeit der Union über die offiziellen geografischen Grenzen Europas hinaus, mit den entsprechenden Folgen für den Rechts- und Justizraum, wodurch Norwegen und Island, in denen die gemeinsamen Auslieferungsbestimmungen des Schengen-Besitzstands gelten werden, die gemeinsamen Auslieferungsbestimmungen gelten......, in denen die gemeinsamen Auslieferungsbestimmungen
2023-09-26 23:36:54 | INFO | fairseq.tasks.translation | example reference: So wird mit dieser schwedischen Initiative der Raum der Freiheit und der Freizügigkeit der Union über die formale Geographie Europas hinaus mit den entsprechenden Folgen im justiziellen Bereich erweitert, indem Norwegen und Island dazu übergehen, die gemeinsamen Bestimmungen des Schengen-Besitzstandes über Auslieferungsverfahren umzusetzen.
2023-09-26 23:36:54 | INFO | fairseq.tasks.translation | example hypothesis: Wir werden mit voller Geschwindigkeit in einem Schmiedeboot den Mississippi hinunter fahren, nach dem großen verborgenen Schatz suchen, uns in den schönen Becky Thatcher verlieben, der ein reiner Dynamit ist, und vor allem werden wir große Freunde sein....., werden wir vor allem große Freunde sein, werden wir große Freunde sein
2023-09-26 23:36:54 | INFO | fairseq.tasks.translation | example reference: Wir werden rasend schnell in einem improvisierten Boot den Mississippi herunter fahren, den großen versteckten Schatz suchen, uns in die schöne Becky Thatcher verlieben, die pures Dynamit ist, und vor Allem werden wir gute Freunde sein.
2023-09-26 23:36:55 | INFO | fairseq.tasks.translation | example hypothesis: In der Praxis harmonisiert die Richtlinie die Definition der Verschmutzung durch Schiffe, die von Einzelpersonen oder juristischen Personen verursacht werden, den Umfang der Reaktion darauf und den Strafcharakter der Sanktionen, die im Falle solcher Verstöße von Einzelpersonen angewendet werden können, die von Einzelpersonen begangen werden können...., die im Falle solcher Verstöße von Einzelpersonen, die von Einzelpersonen begangen werden, die von Einzelpersonen begangen werden
2023-09-26 23:36:55 | INFO | fairseq.tasks.translation | example reference: In der Praxis bedeutet dies, dass mit der Richtlinie die Definition für Meeresverschmutzung durch Schiffe von natürlichen oder juristischen Personen, der Umfang der entsprechenden Reaktion darauf und der Bestrafungscharakter der Sanktionen, die im Fall einer solche Zuwiderhandlung durch Personen angewendet werden können, harmonisiert werden.
2023-09-26 23:36:56 | INFO | fairseq.tasks.translation | example hypothesis: Thierry Falize und Vincent Reynaud wurden in der Tat verurteilt, nur weil sie ihre Arbeit als Journalisten und Kameramänner verübten und eine Gruppe von Bergleuten filmen, die seit Jahren von einem autoritären Regime gejagt werden, das sich über jedes Prinzip der Demokratie hinwegsetzt.. gefilmt, die seit Jahren von einem autoritären Regime
2023-09-26 23:36:56 | INFO | fairseq.tasks.translation | example reference: De facto wurden Thierry Falise und Vincent Reynaud verurteilt, obwohl sie lediglich ihrer Arbeit als Journalisten und Bildreporter nachgingen und eine Gruppe von Bergbewohnern filmten, die seit Jahren durch ein autoritäres Regime verfolgt werden, das alle Grundsätze der Demokratie mit Füßen tritt.
2023-09-26 23:36:57 | INFO | fairseq.tasks.translation | example hypothesis: Zu den Serviceleistungen des Hotels zählen Concierge-Service, ein Friseur- und Schönheitssalon, ein Transport- und Sightseeing-Schalter, ein Wechselstube, kostenloser Schuhputzservice und WLAN-Internetzugang. Das Omni Royal Orleans bietet 346 Zimmer und Suiten mit Blick auf den Innenhof und das Französische Viertel.
2023-09-26 23:36:57 | INFO | fairseq.tasks.translation | example reference: Guests can also enjoy casual dining in the rooftop la Riviera Cafe or a light meal at the Touche Bar. The Omni Royal Orleans offers a state of the art fitness facility as well as a rooftop observation deck and year round heated swimming pool.
2023-09-26 23:36:58 | INFO | fairseq.tasks.translation | example hypothesis: Die Stadt Caldas da Rainha, die ihren Namen der von Königin D. Leonor, der Frau von König D. João II., geliebten Thermalquelle verdankt und für ihre international bekannten Keramik für ihre figürlichen und satirischen Werke bekannt ist, ist auch einen Besuch wert.
2023-09-26 23:36:58 | INFO | fairseq.tasks.translation | example reference: Caldas da Rainha, ein weiteres Highlight, verdankt seinen Namen den Thermalquellen, die schon bei Königin Leonor, Gemahlin von König Johann II, sehr beliebt waren. Der Ort ist auch durch seine Keramiken mit figurativen und satirischen Abbildungen international bekannt geworden.
2023-09-26 23:36:59 | INFO | fairseq.tasks.translation | example hypothesis: Die Selbsttäuschung einiger Leute, die behaupten, dass es sich um gute prowestliche Befürworter auf der einen Seite und Befürworter des früheren Regimes auf der anderen Seite handelt, ist ebenfalls verwerflich, da die Rolle aller heute und davor bekannt ist.
2023-09-26 23:36:59 | INFO | fairseq.tasks.translation | example reference: Und die Illusion mancher, daß auf der einen Seite die guten, prowestlichen Kräfte und auf der anderen Seite die Verfechter des alten Regimes stehen, auch diese Illusion läßt sich revidieren, wenn die Rollen aller, damals und heute, bekannt werden.
2023-09-26 23:37:00 | INFO | fairseq.tasks.translation | example hypothesis: Ich bin mir bewusst, sagen wir es, aber ich kann nicht umhin, darauf hinzuweisen, dass in diesem Regelwerk etwas fehlt, weil viele Schiffe, die unterschiedslos zwischen Flüssen und dem Meer fahren, nicht auf diese Weise erfasst werden, und dies ist sicherlich ein Punkt, der irgendwie abgedeckt werden sollte...., der irgendwie behandelt werden sollte, und das ist sicherlich ein Punkt, der irgendwie behandelt werden sollte
2023-09-26 23:37:00 | INFO | fairseq.tasks.translation | example reference: Dessen bin ich mir natürlich bewusst, aber ich kann nicht unerwähnt lassen, dass in diesen Regelungen etwas fehlt, was dem Umstand zuzuschreiben ist, dass viele Schiffe, die gleichermaßen auf Flüssen und der See navigieren, nicht auf diese Weise abgedeckt sind. Dies ist sicherlich ein Punkt, der in irgendeiner Form geregelt werden sollte.
2023-09-26 23:37:01 | INFO | fairseq.tasks.translation | example hypothesis: (4) Wurden einem Aktionär außerhalb einer Hauptversammlung aufgrund seines Status als Aktionär Informationen zur Verfügung gestellt, so sind diese auf Verlangen an jeden anderen Aktionär in der Hauptversammlung zu übermitteln, auch wenn diese Informationen für eine ordnungsgemäße Beurteilung eines Tagesordnungspunktes nicht erforderlich sind.
2023-09-26 23:37:01 | INFO | fairseq.tasks.translation | example reference: (4) 1Ist einem Aktionär wegen seiner Eigenschaft als Aktionär eine Auskunft außerhalb der Hauptversammlung gegeben worden, so ist sie jedem anderen Aktionär auf dessen Verlangen in der Hauptversammlung zu geben, auch wenn sie zur sachgemäßen Beurteilung des Gegenstands der Tagesordnung nicht erforderlich ist.
2023-09-26 23:37:01 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen auch die Kontrolle haben, weil Milliarden und Abermilliarden Euro in einige Programme fließen, die in der Regel in die Taschen verschiedener Diktatoren fließen und ihren schönen Lebensstil finanzieren, während gleichzeitig Millionen und Abermillionen von Menschen in unseren eigenen Ländern leben, die auch ein sehr erbärmliches Leben führen.... leben, die auch ein sehr elendes Leben führen, die auch ein sehr elendes Leben führen, in unseren eigenen Ländern
2023-09-26 23:37:01 | INFO | fairseq.tasks.translation | example reference: Wir müssen auch die nachfolgende Kontrolle haben, denn viele Milliarden Euro werden in einige Programme gesteckt, die normalerweise die Taschen einzelner Diktatoren füllen und ihren Lebensstil finanzieren, während gleichzeitig viele Millionen Menschen in unseren eigenen Ländern leben und ein sehr schlechtes Leben haben.
2023-09-26 23:37:02 | INFO | fairseq.tasks.translation | example hypothesis: Wir fordern die Mitgliedstaaten auf - denn sie sagen, Flugzeuge aus einem Mitgliedstaat oder der NATO wären in diesen Kriegshandlung verwickelt gewesen -, mit Informationen zu helfen, die es keinen Grund mehr gibt, vertraulich, geheim oder geheim zu halten, damit wir die Fakten wirklich ans Licht bringen können und die ganze Wahrheit erfahren können...., damit wir die Fakten ans Licht bringen und die ganze Wahrheit sagen können, damit wir die ganze Wahrheit ans Licht bringen
2023-09-26 23:37:02 | INFO | fairseq.tasks.translation | example reference: Wir fordern, daß die Mitgliedstaaten - denn es heißt, daß wahrscheinlich Flugzeuge anderer Mitgliedstaaten oder der NATO an dieser militärischen Aktion beteiligt waren - mit Informationen, für deren Zurückhaltung, Vertuschung oder Verheimlichung es keinen Grund mehr gibt, dazu beitragen, daß wirklich die ganze Wahrheit ans Licht gebracht wird.
2023-09-26 23:37:03 | INFO | fairseq.tasks.translation | example hypothesis: Dieses gemütliche Gästehaus im nordwestlichen Stadtteil Reinickendorf liegt nur 5 Gehminuten vom S-Bahnhof Waidmannslust und 30 Fahrminuten mit dem Zug von der Innenstadt entfernt. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet im charmanten Landhausstil eingerichtet. Die komfortablen Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet im Landhausstil
2023-09-26 23:37:03 | INFO | fairseq.tasks.translation | example reference: Diese gemütliche Pension im nordwestlichen Berliner Bezirk Reinickendorf ist 5 Minuten zu Fuß vom S-Bahnhof Waidmannslust und eine 30-minütige Bahnfahrt vom Stadtzentrum entfernt.Die komfortabel eingerichteten Zimmer der Pension Nomaden sind im charmanten Landhausstil eingerichtet.
2023-09-26 23:37:04 | INFO | fairseq.tasks.translation | example hypothesis: "Gemeinsam mit unseren Partnern für das Radar unter der Leitung von Thales in Frankreich, sowie unserer Business Unit Defence Electronics und Indra in Spanien wird das Advanced UAV die modernsten, modularsten Sensorsuite und Datenverbindungen integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unerlässlich sind, die die modernen, außerhalb der Regale liegenden Plattformen niemals erreichen können....., die die modernen, außerhalb der Regale liegenden Plattformen niemals erreichen können, die die modernen,
2023-09-26 23:37:04 | INFO | fairseq.tasks.translation | example reference: In Teamarbeit mit unseren Partnern für das Radar, die von Thales in Frankreich geleitet werden, sowie dem Geschäftsbereich Defence Electronics (DE) und dem spanischen Unternehmen Indra werden wir beim Advanced UAV modernste Sensormodule und Datenlinks integrieren, die für nachhaltige und zuverlässige ISTAR-Missionen unverzichtbar und den marktverfügbare Standardplattformen weit voraus sind.
2023-09-26 23:37:05 | INFO | fairseq.tasks.translation | example hypothesis: Wir müssen ganz klar sagen, dass wir nicht nur für uns, sondern weltweit die Produkte vom Markt nehmen können, die nicht nur für den Inlandsverbrauch, sondern auch für den globalen Markt eine ernste Gefahr darstellen, weil solche Produkte leicht recycelt werden können, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13 sagt....., wie Frau González Álvarez in ihrem neuen Änderungsantrag 13, wie Frau González Álvarez in ihrem neuen Änderungsantrag 13, wie Frau González Á
2023-09-26 23:37:05 | INFO | fairseq.tasks.translation | example reference: Wir müssen eindeutig klarstellen, dass es uns auch darum geht, Produkte, die eine ernste Gefahr darstellen, vom Markt zu nehmen, und zwar nicht nur vom europäischen Binnenmarkt, sondern vom Weltmarkt, weil diese Produkte, wie Frau González Álvarez in ihrem neuen Abänderungsantrag 13 feststellt, leicht auf anderem Wege wieder eingeführt werden können.
2023-09-26 23:37:06 | INFO | fairseq.tasks.translation | example hypothesis: Unter der direkten Verschwörung von Moderne und Postmoderne oder dem klaren Gegensatz von reiner Kunst und engagierter Kunst müssen wir die ursprüngliche und anhaltende Spannung dieser beiden Ästhetik-Politik erkennen, die in genau den Formen der Sichtbarkeit und Verständlichkeit verbirgt, die Kunst als solche identifizierbar machen - jener beiden Politik, die letztlich zu ihrer eigenen Selbstunterdrückung führt...., die letztlich zu ihrer eigenen Selbstunterdrückung führt, die Kunst als solche identifizierbar macht, die letztlich zu ihrer
2023-09-26 23:37:06 | INFO | fairseq.tasks.translation | example reference: Im Moment, da es so aussieht, dass politisch engagierte Kunst nun für die lokale Kunstszene leichter zu akzeptieren ist, gewinnt aktivistische Kunst an Prominenz in internationalen Kunstzirkeln. Die Transformationen der Sprache der Kunst veränderten sich nicht nur im Bereich der Sprache im Allgemeinen, sondern auch im Verhältnis von Sprache und Realität.
2023-09-26 23:37:07 | INFO | fairseq.tasks.translation | example hypothesis: Was jedoch heute angesichts der Bedeutung der Debatten und der Meinungen, die Sie mir gegeben haben und die meine Ausführungen weitgehend unterstützen, und auf der Grundlage der vorangegangenen Beschlüsse werden wir unsere Debatten führen, und wenn die vierzig Petenten nicht anwesend sind, werde ich bei der Abstimmung nicht um die Überprüfung der Beschlußfähigkeit bitten....., wenn die vierzig Petenten nicht anwesend sind, werde ich nicht um die Überprüfung der Beschlußfähigkeit bitten, wenn die 40 Petenten nicht anwesend sind, werde ich nicht um die Prüfung der Beschlußfähigkeit
2023-09-26 23:37:07 | INFO | fairseq.tasks.translation | example reference: Was nun die heutige Sitzung betrifft, so werden wir angesichts der Bedeutung der Debatten sowie angesichts der Standpunkte, die Sie mir vorgetragen haben und die das von mir Gesagte mit eindeutiger Mehrheit bestätigen, sowie aufgrund der früheren Entscheidungen unsere Aussprachen führen, und wenn bei der Abstimmung die 40 Antragsteller nicht anwesend sind, werde ich nicht die Feststellung der Beschlussfähigkeit beantragen.
2023-09-26 23:37:08 | INFO | fairseq.tasks.translation | example hypothesis: Wenn man bedenkt, dass diese Völker die Einschränkung des nationalstaatlichen Prinzips nie akzeptiert haben, dann sind es paradoxerweise gerade sie, die, kaum jemand bekannt, nicht nur Zeugen eines alten, vergessenen Europas sind, sondern gleichzeitig den Weg für ein zukünftiges Europa ebnen, in dem die nationalen Grenzen beseitigt sind, jedoch ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung ethnischer, religiöser, sprachlicher und kultureller Vielfalt zu ermöglichen...., aber ohne das Ziel, eine einheitliche Kultur zu schaffen, sondern auch die Entwicklung der ethnischen, religiösen
2023-09-26 23:37:08 | INFO | fairseq.tasks.translation | example reference: Insofern sich diese Völker niemals auf die Enge des Nationalstaatlichen einließen, sind paradoxerweise gerade sie, die kaum jemand kennt, nicht nur Zeugen eines alten vergessenen Europa, sondern auch Wegbereiter eines künftigen Europa, in dem nationale Grenzen gefallen sind und dennoch keine Einheitskultur entstehen, sondern sich ethnische, religiöse, sprachliche, kulturelle Vielfalt entfalten soll.
2023-09-26 23:37:09 | INFO | fairseq.tasks.translation | example hypothesis: Historische Literatur war auch ein Experiment: Die Zeitschrift - oder besser gesagt, ihr Inhalt - wurde bis 2008 in mehrfacher Form als hybride Form veröffentlicht, für H-Soz-u-Kult geschrieben und über Mailinglisten sowie über die Websites der H-Soz-u-Kult und des Michigan-basierten H-Net an ihre Abonnenten verteilt.
2023-09-26 23:37:09 | INFO | fairseq.tasks.translation | example reference: Die in den jeweiligen Quartalsbänden der Rezensionszeitschrift abgedruckten Besprechungen und Artikel wurden für H-Soz-u-Kult geschrieben und sowohl über den Mailverteiler einzeln an die Subskribenten verteilt als auch über die Websites von H-Soz-u-Kult in Berlin und des H-Net in Michigan der Fachöffentlichkeit zugänglich gemacht.
2023-09-26 23:37:11 | INFO | fairseq.tasks.translation | example hypothesis: Nicht nur mit der Ankunft der neuen Smartphone-Generation haben Mobiltelefone ihre Federn deutlich aufpoliert und von einst blenden Wecker im Taschenformat über polyphonisch tootende Game Boy-Aspiranten bis hin zu schlichten Mini-PCs mit knackigen CD-Qualität Stereo-Sound: Mit ihrer besonderen Kombination von Fähigkeiten könnten sie von den ehemaligen me-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen werden....., dank ihrer besonderen Kombination von Fähigkeiten, können sie sich von den ehemaligen me-too-Wannabes zu Trailblazern neuer technologischer Entwicklungen entwickeln, von den ehemaligen me
2023-09-26 23:37:11 | INFO | fairseq.tasks.translation | example reference: Doch spätestens mit dem Aufkommen der neuen Smartphones sind Handys nicht nur wesentlich prächtiger geworden, haben sich vom piepsigen Taschendigitalwecker über polyphon dudelnde Game Boy-Aspiranten hin zu regelrechten Mini-PCs mit CD-Klang gemausert: Künftig könnten sie Dank der besonderen Kombination ihrer Fähigkeiten vom einstigen Me-Too zum Vorreiter neuer technologischer Entwicklungen aufsteigen.
2023-09-26 23:37:13 | INFO | fairseq.tasks.translation | example hypothesis: A pesar del fin científico del proyecto, el coronel Quaritch, quien dirige la defensa de la base humana en Pandora, conence a Jake para que le proportionación información sobre los nativos en caso de que fuera necesario rerir a la fuerza para que se marchen. Jake cumple profesionalmente su misión, pero se enamora de una de las nativas, Neytiri, y se da cuenta de que éstos jamás renunciarán a su tierra, haciendo un konflito armado; en l édeberá dir de qué lado está.
2023-09-26 23:37:13 | INFO | fairseq.tasks.translation | example reference: Diecisiete días después de que se estrenara, se convirtió en la película que más rápido ha alcanzado la cifra de mil millones de dólares en recaudación y, transcurridas tres semanas, se situó como la segunda película con mayor recaudación de todos los tiempos, siendo sólo superada por Titanic (1997), también de James Cameron.Avatar consiguió superar esa marca en menos de seis semanas, convirtiéndose en la película más taquillera de la historia del cine hasta la fecha, logrando además, ser la primera película en sobrepasar la barrera de los 2.000 millones de dólares en recaudación.
2023-09-26 23:37:13 | INFO | valid | epoch 027 | valid on 'valid' subset | loss 4.108 | nll_loss 2.14 | ppl 4.41 | bleu 27.77 | wps 16120.4 | wpb 12011.9 | bsz 398.1 | num_updates 244570 | best_bleu 29.48
2023-09-26 23:37:13 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 244570 updates
2023-09-26 23:37:13 | INFO | fairseq.trainer | Saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint27.pt
2023-09-26 23:37:19 | INFO | fairseq.trainer | Finished saving checkpoint to /home/Workspace/fairseq/checkpoints/checkpoint27.pt
2023-09-26 23:37:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint27.pt (epoch 27 @ 244570 updates, score 27.77) (writing took 10.155328594031744 seconds)
2023-09-26 23:37:24 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2023-09-26 23:37:24 | INFO | train | epoch 027 | loss 7.656 | nll_loss 3.753 | ppl 13.48 | wps 3743.5 | ups 0.29 | wpb 12977.1 | bsz 430.6 | num_updates 244570 | lr 6.39438e-05 | gnorm 1.252 | loss_scale 4 | train_wall 31292 | gb_free 13.7 | wall 565037
2023-09-26 23:37:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2023-09-26 23:37:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 9060
2023-09-26 23:37:24 | INFO | fairseq.trainer | begin training epoch 28
2023-09-26 23:37:24 | INFO | fairseq_cli.train | Start iterating over samples
pred_new.size(): torch.Size([5792, 42808])
2023-09-26 23:39:07 | INFO | train_inner | epoch 028:     30 / 9060 loss=7.696, nll_loss=3.777, ppl=13.71, wps=3002.8, ups=0.23, wpb=13031.6, bsz=422.2, num_updates=244600, lr=6.39399e-05, gnorm=1.233, loss_scale=4, train_wall=350, gb_free=13.4, wall=565141
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3472, 42808])
2023-09-26 23:44:52 | INFO | train_inner | epoch 028:    130 / 9060 loss=7.511, nll_loss=3.649, ppl=12.54, wps=3781.3, ups=0.29, wpb=13025, bsz=405.8, num_updates=244700, lr=6.39268e-05, gnorm=1.255, loss_scale=4, train_wall=344, gb_free=14.3, wall=565485
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([4680, 42808])
2023-09-26 23:50:46 | INFO | train_inner | epoch 028:    230 / 9060 loss=7.679, nll_loss=3.72, ppl=13.18, wps=3653.1, ups=0.28, wpb=12939, bsz=412.6, num_updates=244800, lr=6.39137e-05, gnorm=1.251, loss_scale=4, train_wall=354, gb_free=13.3, wall=565839
pred_new.size(): torch.Size([2496, 42808])
2023-09-26 23:56:53 | INFO | train_inner | epoch 028:    330 / 9060 loss=7.773, nll_loss=3.786, ppl=13.8, wps=3544.4, ups=0.27, wpb=13022.7, bsz=417.2, num_updates=244900, lr=6.39007e-05, gnorm=1.292, loss_scale=4, train_wall=367, gb_free=15.2, wall=566207
2023-09-27 00:02:36 | INFO | train_inner | epoch 028:    430 / 9060 loss=7.633, nll_loss=3.727, ppl=13.24, wps=3787.9, ups=0.29, wpb=12997.4, bsz=423.9, num_updates=245000, lr=6.38877e-05, gnorm=1.241, loss_scale=4, train_wall=343, gb_free=12.7, wall=566550
2023-09-27 00:08:36 | INFO | train_inner | epoch 028:    530 / 9060 loss=7.681, nll_loss=3.734, ppl=13.31, wps=3637, ups=0.28, wpb=13093.3, bsz=441.6, num_updates=245100, lr=6.38746e-05, gnorm=1.265, loss_scale=4, train_wall=360, gb_free=13, wall=566910
2023-09-27 00:14:41 | INFO | train_inner | epoch 028:    630 / 9060 loss=7.752, nll_loss=3.728, ppl=13.26, wps=3555, ups=0.27, wpb=12946, bsz=427.4, num_updates=245200, lr=6.38616e-05, gnorm=1.295, loss_scale=4, train_wall=364, gb_free=13.4, wall=567274
ter_threshold: 0.545204
num_accepted / total 29 96
loss token level: tensor(8440.5996, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(3192., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2888, 42808])
2023-09-27 00:20:26 | INFO | train_inner | epoch 028:    730 / 9060 loss=7.663, nll_loss=3.742, ppl=13.38, wps=3765.1, ups=0.29, wpb=13016.2, bsz=443.4, num_updates=245300, lr=6.38486e-05, gnorm=1.253, loss_scale=4, train_wall=345, gb_free=13.2, wall=567620
2023-09-27 00:26:25 | INFO | train_inner | epoch 028:    830 / 9060 loss=7.806, nll_loss=3.835, ppl=14.27, wps=3616.9, ups=0.28, wpb=12965.9, bsz=441.2, num_updates=245400, lr=6.38356e-05, gnorm=1.3, loss_scale=4, train_wall=358, gb_free=13.4, wall=567978
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([7777, 42808])
2023-09-27 00:32:09 | INFO | train_inner | epoch 028:    930 / 9060 loss=7.691, nll_loss=3.74, ppl=13.36, wps=3729.7, ups=0.29, wpb=12851.9, bsz=427.7, num_updates=245500, lr=6.38226e-05, gnorm=1.286, loss_scale=4, train_wall=344, gb_free=14.2, wall=568323
pred_new.size(): torch.Size([7811, 42808])
ter_threshold: 0.5455209999999999
num_accepted / total 70 112
loss token level: tensor(9416.8574, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9320., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3280, 42808])
2023-09-27 00:38:07 | INFO | train_inner | epoch 028:   1030 / 9060 loss=7.776, nll_loss=3.799, ppl=13.92, wps=3646.6, ups=0.28, wpb=13048.5, bsz=435.5, num_updates=245600, lr=6.38096e-05, gnorm=1.274, loss_scale=4, train_wall=358, gb_free=13.9, wall=568681
2023-09-27 00:43:55 | INFO | train_inner | epoch 028:   1130 / 9060 loss=7.625, nll_loss=3.724, ppl=13.22, wps=3716.7, ups=0.29, wpb=12942.1, bsz=407.7, num_updates=245700, lr=6.37966e-05, gnorm=1.248, loss_scale=4, train_wall=348, gb_free=12.8, wall=569029
2023-09-27 00:49:51 | INFO | train_inner | epoch 028:   1230 / 9060 loss=7.666, nll_loss=3.76, ppl=13.55, wps=3639.6, ups=0.28, wpb=12938, bsz=413, num_updates=245800, lr=6.37836e-05, gnorm=1.266, loss_scale=4, train_wall=355, gb_free=12.7, wall=569384
2023-09-27 00:55:42 | INFO | train_inner | epoch 028:   1330 / 9060 loss=7.678, nll_loss=3.734, ppl=13.3, wps=3723.3, ups=0.28, wpb=13082.1, bsz=454, num_updates=245900, lr=6.37706e-05, gnorm=1.237, loss_scale=4, train_wall=351, gb_free=15.1, wall=569736
lprobs.size(): torch.Size([3360, 42808])
2023-09-27 01:01:31 | INFO | train_inner | epoch 028:   1430 / 9060 loss=7.782, nll_loss=3.793, ppl=13.86, wps=3704.4, ups=0.29, wpb=12911, bsz=436.2, num_updates=246000, lr=6.37577e-05, gnorm=1.281, loss_scale=4, train_wall=348, gb_free=13.4, wall=570084
pred_new.size(): torch.Size([6825, 42808])
pred_new.size(): torch.Size([1976, 42808])
2023-09-27 01:07:31 | INFO | train_inner | epoch 028:   1530 / 9060 loss=7.811, nll_loss=3.791, ppl=13.84, wps=3631.3, ups=0.28, wpb=13075.4, bsz=432.6, num_updates=246100, lr=6.37447e-05, gnorm=1.284, loss_scale=4, train_wall=360, gb_free=12.6, wall=570444
2023-09-27 01:13:21 | INFO | train_inner | epoch 028:   1630 / 9060 loss=7.728, nll_loss=3.765, ppl=13.59, wps=3704.6, ups=0.29, wpb=12987.6, bsz=455.8, num_updates=246200, lr=6.37318e-05, gnorm=1.287, loss_scale=4, train_wall=350, gb_free=13.5, wall=570795
2023-09-27 01:19:11 | INFO | train_inner | epoch 028:   1730 / 9060 loss=7.618, nll_loss=3.734, ppl=13.31, wps=3696.9, ups=0.29, wpb=12922.8, bsz=415.8, num_updates=246300, lr=6.37188e-05, gnorm=1.268, loss_scale=4, train_wall=349, gb_free=14.3, wall=571144
pred_new.size(): torch.Size([3444, 42808])
pred_new.size(): torch.Size([6237, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.546369
num_accepted / total 30 80
loss token level: tensor(10138.7510, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(5536., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-27 01:24:52 | INFO | train_inner | epoch 028:   1830 / 9060 loss=7.641, nll_loss=3.751, ppl=13.46, wps=3823.9, ups=0.29, wpb=13027.7, bsz=426.2, num_updates=246400, lr=6.37059e-05, gnorm=1.258, loss_scale=4, train_wall=340, gb_free=13.9, wall=571485
torch.Size([6105, 42808])
pred_new.size(): torch.Size([3872, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1600, 42808])
pred_new.size(): torch.Size([810, 42808])
ter_threshold: 0.538646
num_accepted / total 90 136
loss token level: tensor(7835.5303, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13736., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5387
num_accepted / total 6 32
loss token level: tensor(7582.0518, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(2464., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2295, 42808])
lprobs.size(): torch.Size([2912, 42808])
ter_threshold: 0.5388539999999999
num_accepted / total 30 72
loss token level: tensor(9475.0605, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9736., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1440, 42808])
pred_new.size(): torch.Size([7200, 42808])
lprobs.size(): torch.Size([3496, 42808])
ter_threshold: 0.539288
num_accepted / total 152 192
loss token level: tensor(8308.1406, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(9920., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([8201, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([2800, 42808])
pred_new.size(): torch.Size([4104, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([1512, 42808])
ter_threshold: 0.539722
num_accepted / total 35 104
loss token level: tensor(8026.1948, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(4072., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([3222, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3240, 42808])
pred_new.size(): torch.Size([414, 42808])
pred_new.size(): torch.Size([4340, 42808])
pred_new.size(): torch.Size([3000, 42808])
lprobs.size(): torch.Size([3584, 42808])
lprobs.size(): torch.Size([3528, 42808])
lprobs.size(): torch.Size([3264, 42808])
lprobs.size(): torch.Size([3552, 42808])
ter_threshold: 0.540821
num_accepted / total 28 56
loss token level: tensor(8618.9111, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7428., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4550, 42808])
ter_threshold: 0.540947
num_accepted / total 49 80
loss token level: tensor(8705.2207, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8720., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([5106, 42808])
ter_threshold: 0.541252
num_accepted / total 23 96
loss token level: tensor(13961.2266, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5976., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([9490, 42808])
ter_threshold: 0.541539
num_accepted / total 17 64
loss token level: tensor(9881.4170, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3486., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3040, 42808])
pred_new.size(): torch.Size([3976, 42808])
pred_new.size(): torch.Size([1512, 42808])
ter_threshold: 0.541906
num_accepted / total 16 48
loss token level: tensor(10004.5107, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5040., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([6235, 42808])
lprobs.size(): torch.Size([3136, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5202, 42808])
pred_new.size(): torch.Size([4278, 42808])
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([1056, 42808])
lprobs.size(): torch.Size([3552, 42808])
lprobs.size(): torch.Size([3440, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3040, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3136, 42808])
ter_threshold: 0.542821
num_accepted / total 141 192
loss token level: tensor(8593.8438, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(8808., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([5248, 42808])
lprobs.size(): torch.Size([3400, 42808])
lprobs.size(): torch.Size([3528, 42808])
pred_new.size(): torch.Size([4830, 42808])
pred_new.size(): torch.Size([5104, 42808])
lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.543275
num_accepted / total 18 64
loss token level: tensor(8571.0801, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3948., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.5433209999999999
num_accepted / total 80 168
loss token level: tensor(10871.4854, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5772., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7425, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.543513
num_accepted / total 14 56
loss token level: tensor(9327.1289, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(3732., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3192, 42808])
pred_new.size(): torch.Size([1632, 42808])
lprobs.size(): torch.Size([3432, 42808])
ter_threshold: 0.543997
num_accepted / total 94 136
loss token level: tensor(8079.6553, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(14184., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2544, 42808])
pred_new.size(): torch.Size([1500, 42808])
pred_new.size(): torch.Size([4440, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([3536, 42808])
pred_new.size(): torch.Size([5355, 42808])
lprobs.size(): torch.Size([2576, 42808])
pred_new.size(): torch.Size([8100, 42808])
lprobs.size(): torch.Size([3008, 42808])
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.544991
num_accepted / total 7 24
loss token level: tensor(9293.4668, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(5728., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7112, 42808])
ter_threshold: 0.545204
num_accepted / total 74 128
loss token level: tensor(8537.0215, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7608., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4300, 42808])
lprobs.size(): torch.Size([3120, 42808])
lprobs.size(): torch.Size([3248, 42808])
lprobs.size(): torch.Size([3552, 42808])
pred_new.size(): torch.Size([9006, 42808])
lprobs.size(): torch.Size([3200, 42808])
pred_new.size(): torch.Size([2910, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3528, 42808])
ter_threshold: 0.545929
num_accepted / total 50 88
loss token level: tensor(9396.4287, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(13696., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7623, 42808])
pred_new.size(): torch.Size([4505, 42808])
pred_new.size(): torch.Size([3078, 42808])
pred_new.size(): torch.Size([2684, 42808])
lprobs.size(): torch.Size([2928, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.546369
num_accepted / total 42 88
loss token level: tensor(10199.0449, device='cuda:3', grad_fn=<AddBackward0>)
loss seque level: tensor(7640., device='cuda:3', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.546464
num_accepted / total 9 80
loss token level: lprobs.size(): torch.Size([3240, 42808])
ter_threshold: 0.546464
num_accepted / total 178 224
loss token level: tensor(9549.9385, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(9792., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-27 01:30:35 | INFO | train_inner | epoch 028:   1930 / 9060 loss=7.527, nll_loss=3.694, ppl=12.94, wps=3799.7, ups=0.29, wpb=13035.4, bsz=432, num_updates=246500, lr=6.3693e-05, gnorm=1.234, loss_scale=4, train_wall=343, gb_free=13.6, wall=571828
pred_new.size(): torch.Size([3216, 42808])
pred_new.size(): torch.Size([6264, 42808])
2023-09-27 01:36:17 | INFO | train_inner | epoch 028:   2030 / 9060 loss=7.571, nll_loss=3.686, ppl=12.87, wps=3797, ups=0.29, wpb=13007.8, bsz=421.2, num_updates=246600, lr=6.36801e-05, gnorm=1.236, loss_scale=4, train_wall=342, gb_free=11.9, wall=572171
pred_new.size(): torch.Size([4116, 42808])
2023-09-27 01:42:12 | INFO | train_inner | epoch 028:   2130 / 9060 loss=7.807, nll_loss=3.83, ppl=14.22, wps=3676.1, ups=0.28, wpb=13048.9, bsz=438.5, num_updates=246700, lr=6.36672e-05, gnorm=1.286, loss_scale=4, train_wall=355, gb_free=14.9, wall=572526
2023-09-27 01:48:08 | INFO | train_inner | epoch 028:   2230 / 9060 loss=7.851, nll_loss=3.814, ppl=14.06, wps=3618.3, ups=0.28, wpb=12877.2, bsz=428.5, num_updates=246800, lr=6.36543e-05, gnorm=1.306, loss_scale=4, train_wall=356, gb_free=13.8, wall=572882
2023-09-27 01:53:59 | INFO | train_inner | epoch 028:   2330 / 9060 loss=7.598, nll_loss=3.704, ppl=13.03, wps=3707.5, ups=0.29, wpb=12998.5, bsz=447.7, num_updates=246900, lr=6.36414e-05, gnorm=1.26, loss_scale=4, train_wall=350, gb_free=13, wall=573232
lprobs.size(): torch.Size([2512, 42808])
2023-09-27 01:59:52 | INFO | train_inner | epoch 028:   2430 / 9060 loss=7.686, nll_loss=3.747, ppl=13.43, wps=3643, ups=0.28, wpb=12866.4, bsz=422.3, num_updates=247000, lr=6.36285e-05, gnorm=1.275, loss_scale=4, train_wall=353, gb_free=13.5, wall=573585
2023-09-27 02:05:27 | INFO | train_inner | epoch 028:   2530 / 9060 loss=7.549, nll_loss=3.692, ppl=12.92, wps=3878.1, ups=0.3, wpb=12973.5, bsz=432.6, num_updates=247100, lr=6.36156e-05, gnorm=1.274, loss_scale=4, train_wall=334, gb_free=13.4, wall=573920
pred_new.size(): torch.Size([6600, 42808])
2023-09-27 02:11:41 | INFO | train_inner | epoch 028:   2630 / 9060 loss=7.802, nll_loss=3.773, ppl=13.67, wps=3488.6, ups=0.27, wpb=13056.9, bsz=442.8, num_updates=247200, lr=6.36027e-05, gnorm=1.279, loss_scale=8, train_wall=374, gb_free=13.4, wall=574294
pred_new.size(): torch.Size([2030, 42808])
lprobs.size(): torch.Size([3536, 42808])
ter_threshold: 0.547246
num_accepted / total 7 40
loss token level: tensor(8278.7881, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(1856., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.547262
num_accepted / total 13 56
loss token level: tensor(11749.6094, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(4086., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-27 02:17:21 | INFO | train_inner | epoch 028:   2730 / 9060 loss=7.645, nll_loss=3.756, ppl=13.51, wps=3802.4, ups=0.29, wpb=12948.5, bsz=423.6, num_updates=247300, lr=6.35899e-05, gnorm=1.265, loss_scale=8, train_wall=340, gb_free=13.8, wall=574635
lprobs.size(): torch.Size([2376, 42808])
lprobs.size(): torch.Size([3520, 42808])
2023-09-27 02:23:12 | INFO | train_inner | epoch 028:   2830 / 9060 loss=7.602, nll_loss=3.729, ppl=13.26, wps=3682.1, ups=0.28, wpb=12922.3, bsz=418.4, num_updates=247400, lr=6.3577e-05, gnorm=1.247, loss_scale=8, train_wall=351, gb_free=13.2, wall=574986
ter_threshold: 0.547469
num_accepted / total 141 184
loss token level: tensor(8550.5488, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(16576., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-27 02:29:04 | INFO | train_inner | epoch 028:   2930 / 9060 loss=7.694, nll_loss=3.77, ppl=13.64, wps=3700.3, ups=0.28, wpb=13006.2, bsz=447.6, num_updates=247500, lr=6.35642e-05, gnorm=1.271, loss_scale=8, train_wall=351, gb_free=15.2, wall=575337
pred_new.size(): torch.Size([2604, 42808])
lprobs.size(): torch.Size([3360, 42808])
2023-09-27 02:34:50 | INFO | train_inner | epoch 028:   3030 / 9060 loss=7.619, nll_loss=3.729, ppl=13.26, wps=3741.2, ups=0.29, wpb=12947.1, bsz=447.1, num_updates=247600, lr=6.35513e-05, gnorm=1.248, loss_scale=8, train_wall=346, gb_free=12.3, wall=575683
2023-09-27 02:40:54 | INFO | train_inner | epoch 028:   3130 / 9060 loss=7.715, nll_loss=3.798, ppl=13.91, wps=3537.5, ups=0.27, wpb=12876.6, bsz=409.2, num_updates=247700, lr=6.35385e-05, gnorm=1.255, loss_scale=8, train_wall=364, gb_free=13.5, wall=576047
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([3330, 42808])
2023-09-27 02:46:41 | INFO | train_inner | epoch 028:   3230 / 9060 loss=7.578, nll_loss=3.696, ppl=12.96, wps=3730.9, ups=0.29, wpb=12962.8, bsz=428.3, num_updates=247800, lr=6.35257e-05, gnorm=1.265, loss_scale=8, train_wall=347, gb_free=14.5, wall=576395
lprobs.size(): torch.Size([2808, 42808])
lprobs.size(): torch.Size([3072, 42808])
2023-09-27 02:52:34 | INFO | train_inner | epoch 028:   3330 / 9060 loss=7.627, nll_loss=3.735, ppl=13.32, wps=3696.8, ups=0.28, wpb=13029.8, bsz=435.4, num_updates=247900, lr=6.35129e-05, gnorm=1.25, loss_scale=8, train_wall=352, gb_free=14, wall=576747
2023-09-27 02:58:33 | INFO | train_inner | epoch 028:   3430 / 9060 loss=7.935, nll_loss=3.888, ppl=14.8, wps=3606.7, ups=0.28, wpb=12961.7, bsz=430.5, num_updates=248000, lr=6.35001e-05, gnorm=1.342, loss_scale=8, train_wall=359, gb_free=12.4, wall=577107
2023-09-27 03:04:21 | INFO | train_inner | epoch 028:   3530 / 9060 loss=7.763, nll_loss=3.815, ppl=14.08, wps=3723.8, ups=0.29, wpb=12967.5, bsz=432.9, num_updates=248100, lr=6.34873e-05, gnorm=1.279, loss_scale=8, train_wall=348, gb_free=14, wall=577455
2023-09-27 03:10:11 | INFO | train_inner | epoch 028:   3630 / 9060 loss=7.8, nll_loss=3.806, ppl=13.99, wps=3721.6, ups=0.29, wpb=13000.8, bsz=442.2, num_updates=248200, lr=6.34745e-05, gnorm=1.263, loss_scale=8, train_wall=349, gb_free=13, wall=577804
2023-09-27 03:16:09 | INFO | train_inner | epoch 028:   3730 / 9060 loss=7.757, nll_loss=3.806, ppl=13.99, wps=3610.7, ups=0.28, wpb=12939.8, bsz=435.2, num_updates=248300, lr=6.34617e-05, gnorm=1.283, loss_scale=8, train_wall=358, gb_free=12.9, wall=578163
pred_new.size(): torch.Size([5184, 42808])
2023-09-27 03:21:53 | INFO | train_inner | epoch 028:   3830 / 9060 loss=7.588, nll_loss=3.73, ppl=13.27, wps=3771, ups=0.29, wpb=12969.6, bsz=433, num_updates=248400, lr=6.34489e-05, gnorm=1.242, loss_scale=8, train_wall=344, gb_free=12.5, wall=578506
pred_new.size(): torch.Size([1833, 42808])
pred_new.size(): torch.Size([5537, 42808])
2023-09-27 03:27:31 | INFO | train_inner | epoch 028:   3930 / 9060 loss=7.658, nll_loss=3.719, ppl=13.17, wps=3852.3, ups=0.3, wpb=13040.2, bsz=435.3, num_updates=248500, lr=6.34361e-05, gnorm=1.269, loss_scale=8, train_wall=338, gb_free=13.5, wall=578845
2023-09-27 03:33:22 | INFO | train_inner | epoch 028:   4030 / 9060 loss=7.808, nll_loss=3.825, ppl=14.17, wps=3735.7, ups=0.29, wpb=13104.7, bsz=445.6, num_updates=248600, lr=6.34234e-05, gnorm=1.276, loss_scale=8, train_wall=351, gb_free=13.6, wall=579196
pred_new.size(): torch.Size([1908, 42808])
lprobs.size(): torch.Size([3000, 42808])
2023-09-27 03:39:16 | INFO | train_inner | epoch 028:   4130 / 9060 loss=7.722, nll_loss=3.774, ppl=13.68, wps=3674.4, ups=0.28, wpb=12990.5, bsz=427.2, num_updates=248700, lr=6.34106e-05, gnorm=1.3, loss_scale=8, train_wall=353, gb_free=14.1, wall=579549
2023-09-27 03:45:07 | INFO | train_inner | epoch 028:   4230 / 9060 loss=7.718, nll_loss=3.784, ppl=13.77, wps=3681.5, ups=0.28, wpb=12945, bsz=423.4, num_updates=248800, lr=6.33979e-05, gnorm=1.282, loss_scale=8, train_wall=351, gb_free=14.4, wall=579901
lprobs.size(): torch.Size([3456, 42808])
2023-09-27 03:50:55 | INFO | train_inner | epoch 028:   4330 / 9060 loss=7.663, nll_loss=3.771, ppl=13.65, wps=3771.1, ups=0.29, wpb=13117.2, bsz=433.5, num_updates=248900, lr=6.33852e-05, gnorm=1.248, loss_scale=8, train_wall=348, gb_free=13.3, wall=580249
lprobs.size(): torch.Size([2720, 42808])
2023-09-27 03:56:45 | INFO | train_inner | epoch 028:   4430 / 9060 loss=7.673, nll_loss=3.769, ppl=13.64, wps=3687.2, ups=0.29, wpb=12884.5, bsz=440.7, num_updates=249000, lr=6.33724e-05, gnorm=1.317, loss_scale=8, train_wall=349, gb_free=15.1, wall=580598
2023-09-27 04:02:42 | INFO | train_inner | epoch 028:   4530 / 9060 loss=7.855, nll_loss=3.852, ppl=14.44, wps=3627.1, ups=0.28, wpb=12961.1, bsz=424.5, num_updates=249100, lr=6.33597e-05, gnorm=1.293, loss_scale=8, train_wall=357, gb_free=13.5, wall=580956
pred_new.size(): torch.Size([1144, 42808])
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([7139, 42808])
2023-09-27 04:08:34 | INFO | train_inner | epoch 028:   4630 / 9060 loss=7.449, nll_loss=3.701, ppl=13.01, wps=3630.1, ups=0.28, wpb=12793.4, bsz=424, num_updates=249200, lr=6.3347e-05, gnorm=1.297, loss_scale=8, train_wall=352, gb_free=12.7, wall=581308
2023-09-27 04:14:20 | INFO | train_inner | epoch 028:   4730 / 9060 loss=7.757, nll_loss=3.799, ppl=13.92, wps=3749.9, ups=0.29, wpb=12963.1, bsz=438, num_updates=249300, lr=6.33343e-05, gnorm=1.309, loss_scale=8, train_wall=345, gb_free=14.8, wall=581654
2023-09-27 04:20:22 | INFO | train_inner | epoch 028:   4830 / 9060 loss=7.753, nll_loss=3.798, ppl=13.91, wps=3556.5, ups=0.28, wpb=12882.6, bsz=425, num_updates=249400, lr=6.33216e-05, gnorm=1.305, loss_scale=8, train_wall=362, gb_free=14.3, wall=582016
pred_new.size(): torch.Size([1800, 42808])
2023-09-27 04:26:11 | INFO | train_inner | epoch 028:   4930 / 9060 loss=7.662, nll_loss=3.782, ppl=13.76, wps=3724.1, ups=0.29, wpb=12970, bsz=435.8, num_updates=249500, lr=6.33089e-05, gnorm=1.257, loss_scale=8, train_wall=348, gb_free=13.4, wall=582364
lprobs.size(): torch.Size([2912, 42808])
lprobs.size(): torch.Size([2960, 42808])
lprobs.size(): torch.Size([3528, 42808])
2023-09-27 04:32:01 | INFO | train_inner | epoch 028:   5030 / 9060 loss=7.764, nll_loss=3.806, ppl=13.99, wps=3700.6, ups=0.29, wpb=12959.6, bsz=437.3, num_updates=249600, lr=6.32962e-05, gnorm=1.285, loss_scale=8, train_wall=350, gb_free=12.9, wall=582714
lprobs.size(): torch.Size([3248, 42808])
2023-09-27 04:33:29 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2023-09-27 04:37:52 | INFO | train_inner | epoch 028:   5131 / 9060 loss=7.667, nll_loss=3.772, ppl=13.66, wps=3692.4, ups=0.28, wpb=12960.6, bsz=439, num_updates=249700, lr=6.32835e-05, gnorm=1.251, loss_scale=4, train_wall=351, gb_free=13.4, wall=583065
lprobs.size(): torch.Size([3552, 42808])
2023-09-27 04:43:49 | INFO | train_inner | epoch 028:   5231 / 9060 loss=7.858, nll_loss=3.879, ppl=14.71, wps=3624.4, ups=0.28, wpb=12925.8, bsz=438.6, num_updates=249800, lr=6.32709e-05, gnorm=1.299, loss_scale=4, train_wall=356, gb_free=13.9, wall=583422
lprobs.size(): torch.Size([3536, 42808])
2023-09-27 04:49:45 | INFO | train_inner | epoch 028:   5331 / 9060 loss=7.773, nll_loss=3.818, ppl=14.11, wps=3658.9, ups=0.28, wpb=13059.7, bsz=419.4, num_updates=249900, lr=6.32582e-05, gnorm=1.276, loss_scale=4, train_wall=357, gb_free=13.3, wall=583779
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.549951
num_accepted / total 20 72
loss token level: tensor(8410.1221, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(6372., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
2023-09-27 04:55:48 | INFO | train_inner | epoch 028:   5431 / 9060 loss=7.677, nll_loss=3.747, ppl=13.43, wps=3561.7, ups=0.28, wpb=12930.7, bsz=423, num_updates=250000, lr=6.32456e-05, gnorm=1.296, loss_scale=4, train_wall=363, gb_free=14, wall=584142
lprobs.size(): torch.Size([2576, 42808])
2023-09-27 05:01:29 | INFO | train_inner | epoch 028:   5531 / 9060 loss=7.52, nll_loss=3.708, ppl=13.07, wps=3801.9, ups=0.29, wpb=12944.3, bsz=425.8, num_updates=250100, lr=6.32329e-05, gnorm=1.244, loss_scale=4, train_wall=340, gb_free=14.2, wall=584482
lprobs.size(): torch.Size([3456, 42808])
2023-09-27 05:07:19 | INFO | train_inner | epoch 028:   5631 / 9060 loss=7.7, nll_loss=3.763, ppl=13.58, wps=3703.3, ups=0.29, wpb=12953.4, bsz=425.1, num_updates=250200, lr=6.32203e-05, gnorm=1.283, loss_scale=4, train_wall=350, gb_free=13.1, wall=584832
lprobs.size(): torch.Size([3456, 42808])
2023-09-27 05:13:21 | INFO | train_inner | epoch 028:   5731 / 9060 loss=7.79, nll_loss=3.806, ppl=13.99, wps=3613.1, ups=0.28, wpb=13086.8, bsz=424.9, num_updates=250300, lr=6.32076e-05, gnorm=1.274, loss_scale=4, train_wall=362, gb_free=12.5, wall=585194
pred_new.size(): torch.Size([2378, 42808])
ter_threshold: 0.550378
num_accepted / total 84 128
loss token level: tensor(9349.8047, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(8528., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-27 05:19:14 | INFO | train_inner | epoch 028:   5831 / 9060 loss=7.571, nll_loss=3.685, ppl=12.87, wps=3705.1, ups=0.28, wpb=13084.2, bsz=432.2, num_updates=250400, lr=6.3195e-05, gnorm=1.24, loss_scale=4, train_wall=353, gb_free=12.7, wall=585548
2023-09-27 05:25:10 | INFO | train_inner | epoch 028:   5931 / 9060 loss=7.855, nll_loss=3.815, ppl=14.07, wps=3700.1, ups=0.28, wpb=13160.1, bsz=445.2, num_updates=250500, lr=6.31824e-05, gnorm=1.281, loss_scale=4, train_wall=355, gb_free=14.5, wall=585903
ter_threshold: 0.550577
num_accepted / total 54 104
loss token level: tensor(8396.8213, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(11552., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
2023-09-27 05:31:03 | INFO | train_inner | epoch 028:   6031 / 9060 loss=7.785, nll_loss=3.826, ppl=14.18, wps=3681.3, ups=0.28, wpb=12989.8, bsz=417, num_updates=250600, lr=6.31698e-05, gnorm=1.312, loss_scale=4, train_wall=353, gb_free=13, wall=586256
lprobs.size(): torch.Size([3520, 42808])
2023-09-27 05:37:03 | INFO | train_inner | epoch 028:   6131 / 9060 loss=7.735, nll_loss=3.808, ppl=14, wps=3612.4, ups=0.28, wpb=13034.2, bsz=443.2, num_updates=250700, lr=6.31572e-05, gnorm=1.259, loss_scale=4, train_wall=361, gb_free=14.7, wall=586617
pred_new.size(): torch.Size([9009, 42808])
lprobs.size(): torch.Size([3000, 42808])
pred_new.size(): torch.Size([6798, 42808])
2023-09-27 05:42:53 | INFO | train_inner | epoch 028:   6231 / 9060 loss=7.679, nll_loss=3.781, ppl=13.75, wps=3734, ups=0.29, wpb=13056, bsz=436.8, num_updates=250800, lr=6.31446e-05, gnorm=1.25, loss_scale=4, train_wall=349, gb_free=12.4, wall=586967
loss token level: tensor(9196.4219, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(6764., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3136, 42808])
pred_new.size(): torch.Size([2006, 42808])
ter_threshold: 0.541252
num_accepted / total 20 72
loss token level: tensor(8070.5107, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(5312., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2736, 42808])
pred_new.size(): torch.Size([5950, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3200, 42808])
lprobs.size(): torch.Size([3360, 42808])
pred_new.size(): torch.Size([4264, 42808])
lprobs.size(): torch.Size([3304, 42808])
lprobs.size(): torch.Size([3456, 42808])
lprobs.size(): torch.Size([3280, 42808])
lprobs.size(): torch.Size([2688, 42808])
pred_new.size(): torch.Size([780, 42808])
pred_new.size(): torch.Size([8502, 42808])
pred_new.size(): torch.Size([8748, 42808])
lprobs.size(): torch.Size([3440, 42808])
pred_new.size(): torch.Size([3021, 42808])
ter_threshold: 0.542422
num_accepted / total 109 160
loss token level: tensor(9226.6875, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(15920., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([2808, 42808])
pred_new.size(): torch.Size([5060, 42808])
pred_new.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3328, 42808])
lprobs.size(): torch.Size([3536, 42808])
lprobs.size(): torch.Size([3480, 42808])
ter_threshold: 0.542848
num_accepted / total 91 128
loss token level: tensor(9040.7402, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(9464., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([4600, 42808])
pred_new.size(): torch.Size([7820, 42808])
lprobs.size(): torch.Size([3232, 42808])
lprobs.size(): torch.Size([3472, 42808])
ter_threshold: 0.543239
num_accepted / total 105 160
loss token level: tensor(10000.3809, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8408., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([5562, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5440, 42808])
pred_new.size(): torch.Size([378, 42808])
pred_new.size(): torch.Size([600, 42808])
ter_threshold: 0.543763
num_accepted / total 88 120
loss token level: tensor(8768.9111, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(18112., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.543997
num_accepted / total 187 232
loss token level: tensor(8069.9175, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14096., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
pred_new.size(): torch.Size([1178, 42808])
pred_new.size(): torch.Size([1984, 42808])
lprobs.size(): torch.Size([3360, 42808])
ter_threshold: 0.54428
num_accepted / total 42 88
loss token level: tensor(9711.5664, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(7336., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([1911, 42808])
lprobs.size(): torch.Size([3360, 42808])
lprobs.size(): torch.Size([3320, 42808])
pred_new.size(): torch.Size([4160, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.544888
num_accepted / total 217 256
loss token level: tensor(8989.8252, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(15472., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([9594, 42808])
pred_new.size(): torch.Size([1378, 42808])
ter_threshold: 0.545204
num_accepted / total 233 296
loss token level: tensor(8014.8618, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8560., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3128, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([4224, 42808])
pred_new.size(): torch.Size([3990, 42808])
pred_new.size(): torch.Size([5628, 42808])
ter_threshold: 0.545929
num_accepted / total 59 96
loss token level: tensor(10046.1816, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13272., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3496, 42808])
pred_new.size(): torch.Size([7150, 42808])
pred_new.size(): torch.Size([4050, 42808])
ter_threshold: 0.546412
num_accepted / total 8 40
loss token level: tensor(9575.4023, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(3164., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.546464
num_accepted / total 73 112
loss token level: tensor(9394.0234, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(8096., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3472, 42808])
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([8190, 42808])
lprobs.size(): torch.Size([3520, 42808])
ter_threshold: 0.546853
num_accepted / total 64 96
loss token level: tensor(8577.1104, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14560., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
ter_threshold: 0.54705
num_accepted / total 214 256
loss token level: tensor(8856.0459, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(14592., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3584, 42808])
pred_new.size(): torch.Size([7215, 42808])
lprobs.size(): torch.Size([3432, 42808])
lprobs.size(): torch.Size([2880, 42808])
lprobs.size(): torch.Size([2704, 42808])
ter_threshold: 0.547469
num_accepted / total 84 120
loss token level: tensor(8783.5068, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(16056., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([7980, 42808])
pred_new.size(): torch.Size([5537, 42808])
pred_new.size(): torch.Size([9520, 42808])
lprobs.size(): torch.Size([3432, 42808])
pred_new.size(): torch.Size([4536, 42808])
lprobs.size(): torch.Size([3392, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3440, 42808])
ter_threshold: 0.548113
num_accepted / total 12 64
loss token level: tensor(8276.2461, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(1961., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
pred_new.size(): torch.Size([2848, 42808])
pred_new.size(): torch.Size([2660, 42808])
pred_new.size(): torch.Size([4620, 42808])
pred_new.size(): torch.Size([3082, 42808])
lprobs.size(): torch.Size([3312, 42808])
lprobs.size(): torch.Size([3312, 42808])
pred_new.size(): torch.Size([2430, 42808])
lprobs.size(): torch.Size([2968, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([3224, 42808])
pred_new.size(): torch.Size([1254, 42808])
pred_new.size(): torch.Size([2640, 42808])
lprobs.size(): torch.Size([3456, 42808])
ter_threshold: 0.549783
num_accepted / total 68 112
loss token level: tensor(8479.5742, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(13968., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3456, 42808])
pred_new.size(): torch.Size([5408, 42808])
pred_new.size(): torch.Size([2024, 42808])
lprobs.size(): torch.Size([3520, 42808])
lprobs.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([3976, 42808])
lprobs.size(): torch.Size([2584, 42808])
pred_new.size(): torch.Size([2448, 42808])
lprobs.size(): torch.Size([3264, 42808])
pred_new.size(): torch.Size([4462, 42808])
ter_threshold: 0.550378
num_accepted / total 95 128
loss token level: tensor(8550.8311, device='cuda:1', grad_fn=<AddBackward0>)
loss seque level: tensor(10024., device='cuda:1', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3344, 42808])
lprobs.size(): torch.Size([3304, 42808])
ter_threshold: 0.5508109999999999
num_accepted / total 118 ter_threshold: 0.5508109999999999
num_accepted / total 79 120
loss token level: tensor(8913.4805, device='cuda:0', grad_fn=<AddBackward0>)
loss seque level: tensor(15128., device='cuda:0', dtype=torch.float16, grad_fn=<AddBackward0>)
lprobs.size(): torch.Size([3168, 42808])
pred_new.size(): torch.Size([6090, 42808])
2023-09-27 05:48:34 | INFO | train_inner | epoch 028:   6331 / 9060 loss=7.621, nll_loss=3.75, ppl=13.45, wps=3788.7, ups=0.29, wpb=12911.1, bsz=428.6, num_updates=250900, lr=6.3132e-05, gnorm=1.258, loss_scale=4, train_wall=340, gb_free=12.7, wall=587307
2023-09-27 05:54:27 | INFO | train_inner | epoch 028:   6431 / 9060 loss=7.708, nll_loss=3.734, ppl=13.31, wps=3663.6, ups=0.28, wpb=12952.2, bsz=433.4, num_updates=251000, lr=6.31194e-05, gnorm=1.291, loss_scale=4, train_wall=353, gb_free=15.4, wall=587661
2023-09-27 06:00:11 | INFO | train_inner | epoch 028:   6531 / 9060 loss=7.568, nll_loss=3.723, ppl=13.21, wps=3762.2, ups=0.29, wpb=12938.4, bsz=412.5, num_updates=251100, lr=6.31069e-05, gnorm=1.26, loss_scale=4, train_wall=344, gb_free=13.4, wall=588005
2023-09-27 06:05:46 | INFO | train_inner | epoch 028:   6631 / 9060 loss=7.64, nll_loss=3.776, ppl=13.7, wps=3850.9, ups=0.3, wpb=12886, bsz=429.5, num_updates=251200, lr=6.30943e-05, gnorm=1.263, loss_scale=4, train_wall=334, gb_free=12.6, wall=588339
2023-09-27 06:11:42 | INFO | train_inner | epoch 028:   6731 / 9060 loss=7.787, nll_loss=3.803, ppl=13.96, wps=3637.3, ups=0.28, wpb=12938.2, bsz=452, num_updates=251300, lr=6.30818e-05, gnorm=1.3, loss_scale=4, train_wall=355, gb_free=14, wall=588695
lprobs.size(): torch.Size([2592, 42808])
2023-09-27 06:17:26 | INFO | train_inner | epoch 028:   6831 / 9060 loss=7.444, nll_loss=3.661, ppl=12.65, wps=3734.4, ups=0.29, wpb=12867.7, bsz=433, num_updates=251400, lr=6.30692e-05, gnorm=1.243, loss_scale=4, train_wall=344, gb_free=14, wall=589040
Traceback (most recent call last):
  File "/root/anaconda3/bin/fairseq-train", line 8, in <module>
    sys.exit(cli_main())
  File "/home/Workspace/fairseq/fairseq_cli/train.py", line 579, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/Workspace/fairseq/fairseq/distributed/utils.py", line 379, in call_main
    torch.multiprocessing.spawn(
  File "/root/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 239, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/root/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 197, in start_processes
    while not context.join():
  File "/root/anaconda3/lib/python3.9/site-packages/torch/multiprocessing/spawn.py", line 109, in join
    ready = multiprocessing.connection.wait(
  File "/root/anaconda3/lib/python3.9/multiprocessing/connection.py", line 936, in wait
    ready = selector.select(timeout)
  File "/root/anaconda3/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File "/root/anaconda3/lib/python3.9/multiprocessing/popen_fork.py", line 27, in poll
    pid, sts = os.waitpid(self.pid, flag)
KeyboardInterrupt
